COMPAT_SYSCALL_DEFINE1() <COMPAT_SYSCALL_DEFINE1 (sysctl, struct compat_sysctl_args __user *, args) at sysctl_binary.c:1462>:
    do_sys_times() <void do_sys_times (struct tms *tms) at sys.c:882>:
        thread_group_cputime_adjusted()
        cputime_to_clock_t()
    clock_t_to_compat_clock_t() <compat_clock_t clock_t_to_compat_clock_t (clock_t x) at compat.c:343>:
        compat_jiffies_to_clock_t()
        clock_t_to_jiffies()
    copy_to_user()
    force_successful_syscall_return()
    compat_jiffies_to_clock_t()
    get_fs()
    set_fs()
    sys_sigpending()
    put_user()
    do_gettimeofday()
    get_user()
    security_settime()
    do_settimeofday()
    compat_get_timex() <int compat_get_timex (struct timex *txc, struct compat_timex __user *utp) at compat.c:33>:
        access_ok()
    do_adjtimex()
    compat_put_timex() <int compat_put_timex (struct compat_timex __user *utp, struct timex *txc) at compat.c:63>:
        access_ok()
    do_sysinfo() <int do_sysinfo (struct sysinfo *info) at sys.c:2293>:
        get_monotonic_boottime()
        get_avenrun()
        si_meminfo()
        si_swapinfo()
    upper_32_bits()
    access_ok()
    copy_from_user()
    compat_ptr()
    do_sysctl() <ssize_t do_sysctl (int __user *args_name, int nlen, void __user *oldval, size_t oldlen, void __user *newval, size_t newlen) at sysctl_binary.c:1401>:
        get_user()
        warn_on_bintable() <void warn_on_bintable (const int *name, int nlen) at sysctl_binary.c:1388>:
            deprecated_sysctl_warning() <void deprecated_sysctl_warning (const int *name, int nlen) at sysctl_binary.c:1350>:
                printk_ratelimit()
                printk()
        binary_sysctl() <ssize_t binary_sysctl (const int *name, int nlen, void __user *oldval, size_t oldlen, void __user *newval, size_t newlen) at sysctl_binary.c:1341>:
            sysctl_getname() <char *sysctl_getname (const int *name, int nlen, const struct bin_table **tablep) at sysctl_binary.c:1278>:
                ERR_PTR()
                get_sysctl() <const struct bin_table *get_sysctl (const int *name, int nlen, char *path) at sysctl_binary.c:1223>:
                    ERR_PTR()
                    dev_get_by_index()
                    dev_put()
                IS_ERR()
                ERR_CAST()
            PTR_ERR()
            IS_ERR()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
            file_open_root()
            fput()
COMPAT_SYSCALL_DEFINE2() <COMPAT_SYSCALL_DEFINE2 (getrusage, int, who, struct compat_rusage __user *, ru) at sys.c:1633>:
    do_gettimeofday()
    compat_put_timeval() <int compat_put_timeval (const struct timeval *tv, void __user *utv) at compat.c:166>:
        copy_to_user()
    copy_to_user()
    compat_get_timeval() <int compat_get_timeval (struct timeval *tv, const void __user *utv) at compat.c:157>:
        copy_from_user()
    copy_from_user()
    do_sys_settimeofday()
    compat_get_timespec() <int compat_get_timespec (struct timespec *ts, const void __user *uts) at compat.c:175>:
        copy_from_user()
    timespec_valid()
    get_fs()
    set_fs()
    hrtimer_nanosleep()
    compat_nanosleep_restart() <long compat_nanosleep_restart (struct restart_block *restart) at compat.c:216>:
        get_fs()
        set_fs()
        hrtimer_nanosleep_restart()
        compat_put_timespec() <int compat_put_timespec (const struct timespec *ts, void __user *uts) at compat.c:184>:
            copy_to_user()
    compat_put_timespec() <int compat_put_timespec (const struct timespec *ts, void __user *uts) at compat.c:184>:
        copy_to_user()
    do_getitimer()
    put_compat_itimerval() <inline long put_compat_itimerval (struct compat_itimerval __user *o, struct itimerval *i) at compat.c:300>:
        access_ok()
    access_ok()
    do_prlimit() <int do_prlimit (struct task_struct *tsk, unsigned int resource, struct rlimit *new_rlim, struct rlimit *old_rlim) at sys.c:1360>:
        read_lock()
        task_lock()
        capable() <bool capable (int cap) at capability.c:401>:
            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                unlikely()
                cap_valid()
                pr_crit()
                BUG()
                security_capable()
                current_cred()
        security_task_setrlimit()
        task_unlock()
        update_rlimit_cpu()
        read_unlock()
    sys_old_getrlimit()
    rlimit()
    sys_timer_gettime()
    put_compat_itimerspec() <int put_compat_itimerspec (struct compat_itimerspec __user *dst, const struct itimerspec *src) at compat.c:673>:
    sys_clock_settime()
    sys_clock_gettime()
    compat_get_timex() <int compat_get_timex (struct timex *txc, struct compat_timex __user *utp) at compat.c:33>:
        access_ok()
    sys_clock_adjtime()
    compat_put_timex() <int compat_put_timex (struct compat_timex __user *utp, struct timex *txc) at compat.c:63>:
        access_ok()
    sys_clock_getres()
    sys_sched_rr_get_interval()
    unlikely()
    do_sigpending() <int do_sigpending (void *set, unsigned long sigsetsize) at signal.c:2604>:
        spin_lock_irq()
        sigorsets()
        spin_unlock_irq()
        sigandsets()
    sigset_to_compat() <void sigset_to_compat (compat_sigset_t *compat, const sigset_t *set) at compat.c:986>:
    sys_rt_sigpending()
    compat_ptr()
    do_sigaltstack() <int do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long sp) at signal.c:3091>:
        sas_ss_flags()
        access_ok()
        on_sig_stack()
    compat_user_stack_pointer()
    ptr_to_compat()
    sigset_from_compat() <void sigset_from_compat (sigset_t *set, const compat_sigset_t *compat) at compat.c:974>:
    sigsuspend() <int sigsuspend (sigset_t *set) at signal.c:3506>:
        set_current_blocked() <void set_current_blocked (sigset_t *newset) at signal.c:2478>:
            sigdelsetmask()
        signal_pending()
        schedule()
        set_restore_sigmask()
    sys_rt_sigsuspend()
    k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
        task_cputime_adjusted()
        accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
            task_io_get_inblock()
            task_io_get_oublock()
        lock_task_sighand()
        thread_group_cputime_adjusted()
        while_each_thread()
        BUG()
        unlock_task_sighand()
        cputime_to_timeval()
        get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
            task_lock()
            atomic_inc()
            task_unlock()
        setmax_mm_hiwater_rss()
        mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
            might_sleep()
            atomic_dec_and_test()
            uprobe_clear_state()
            exit_aio()
            ksm_exit()
            khugepaged_exit()
            exit_mmap()
            set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                rcu_dereference_raw()
                get_file()
                rcu_assign_pointer()
                fput()
            list_empty()
            spin_lock()
            list_del()
            spin_unlock()
            module_put() <void module_put (struct module *module) at module.c:1098>:
                preempt_disable()
                atomic_dec_if_positive()
                WARN_ON()
                trace_module_put()
                preempt_enable()
            mmdrop()
    put_compat_rusage() <int put_compat_rusage (const struct rusage *r, struct compat_rusage __user *ru) at compat.c:511>:
        access_ok()
COMPAT_SYSCALL_DEFINE3() <COMPAT_SYSCALL_DEFINE3 (sigaction, int, sig, const struct compat_old_sigaction __user *, act, struct compat_old_sigaction __user *, oact) at signal.c:3410>:
    get_compat_itimerval() <inline long get_compat_itimerval (struct itimerval *o, struct compat_itimerval __user *i) at compat.c:290>:
        access_ok()
    do_setitimer()
    put_compat_itimerval() <inline long put_compat_itimerval (struct compat_itimerval __user *o, struct itimerval *i) at compat.c:300>:
        access_ok()
    get_user()
    sigaddsetmask()
    sigdelsetmask()
    compat_sig_setmask() <inline void compat_sig_setmask (sigset_t *blocked, compat_sigset_word set) at compat.c:396>:
    set_current_blocked() <void set_current_blocked (sigset_t *newset) at signal.c:2478>:
        sigdelsetmask()
    put_user()
    alloc_cpumask_var()
    compat_get_user_cpu_mask() <int compat_get_user_cpu_mask (compat_ulong_t __user *user_mask_ptr, unsigned len, struct cpumask *new_mask) at compat.c:602>:
        cpumask_size()
        cpumask_bits()
        compat_get_bitmap() <long compat_get_bitmap (unsigned long *mask, const compat_ulong_t __user *umask, unsigned long bitmap_size) at compat.c:890>:
            ALIGN()
            access_ok()
            BITS_TO_COMPAT_LONGS()
            BITS_TO_LONGS()
    free_cpumask_var()
    min_t()
    cpumask_size()
    compat_put_bitmap() <long compat_put_bitmap (compat_ulong_t __user *umask, unsigned long *mask, unsigned long bitmap_size) at compat.c:932>:
        ALIGN()
        access_ok()
        BITS_TO_COMPAT_LONGS()
        BITS_TO_LONGS()
    cpumask_bits()
    compat_alloc_user_space() <void __user *compat_alloc_user_space (unsigned long len) at compat.c:1161>:
        unlikely()
        arch_compat_alloc_user_space()
        access_ok()
    get_compat_sigevent() <int get_compat_sigevent (struct sigevent *event, const struct compat_sigevent __user *u_event) at compat.c:876>:
        access_ok()
    copy_to_user()
    sys_timer_create()
    rcu_read_lock()
    find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
        find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
            RCU_LOCKDEP_WARN()
            rcu_read_lock_held()
            pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                rcu_dereference_check()
                hlist_first_rcu()
                lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                    lockdep_is_held()
                hlist_entry()
            find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                hlist_for_each_entry_rcu()
                pid_hashfn()
                container_of()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
    ptrace_may_access() <bool ptrace_may_access (struct task_struct *task, unsigned int mode) at ptrace.c:287>:
        task_lock()
        task_unlock()
    rcu_read_unlock()
    ptr_to_compat()
    copy_siginfo_from_user32()
    unlikely()
    do_rt_sigqueueinfo() <int do_rt_sigqueueinfo (pid_t pid, int sig, siginfo_t *info) at signal.c:2938>:
        task_pid_vnr()
        kill_proc_info() <int kill_proc_info (int sig, struct siginfo *info, pid_t pid) at signal.c:1310>:
            rcu_read_lock()
            kill_pid_info() <int kill_pid_info (int sig, struct siginfo *info, struct pid *pid) at signal.c:1288>:
                rcu_read_lock()
                pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                    rcu_dereference_check()
                    hlist_first_rcu()
                    lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                        lockdep_is_held()
                    hlist_entry()
                group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                    rcu_read_lock()
                    check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                        valid_signal()
                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                            SI_FROMUSER()
                        audit_signal_info()
                        same_thread_group()
                        kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                            current_cred()
                            uid_eq()
                            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                unlikely()
                                cap_valid()
                                pr_crit()
                                BUG()
                                security_capable()
                                current_cred()
                        task_session()
                        security_task_kill()
                    rcu_read_unlock()
                    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                        lock_task_sighand()
                        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                SI_FROMUSER()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                        unlock_task_sighand()
                rcu_read_unlock()
                likely()
            find_vpid() <struct pid *find_vpid (int nr) at pid.c:380>:
                find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                    hlist_for_each_entry_rcu()
                    pid_hashfn()
                    container_of()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
            rcu_read_unlock()
    access_ok()
    compat_ptr()
    siginitset()
    do_sigaction() <int do_sigaction (int sig, struct k_sigaction *act, struct k_sigaction *oact) at signal.c:3047>:
        valid_signal()
        sig_kernel_only()
        spin_lock_irq()
        sigdelsetmask()
        sig_handler_ignored() <int sig_handler_ignored (void __user *handler, int sig) at signal.c:61>:
            sig_kernel_ignore()
        sig_handler() <void __user *sig_handler (struct task_struct *t, int sig) at signal.c:56>:
        flush_sigqueue_mask() <int flush_sigqueue_mask (sigset_t *mask, struct sigpending *s) at signal.c:659>:
            sigandsets()
            sigisemptyset()
            sigandnsets()
            list_for_each_entry_safe()
            list_del_init()
        for_each_thread()
        spin_unlock_irq()
COMPAT_SYSCALL_DEFINE4() <COMPAT_SYSCALL_DEFINE4 (rt_sigaction, int, sig, const struct compat_sigaction __user *, act, struct compat_sigaction __user *, oact, compat_size_t, sigsetsize) at signal.c:3325>:
    sys_wait4()
    get_fs()
    set_fs()
    put_compat_rusage() <int put_compat_rusage (const struct rusage *r, struct compat_rusage __user *ru) at compat.c:511>:
        access_ok()
    put_user()
    get_compat_itimerspec() <int get_compat_itimerspec (struct itimerspec *dst, const struct compat_itimerspec __user *src) at compat.c:664>:
    sys_timer_settime()
    put_compat_itimerspec() <int put_compat_itimerspec (struct compat_itimerspec __user *dst, const struct itimerspec *src) at compat.c:673>:
    compat_get_timespec() <int compat_get_timespec (struct timespec *ts, const void __user *uts) at compat.c:175>:
        copy_from_user()
    sys_clock_nanosleep()
    compat_put_timespec() <int compat_put_timespec (const struct timespec *ts, void __user *uts) at compat.c:184>:
        copy_to_user()
    compat_clock_nanosleep_restart() <long compat_clock_nanosleep_restart (struct restart_block *restart) at compat.c:814> (R):
        get_fs()
        set_fs()
        clock_nanosleep_restart()
        compat_put_timespec() <int compat_put_timespec (const struct timespec *ts, void __user *uts) at compat.c:184>:
            copy_to_user()
        compat_clock_nanosleep_restart() <long compat_clock_nanosleep_restart (struct restart_block *restart) at compat.c:814> (recursive: see 347)
    copy_from_user()
    sigset_from_compat() <void sigset_from_compat (sigset_t *set, const compat_sigset_t *compat) at compat.c:974>:
    do_sigtimedwait() <int do_sigtimedwait (const sigset_t *which, siginfo_t *info, const struct timespec *ts) at signal.c:2749>:
        timespec_valid()
        timespec_to_jiffies()
        sigdelsetmask()
        signotset()
        spin_lock_irq()
        dequeue_signal() <int dequeue_signal (struct task_struct *tsk, sigset_t *mask, siginfo_t *info) at signal.c:559>:
            unlikely()
            hrtimer_is_queued()
            hrtimer_forward()
            get_time()
            hrtimer_restart()
            recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
                recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                    PENDING()
                    set_tsk_thread_flag()
                freezing()
                clear_thread_flag()
            sig_kernel_stop()
            spin_unlock()
            do_schedule_next_timer()
            spin_lock()
        sigandsets()
        recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
            recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                PENDING()
                set_tsk_thread_flag()
            freezing()
            clear_thread_flag()
        spin_unlock_irq()
        freezable_schedule_timeout_interruptible()
    copy_siginfo_to_user32()
    min_t()
    ALIGN()
    compat_get_bitmap() <long compat_get_bitmap (unsigned long *mask, const compat_ulong_t __user *umask, unsigned long bitmap_size) at compat.c:890>:
        ALIGN()
        access_ok()
        BITS_TO_COMPAT_LONGS()
        BITS_TO_LONGS()
    nodes_addr()
    compat_alloc_user_space() <void __user *compat_alloc_user_space (unsigned long len) at compat.c:1161>:
        unlikely()
        arch_compat_alloc_user_space()
        access_ok()
    copy_to_user()
    sys_migrate_pages()
    compat_ptr()
    sys_kexec_load()
    ptrace_traceme() <int ptrace_traceme (void) at ptrace.c:410>:
        write_lock_irq()
        security_ptrace_traceme()
        write_unlock_irq()
    ptrace_get_task_struct() <struct task_struct *ptrace_get_task_struct (pid_t pid) at ptrace.c:1060>:
        rcu_read_lock()
        find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
            find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                RCU_LOCKDEP_WARN()
                rcu_read_lock_held()
                pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                    rcu_dereference_check()
                    hlist_first_rcu()
                    lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                        lockdep_is_held()
                    hlist_entry()
                find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                    hlist_for_each_entry_rcu()
                    pid_hashfn()
                    container_of()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
        get_task_struct()
        rcu_read_unlock()
        ERR_PTR()
    IS_ERR()
    PTR_ERR()
    ptrace_attach() <int ptrace_attach (struct task_struct *task, long request, unsigned long addr, unsigned long flags) at ptrace.c:296>:
        audit_ptrace()
        unlikely()
        same_thread_group()
        mutex_lock_interruptible()
        task_lock()
        task_unlock()
        write_lock_irq()
        rcu_read_lock()
        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
            unlikely()
            cap_valid()
            pr_crit()
            BUG()
            security_capable()
            current_cred()
        rcu_read_unlock()
        send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
            valid_signal()
            do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                lock_task_sighand()
                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                        SI_FROMUSER()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                unlock_task_sighand()
        spin_lock()
        task_is_stopped()
        task_set_jobctl_pending() <bool task_set_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:248>:
            BUG_ON()
            unlikely()
            fatal_signal_pending()
        signal_wake_up_state() <void signal_wake_up_state (struct task_struct *t, unsigned int state) at signal.c:639>:
            set_tsk_thread_flag()
            wake_up_state()
            kick_process()
        spin_unlock()
        write_unlock_irq()
        mutex_unlock()
        wait_on_bit()
        proc_ptrace_connector()
    arch_ptrace_attach()
    ptrace_check_attach() <int ptrace_check_attach (struct task_struct *child, bool ignore_state) at ptrace.c:172>:
        read_lock()
        WARN_ON()
        ptrace_freeze_traced() <bool ptrace_freeze_traced (struct task_struct *task) at ptrace.c:122>:
            spin_lock_irq()
            task_is_traced()
            spin_unlock_irq()
        read_unlock()
        wait_task_inactive()
    compat_arch_ptrace()
    ptrace_unfreeze_traced() <void ptrace_unfreeze_traced (struct task_struct *task) at ptrace.c:140>:
        WARN_ON()
        spin_lock_irq()
        wake_up_state()
        spin_unlock_irq()
    put_task_struct()
    sigdelsetmask()
    sigprocmask() <int sigprocmask (int how, sigset_t *set, sigset_t *oldset) at signal.c:2501>:
        sigorsets()
        sigandnsets()
    sigset_to_compat() <void sigset_to_compat (compat_sigset_t *compat, const sigset_t *set) at compat.c:986>:
    sys_rt_sigprocmask()
    copy_siginfo_from_user32()
    do_rt_tgsigqueueinfo() <int do_rt_tgsigqueueinfo (pid_t tgid, pid_t pid, int sig, siginfo_t *info) at signal.c:2982>:
        task_pid_vnr()
        do_send_specific() <int do_send_specific (pid_t tgid, pid_t pid, int sig, struct siginfo *info) at signal.c:2861>:
            rcu_read_lock()
            find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
                find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                    RCU_LOCKDEP_WARN()
                    rcu_read_lock_held()
                    pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                        rcu_dereference_check()
                        hlist_first_rcu()
                        lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                            lockdep_is_held()
                        hlist_entry()
                    find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                        hlist_for_each_entry_rcu()
                        pid_hashfn()
                        container_of()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
            task_tgid_vnr()
            check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                valid_signal()
                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                    SI_FROMUSER()
                audit_signal_info()
                same_thread_group()
                kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                    current_cred()
                    uid_eq()
                    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                        unlikely()
                        cap_valid()
                        pr_crit()
                        BUG()
                        security_capable()
                        current_cred()
                task_session()
                security_task_kill()
            do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                lock_task_sighand()
                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                        SI_FROMUSER()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                unlock_task_sighand()
            unlikely()
            rcu_read_unlock()
    get_user()
    do_sigaction() <int do_sigaction (int sig, struct k_sigaction *act, struct k_sigaction *oact) at signal.c:3047>:
        valid_signal()
        sig_kernel_only()
        spin_lock_irq()
        sigdelsetmask()
        sig_handler_ignored() <int sig_handler_ignored (void __user *handler, int sig) at signal.c:61>:
            sig_kernel_ignore()
        sig_handler() <void __user *sig_handler (struct task_struct *t, int sig) at signal.c:56>:
        flush_sigqueue_mask() <int flush_sigqueue_mask (sigset_t *mask, struct sigpending *s) at signal.c:659>:
            sigandsets()
            sigisemptyset()
            sigandnsets()
            list_for_each_entry_safe()
            list_del_init()
        for_each_thread()
        spin_unlock_irq()
    ptr_to_compat()
COMPAT_SYSCALL_DEFINE5() <COMPAT_SYSCALL_DEFINE5 (waitid, int, which, compat_pid_t, pid, struct compat_siginfo __user *, uinfo, int, options, struct compat_rusage __user *, uru) at compat.c:567>:
    get_fs()
    set_fs()
    sys_waitid()
    copy_to_user()
    put_compat_rusage() <int put_compat_rusage (const struct rusage *r, struct compat_rusage __user *ru) at compat.c:511>:
        access_ok()
    BUG_ON()
    copy_siginfo_to_user32()
COMPAT_SYSCALL_DEFINE6() <COMPAT_SYSCALL_DEFINE6 (futex, u32 __user *, uaddr, int, op, u32, val, struct compat_timespec __user *, utime, u32 __user *, uaddr2, u32, val3) at futex_compat.c:174>:
    compat_alloc_user_space() <void __user *compat_alloc_user_space (unsigned long len) at compat.c:1161>:
        unlikely()
        arch_compat_alloc_user_space()
        access_ok()
    get_user()
    put_user()
    compat_ptr()
    sys_move_pages()
    compat_get_timespec() <int compat_get_timespec (struct timespec *ts, const void __user *uts) at compat.c:175>:
        copy_from_user()
    timespec_valid()
    timespec_to_ktime()
    ktime_add_safe()
    ktime_get()
    do_futex() <long do_futex (u32 __user *uaddr, int op, u32 val, ktime_t *timeout, u32 __user *uaddr2, u32 val2, u32 val3) at futex.c:3041>:
        futex_wait() <int futex_wait (u32 __user *uaddr, unsigned int flags, u32 val, ktime_t *abs_time, u32 bitset) at futex.c:2267> (R):
            hrtimer_init_on_stack()
            hrtimer_init_sleeper()
            hrtimer_set_expires_range_ns()
            futex_wait_setup() <int futex_wait_setup (u32 __user *uaddr, u32 val, unsigned int flags, struct futex_q *q, struct futex_hash_bucket **hb) at futex.c:2208>:
                get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                    unlikely()
                    access_ok()
                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                        should_fail()
                    get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                        ihold()
                        futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                            atomic_inc()
                            smp_mb__after_atomic()
                        smp_mb()
                    get_user_pages_fast()
                    lock_page()
                    compound_head()
                    PageSwapCache()
                    unlock_page()
                    put_page()
                    PageAnon()
                    basepage_index()
                unlikely()
                queue_lock() <inline struct futex_hash_bucket *queue_lock (struct futex_q *q) at futex.c:1848>:
                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                        jhash2()
                    hb_waiters_inc() <inline void hb_waiters_inc (struct futex_hash_bucket *hb) at futex.c:345>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    spin_lock()
                get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                    pagefault_disable()
                    pagefault_enable()
                queue_unlock() <inline void queue_unlock (struct futex_hash_bucket *hb) at futex.c:1872>:
                    spin_unlock()
                    hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                        atomic_dec()
                get_user()
                put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                    drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                        WARN_ON_ONCE()
                        iput()
                        mmdrop()
            futex_wait_queue_me() <void futex_wait_queue_me (struct futex_hash_bucket *hb, struct futex_q *q, struct hrtimer_sleeper *timeout) at futex.c:2159>:
                set_current_state()
                queue_me() <inline void queue_me (struct futex_q *q, struct futex_hash_bucket *hb) at futex.c:1891>:
                    min()
                    plist_node_init()
                    plist_add()
                    spin_unlock()
                hrtimer_start_expires()
                likely()
                plist_node_empty()
                freezable_schedule()
            unqueue_me() <int unqueue_me (struct futex_q *q) at futex.c:1923>:
                barrier()
                spin_lock()
                unlikely()
                spin_unlock()
                BUG_ON()
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
            signal_pending()
            futex_wait_restart() <long futex_wait_restart (struct restart_block *restart) at futex.c:2342> (R):
                do_no_restart_syscall() <long do_no_restart_syscall (struct restart_block *param) at signal.c:2454>:
                futex_wait() <int futex_wait (u32 __user *uaddr, unsigned int flags, u32 val, ktime_t *abs_time, u32 bitset) at futex.c:2267> (recursive: see 606)
            hrtimer_cancel()
            destroy_hrtimer_on_stack()
        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
            WAKE_Q()
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            unlikely()
            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                jhash2()
            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                atomic_read()
            spin_lock()
            plist_for_each_entry_safe()
            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                WARN()
                wake_q_add()
                smp_wmb()
            spin_unlock()
            wake_up_q()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
        futex_requeue() <int futex_requeue (u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2, int nr_wake, int nr_requeue, u32 *cmpval, int requeue_pi) at futex.c:1571>:
            WAKE_Q()
            refill_pi_state_cache() <int refill_pi_state_cache (void) at futex.c:659>:
                likely()
                kzalloc()
                INIT_LIST_HEAD()
                atomic_set()
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            unlikely()
            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                jhash2()
            hb_waiters_inc() <inline void hb_waiters_inc (struct futex_hash_bucket *hb) at futex.c:345>:
                atomic_inc()
                smp_mb__after_atomic()
            double_lock_hb() <inline void double_lock_hb (struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2) at futex.c:1257>:
                spin_lock()
                spin_lock_nested()
            likely()
            get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                pagefault_disable()
                pagefault_enable()
            double_unlock_hb() <inline void double_unlock_hb (struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2) at futex.c:1270>:
                spin_unlock()
            hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                atomic_dec()
            get_user()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
            futex_proxy_trylock_atomic() <int futex_proxy_trylock_atomic (u32 __user *pifutex, struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2, union futex_key *key1, union futex_key *key2, struct futex_pi_state **ps, int set_waiters) at futex.c:1504>:
                get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                    pagefault_disable()
                    pagefault_enable()
                unlikely()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                futex_top_waiter() <struct futex_q *futex_top_waiter (struct futex_hash_bucket *hb, union futex_key *key) at futex.c:620>:
                    plist_for_each_entry()
                    match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                task_pid_vnr()
                futex_lock_pi_atomic() <int futex_lock_pi_atomic (u32 __user *uaddr, struct futex_hash_bucket *hb, union futex_key *key, struct futex_pi_state **ps, struct task_struct *task, int set_waiters) at futex.c:1050>:
                    task_pid_vnr()
                    get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                        pagefault_disable()
                        pagefault_enable()
                    unlikely()
                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                        should_fail()
                    futex_top_waiter() <struct futex_q *futex_top_waiter (struct futex_hash_bucket *hb, union futex_key *key) at futex.c:620>:
                        plist_for_each_entry()
                        match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                    attach_to_pi_state() <int attach_to_pi_state (u32 uval, struct futex_pi_state *pi_state, struct futex_pi_state **ps) at futex.c:860>:
                        unlikely()
                        WARN_ON()
                        atomic_read()
                        task_pid_vnr()
                        atomic_inc()
                    lock_pi_update_atomic() <int lock_pi_update_atomic (u32 __user *uaddr, u32 uval, u32 newval) at futex.c:1018>:
                        uninitialized_var()
                        unlikely()
                        should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                            should_fail()
                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                            pagefault_disable()
                            futex_atomic_cmpxchg_inatomic()
                            pagefault_enable()
                    attach_to_pi_owner() <int attach_to_pi_owner (u32 uval, union futex_key *key, struct futex_pi_state **ps) at futex.c:931>:
                        futex_find_get_task() <struct task_struct *futex_find_get_task (pid_t pid) at futex.c:736>:
                            rcu_read_lock()
                            find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
                                find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                                    RCU_LOCKDEP_WARN()
                                    rcu_read_lock_held()
                                    pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                                        rcu_dereference_check()
                                        hlist_first_rcu()
                                        lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                                            lockdep_is_held()
                                        hlist_entry()
                                    find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                                        hlist_for_each_entry_rcu()
                                        pid_hashfn()
                                        container_of()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                            get_task_struct()
                            rcu_read_unlock()
                        unlikely()
                        put_task_struct()
                        raw_spin_lock_irq()
                        raw_spin_unlock_irq()
                        alloc_pi_state() <struct futex_pi_state *alloc_pi_state (void) at futex.c:682>:
                            WARN_ON()
                        rt_mutex_init_proxy_locked()
                        WARN_ON()
                        list_empty()
                        list_add()
                requeue_pi_wake_futex() <inline void requeue_pi_wake_futex (struct futex_q *q, union futex_key *key, struct futex_hash_bucket *hb) at futex.c:1468>:
                    get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                        ihold()
                        futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                            atomic_inc()
                            smp_mb__after_atomic()
                        smp_mb()
                    WARN_ON()
                    wake_up_state()
            WARN_ON()
            lookup_pi_state() <int lookup_pi_state (u32 uval, struct futex_hash_bucket *hb, union futex_key *key, struct futex_pi_state **ps) at futex.c:999>:
                futex_top_waiter() <struct futex_q *futex_top_waiter (struct futex_hash_bucket *hb, union futex_key *key) at futex.c:620>:
                    plist_for_each_entry()
                    match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                attach_to_pi_state() <int attach_to_pi_state (u32 uval, struct futex_pi_state *pi_state, struct futex_pi_state **ps) at futex.c:860>:
                    unlikely()
                    WARN_ON()
                    atomic_read()
                    task_pid_vnr()
                    atomic_inc()
                attach_to_pi_owner() <int attach_to_pi_owner (u32 uval, union futex_key *key, struct futex_pi_state **ps) at futex.c:931>:
                    futex_find_get_task() <struct task_struct *futex_find_get_task (pid_t pid) at futex.c:736>:
                        rcu_read_lock()
                        find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
                            find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                                RCU_LOCKDEP_WARN()
                                rcu_read_lock_held()
                                pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                                    rcu_dereference_check()
                                    hlist_first_rcu()
                                    lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                                        lockdep_is_held()
                                    hlist_entry()
                                find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                                    hlist_for_each_entry_rcu()
                                    pid_hashfn()
                                    container_of()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                        get_task_struct()
                        rcu_read_unlock()
                    unlikely()
                    put_task_struct()
                    raw_spin_lock_irq()
                    raw_spin_unlock_irq()
                    alloc_pi_state() <struct futex_pi_state *alloc_pi_state (void) at futex.c:682>:
                        WARN_ON()
                    rt_mutex_init_proxy_locked()
                    WARN_ON()
                    list_empty()
                    list_add()
            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                down_read()
                fixup_user_fault()
                up_read()
            cond_resched()
            plist_for_each_entry_safe()
            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                WARN()
                wake_q_add()
                smp_wmb()
            atomic_inc()
            rt_mutex_start_proxy_lock()
            requeue_pi_wake_futex() <inline void requeue_pi_wake_futex (struct futex_q *q, union futex_key *key, struct futex_hash_bucket *hb) at futex.c:1468>:
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                WARN_ON()
                wake_up_state()
            put_pi_state() <void put_pi_state (struct futex_pi_state *pi_state) at futex.c:698>:
                atomic_dec_and_test()
                raw_spin_lock_irq()
                list_del_init()
                raw_spin_unlock_irq()
                rt_mutex_proxy_unlock()
                kfree()
                atomic_set()
            requeue_futex() <inline void requeue_futex (struct futex_q *q, struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2, union futex_key *key2) at futex.c:1434>:
                likely()
                plist_del()
                hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                    atomic_dec()
                plist_add()
                hb_waiters_inc() <inline void hb_waiters_inc (struct futex_hash_bucket *hb) at futex.c:345>:
                    atomic_inc()
                    smp_mb__after_atomic()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
            wake_up_q()
            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                WARN_ON_ONCE()
                iput()
                mmdrop()
        futex_wake_op() <int futex_wake_op (u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2, int nr_wake, int nr_wake2, int op) at futex.c:1334>:
            WAKE_Q()
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            unlikely()
            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                jhash2()
            double_lock_hb() <inline void double_lock_hb (struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2) at futex.c:1257>:
                spin_lock()
                spin_lock_nested()
            futex_atomic_op_inuser()
            double_unlock_hb() <inline void double_unlock_hb (struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2) at futex.c:1270>:
                spin_unlock()
            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                down_read()
                fixup_user_fault()
                up_read()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
            plist_for_each_entry_safe()
            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                WARN()
                wake_q_add()
                smp_wmb()
            wake_up_q()
        futex_lock_pi() <int futex_lock_pi (u32 __user *uaddr, unsigned int flags, ktime_t *time, int trylock) at futex.c:2367>:
            refill_pi_state_cache() <int refill_pi_state_cache (void) at futex.c:659>:
                likely()
                kzalloc()
                INIT_LIST_HEAD()
                atomic_set()
            hrtimer_init_on_stack()
            hrtimer_init_sleeper()
            hrtimer_set_expires()
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            unlikely()
            queue_lock() <inline struct futex_hash_bucket *queue_lock (struct futex_q *q) at futex.c:1848>:
                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                    jhash2()
                hb_waiters_inc() <inline void hb_waiters_inc (struct futex_hash_bucket *hb) at futex.c:345>:
                    atomic_inc()
                    smp_mb__after_atomic()
                spin_lock()
            futex_lock_pi_atomic() <int futex_lock_pi_atomic (u32 __user *uaddr, struct futex_hash_bucket *hb, union futex_key *key, struct futex_pi_state **ps, struct task_struct *task, int set_waiters) at futex.c:1050>:
                task_pid_vnr()
                get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                    pagefault_disable()
                    pagefault_enable()
                unlikely()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                futex_top_waiter() <struct futex_q *futex_top_waiter (struct futex_hash_bucket *hb, union futex_key *key) at futex.c:620>:
                    plist_for_each_entry()
                    match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                attach_to_pi_state() <int attach_to_pi_state (u32 uval, struct futex_pi_state *pi_state, struct futex_pi_state **ps) at futex.c:860>:
                    unlikely()
                    WARN_ON()
                    atomic_read()
                    task_pid_vnr()
                    atomic_inc()
                lock_pi_update_atomic() <int lock_pi_update_atomic (u32 __user *uaddr, u32 uval, u32 newval) at futex.c:1018>:
                    uninitialized_var()
                    unlikely()
                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                        should_fail()
                    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                        pagefault_disable()
                        futex_atomic_cmpxchg_inatomic()
                        pagefault_enable()
                attach_to_pi_owner() <int attach_to_pi_owner (u32 uval, union futex_key *key, struct futex_pi_state **ps) at futex.c:931>:
                    futex_find_get_task() <struct task_struct *futex_find_get_task (pid_t pid) at futex.c:736>:
                        rcu_read_lock()
                        find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
                            find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                                RCU_LOCKDEP_WARN()
                                rcu_read_lock_held()
                                pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                                    rcu_dereference_check()
                                    hlist_first_rcu()
                                    lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                                        lockdep_is_held()
                                    hlist_entry()
                                find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                                    hlist_for_each_entry_rcu()
                                    pid_hashfn()
                                    container_of()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                        get_task_struct()
                        rcu_read_unlock()
                    unlikely()
                    put_task_struct()
                    raw_spin_lock_irq()
                    raw_spin_unlock_irq()
                    alloc_pi_state() <struct futex_pi_state *alloc_pi_state (void) at futex.c:682>:
                        WARN_ON()
                    rt_mutex_init_proxy_locked()
                    WARN_ON()
                    list_empty()
                    list_add()
            queue_unlock() <inline void queue_unlock (struct futex_hash_bucket *hb) at futex.c:1872>:
                spin_unlock()
                hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                    atomic_dec()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
            cond_resched()
            queue_me() <inline void queue_me (struct futex_q *q, struct futex_hash_bucket *hb) at futex.c:1891>:
                min()
                plist_node_init()
                plist_add()
                spin_unlock()
            WARN_ON()
            rt_mutex_timed_futex_lock()
            rt_mutex_trylock()
            spin_lock()
            fixup_owner() <int fixup_owner (u32 __user *uaddr, struct futex_q *q, int locked) at futex.c:2095>:
                fixup_pi_state_owner() <int fixup_pi_state_owner (u32 __user *uaddr, struct futex_q *q, struct task_struct *newowner) at futex.c:1986>:
                    task_pid_vnr()
                    uninitialized_var()
                    get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                        pagefault_disable()
                        pagefault_enable()
                    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                        pagefault_disable()
                        futex_atomic_cmpxchg_inatomic()
                        pagefault_enable()
                    raw_spin_lock_irq()
                    WARN_ON()
                    list_empty()
                    list_del_init()
                    raw_spin_unlock_irq()
                    list_add()
                    spin_unlock()
                    fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                        down_read()
                        fixup_user_fault()
                        up_read()
                    spin_lock()
                rt_mutex_trylock()
                raw_spin_lock_irq()
                rt_mutex_owner()
                rt_mutex_next_owner()
                raw_spin_unlock_irq()
                printk()
            rt_mutex_owner()
            rt_mutex_unlock()
            unqueue_me_pi() < at futex.c:1968>:
                BUG_ON()
                put_pi_state() <void put_pi_state (struct futex_pi_state *pi_state) at futex.c:698>:
                    atomic_dec_and_test()
                    raw_spin_lock_irq()
                    list_del_init()
                    raw_spin_unlock_irq()
                    rt_mutex_proxy_unlock()
                    kfree()
                    atomic_set()
                spin_unlock()
            destroy_hrtimer_on_stack()
            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                down_read()
                fixup_user_fault()
                up_read()
        futex_unlock_pi() <int futex_unlock_pi (u32 __user *uaddr, unsigned int flags) at futex.c:2494>:
            uninitialized_var()
            task_pid_vnr()
            get_user()
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                jhash2()
            spin_lock()
            futex_top_waiter() <struct futex_q *futex_top_waiter (struct futex_hash_bucket *hb, union futex_key *key) at futex.c:620>:
                plist_for_each_entry()
                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            wake_futex_pi() <int wake_futex_pi (u32 __user *uaddr, u32 uval, struct futex_q *this, struct futex_hash_bucket *hb) at futex.c:1174>:
                uninitialized_var()
                WAKE_Q()
                raw_spin_lock_irq()
                rt_mutex_next_owner()
                task_pid_vnr()
                unlikely()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                    pagefault_disable()
                    futex_atomic_cmpxchg_inatomic()
                    pagefault_enable()
                raw_spin_unlock_irq()
                raw_spin_lock()
                WARN_ON()
                list_empty()
                list_del_init()
                raw_spin_unlock()
                list_add()
                rt_mutex_futex_unlock()
                spin_unlock()
                wake_up_q()
                rt_mutex_adjust_prio()
            cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                pagefault_disable()
                futex_atomic_cmpxchg_inatomic()
                pagefault_enable()
            spin_unlock()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                down_read()
                fixup_user_fault()
                up_read()
        futex_wait_requeue_pi() <int futex_wait_requeue_pi (u32 __user *uaddr, unsigned int flags, u32 val, ktime_t *abs_time, u32 bitset, u32 __user *uaddr2) at futex.c:2666>:
            hrtimer_init_on_stack()
            hrtimer_init_sleeper()
            hrtimer_set_expires_range_ns()
            debug_rt_mutex_init_waiter()
            RB_CLEAR_NODE()
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            unlikely()
            futex_wait_setup() <int futex_wait_setup (u32 __user *uaddr, u32 val, unsigned int flags, struct futex_q *q, struct futex_hash_bucket **hb) at futex.c:2208>:
                get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                    unlikely()
                    access_ok()
                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                        should_fail()
                    get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                        ihold()
                        futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                            atomic_inc()
                            smp_mb__after_atomic()
                        smp_mb()
                    get_user_pages_fast()
                    lock_page()
                    compound_head()
                    PageSwapCache()
                    unlock_page()
                    put_page()
                    PageAnon()
                    basepage_index()
                unlikely()
                queue_lock() <inline struct futex_hash_bucket *queue_lock (struct futex_q *q) at futex.c:1848>:
                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                        jhash2()
                    hb_waiters_inc() <inline void hb_waiters_inc (struct futex_hash_bucket *hb) at futex.c:345>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    spin_lock()
                get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                    pagefault_disable()
                    pagefault_enable()
                queue_unlock() <inline void queue_unlock (struct futex_hash_bucket *hb) at futex.c:1872>:
                    spin_unlock()
                    hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                        atomic_dec()
                get_user()
                put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                    drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                        WARN_ON_ONCE()
                        iput()
                        mmdrop()
            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            queue_unlock() <inline void queue_unlock (struct futex_hash_bucket *hb) at futex.c:1872>:
                spin_unlock()
                hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                    atomic_dec()
            futex_wait_queue_me() <void futex_wait_queue_me (struct futex_hash_bucket *hb, struct futex_q *q, struct hrtimer_sleeper *timeout) at futex.c:2159>:
                set_current_state()
                queue_me() <inline void queue_me (struct futex_q *q, struct futex_hash_bucket *hb) at futex.c:1891>:
                    min()
                    plist_node_init()
                    plist_add()
                    spin_unlock()
                hrtimer_start_expires()
                likely()
                plist_node_empty()
                freezable_schedule()
            spin_lock()
            handle_early_requeue_pi_wakeup() <inline int handle_early_requeue_pi_wakeup (struct futex_hash_bucket *hb, struct futex_q *q, union futex_key *key2, struct hrtimer_sleeper *timeout) at futex.c:2594>:
                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                WARN_ON()
                plist_del()
                hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                    atomic_dec()
                signal_pending()
            spin_unlock()
            fixup_pi_state_owner() <int fixup_pi_state_owner (u32 __user *uaddr, struct futex_q *q, struct task_struct *newowner) at futex.c:1986>:
                task_pid_vnr()
                uninitialized_var()
                get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                    pagefault_disable()
                    pagefault_enable()
                cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                    pagefault_disable()
                    futex_atomic_cmpxchg_inatomic()
                    pagefault_enable()
                raw_spin_lock_irq()
                WARN_ON()
                list_empty()
                list_del_init()
                raw_spin_unlock_irq()
                list_add()
                spin_unlock()
                fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                    down_read()
                    fixup_user_fault()
                    up_read()
                spin_lock()
            put_pi_state() <void put_pi_state (struct futex_pi_state *pi_state) at futex.c:698>:
                atomic_dec_and_test()
                raw_spin_lock_irq()
                list_del_init()
                raw_spin_unlock_irq()
                rt_mutex_proxy_unlock()
                kfree()
                atomic_set()
            WARN_ON()
            rt_mutex_finish_proxy_lock()
            debug_rt_mutex_free_waiter()
            fixup_owner() <int fixup_owner (u32 __user *uaddr, struct futex_q *q, int locked) at futex.c:2095>:
                fixup_pi_state_owner() <int fixup_pi_state_owner (u32 __user *uaddr, struct futex_q *q, struct task_struct *newowner) at futex.c:1986>:
                    task_pid_vnr()
                    uninitialized_var()
                    get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                        pagefault_disable()
                        pagefault_enable()
                    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                        pagefault_disable()
                        futex_atomic_cmpxchg_inatomic()
                        pagefault_enable()
                    raw_spin_lock_irq()
                    WARN_ON()
                    list_empty()
                    list_del_init()
                    raw_spin_unlock_irq()
                    list_add()
                    spin_unlock()
                    fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                        down_read()
                        fixup_user_fault()
                        up_read()
                    spin_lock()
                rt_mutex_trylock()
                raw_spin_lock_irq()
                rt_mutex_owner()
                rt_mutex_next_owner()
                raw_spin_unlock_irq()
                printk()
            unqueue_me_pi() < at futex.c:1968>:
                BUG_ON()
                put_pi_state() <void put_pi_state (struct futex_pi_state *pi_state) at futex.c:698>:
                    atomic_dec_and_test()
                    raw_spin_lock_irq()
                    list_del_init()
                    raw_spin_unlock_irq()
                    rt_mutex_proxy_unlock()
                    kfree()
                    atomic_set()
                spin_unlock()
            rt_mutex_owner()
            rt_mutex_unlock()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
            hrtimer_cancel()
            destroy_hrtimer_on_stack()
SYSCALL_DEFINE0() <SYSCALL_DEFINE0 (getegid16) at uid16.c:214>:
    signal_pending()
    schedule()
    task_tgid_vnr()
    task_pid_vnr()
    rcu_read_lock()
    rcu_dereference()
    rcu_read_unlock()
    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
    current_user_ns()
    current_uid()
    current_euid()
    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
    current_gid()
    current_egid()
    sys_getpgid()
    task_pid()
    pid_vnr() <pid_t pid_vnr (struct pid *pid) at pid.c:514>:
        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
    write_lock_irq()
    pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
        rcu_dereference_check()
        hlist_first_rcu()
        lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
            lockdep_is_held()
        hlist_entry()
    set_special_pids() <void set_special_pids (struct pid *pid) at sys.c:1055>:
        task_session()
        change_pid() <void change_pid (struct task_struct *task, enum pid_type type, struct pid *pid) at pid.c:420>:
            attach_pid() <void attach_pid (struct task_struct *task, enum pid_type type) at pid.c:389>:
                hlist_add_head_rcu()
        task_pgrp()
    proc_clear_tty()
    write_unlock_irq()
    proc_sid_connector()
    sched_autogroup_create_attach()
    high2lowuid()
    high2lowgid()
SYSCALL_DEFINE1() <SYSCALL_DEFINE1 (setfsgid16, old_gid_t, gid) at uid16.c:106>:
    capable() <bool capable (int cap) at capability.c:401>:
        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
            unlikely()
            cap_valid()
            pr_crit()
            BUG()
            security_capable()
            current_cred()
    getname()
    IS_ERR()
    PTR_ERR()
    mutex_lock()
    acct_on() <int acct_on (struct filename *pathname) at acct.c:190>:
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
        kzalloc()
        file_open_name()
        IS_ERR()
        kfree()
        PTR_ERR()
        file_inode()
        filp_close()
        mnt_clone_internal()
        mnt_want_write()
        mntput()
        atomic_long_set()
        init_fs_pin()
        acct_pin_kill() <void acct_pin_kill (struct fs_pin *pin) at acct.c:167>:
            to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                container_of()
            mutex_lock()
            do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                    kdebug()
                    atomic_read()
                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                        atomic_read()
                    validate_creds()
                    get_cred()
                    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                        atomic_add()
                    rcu_assign_pointer()
                check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                    time_is_before_jiffies()
                    vfs_statfs()
                    do_div()
                    pr_info()
                fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                    strlcpy()
                    ktime_get_ns()
                    nsec_to_AHZ()
                    encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                    encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                    encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                    do_div()
                    get_seconds()
                    spin_lock_irq()
                    old_encode_dev()
                    tty_devnum()
                    jiffies_to_AHZ()
                    cputime_to_jiffies()
                    spin_unlock_irq()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                    from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                    pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                    task_tgid()
                rcu_read_lock()
                rcu_dereference()
                rcu_read_unlock()
                file_start_write_trylock()
                file_end_write()
                revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                    kdebug()
                    atomic_read()
                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                        atomic_read()
                    validate_creds()
                    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                        atomic_add()
                    rcu_assign_pointer()
                    put_cred()
            schedule_work()
            wait_for_completion()
            cmpxchg()
            mutex_unlock()
            pin_remove()
            acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                atomic_long_dec_and_test()
                kfree_rcu()
        mutex_init()
        INIT_WORK()
        close_work() <void close_work (struct work_struct *work) at acct.c:180>:
            container_of()
            flush()
            complete()
        init_completion()
        mutex_lock_nested()
        pin_insert()
        rcu_read_lock()
        xchg()
        mutex_unlock()
        pin_kill()
        mnt_drop_write()
    mutex_unlock()
    putname()
    rcu_read_lock()
    pin_kill()
    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
        ns_of_pid()
        task_pid()
    set_personality()
    do_exit() <void do_exit (long code) at exit.c:651>:
        TASKS_RCU()
        profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
            blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
        WARN_ON()
        blk_needs_flush_plug()
        unlikely()
        in_interrupt()
        panic() <void panic (const char *fmt, ...) at panic.c:83>:
            local_irq_disable()
            raw_smp_processor_id()
            atomic_cmpxchg()
            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                cpu_relax()
            console_verbose()
            bust_spinlocks()
            pr_emerg()
            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                test_bit()
            dump_stack()
            smp_send_stop()
            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
            kmsg_dump()
            debug_locks_off()
            console_flush_on_panic()
            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
            no_blink() <long no_blink (int state) at panic.c:46>
            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                raw_cpu_write()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            mdelay()
            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                kmsg_dump()
                machine_emergency_restart()
            disabled_wait()
            local_irq_enable()
            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                    raw_cpu_write()
                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                    per_cpu()
                raw_smp_processor_id()
        set_fs()
        ptrace_event()
        validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
        pr_alert()
        set_current_state()
        schedule()
        exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
            threadgroup_change_begin()
            thread_group_empty()
            signal_group_exit()
            threadgroup_change_end()
            spin_lock_irq()
            signal_pending()
            signotset()
            retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                sigandsets()
                sigisemptyset()
                while_each_thread()
                has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                signal_pending()
                signal_wake_up()
            unlikely()
            task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                WARN_ON_ONCE()
                task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                    BUG_ON()
                    task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                        unlikely()
                        smp_mb()
                        wake_up_bit()
            spin_unlock_irq()
            read_lock()
            do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                BUG()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
            read_unlock()
        smp_mb()
        raw_spin_unlock_wait()
        in_atomic()
        pr_info()
        task_pid_nr()
        preempt_count()
        preempt_count_set()
        sync_mm_rss()
        acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
            task_cputime()
        atomic_dec_and_test()
        hrtimer_cancel()
        exit_itimers()
        setmax_mm_hiwater_rss()
        acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
            down_read()
            up_read()
            spin_lock_irq()
            thread_group_leader()
            task_cputime()
            spin_unlock_irq()
        tty_audit_exit()
        audit_free()
        taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
            taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                nla_total_size()
            taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                thread_group_empty()
                kmem_cache_zalloc()
                spin_lock_irq()
                spin_unlock_irq()
                kmem_cache_free()
            fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                spin_lock_irqsave()
                delayacct_add_tsk()
                spin_unlock_irqrestore()
            raw_cpu_ptr()
            list_empty()
            prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                genlmsg_new()
                this_cpu_inc_return()
                genlmsg_put()
                genlmsg_put_reply()
                nlmsg_free()
            mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                nla_put()
                nla_nest_start()
                nla_nest_cancel()
                nla_reserve()
                nla_nest_end()
                nla_data()
            task_pid_nr_ns()
            fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                delayacct_add_tsk()
                bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                    BUILD_BUG_ON()
                    ktime_get_ns()
                    do_div()
                    get_seconds()
                    thread_group_leader()
                    task_nice()
                    task_pid_nr_ns()
                    rcu_read_lock()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    pid_alive()
                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                        task_tgid()
                    rcu_dereference()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_usecs()
                    task_cputime_scaled()
                xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                    get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                        task_lock()
                        atomic_inc()
                        task_unlock()
                    get_mm_hiwater_rss()
                    get_mm_hiwater_vm()
                    mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                        might_sleep()
                        atomic_dec_and_test()
                        uprobe_clear_state()
                        exit_aio()
                        ksm_exit()
                        khugepaged_exit()
                        exit_mmap()
                        set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                            rcu_dereference_raw()
                            get_file()
                            rcu_assign_pointer()
                            fput()
                        list_empty()
                        spin_lock()
                        list_del()
                        spin_unlock()
                        module_put() <void module_put (struct module *module) at module.c:1098>:
                            preempt_disable()
                            atomic_dec_if_positive()
                            WARN_ON()
                            trace_module_put()
                            preempt_enable()
                        mmdrop()
            task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                task_tgid()
            send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                nlmsg_data()
                nlmsg_hdr()
                genlmsg_data()
                genlmsg_end()
                down_read()
                list_for_each_entry()
                list_is_last()
                skb_clone()
                genlmsg_unicast()
                up_read()
                nlmsg_free()
                down_write()
                list_for_each_entry_safe()
                list_del()
                kfree()
                up_write()
            nlmsg_free()
        exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
            mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                unlikely()
                exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                    uninitialized_var()
                    fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                        get_user()
                    get_user()
                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                        uninitialized_var()
                        get_user()
                        task_pid_vnr()
                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                            pagefault_disable()
                            futex_atomic_cmpxchg_inatomic()
                            pagefault_enable()
                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                            down_read()
                            fixup_user_fault()
                            up_read()
                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                            WAKE_Q()
                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                unlikely()
                                access_ok()
                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                    should_fail()
                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                    ihold()
                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                        atomic_inc()
                                        smp_mb__after_atomic()
                                    smp_mb()
                                get_user_pages_fast()
                                lock_page()
                                compound_head()
                                PageSwapCache()
                                unlock_page()
                                put_page()
                                PageAnon()
                                basepage_index()
                            unlikely()
                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                jhash2()
                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                atomic_read()
                            spin_lock()
                            plist_for_each_entry_safe()
                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                WARN()
                                wake_q_add()
                                smp_wmb()
                            spin_unlock()
                            wake_up_q()
                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                    WARN_ON_ONCE()
                                    iput()
                                    mmdrop()
                    cond_resched()
                compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                    uninitialized_var()
                    fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                        get_user()
                        compat_ptr()
                    get_user()
                    futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                        ptr_to_compat()
                        compat_ptr()
                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                        uninitialized_var()
                        get_user()
                        task_pid_vnr()
                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                            pagefault_disable()
                            futex_atomic_cmpxchg_inatomic()
                            pagefault_enable()
                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                            down_read()
                            fixup_user_fault()
                            up_read()
                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                            WAKE_Q()
                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                unlikely()
                                access_ok()
                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                    should_fail()
                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                    ihold()
                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                        atomic_inc()
                                        smp_mb__after_atomic()
                                    smp_mb()
                                get_user_pages_fast()
                                lock_page()
                                compound_head()
                                PageSwapCache()
                                unlock_page()
                                put_page()
                                PageAnon()
                                basepage_index()
                            unlikely()
                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                jhash2()
                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                atomic_read()
                            spin_lock()
                            plist_for_each_entry_safe()
                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                WARN()
                                wake_q_add()
                                smp_wmb()
                            spin_unlock()
                            wake_up_q()
                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                    WARN_ON_ONCE()
                                    iput()
                                    mmdrop()
                    cond_resched()
                list_empty()
                exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                    raw_spin_lock_irq()
                    list_empty()
                    list_entry()
                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                        jhash2()
                    raw_spin_unlock_irq()
                    spin_lock()
                    spin_unlock()
                    WARN_ON()
                    list_del_init()
                    rt_mutex_unlock()
                uprobe_free_utask()
                deactivate_mm()
                atomic_read()
                put_user()
                sys_futex()
                complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                    task_lock()
                    likely()
                    complete()
                    task_unlock()
            sync_mm_rss()
            down_read()
            up_read()
            xchg()
            atomic_dec_and_test()
            complete()
            set_task_state()
            freezable_schedule()
            atomic_inc()
            BUG_ON()
            task_lock()
            enter_lazy_tlb()
            task_unlock()
            mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                atomic_read()
                read_lock()
                list_for_each_entry()
                for_each_process()
                for_each_thread()
                read_unlock()
                BUG_ON()
                get_task_struct()
                task_lock()
                task_unlock()
                put_task_struct()
            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                might_sleep()
                atomic_dec_and_test()
                uprobe_clear_state()
                exit_aio()
                ksm_exit()
                khugepaged_exit()
                exit_mmap()
                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                    rcu_dereference_raw()
                    get_file()
                    rcu_assign_pointer()
                    fput()
                list_empty()
                spin_lock()
                list_del()
                spin_unlock()
                module_put() <void module_put (struct module *module) at module.c:1098>:
                    preempt_disable()
                    atomic_dec_if_positive()
                    WARN_ON()
                    trace_module_put()
                    preempt_enable()
                mmdrop()
            test_thread_flag()
            exit_oom_victim()
        acct_process() <void acct_process (void) at acct.c:587>:
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
            unlikely()
            slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                    smp_rmb()
                    rcu_read_lock()
                    to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                        container_of()
                    ACCESS_ONCE()
                    rcu_read_unlock()
                    atomic_long_inc_not_zero()
                    cpu_relax()
                    mutex_lock()
                    mutex_unlock()
                    acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                        atomic_long_dec_and_test()
                        kfree_rcu()
                do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                    override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        validate_creds()
                        get_cred()
                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                            atomic_add()
                        rcu_assign_pointer()
                    check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                        time_is_before_jiffies()
                        vfs_statfs()
                        do_div()
                        pr_info()
                    fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                        strlcpy()
                        ktime_get_ns()
                        nsec_to_AHZ()
                        encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                        encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                        encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                        do_div()
                        get_seconds()
                        spin_lock_irq()
                        old_encode_dev()
                        tty_devnum()
                        jiffies_to_AHZ()
                        cputime_to_jiffies()
                        spin_unlock_irq()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                        task_tgid()
                    rcu_read_lock()
                    rcu_dereference()
                    rcu_read_unlock()
                    file_start_write_trylock()
                    file_end_write()
                    revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        validate_creds()
                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                            atomic_add()
                        rcu_assign_pointer()
                        put_cred()
                mutex_unlock()
                acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                    atomic_long_dec_and_test()
                    kfree_rcu()
        trace_sched_process_exit()
        exit_sem()
        exit_shm()
        exit_files()
        exit_fs()
        disassociate_ctty()
        exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
            switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                might_sleep()
                task_lock()
                task_unlock()
                atomic_dec_and_test()
                free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                    put_mnt_ns()
                    put_uts_ns()
                    put_ipc_ns()
                    put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                        kref_put()
                        free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                            container_of()
                            destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                ns_free_inum()
                                kfree()
                                put_user_ns()
                                call_rcu()
                                delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                    kmem_cache_free()
                                    container_of()
                    put_net()
                    kmem_cache_free()
        exit_task_work()
        exit_thread()
        perf_event_exit_task()
        cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
            task_css_set()
            list_empty()
            spin_lock_bh()
            css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                lockdep_assert_held()
                WARN_ON_ONCE()
                list_empty()
                list_for_each_entry_safe()
                css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                    lockdep_assert_held()
                    WARN_ON_ONCE()
                    css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                        lockdep_assert_held()
                        container_of()
                        list_entry()
                        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                            lockdep_assert_held()
                            list_empty()
                        list_empty()
                        list_del()
                        put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                            lockdep_assert_held()
                            atomic_dec_and_test()
                            for_each_subsys()
                            list_del()
                            css_put()
                            hash_del()
                            list_for_each_entry_safe()
                            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                container_of()
                            cgroup_put()
                            kfree()
                            kfree_rcu()
                        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                            atomic_inc()
                        list_add()
                list_del_init()
                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                    lockdep_assert_held()
                    list_empty()
                css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                    lockdep_assert_held()
                    list_for_each_entry()
                    cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                        lockdep_assert_held()
                        check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                            notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                test_bit()
                            cgroup_is_populated()
                            css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                rcu_read_lock()
                                css_for_each_child()
                                rcu_read_unlock()
                            cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                            schedule_work()
                        cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                            spin_lock_irqsave()
                            kernfs_notify()
                            spin_unlock_irqrestore()
                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                            container_of()
                rcu_assign_pointer()
                list_add_tail()
            spin_unlock_bh()
            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                atomic_inc()
            for_each_subsys_which()
        flush_ptrace_hw_breakpoint()
        preempt_disable()
        preempt_enable()
        exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
            LIST_HEAD()
            write_lock_irq()
            forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                unlikely()
                list_empty()
                exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                    list_for_each_entry_safe()
                    unlikely()
                    send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                        valid_signal()
                        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                            lock_task_sighand()
                            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                    SI_FROMUSER()
                                task_pid_nr_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                            unlock_task_sighand()
                    list_add()
                find_child_reaper()
                find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                    find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                        for_each_thread()
                    same_thread_group()
                list_for_each_entry()
                for_each_thread()
                BUG_ON()
                likely()
                group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                    rcu_read_lock()
                    check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                        valid_signal()
                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                            SI_FROMUSER()
                        audit_signal_info()
                        same_thread_group()
                        kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                            current_cred()
                            uid_eq()
                            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                unlikely()
                                cap_valid()
                                pr_crit()
                                BUG()
                                security_capable()
                                current_cred()
                        task_session()
                        security_task_kill()
                    rcu_read_unlock()
                    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                        lock_task_sighand()
                        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                SI_FROMUSER()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                        unlock_task_sighand()
                same_thread_group()
                reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                    unlikely()
                    thread_group_empty()
                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                        BUG_ON()
                        task_is_stopped_or_traced()
                        thread_group_empty()
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        spin_lock_irqsave()
                        valid_signal()
                        spin_unlock_irqrestore()
                    list_add()
                    kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                        task_pgrp()
                        task_session()
                        will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                            do_each_pid_task()
                            thread_group_empty()
                            is_global_init()
                            task_pgrp()
                            task_session()
                            while_each_pid_task()
                        has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                            do_each_pid_task()
                            while_each_pid_task()
                list_splice_tail_init()
            kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                task_pgrp()
                task_session()
                will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                    do_each_pid_task()
                    thread_group_empty()
                    is_global_init()
                    task_pgrp()
                    task_session()
                    while_each_pid_task()
                has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                    do_each_pid_task()
                    while_each_pid_task()
            unlikely()
            thread_group_leader()
            thread_group_empty()
            ptrace_reparented()
            do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                BUG_ON()
                task_is_stopped_or_traced()
                thread_group_empty()
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                spin_lock_irqsave()
                valid_signal()
                spin_unlock_irqrestore()
            list_add()
            wake_up_process()
            write_unlock_irq()
            list_for_each_entry_safe()
            list_del_init()
            release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                rcu_read_lock()
                atomic_dec()
                rcu_read_unlock()
                proc_flush_task()
                write_lock_irq()
                ptrace_release_task()
                thread_group_empty()
                do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                    BUG_ON()
                    task_is_stopped_or_traced()
                    thread_group_empty()
                    rcu_read_lock()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_cred_xxx()
                    task_uid()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_clock_t()
                    spin_lock_irqsave()
                    valid_signal()
                    spin_unlock_irqrestore()
                write_unlock_irq()
                release_thread()
                call_rcu()
                delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                    container_of()
                    perf_event_delayed_put()
                    trace_sched_process_free()
                    put_task_struct()
                unlikely()
        proc_exit_connector()
        task_lock()
        mpol_put()
        task_unlock()
        kfree()
        debug_check_no_locks_held()
        exit_io_context()
        free_pipe_info()
        put_page()
        check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
            stack_not_used()
            spin_lock()
            pr_warn()
            task_pid_nr()
            spin_unlock()
        exit_rcu()
        BUG()
        cpu_relax()
    do_group_exit() <void do_group_exit (int exit_code) at exit.c:853>:
        BUG_ON()
        signal_group_exit()
        thread_group_empty()
        spin_lock_irq()
        zap_other_threads() <int zap_other_threads (struct task_struct *p) at signal.c:1188>:
            while_each_thread()
            task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                BUG_ON()
                task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                    unlikely()
                    smp_mb()
                    wake_up_bit()
            signal_wake_up()
        spin_unlock_irq()
        do_exit() <void do_exit (long code) at exit.c:651>:
            TASKS_RCU()
            profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
                blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
            WARN_ON()
            blk_needs_flush_plug()
            unlikely()
            in_interrupt()
            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                local_irq_disable()
                raw_smp_processor_id()
                atomic_cmpxchg()
                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                    cpu_relax()
                console_verbose()
                bust_spinlocks()
                pr_emerg()
                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                    test_bit()
                dump_stack()
                smp_send_stop()
                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                kmsg_dump()
                debug_locks_off()
                console_flush_on_panic()
                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                no_blink() <long no_blink (int state) at panic.c:46>
                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                    raw_cpu_write()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
                mdelay()
                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                    kmsg_dump()
                    machine_emergency_restart()
                disabled_wait()
                local_irq_enable()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            set_fs()
            ptrace_event()
            validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
                kdebug()
                atomic_read()
                read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                    atomic_read()
            pr_alert()
            set_current_state()
            schedule()
            exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
                threadgroup_change_begin()
                thread_group_empty()
                signal_group_exit()
                threadgroup_change_end()
                spin_lock_irq()
                signal_pending()
                signotset()
                retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                    sigandsets()
                    sigisemptyset()
                    while_each_thread()
                    has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                    signal_pending()
                    signal_wake_up()
                unlikely()
                task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                    WARN_ON_ONCE()
                    task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                        BUG_ON()
                        task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                            unlikely()
                            smp_mb()
                            wake_up_bit()
                spin_unlock_irq()
                read_lock()
                do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                    rcu_read_lock()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_cred_xxx()
                    task_uid()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_clock_t()
                    BUG()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                read_unlock()
            smp_mb()
            raw_spin_unlock_wait()
            in_atomic()
            pr_info()
            task_pid_nr()
            preempt_count()
            preempt_count_set()
            sync_mm_rss()
            acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
                task_cputime()
            atomic_dec_and_test()
            hrtimer_cancel()
            exit_itimers()
            setmax_mm_hiwater_rss()
            acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
                down_read()
                up_read()
                spin_lock_irq()
                thread_group_leader()
                task_cputime()
                spin_unlock_irq()
            tty_audit_exit()
            audit_free()
            taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
                taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                    nla_total_size()
                taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                    thread_group_empty()
                    kmem_cache_zalloc()
                    spin_lock_irq()
                    spin_unlock_irq()
                    kmem_cache_free()
                fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                    spin_lock_irqsave()
                    delayacct_add_tsk()
                    spin_unlock_irqrestore()
                raw_cpu_ptr()
                list_empty()
                prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                    genlmsg_new()
                    this_cpu_inc_return()
                    genlmsg_put()
                    genlmsg_put_reply()
                    nlmsg_free()
                mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                    nla_put()
                    nla_nest_start()
                    nla_nest_cancel()
                    nla_reserve()
                    nla_nest_end()
                    nla_data()
                task_pid_nr_ns()
                fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                    delayacct_add_tsk()
                    bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                        BUILD_BUG_ON()
                        ktime_get_ns()
                        do_div()
                        get_seconds()
                        thread_group_leader()
                        task_nice()
                        task_pid_nr_ns()
                        rcu_read_lock()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                            from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        pid_alive()
                        task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                            pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                            task_tgid()
                        rcu_dereference()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_usecs()
                        task_cputime_scaled()
                    xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                        get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                            task_lock()
                            atomic_inc()
                            task_unlock()
                        get_mm_hiwater_rss()
                        get_mm_hiwater_vm()
                        mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                            might_sleep()
                            atomic_dec_and_test()
                            uprobe_clear_state()
                            exit_aio()
                            ksm_exit()
                            khugepaged_exit()
                            exit_mmap()
                            set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                rcu_dereference_raw()
                                get_file()
                                rcu_assign_pointer()
                                fput()
                            list_empty()
                            spin_lock()
                            list_del()
                            spin_unlock()
                            module_put() <void module_put (struct module *module) at module.c:1098>:
                                preempt_disable()
                                atomic_dec_if_positive()
                                WARN_ON()
                                trace_module_put()
                                preempt_enable()
                            mmdrop()
                task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                    pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                    task_tgid()
                send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                    nlmsg_data()
                    nlmsg_hdr()
                    genlmsg_data()
                    genlmsg_end()
                    down_read()
                    list_for_each_entry()
                    list_is_last()
                    skb_clone()
                    genlmsg_unicast()
                    up_read()
                    nlmsg_free()
                    down_write()
                    list_for_each_entry_safe()
                    list_del()
                    kfree()
                    up_write()
                nlmsg_free()
            exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
                mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                    unlikely()
                    exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                        uninitialized_var()
                        fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                            get_user()
                        get_user()
                        handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                            uninitialized_var()
                            get_user()
                            task_pid_vnr()
                            cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                pagefault_disable()
                                futex_atomic_cmpxchg_inatomic()
                                pagefault_enable()
                            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                down_read()
                                fixup_user_fault()
                                up_read()
                            futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                WAKE_Q()
                                get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                    unlikely()
                                    access_ok()
                                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                        should_fail()
                                    get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                        ihold()
                                        futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                            atomic_inc()
                                            smp_mb__after_atomic()
                                        smp_mb()
                                    get_user_pages_fast()
                                    lock_page()
                                    compound_head()
                                    PageSwapCache()
                                    unlock_page()
                                    put_page()
                                    PageAnon()
                                    basepage_index()
                                unlikely()
                                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                    jhash2()
                                hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                    atomic_read()
                                spin_lock()
                                plist_for_each_entry_safe()
                                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                    WARN()
                                    wake_q_add()
                                    smp_wmb()
                                spin_unlock()
                                wake_up_q()
                                put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                    drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                        WARN_ON_ONCE()
                                        iput()
                                        mmdrop()
                        cond_resched()
                    compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                        uninitialized_var()
                        fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                            get_user()
                            compat_ptr()
                        get_user()
                        futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                            ptr_to_compat()
                            compat_ptr()
                        handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                            uninitialized_var()
                            get_user()
                            task_pid_vnr()
                            cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                pagefault_disable()
                                futex_atomic_cmpxchg_inatomic()
                                pagefault_enable()
                            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                down_read()
                                fixup_user_fault()
                                up_read()
                            futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                WAKE_Q()
                                get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                    unlikely()
                                    access_ok()
                                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                        should_fail()
                                    get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                        ihold()
                                        futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                            atomic_inc()
                                            smp_mb__after_atomic()
                                        smp_mb()
                                    get_user_pages_fast()
                                    lock_page()
                                    compound_head()
                                    PageSwapCache()
                                    unlock_page()
                                    put_page()
                                    PageAnon()
                                    basepage_index()
                                unlikely()
                                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                    jhash2()
                                hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                    atomic_read()
                                spin_lock()
                                plist_for_each_entry_safe()
                                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                    WARN()
                                    wake_q_add()
                                    smp_wmb()
                                spin_unlock()
                                wake_up_q()
                                put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                    drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                        WARN_ON_ONCE()
                                        iput()
                                        mmdrop()
                        cond_resched()
                    list_empty()
                    exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                        raw_spin_lock_irq()
                        list_empty()
                        list_entry()
                        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                            jhash2()
                        raw_spin_unlock_irq()
                        spin_lock()
                        spin_unlock()
                        WARN_ON()
                        list_del_init()
                        rt_mutex_unlock()
                    uprobe_free_utask()
                    deactivate_mm()
                    atomic_read()
                    put_user()
                    sys_futex()
                    complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                        task_lock()
                        likely()
                        complete()
                        task_unlock()
                sync_mm_rss()
                down_read()
                up_read()
                xchg()
                atomic_dec_and_test()
                complete()
                set_task_state()
                freezable_schedule()
                atomic_inc()
                BUG_ON()
                task_lock()
                enter_lazy_tlb()
                task_unlock()
                mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                    atomic_read()
                    read_lock()
                    list_for_each_entry()
                    for_each_process()
                    for_each_thread()
                    read_unlock()
                    BUG_ON()
                    get_task_struct()
                    task_lock()
                    task_unlock()
                    put_task_struct()
                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                    might_sleep()
                    atomic_dec_and_test()
                    uprobe_clear_state()
                    exit_aio()
                    ksm_exit()
                    khugepaged_exit()
                    exit_mmap()
                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                        rcu_dereference_raw()
                        get_file()
                        rcu_assign_pointer()
                        fput()
                    list_empty()
                    spin_lock()
                    list_del()
                    spin_unlock()
                    module_put() <void module_put (struct module *module) at module.c:1098>:
                        preempt_disable()
                        atomic_dec_if_positive()
                        WARN_ON()
                        trace_module_put()
                        preempt_enable()
                    mmdrop()
                test_thread_flag()
                exit_oom_victim()
            acct_process() <void acct_process (void) at acct.c:587>:
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                unlikely()
                slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                    acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                        smp_rmb()
                        rcu_read_lock()
                        to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                            container_of()
                        ACCESS_ONCE()
                        rcu_read_unlock()
                        atomic_long_inc_not_zero()
                        cpu_relax()
                        mutex_lock()
                        mutex_unlock()
                        acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                            atomic_long_dec_and_test()
                            kfree_rcu()
                    do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                        override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                            kdebug()
                            atomic_read()
                            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                atomic_read()
                            validate_creds()
                            get_cred()
                            alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                atomic_add()
                            rcu_assign_pointer()
                        check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                            time_is_before_jiffies()
                            vfs_statfs()
                            do_div()
                            pr_info()
                        fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                            strlcpy()
                            ktime_get_ns()
                            nsec_to_AHZ()
                            encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                            encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                            encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                            do_div()
                            get_seconds()
                            spin_lock_irq()
                            old_encode_dev()
                            tty_devnum()
                            jiffies_to_AHZ()
                            cputime_to_jiffies()
                            spin_unlock_irq()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                            from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                            pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                            task_tgid()
                        rcu_read_lock()
                        rcu_dereference()
                        rcu_read_unlock()
                        file_start_write_trylock()
                        file_end_write()
                        revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                            kdebug()
                            atomic_read()
                            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                atomic_read()
                            validate_creds()
                            alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                atomic_add()
                            rcu_assign_pointer()
                            put_cred()
                    mutex_unlock()
                    acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                        atomic_long_dec_and_test()
                        kfree_rcu()
            trace_sched_process_exit()
            exit_sem()
            exit_shm()
            exit_files()
            exit_fs()
            disassociate_ctty()
            exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
                switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                    might_sleep()
                    task_lock()
                    task_unlock()
                    atomic_dec_and_test()
                    free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                        put_mnt_ns()
                        put_uts_ns()
                        put_ipc_ns()
                        put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                            kref_put()
                            free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                container_of()
                                destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                    ns_free_inum()
                                    kfree()
                                    put_user_ns()
                                    call_rcu()
                                    delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                        kmem_cache_free()
                                        container_of()
                        put_net()
                        kmem_cache_free()
            exit_task_work()
            exit_thread()
            perf_event_exit_task()
            cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
                task_css_set()
                list_empty()
                spin_lock_bh()
                css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                    lockdep_assert_held()
                    WARN_ON_ONCE()
                    list_empty()
                    list_for_each_entry_safe()
                    css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                        lockdep_assert_held()
                        WARN_ON_ONCE()
                        css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                            lockdep_assert_held()
                            container_of()
                            list_entry()
                            css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                lockdep_assert_held()
                                list_empty()
                            list_empty()
                            list_del()
                            put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                                lockdep_assert_held()
                                atomic_dec_and_test()
                                for_each_subsys()
                                list_del()
                                css_put()
                                hash_del()
                                list_for_each_entry_safe()
                                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                    container_of()
                                cgroup_put()
                                kfree()
                                kfree_rcu()
                            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                atomic_inc()
                            list_add()
                    list_del_init()
                    css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                        lockdep_assert_held()
                        list_empty()
                    css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                        lockdep_assert_held()
                        list_for_each_entry()
                        cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                            lockdep_assert_held()
                            check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                                notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                    test_bit()
                                cgroup_is_populated()
                                css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                    rcu_read_lock()
                                    css_for_each_child()
                                    rcu_read_unlock()
                                cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                                schedule_work()
                            cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                                spin_lock_irqsave()
                                kernfs_notify()
                                spin_unlock_irqrestore()
                            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                container_of()
                    rcu_assign_pointer()
                    list_add_tail()
                spin_unlock_bh()
                get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                    atomic_inc()
                for_each_subsys_which()
            flush_ptrace_hw_breakpoint()
            preempt_disable()
            preempt_enable()
            exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
                LIST_HEAD()
                write_lock_irq()
                forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                    unlikely()
                    list_empty()
                    exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                        list_for_each_entry_safe()
                        unlikely()
                        send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                            valid_signal()
                            do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                lock_task_sighand()
                                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                        SI_FROMUSER()
                                    task_pid_nr_ns()
                                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                        ns_of_pid()
                                        task_pid()
                                unlock_task_sighand()
                        list_add()
                    find_child_reaper()
                    find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                        find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                            for_each_thread()
                        same_thread_group()
                    list_for_each_entry()
                    for_each_thread()
                    BUG_ON()
                    likely()
                    group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                        rcu_read_lock()
                        check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                            valid_signal()
                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                SI_FROMUSER()
                            audit_signal_info()
                            same_thread_group()
                            kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                                current_cred()
                                uid_eq()
                                ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                    unlikely()
                                    cap_valid()
                                    pr_crit()
                                    BUG()
                                    security_capable()
                                    current_cred()
                            task_session()
                            security_task_kill()
                        rcu_read_unlock()
                        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                            lock_task_sighand()
                            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                    SI_FROMUSER()
                                task_pid_nr_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                            unlock_task_sighand()
                    same_thread_group()
                    reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                        unlikely()
                        thread_group_empty()
                        do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                            BUG_ON()
                            task_is_stopped_or_traced()
                            thread_group_empty()
                            rcu_read_lock()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            task_cred_xxx()
                            task_uid()
                            rcu_read_unlock()
                            task_cputime()
                            cputime_to_clock_t()
                            spin_lock_irqsave()
                            valid_signal()
                            spin_unlock_irqrestore()
                        list_add()
                        kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                            task_pgrp()
                            task_session()
                            will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                                do_each_pid_task()
                                thread_group_empty()
                                is_global_init()
                                task_pgrp()
                                task_session()
                                while_each_pid_task()
                            has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                                do_each_pid_task()
                                while_each_pid_task()
                    list_splice_tail_init()
                kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                    task_pgrp()
                    task_session()
                    will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                        do_each_pid_task()
                        thread_group_empty()
                        is_global_init()
                        task_pgrp()
                        task_session()
                        while_each_pid_task()
                    has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                        do_each_pid_task()
                        while_each_pid_task()
                unlikely()
                thread_group_leader()
                thread_group_empty()
                ptrace_reparented()
                do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                    BUG_ON()
                    task_is_stopped_or_traced()
                    thread_group_empty()
                    rcu_read_lock()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_cred_xxx()
                    task_uid()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_clock_t()
                    spin_lock_irqsave()
                    valid_signal()
                    spin_unlock_irqrestore()
                list_add()
                wake_up_process()
                write_unlock_irq()
                list_for_each_entry_safe()
                list_del_init()
                release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                    rcu_read_lock()
                    atomic_dec()
                    rcu_read_unlock()
                    proc_flush_task()
                    write_lock_irq()
                    ptrace_release_task()
                    thread_group_empty()
                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                        BUG_ON()
                        task_is_stopped_or_traced()
                        thread_group_empty()
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        spin_lock_irqsave()
                        valid_signal()
                        spin_unlock_irqrestore()
                    write_unlock_irq()
                    release_thread()
                    call_rcu()
                    delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                        container_of()
                        perf_event_delayed_put()
                        trace_sched_process_free()
                        put_task_struct()
                    unlikely()
            proc_exit_connector()
            task_lock()
            mpol_put()
            task_unlock()
            kfree()
            debug_check_no_locks_held()
            exit_io_context()
            free_pipe_info()
            put_page()
            check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
                stack_not_used()
                spin_lock()
                pr_warn()
                task_pid_nr()
                spin_unlock()
            exit_rcu()
            BUG()
            cpu_relax()
    task_pid_vnr()
    check_unshare_flags() <int check_unshare_flags (unsigned long unshare_flags) at fork.c:1882>:
        thread_group_empty()
        atomic_read()
        current_is_single_threaded()
    unshare_fs() <int unshare_fs (unsigned long unshare_flags, struct fs_struct **new_fsp) at fork.c:1914>:
        copy_fs_struct()
    unshare_fd() <int unshare_fd (unsigned long unshare_flags, struct files_struct **new_fdp) at fork.c:1935>:
        atomic_read()
        dup_fd()
    unshare_userns() <int unshare_userns (unsigned long unshare_flags, struct cred **new_cred) at user_namespace.c:118>:
        prepare_creds() <struct cred *prepare_creds (void) at cred.c:243>:
            validate_process_creds()
            kmem_cache_alloc()
            kdebug()
            atomic_set()
            set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
                atomic_set()
            get_group_info()
            get_uid()
            get_user_ns()
            key_get()
            security_prepare_creds()
            validate_creds()
            abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
                kdebug()
                atomic_read()
                read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                    atomic_read()
                BUG_ON()
                put_cred()
        create_user_ns() <int create_user_ns (struct cred *new) at user_namespace.c:60>:
            current_chrooted()
            kuid_has_mapping()
            kgid_has_mapping()
            kmem_cache_zalloc()
            ns_alloc_inum()
            kmem_cache_free()
            atomic_set()
            mutex_lock()
            mutex_unlock()
            set_cred_user_ns() <void set_cred_user_ns (struct cred *cred, struct user_namespace *user_ns) at user_namespace.c:33>:
                key_put()
            init_rwsem()
        put_cred()
    unshare_nsproxy_namespaces() <int unshare_nsproxy_namespaces (unsigned long unshare_flags, struct nsproxy **new_nsp, struct cred *new_cred, struct fs_struct *new_fs) at nsproxy.c:176>:
        current_user_ns()
        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
            unlikely()
            cap_valid()
            pr_crit()
            BUG()
            security_capable()
            current_cred()
        create_new_namespaces() <struct nsproxy *create_new_namespaces (unsigned long flags, struct task_struct *tsk, struct user_namespace *user_ns, struct fs_struct *new_fs) at nsproxy.c:59>:
            create_nsproxy() <inline struct nsproxy *create_nsproxy (void) at nsproxy.c:44>:
                kmem_cache_alloc()
                atomic_set()
            ERR_PTR()
            copy_mnt_ns()
            IS_ERR()
            PTR_ERR()
            copy_utsname() <struct uts_namespace *copy_utsname (unsigned long flags, struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:66>:
                BUG_ON()
                get_uts_ns()
                clone_uts_ns() <struct uts_namespace *clone_uts_ns (struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:35>:
                    create_uts_ns() <struct uts_namespace *create_uts_ns (void) at utsname.c:20>:
                        kmalloc()
                        kref_init()
                    ERR_PTR()
                    ns_alloc_inum()
                    kfree()
                    down_read()
                    get_user_ns()
                    up_read()
                put_uts_ns()
            copy_ipcs()
            copy_pid_ns() <struct pid_namespace *copy_pid_ns (unsigned long flags, struct user_namespace *user_ns, struct pid_namespace *old_ns) at pid_namespace.c:153>:
                get_pid_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                ERR_PTR()
                create_pid_namespace() <struct pid_namespace *create_pid_namespace (struct user_namespace *user_ns, struct pid_namespace *parent_pid_ns) at pid_namespace.c:82>:
                    kmem_cache_zalloc()
                    kzalloc()
                    create_pid_cachep() <struct kmem_cache *create_pid_cachep (int nr_ids) at pid_namespace.c:38>:
                        mutex_lock()
                        list_for_each_entry()
                        kmalloc()
                        kmem_cache_create()
                        list_add()
                        mutex_unlock()
                        kfree()
                    ns_alloc_inum()
                    kref_init()
                    get_pid_ns()
                    get_user_ns()
                    INIT_WORK()
                    proc_cleanup_work() <void proc_cleanup_work (struct work_struct *work) at pid_namespace.c:73>:
                        container_of()
                        pid_ns_release_proc()
                    set_bit()
                    atomic_set()
                    kfree()
                    kmem_cache_free()
                    ERR_PTR()
            copy_net_ns()
            put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                kref_put()
                free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                    container_of()
                    destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                        ns_free_inum()
                        kfree()
                        put_user_ns()
                        call_rcu()
                        delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                            kmem_cache_free()
                            container_of()
            put_ipc_ns()
            put_uts_ns()
            put_mnt_ns()
            kmem_cache_free()
        IS_ERR()
        PTR_ERR()
    exit_sem()
    exit_shm()
    shm_init_task()
    switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
        might_sleep()
        task_lock()
        task_unlock()
        atomic_dec_and_test()
        free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
            put_mnt_ns()
            put_uts_ns()
            put_ipc_ns()
            put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                kref_put()
                free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                    container_of()
                    destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                        ns_free_inum()
                        kfree()
                        put_user_ns()
                        call_rcu()
                        delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                            kmem_cache_free()
                            container_of()
            put_net()
            kmem_cache_free()
    task_lock()
    spin_lock()
    spin_unlock()
    task_unlock()
    commit_creds() <int commit_creds (struct cred *new) at cred.c:422>:
        kdebug()
        atomic_read()
        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
            atomic_read()
        BUG_ON()
        validate_creds()
        get_cred()
        uid_eq()
        gid_eq()
        cred_cap_issubset() <bool cred_cap_issubset (const struct cred *set, const struct cred *subset) at cred.c:383>:
            cap_issubset()
            uid_eq()
        set_dumpable()
        smp_wmb()
        key_fsuid_changed()
        key_fsgid_changed()
        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
            atomic_add()
        atomic_inc()
        rcu_assign_pointer()
        atomic_dec()
        proc_id_connector()
        put_cred()
    put_cred()
    put_files_struct()
    free_fs_struct()
    sys_rt_sigpending()
    siginitset()
    set_current_blocked() <void set_current_blocked (sigset_t *newset) at signal.c:2478>:
        sigdelsetmask()
    current_user_ns()
    make_kgid() <kgid_t make_kgid (struct user_namespace *ns, gid_t gid) at user_namespace.c:307>:
        KGIDT_INIT()
        map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
            smp_rmb()
    gid_valid()
    prepare_creds() <struct cred *prepare_creds (void) at cred.c:243>:
        validate_process_creds()
        kmem_cache_alloc()
        kdebug()
        atomic_set()
        set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
            atomic_set()
        get_group_info()
        get_uid()
        get_user_ns()
        key_get()
        security_prepare_creds()
        validate_creds()
        abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
            BUG_ON()
            put_cred()
    current_cred()
    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
        unlikely()
        cap_valid()
        pr_crit()
        BUG()
        security_capable()
        current_cred()
    gid_eq()
    abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
        kdebug()
        atomic_read()
        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
            atomic_read()
        BUG_ON()
        put_cred()
    make_kuid() <kuid_t make_kuid (struct user_namespace *ns, uid_t uid) at user_namespace.c:239>:
        KUIDT_INIT()
        map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
            smp_rmb()
    uid_valid()
    uid_eq()
    set_user() <int set_user (struct cred *new) at sys.c:421>:
        alloc_uid() <struct user_struct *alloc_uid (kuid_t uid) at user.c:171>:
            uidhashentry()
            spin_lock_irq()
            uid_hash_find() <struct user_struct *uid_hash_find (kuid_t uid, struct hlist_head *hashent) at user.c:112>:
                hlist_for_each_entry()
                uid_eq()
                atomic_inc()
            spin_unlock_irq()
            kmem_cache_zalloc()
            atomic_set()
            key_put()
            kmem_cache_free()
            uid_hash_insert() <void uid_hash_insert (struct user_struct *up, struct hlist_head *hashent) at user.c:102>:
                hlist_add_head()
        atomic_read()
        rlimit()
        free_uid() <void free_uid (struct user_struct *up) at user.c:157>:
            local_irq_save()
            atomic_dec_and_lock()
            free_user() <void free_user (struct user_struct *up, unsigned long flags) at user.c:130>:
                uid_hash_remove() <void uid_hash_remove (struct user_struct *up) at user.c:107>:
                    hlist_del_init()
                spin_unlock_irqrestore()
                key_put()
                kmem_cache_free()
            local_irq_restore()
    security_task_fix_setuid()
    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
    do_sys_times() <void do_sys_times (struct tms *tms) at sys.c:882>:
        thread_group_cputime_adjusted()
        cputime_to_clock_t()
    copy_to_user()
    force_successful_syscall_return()
    jiffies_64_to_clock_t()
    get_jiffies_64()
    task_pgrp()
    find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
        find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
            RCU_LOCKDEP_WARN()
            rcu_read_lock_held()
            pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                rcu_dereference_check()
                hlist_first_rcu()
                lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                    lockdep_is_held()
                hlist_entry()
            find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                hlist_for_each_entry_rcu()
                pid_hashfn()
                container_of()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
    security_task_getpgid()
    pid_vnr() <pid_t pid_vnr (struct pid *pid) at pid.c:514>:
        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
    rcu_read_unlock()
    task_session()
    security_task_getsid()
    down_read()
    utsname()
    up_read()
    override_release() <int override_release (char __user *release, size_t len) at sys.c:1115>:
        clamp_t()
        scnprintf()
        copy_to_user()
    override_architecture()
    access_ok()
    xchg()
    do_sysinfo() <int do_sysinfo (struct sysinfo *info) at sys.c:2293>:
        get_monotonic_boottime()
        get_avenrun()
        si_meminfo()
        si_swapinfo()
    copy_from_user()
    get_user()
    do_sysctl() <ssize_t do_sysctl (int __user *args_name, int nlen, void __user *oldval, size_t oldlen, void __user *newval, size_t newlen) at sysctl_binary.c:1401>:
        get_user()
        warn_on_bintable() <void warn_on_bintable (const int *name, int nlen) at sysctl_binary.c:1388>:
            deprecated_sysctl_warning() <void deprecated_sysctl_warning (const int *name, int nlen) at sysctl_binary.c:1350>:
                printk_ratelimit()
                printk()
        binary_sysctl() <ssize_t binary_sysctl (const int *name, int nlen, void __user *oldval, size_t oldlen, void __user *newval, size_t newlen) at sysctl_binary.c:1341>:
            sysctl_getname() <char *sysctl_getname (const int *name, int nlen, const struct bin_table **tablep) at sysctl_binary.c:1278>:
                ERR_PTR()
                get_sysctl() <const struct bin_table *get_sysctl (const int *name, int nlen, char *path) at sysctl_binary.c:1223>:
                    ERR_PTR()
                    dev_get_by_index()
                    dev_put()
                IS_ERR()
                ERR_CAST()
            PTR_ERR()
            IS_ERR()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
            file_open_root()
            fput()
    put_user()
    sys_setgid()
    low2highgid()
    sys_setuid()
    low2highuid()
    sys_setfsuid()
    sys_setfsgid()
SYSCALL_DEFINE2() <SYSCALL_DEFINE2 (setgroups16, int, gidsetsize, old_gid_t __user *, grouplist) at uid16.c:174>:
    cap_validate_magic() <int cap_validate_magic (cap_user_header_t header, unsigned *tocopy) at capability.c:81>:
        get_user()
        warn_legacy_capability_use() <void warn_legacy_capability_use (void) at capability.c:45>:
            pr_info_once()
            get_task_comm()
        warn_deprecated_v2() <void warn_deprecated_v2 (void) at capability.c:69>:
            pr_info_once()
            get_task_comm()
        put_user()
    get_user()
    cap_get_target_pid() <inline int cap_get_target_pid (pid_t pid, kernel_cap_t *pEp, kernel_cap_t *pIp, kernel_cap_t *pPp) at capability.c:117>:
        task_pid_vnr()
        rcu_read_lock()
        find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
            find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                RCU_LOCKDEP_WARN()
                rcu_read_lock_held()
                pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                    rcu_dereference_check()
                    hlist_first_rcu()
                    lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                        lockdep_is_held()
                    hlist_entry()
                find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                    hlist_for_each_entry_rcu()
                    pid_hashfn()
                    container_of()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
        security_capget()
        rcu_read_unlock()
    copy_to_user()
    task_pid_vnr()
    copy_from_user()
    prepare_creds() <struct cred *prepare_creds (void) at cred.c:243>:
        validate_process_creds()
        kmem_cache_alloc()
        kdebug()
        atomic_set()
        set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
            atomic_set()
        get_group_info()
        get_uid()
        get_user_ns()
        key_get()
        security_prepare_creds()
        validate_creds()
        abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
            BUG_ON()
            put_cred()
    security_capset()
    current_cred()
    audit_log_capset()
    commit_creds() <int commit_creds (struct cred *new) at cred.c:422>:
        kdebug()
        atomic_read()
        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
            atomic_read()
        BUG_ON()
        validate_creds()
        get_cred()
        uid_eq()
        gid_eq()
        cred_cap_issubset() <bool cred_cap_issubset (const struct cred *set, const struct cred *subset) at cred.c:383>:
            cap_issubset()
            uid_eq()
        set_dumpable()
        smp_wmb()
        key_fsuid_changed()
        key_fsgid_changed()
        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
            atomic_add()
        atomic_inc()
        rcu_assign_pointer()
        atomic_dec()
        proc_id_connector()
        put_cred()
    abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
        kdebug()
        atomic_read()
        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
            atomic_read()
        BUG_ON()
        put_cred()
    unlikely()
    groups_to_user() <int groups_to_user (gid_t __user *grouplist, const struct group_info *group_info) at groups.c:64>:
        current_user_ns()
        from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
            from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                    smp_rmb()
        GROUP_AT()
        put_user()
    may_setgroups() <bool may_setgroups (void) at groups.c:214>:
        current_user_ns()
        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
            unlikely()
            cap_valid()
            pr_crit()
            BUG()
            security_capable()
            current_cred()
        userns_may_setgroups() <bool userns_may_setgroups (const struct user_namespace *ns) at user_namespace.c:925>:
            mutex_lock()
            mutex_unlock()
    groups_alloc() <struct group_info *groups_alloc (int gidsetsize) at groups.c:12>:
        kmalloc()
        atomic_set()
        free_page()
        kfree()
    groups_from_user() <int groups_from_user (struct group_info *group_info, gid_t __user *grouplist) at groups.c:81>:
        current_user_ns()
        get_user()
        make_kgid() <kgid_t make_kgid (struct user_namespace *ns, gid_t gid) at user_namespace.c:307>:
            KGIDT_INIT()
            map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
                smp_rmb()
        gid_valid()
        GROUP_AT()
    put_group_info()
    set_current_groups() <int set_current_groups (struct group_info *group_info) at groups.c:176>:
        prepare_creds() <struct cred *prepare_creds (void) at cred.c:243>:
            validate_process_creds()
            kmem_cache_alloc()
            kdebug()
            atomic_set()
            set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
                atomic_set()
            get_group_info()
            get_uid()
            get_user_ns()
            key_get()
            security_prepare_creds()
            validate_creds()
            abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
                kdebug()
                atomic_read()
                read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                    atomic_read()
                BUG_ON()
                put_cred()
        set_groups() <void set_groups (struct cred *new, struct group_info *group_info) at groups.c:159>:
            put_group_info()
            groups_sort() <void groups_sort (struct group_info *group_info) at groups.c:104>:
                GROUP_AT()
                gid_gt()
            get_group_info()
        commit_creds() <int commit_creds (struct cred *new) at cred.c:422>:
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
            BUG_ON()
            validate_creds()
            get_cred()
            uid_eq()
            gid_eq()
            cred_cap_issubset() <bool cred_cap_issubset (const struct cred *set, const struct cred *subset) at cred.c:383>:
                cap_issubset()
                uid_eq()
            set_dumpable()
            smp_wmb()
            key_fsuid_changed()
            key_fsgid_changed()
            alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                atomic_add()
            atomic_inc()
            rcu_assign_pointer()
            atomic_dec()
            proc_id_connector()
            put_cred()
    num_online_cpus()
    synchronize_sched()
    capable() <bool capable (int cap) at capability.c:401>:
        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
            unlikely()
            cap_valid()
            pr_crit()
            BUG()
            security_capable()
            current_cred()
    strncpy_from_user()
    mutex_lock_interruptible()
    find_module() <struct module *find_module (const char *name) at module.c:604>:
        module_assert_mutex() <void module_assert_mutex (void) at module.c:255>:
            lockdep_assert_held()
        find_module_all() <struct module *find_module_all (const char *name, size_t len, bool even_unformed) at module.c:588>:
            module_assert_mutex_or_preempt() <void module_assert_mutex_or_preempt (void) at module.c:260>:
                unlikely()
                WARN_ON()
                rcu_read_lock_sched_held()
                lockdep_is_held()
            list_for_each_entry()
    list_empty()
    pr_debug()
    try_force_unload() <inline int try_force_unload (unsigned int flags) at module.c:875>:
        add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
            pr_warn()
            set_bit()
    try_stop_module() <int try_stop_module (struct module *mod, int flags, int *forced) at module.c:896>:
        try_release_module_ref() <int try_release_module_ref (struct module *mod) at module.c:882>:
            atomic_sub_return()
            BUG_ON()
            atomic_add_unless()
        try_force_unload() <inline int try_force_unload (unsigned int flags) at module.c:875>:
            add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
                pr_warn()
                set_bit()
    mutex_unlock()
    blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
    ftrace_release_mod()
    async_synchronize_full() <void async_synchronize_full (void) at async.c:237>:
        async_synchronize_full_domain() <void async_synchronize_full_domain (struct async_domain *domain) at async.c:268>:
            async_synchronize_cookie_domain() <void async_synchronize_cookie_domain (async_cookie_t cookie, struct async_domain *domain) at async.c:283>:
                uninitialized_var()
                pr_debug()
                task_pid_nr()
                ktime_get()
                wait_event()
                lowest_in_progress() <async_cookie_t lowest_in_progress (struct async_domain *domain) at async.c:85>:
                    spin_lock_irqsave()
                    list_empty()
                    list_first_entry()
                    spin_unlock_irqrestore()
                ktime_sub()
                ktime_to_ns()
    strlcpy()
    free_module() <void free_module (struct module *mod) at module.c:1988>:
        trace_module_free()
        mod_sysfs_teardown() <void mod_sysfs_teardown (struct module *mod) at module.c:1843>:
            del_usage_links() <void del_usage_links (struct module *mod) at module.c:1834>:
                mutex_lock()
                list_for_each_entry()
                sysfs_remove_link()
                mutex_unlock()
            module_remove_modinfo_attrs() <void module_remove_modinfo_attrs (struct module *mod) at module.c:1830>:
                sysfs_remove_file()
                kfree()
            module_param_sysfs_remove() <void module_param_sysfs_remove (struct module *mod) at params.c:778>:
                sysfs_remove_group()
                free_module_param_attrs() <void free_module_param_attrs (struct module_kobject *mk) at params.c:726>:
                    kfree()
            kobject_put()
            mod_sysfs_fini() <void mod_sysfs_fini (struct module *mod) at module.c:1826>:
                remove_notes_attrs() <inline void remove_notes_attrs (struct module *mod) at module.c:1647>:
                    free_notes_attrs() <void free_notes_attrs (struct module_notes_attrs *notes_attrs, unsigned int i) at module.c:1554>:
                        sysfs_remove_bin_file()
                        kobject_put()
                        kfree()
                remove_sect_attrs() <inline void remove_sect_attrs (struct module *mod) at module.c:1638>:
                    sysfs_remove_group()
                    free_sect_attrs() <void free_sect_attrs (struct module_sect_attrs *sect_attrs) at module.c:1458>:
                        kfree()
                mod_kobject_put() <void mod_kobject_put (struct module *mod) at module.c:1722>:
                    DECLARE_COMPLETION_ONSTACK()
                    kobject_put()
                    wait_for_completion()
        mutex_lock()
        mutex_unlock()
        ddebug_remove_module()
        module_arch_cleanup() <void __weak module_arch_cleanup (struct module *mod) at module.c:1979>
        module_unload_free() <inline void module_unload_free (struct module *mod) at module.c:1119>:
            mutex_lock()
            list_for_each_entry_safe()
            pr_debug()
            module_put() <void module_put (struct module *module) at module.c:1098>:
                preempt_disable()
                atomic_dec_if_positive()
                WARN_ON()
                trace_module_put()
                preempt_enable()
            list_del()
            kfree()
            mutex_unlock()
        destroy_params() <void destroy_params (const struct kernel_param *params, unsigned num) at params.c:789>:
        list_del_rcu()
        mod_tree_remove() <void mod_tree_remove (struct module *mod) at module.c:213>:
            mod_tree_remove_init() <void mod_tree_remove_init (struct module *mod) at module.c:212>:
        module_bug_cleanup()
        synchronize_sched()
        disable_ro_nx() <void disable_ro_nx (const struct module_layout *layout) at module.c:1969>:
            frob_text() <void frob_text (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1866>:
                BUG_ON()
            frob_rodata() <void frob_rodata (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1875>:
                BUG_ON()
            frob_writable_data() <void frob_writable_data (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1885>:
                BUG_ON()
        module_arch_freeing_init() <void __weak module_arch_freeing_init (struct module *mod) at module.c:1983>
        module_memfree() <void __weak module_memfree (void *module_region) at module.c:1974>:
            vfree()
        kfree()
        percpu_modfree() <inline void percpu_modfree (struct module *mod) at module.c:710>:
            free_percpu()
        lockdep_free_key_range()
        update_protections()
    proc_ns_fget()
    IS_ERR()
    PTR_ERR()
    get_proc_ns()
    file_inode()
    create_new_namespaces() <struct nsproxy *create_new_namespaces (unsigned long flags, struct task_struct *tsk, struct user_namespace *user_ns, struct fs_struct *new_fs) at nsproxy.c:59>:
        create_nsproxy() <inline struct nsproxy *create_nsproxy (void) at nsproxy.c:44>:
            kmem_cache_alloc()
            atomic_set()
        ERR_PTR()
        copy_mnt_ns()
        IS_ERR()
        PTR_ERR()
        copy_utsname() <struct uts_namespace *copy_utsname (unsigned long flags, struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:66>:
            BUG_ON()
            get_uts_ns()
            clone_uts_ns() <struct uts_namespace *clone_uts_ns (struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:35>:
                create_uts_ns() <struct uts_namespace *create_uts_ns (void) at utsname.c:20>:
                    kmalloc()
                    kref_init()
                ERR_PTR()
                ns_alloc_inum()
                kfree()
                down_read()
                get_user_ns()
                up_read()
            put_uts_ns()
        copy_ipcs()
        copy_pid_ns() <struct pid_namespace *copy_pid_ns (unsigned long flags, struct user_namespace *user_ns, struct pid_namespace *old_ns) at pid_namespace.c:153>:
            get_pid_ns()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
            ERR_PTR()
            create_pid_namespace() <struct pid_namespace *create_pid_namespace (struct user_namespace *user_ns, struct pid_namespace *parent_pid_ns) at pid_namespace.c:82>:
                kmem_cache_zalloc()
                kzalloc()
                create_pid_cachep() <struct kmem_cache *create_pid_cachep (int nr_ids) at pid_namespace.c:38>:
                    mutex_lock()
                    list_for_each_entry()
                    kmalloc()
                    kmem_cache_create()
                    list_add()
                    mutex_unlock()
                    kfree()
                ns_alloc_inum()
                kref_init()
                get_pid_ns()
                get_user_ns()
                INIT_WORK()
                proc_cleanup_work() <void proc_cleanup_work (struct work_struct *work) at pid_namespace.c:73>:
                    container_of()
                    pid_ns_release_proc()
                set_bit()
                atomic_set()
                kfree()
                kmem_cache_free()
                ERR_PTR()
        copy_net_ns()
        put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
            kref_put()
            free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                container_of()
                destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                    ns_free_inum()
                    kfree()
                    put_user_ns()
                    call_rcu()
                    delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                        kmem_cache_free()
                        container_of()
        put_ipc_ns()
        put_uts_ns()
        put_mnt_ns()
        kmem_cache_free()
    current_user_ns()
    install()
    free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
        put_mnt_ns()
        put_uts_ns()
        put_ipc_ns()
        put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
            kref_put()
            free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                container_of()
                destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                    ns_free_inum()
                    kfree()
                    put_user_ns()
                    call_rcu()
                    delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                        kmem_cache_free()
                        container_of()
        put_net()
        kmem_cache_free()
    switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
        might_sleep()
        task_lock()
        task_unlock()
        atomic_dec_and_test()
        free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
            put_mnt_ns()
            put_uts_ns()
            put_ipc_ns()
            put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                kref_put()
                free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                    container_of()
                    destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                        ns_free_inum()
                        kfree()
                        put_user_ns()
                        call_rcu()
                        delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                            kmem_cache_free()
                            container_of()
            put_net()
            kmem_cache_free()
    fput()
    do_sigpending() <int do_sigpending (void *set, unsigned long sigsetsize) at signal.c:2604>:
        spin_lock_irq()
        sigorsets()
        spin_unlock_irq()
        sigandsets()
    task_tgid_vnr()
    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
    current_uid()
    kill_something_info() <int kill_something_info (int sig, struct siginfo *info, pid_t pid) at signal.c:1374>:
        rcu_read_lock()
        kill_pid_info() <int kill_pid_info (int sig, struct siginfo *info, struct pid *pid) at signal.c:1288>:
            rcu_read_lock()
            pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                rcu_dereference_check()
                hlist_first_rcu()
                lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                    lockdep_is_held()
                hlist_entry()
            group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                rcu_read_lock()
                check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                    valid_signal()
                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                        SI_FROMUSER()
                    audit_signal_info()
                    same_thread_group()
                    kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                        current_cred()
                        uid_eq()
                        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                            unlikely()
                            cap_valid()
                            pr_crit()
                            BUG()
                            security_capable()
                            current_cred()
                    task_session()
                    security_task_kill()
                rcu_read_unlock()
                do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                    lock_task_sighand()
                    send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                            SI_FROMUSER()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                    unlock_task_sighand()
            rcu_read_unlock()
            likely()
        find_vpid() <struct pid *find_vpid (int nr) at pid.c:380>:
            find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                hlist_for_each_entry_rcu()
                pid_hashfn()
                container_of()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
        rcu_read_unlock()
        read_lock()
        task_pgrp()
        for_each_process()
        task_pid_vnr()
        same_thread_group()
        group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
            rcu_read_lock()
            check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                valid_signal()
                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                    SI_FROMUSER()
                audit_signal_info()
                same_thread_group()
                kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                    current_cred()
                    uid_eq()
                    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                        unlikely()
                        cap_valid()
                        pr_crit()
                        BUG()
                        security_capable()
                        current_cred()
                task_session()
                security_task_kill()
            rcu_read_unlock()
            do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                lock_task_sighand()
                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                        SI_FROMUSER()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                unlock_task_sighand()
        read_unlock()
    do_tkill() <int do_tkill (pid_t tgid, pid_t pid, int sig) at signal.c:2890>:
        task_tgid_vnr()
        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                    smp_rmb()
        current_user_ns()
        current_uid()
        do_send_specific() <int do_send_specific (pid_t tgid, pid_t pid, int sig, struct siginfo *info) at signal.c:2861>:
            rcu_read_lock()
            find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
                find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                    RCU_LOCKDEP_WARN()
                    rcu_read_lock_held()
                    pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                        rcu_dereference_check()
                        hlist_first_rcu()
                        lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                            lockdep_is_held()
                        hlist_entry()
                    find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                        hlist_for_each_entry_rcu()
                        pid_hashfn()
                        container_of()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
            task_tgid_vnr()
            check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                valid_signal()
                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                    SI_FROMUSER()
                audit_signal_info()
                same_thread_group()
                kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                    current_cred()
                    uid_eq()
                    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                        unlikely()
                        cap_valid()
                        pr_crit()
                        BUG()
                        security_capable()
                        current_cred()
                task_session()
                security_task_kill()
            do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                lock_task_sighand()
                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                        SI_FROMUSER()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                unlock_task_sighand()
            unlikely()
            rcu_read_unlock()
    do_sigaltstack() <int do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long sp) at signal.c:3091>:
        sas_ss_flags()
        access_ok()
        on_sig_stack()
    current_user_stack_pointer()
    do_sigaction() <int do_sigaction (int sig, struct k_sigaction *act, struct k_sigaction *oact) at signal.c:3047>:
        valid_signal()
        sig_kernel_only()
        spin_lock_irq()
        sigdelsetmask()
        sig_handler_ignored() <int sig_handler_ignored (void __user *handler, int sig) at signal.c:61>:
            sig_kernel_ignore()
        sig_handler() <void __user *sig_handler (struct task_struct *t, int sig) at signal.c:56>:
        flush_sigqueue_mask() <int flush_sigqueue_mask (sigset_t *mask, struct sigpending *s) at signal.c:659>:
            sigandsets()
            sigisemptyset()
            sigandnsets()
            list_for_each_entry_safe()
            list_del_init()
        for_each_thread()
        spin_unlock_irq()
    sigsuspend() <int sigsuspend (sigset_t *set) at signal.c:3506>:
        set_current_blocked() <void set_current_blocked (sigset_t *newset) at signal.c:2478>:
            sigdelsetmask()
        signal_pending()
        schedule()
        set_restore_sigmask()
    rcu_read_lock()
    read_lock()
    find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
        find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
            RCU_LOCKDEP_WARN()
            rcu_read_lock_held()
            pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                rcu_dereference_check()
                hlist_first_rcu()
                lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                    lockdep_is_held()
                hlist_entry()
            find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                hlist_for_each_entry_rcu()
                pid_hashfn()
                container_of()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
    nice_to_rlimit()
    task_nice()
    find_vpid() <struct pid *find_vpid (int nr) at pid.c:380>:
        find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
            hlist_for_each_entry_rcu()
            pid_hashfn()
            container_of()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
    task_pgrp()
    do_each_pid_thread()
    while_each_pid_thread()
    make_kuid() <kuid_t make_kuid (struct user_namespace *ns, uid_t uid) at user_namespace.c:239>:
        KUIDT_INIT()
        map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
            smp_rmb()
    uid_eq()
    find_user() <struct user_struct *find_user (kuid_t uid) at user.c:146>:
        spin_lock_irqsave()
        uid_hash_find() <struct user_struct *uid_hash_find (kuid_t uid, struct hlist_head *hashent) at user.c:112>:
            hlist_for_each_entry()
            uid_eq()
            atomic_inc()
        uidhashentry()
        spin_unlock_irqrestore()
    do_each_thread()
    task_uid()
    while_each_thread()
    free_uid() <void free_uid (struct user_struct *up) at user.c:157>:
        local_irq_save()
        atomic_dec_and_lock()
        free_user() <void free_user (struct user_struct *up, unsigned long flags) at user.c:130>:
            uid_hash_remove() <void uid_hash_remove (struct user_struct *up) at user.c:107>:
                hlist_del_init()
            spin_unlock_irqrestore()
            key_put()
            kmem_cache_free()
        local_irq_restore()
    read_unlock()
    rcu_read_unlock()
    make_kgid() <kgid_t make_kgid (struct user_namespace *ns, gid_t gid) at user_namespace.c:307>:
        KGIDT_INIT()
        map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
            smp_rmb()
    gid_valid()
    gid_eq()
    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
        unlikely()
        cap_valid()
        pr_crit()
        BUG()
        security_capable()
        current_cred()
    uid_valid()
    set_user() <int set_user (struct cred *new) at sys.c:421>:
        alloc_uid() <struct user_struct *alloc_uid (kuid_t uid) at user.c:171>:
            uidhashentry()
            spin_lock_irq()
            uid_hash_find() <struct user_struct *uid_hash_find (kuid_t uid, struct hlist_head *hashent) at user.c:112>:
                hlist_for_each_entry()
                uid_eq()
                atomic_inc()
            spin_unlock_irq()
            kmem_cache_zalloc()
            atomic_set()
            key_put()
            kmem_cache_free()
            uid_hash_insert() <void uid_hash_insert (struct user_struct *up, struct hlist_head *hashent) at user.c:102>:
                hlist_add_head()
        atomic_read()
        rlimit()
        free_uid() <void free_uid (struct user_struct *up) at user.c:157>:
            local_irq_save()
            atomic_dec_and_lock()
            free_user() <void free_user (struct user_struct *up, unsigned long flags) at user.c:130>:
                uid_hash_remove() <void uid_hash_remove (struct user_struct *up) at user.c:107>:
                    hlist_del_init()
                spin_unlock_irqrestore()
                key_put()
                kmem_cache_free()
            local_irq_restore()
    security_task_fix_setuid()
    write_lock_irq()
    thread_group_leader()
    same_thread_group()
    task_session()
    task_pid()
    pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
        rcu_dereference_check()
        hlist_first_rcu()
        lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
            lockdep_is_held()
        hlist_entry()
    security_task_setpgid()
    change_pid() <void change_pid (struct task_struct *task, enum pid_type type, struct pid *pid) at pid.c:420>:
        attach_pid() <void attach_pid (struct task_struct *task, enum pid_type type) at pid.c:389>:
            hlist_add_head_rcu()
    write_unlock_irq()
    down_write()
    utsname()
    uts_proc_notify() <void uts_proc_notify (enum uts_proc proc) at utsname_sysctl.c:124>:
        proc_sys_poll_notify()
    up_write()
    down_read()
    up_read()
    do_prlimit() <int do_prlimit (struct task_struct *tsk, unsigned int resource, struct rlimit *new_rlim, struct rlimit *old_rlim) at sys.c:1360>:
        read_lock()
        task_lock()
        capable() <bool capable (int cap) at capability.c:401>:
            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                unlikely()
                cap_valid()
                pr_crit()
                BUG()
                security_capable()
                current_cred()
        security_task_setrlimit()
        task_unlock()
        update_rlimit_cpu()
        read_unlock()
    task_lock()
    task_unlock()
    sys_setregid()
    low2highgid()
    sys_setreuid()
    low2highuid()
    groups16_to_user() <int groups16_to_user (old_gid_t __user *grouplist, struct group_info *group_info) at uid16.c:111>:
        current_user_ns()
        GROUP_AT()
        high2lowgid()
        from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
            from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                    smp_rmb()
        put_user()
    groups16_from_user() <int groups16_from_user (struct group_info *group_info, old_gid_t __user *grouplist) at uid16.c:129>:
        current_user_ns()
        get_user()
        make_kgid() <kgid_t make_kgid (struct user_namespace *ns, gid_t gid) at user_namespace.c:307>:
            KGIDT_INIT()
            map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
                smp_rmb()
        low2highgid()
        gid_valid()
        GROUP_AT()
SYSCALL_DEFINE3() <SYSCALL_DEFINE3 (getresgid16, old_gid_t __user *, rgidp, old_gid_t __user *, egidp, old_gid_t __user *, sgidp) at uid16.c:84>:
    sys_wait4()
    rcu_read_lock()
    find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
        find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
            RCU_LOCKDEP_WARN()
            rcu_read_lock_held()
            pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                rcu_dereference_check()
                hlist_first_rcu()
                lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                    lockdep_is_held()
                hlist_entry()
            find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                hlist_for_each_entry_rcu()
                pid_hashfn()
                container_of()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
    ptrace_may_access() <bool ptrace_may_access (struct task_struct *task, unsigned int mode) at ptrace.c:287>:
        task_lock()
        task_unlock()
    rcu_read_unlock()
    put_user()
    may_init_module() <int may_init_module (void) at module.c:3324>:
        capable() <bool capable (int cap) at capability.c:401>:
            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                unlikely()
                cap_valid()
                pr_crit()
                BUG()
                security_capable()
                current_cred()
    pr_debug()
    copy_module_from_user() <int copy_module_from_user (const void __user *umod, unsigned long len, struct load_info *info) at module.c:2669>:
        security_kernel_module_from_file()
        copy_chunked_from_user() <int copy_chunked_from_user (void *dst, const void __user *usrc, unsigned long len) at module.c:2653>:
            min()
            copy_from_user()
            cond_resched()
        vfree()
    load_module() <int load_module (struct load_info *info, const char __user *uargs, int flags) at module.c:3425>:
        module_sig_check() <int module_sig_check (struct load_info *info) at module.c:2625>:
            mod_verify_sig() <int mod_verify_sig (const void *mod, unsigned long *_modlen) at module_signing.c:41>:
                pr_devel()
                be32_to_cpu()
                pr_err()
                system_verify_data()
        free_copy() <void free_copy (struct load_info *info) at module.c:2753>:
            vfree()
        elf_header_check() <int elf_header_check (struct load_info *info) at module.c:2632>:
            elf_check_arch()
        layout_and_allocate() <struct module *layout_and_allocate (struct load_info *info, int flags) at module.c:3101>:
            setup_load_info() <struct module *setup_load_info (struct load_info *info, int flags) at module.c:2803>:
                rewrite_section_headers() <int rewrite_section_headers (struct load_info *info, int flags) at module.c:2758>:
                    pr_err()
                    strstarts()
                    find_sec() <unsigned int find_sec (const struct load_info *info, const char *name) at module.c:346>:
                ERR_PTR()
                find_sec() <unsigned int find_sec (const struct load_info *info, const char *name) at module.c:346>:
                pr_warn()
                find_pcpusec() <unsigned int find_pcpusec (struct load_info *info) at module.c:713>:
                    find_sec() <unsigned int find_sec (const struct load_info *info, const char *name) at module.c:346>:
                check_modstruct_version() <inline int check_modstruct_version (Elf_Shdr *sechdrs, unsigned int versindex, struct module *mod) at module.c:1351>:
                    preempt_disable()
                    find_symbol() <const struct kernel_symbol *find_symbol (const char *name, struct module **owner, const unsigned long **crc, bool gplok, bool warn) at module.c:559>:
                        each_symbol_section() <bool each_symbol_section (bool (*fn) (const struct symsearch *arr, struct module *owner, void *data), void *data) at module.c:424>:
                            module_assert_mutex_or_preempt() <void module_assert_mutex_or_preempt (void) at module.c:260>:
                                unlikely()
                                WARN_ON()
                                rcu_read_lock_sched_held()
                                lockdep_is_held()
                            each_symbol_in_section() <bool each_symbol_in_section (const struct symsearch *arr, unsigned int arrsize, struct module *owner, bool (*fn) (const struct symsearch *syms, struct module *owner, void *data), void *data) at module.c:405>:
                                fn()
                            ARRAY_SIZE()
                            fn()
                            list_for_each_entry_rcu()
                        find_symbol_in_section() <bool find_symbol_in_section (const struct symsearch *syms, struct module *owner, void *data) at module.c:541>:
                            cmp_name() <int cmp_name (const void *va, const void *vb) at module.c:533>:
                            check_symbol() <bool check_symbol (const struct symsearch *syms, struct module *owner, unsigned int symnum, void *data) at module.c:499>:
                                pr_warn()
                                symversion()
                        pr_debug()
                    VMLINUX_SYMBOL_STR()
                    module_layout() <void module_layout (struct module *mod, struct modversion_info *ver, struct kernel_param *kp, struct kernel_symbol *ks, struct tracepoint *const *tp) at module.c:4106>
                    preempt_enable()
                    BUG()
                    check_version() <inline int check_version (Elf_Shdr *sechdrs, unsigned int versindex, const char *symname, struct module *mod, const unsigned long *crc, const struct module *crc_owner) at module.c:1341>:
                        try_to_force_load() <int try_to_force_load (struct module *mod, const char *reason) at module.c:1242>:
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            pr_warn()
                            add_taint_module() <inline void add_taint_module (struct module *mod, unsigned flag, enum lockdep_ok lockdep_ok) at module.c:327>:
                                add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
                                    pr_warn()
                                    set_bit()
                        maybe_relocated() <unsigned long maybe_relocated (unsigned long crc, const struct module *crc_owner) at module.c:1256>:
                        pr_debug()
                        pr_warn()
            IS_ERR()
            check_modinfo() <int check_modinfo (struct module *mod, struct load_info *info, int flags) at module.c:2851>:
                get_modinfo() <char *get_modinfo (struct load_info *info, const char *tag) at module.c:2320>:
                    next_string() <char *next_string (char *string, unsigned long *secsize) at module.c:2302>:
                try_to_force_load() <int try_to_force_load (struct module *mod, const char *reason) at module.c:1242>:
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    pr_warn()
                    add_taint_module() <inline void add_taint_module (struct module *mod, unsigned flag, enum lockdep_ok lockdep_ok) at module.c:327>:
                        add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
                            pr_warn()
                            set_bit()
                same_magic() <inline int same_magic (const char *amagic, const char *bmagic, bool has_crcs) at module.c:1358>:
                pr_err()
                add_taint_module() <inline void add_taint_module (struct module *mod, unsigned flag, enum lockdep_ok lockdep_ok) at module.c:327>:
                    add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
                        pr_warn()
                        set_bit()
                pr_warn()
                set_license() <void set_license (struct module *mod, const char *license) at module.c:2287>:
                    license_is_gpl_compatible()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    pr_warn()
                    add_taint_module() <inline void add_taint_module (struct module *mod, unsigned flag, enum lockdep_ok lockdep_ok) at module.c:327>:
                        add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
                            pr_warn()
                            set_bit()
            ERR_PTR()
            module_frob_arch_sections() <int __weak module_frob_arch_sections (Elf_Ehdr *hdr, Elf_Shdr *sechdrs, char *secstrings, struct module *mod) at module.c:3093>
            layout_sections() <void layout_sections (struct module *mod, struct load_info *info) at module.c:2211>:
                pr_debug()
                ARRAY_SIZE()
                strstarts()
                get_offset() <long get_offset (struct module *mod, unsigned int *size, Elf_Shdr *sechdr, unsigned int section) at module.c:2196>:
                    arch_mod_section_prepend() <unsigned int __weak arch_mod_section_prepend (struct module *mod, unsigned int section) at module.c:2188>
                    ALIGN()
                debug_align()
            layout_symtab() <inline void layout_symtab (struct module *mod, struct load_info *info) at module.c:2541>:
                get_offset() <long get_offset (struct module *mod, unsigned int *size, Elf_Shdr *sechdr, unsigned int section) at module.c:2196>:
                    arch_mod_section_prepend() <unsigned int __weak arch_mod_section_prepend (struct module *mod, unsigned int section) at module.c:2188>
                    ALIGN()
                pr_debug()
                is_core_symbol() <bool is_core_symbol (const Elf_Sym *src, const Elf_Shdr *sechdrs, unsigned int shnum, unsigned int pcpundx) at module.c:2419>:
                ALIGN()
                debug_align()
            move_module() <int move_module (struct module *mod, struct load_info *info) at module.c:2971>:
                module_alloc() <void *__weak module_alloc (unsigned long size) at module.c:2567>:
                    vmalloc_exec()
                kmemleak_not_leak()
                kmemleak_ignore()
                module_memfree() <void __weak module_memfree (void *module_region) at module.c:1974>:
                    vfree()
                pr_debug()
            kmemleak_load_module() <inline void kmemleak_load_module (const struct module *mod, const struct load_info *info) at module.c:2593>:
                kmemleak_scan_area()
        IS_ERR()
        PTR_ERR()
        add_unformed_module() <int add_unformed_module (struct module *mod) at module.c:3337>:
            mutex_lock()
            find_module_all() <struct module *find_module_all (const char *name, size_t len, bool even_unformed) at module.c:588>:
                module_assert_mutex_or_preempt() <void module_assert_mutex_or_preempt (void) at module.c:260>:
                    unlikely()
                    WARN_ON()
                    rcu_read_lock_sched_held()
                    lockdep_is_held()
                list_for_each_entry()
            mutex_unlock()
            wait_event_interruptible()
            finished_loading() <bool finished_loading (const char *name) at module.c:3174>:
                sched_annotate_sleep()
                mutex_lock()
                find_module_all() <struct module *find_module_all (const char *name, size_t len, bool even_unformed) at module.c:588>:
                    module_assert_mutex_or_preempt() <void module_assert_mutex_or_preempt (void) at module.c:260>:
                        unlikely()
                        WARN_ON()
                        rcu_read_lock_sched_held()
                        lockdep_is_held()
                    list_for_each_entry()
                mutex_unlock()
            mod_update_bounds() <void mod_update_bounds (struct module *mod) at module.c:244>:
            list_add_rcu()
            mod_tree_insert() <void mod_tree_insert (struct module *mod) at module.c:211>:
        free_module() <void free_module (struct module *mod) at module.c:1988>:
            trace_module_free()
            mod_sysfs_teardown() <void mod_sysfs_teardown (struct module *mod) at module.c:1843>:
                del_usage_links() <void del_usage_links (struct module *mod) at module.c:1834>:
                    mutex_lock()
                    list_for_each_entry()
                    sysfs_remove_link()
                    mutex_unlock()
                module_remove_modinfo_attrs() <void module_remove_modinfo_attrs (struct module *mod) at module.c:1830>:
                    sysfs_remove_file()
                    kfree()
                module_param_sysfs_remove() <void module_param_sysfs_remove (struct module *mod) at params.c:778>:
                    sysfs_remove_group()
                    free_module_param_attrs() <void free_module_param_attrs (struct module_kobject *mk) at params.c:726>:
                        kfree()
                kobject_put()
                mod_sysfs_fini() <void mod_sysfs_fini (struct module *mod) at module.c:1826>:
                    remove_notes_attrs() <inline void remove_notes_attrs (struct module *mod) at module.c:1647>:
                        free_notes_attrs() <void free_notes_attrs (struct module_notes_attrs *notes_attrs, unsigned int i) at module.c:1554>:
                            sysfs_remove_bin_file()
                            kobject_put()
                            kfree()
                    remove_sect_attrs() <inline void remove_sect_attrs (struct module *mod) at module.c:1638>:
                        sysfs_remove_group()
                        free_sect_attrs() <void free_sect_attrs (struct module_sect_attrs *sect_attrs) at module.c:1458>:
                            kfree()
                    mod_kobject_put() <void mod_kobject_put (struct module *mod) at module.c:1722>:
                        DECLARE_COMPLETION_ONSTACK()
                        kobject_put()
                        wait_for_completion()
            mutex_lock()
            mutex_unlock()
            ddebug_remove_module()
            module_arch_cleanup() <void __weak module_arch_cleanup (struct module *mod) at module.c:1979>
            module_unload_free() <inline void module_unload_free (struct module *mod) at module.c:1119>:
                mutex_lock()
                list_for_each_entry_safe()
                pr_debug()
                module_put() <void module_put (struct module *module) at module.c:1098>:
                    preempt_disable()
                    atomic_dec_if_positive()
                    WARN_ON()
                    trace_module_put()
                    preempt_enable()
                list_del()
                kfree()
                mutex_unlock()
            destroy_params() <void destroy_params (const struct kernel_param *params, unsigned num) at params.c:789>:
            list_del_rcu()
            mod_tree_remove() <void mod_tree_remove (struct module *mod) at module.c:213>:
                mod_tree_remove_init() <void mod_tree_remove_init (struct module *mod) at module.c:212>:
            module_bug_cleanup()
            synchronize_sched()
            disable_ro_nx() <void disable_ro_nx (const struct module_layout *layout) at module.c:1969>:
                frob_text() <void frob_text (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1866>:
                    BUG_ON()
                frob_rodata() <void frob_rodata (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1875>:
                    BUG_ON()
                frob_writable_data() <void frob_writable_data (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1885>:
                    BUG_ON()
            module_arch_freeing_init() <void __weak module_arch_freeing_init (struct module *mod) at module.c:1983>
            module_memfree() <void __weak module_memfree (void *module_region) at module.c:1974>:
                vfree()
            kfree()
            percpu_modfree() <inline void percpu_modfree (struct module *mod) at module.c:710>:
                free_percpu()
            lockdep_free_key_range()
            update_protections()
        pr_notice_once()
        add_taint_module() <inline void add_taint_module (struct module *mod, unsigned flag, enum lockdep_ok lockdep_ok) at module.c:327>:
            add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
                pr_warn()
                set_bit()
        percpu_modalloc() <int percpu_modalloc (struct module *mod, struct load_info *info) at module.c:703>:
            pr_warn()
        module_unload_init() <inline int module_unload_init (struct module *mod) at module.c:1129>:
            atomic_set()
            INIT_LIST_HEAD()
            atomic_inc()
        init_param_lock() <void init_param_lock (struct module *mod) at module.c:1838>:
            mutex_init()
        find_module_sections() <int find_module_sections (struct module *mod, struct load_info *info) at module.c:2885>:
            section_objs() <void *section_objs (const struct load_info *info, const char *name, size_t object_size, unsigned int *num) at module.c:368>:
                find_sec() <unsigned int find_sec (const struct load_info *info, const char *name) at module.c:346>:
            section_addr() <void *section_addr (const struct load_info *info, const char *name) at module.c:361>:
                find_sec() <unsigned int find_sec (const struct load_info *info, const char *name) at module.c:346>:
            find_sec() <unsigned int find_sec (const struct load_info *info, const char *name) at module.c:346>:
            pr_warn()
        check_module_license_and_versions() <int check_module_license_and_versions (struct module *mod) at module.c:3034>:
            add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
                pr_warn()
                set_bit()
            add_taint_module() <inline void add_taint_module (struct module *mod, unsigned flag, enum lockdep_ok lockdep_ok) at module.c:327>:
                add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
                    pr_warn()
                    set_bit()
            try_to_force_load() <int try_to_force_load (struct module *mod, const char *reason) at module.c:1242>:
                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                    test_bit()
                pr_warn()
                add_taint_module() <inline void add_taint_module (struct module *mod, unsigned flag, enum lockdep_ok lockdep_ok) at module.c:327>:
                    add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
                        pr_warn()
                        set_bit()
        setup_modinfo() <void setup_modinfo (struct module *mod, struct load_info *info) at module.c:2334>:
            get_modinfo() <char *get_modinfo (struct load_info *info, const char *tag) at module.c:2320>:
                next_string() <char *next_string (char *string, unsigned long *secsize) at module.c:2302>:
        simplify_symbols() <int simplify_symbols (struct module *mod, const struct load_info *info) at module.c:2095>:
            pr_debug()
            pr_warn()
            resolve_symbol_wait() <const struct kernel_symbol *resolve_symbol_wait (struct module *mod, const struct load_info *info, const char *name) at module.c:1409>:
                wait_event_interruptible_timeout()
                IS_ERR()
                resolve_symbol() <const struct kernel_symbol *resolve_symbol (struct module *mod, const struct load_info *info, const char *name, char ownername[]) at module.c:1366>:
                    sched_annotate_sleep()
                    mutex_lock()
                    find_symbol() <const struct kernel_symbol *find_symbol (const char *name, struct module **owner, const unsigned long **crc, bool gplok, bool warn) at module.c:559>:
                        each_symbol_section() <bool each_symbol_section (bool (*fn) (const struct symsearch *arr, struct module *owner, void *data), void *data) at module.c:424>:
                            module_assert_mutex_or_preempt() <void module_assert_mutex_or_preempt (void) at module.c:260>:
                                unlikely()
                                WARN_ON()
                                rcu_read_lock_sched_held()
                                lockdep_is_held()
                            each_symbol_in_section() <bool each_symbol_in_section (const struct symsearch *arr, unsigned int arrsize, struct module *owner, bool (*fn) (const struct symsearch *syms, struct module *owner, void *data), void *data) at module.c:405>:
                                fn()
                            ARRAY_SIZE()
                            fn()
                            list_for_each_entry_rcu()
                        find_symbol_in_section() <bool find_symbol_in_section (const struct symsearch *syms, struct module *owner, void *data) at module.c:541>:
                            cmp_name() <int cmp_name (const void *va, const void *vb) at module.c:533>:
                            check_symbol() <bool check_symbol (const struct symsearch *syms, struct module *owner, unsigned int symnum, void *data) at module.c:499>:
                                pr_warn()
                                symversion()
                        pr_debug()
                    check_version() <inline int check_version (Elf_Shdr *sechdrs, unsigned int versindex, const char *symname, struct module *mod, const unsigned long *crc, const struct module *crc_owner) at module.c:1341>:
                        try_to_force_load() <int try_to_force_load (struct module *mod, const char *reason) at module.c:1242>:
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            pr_warn()
                            add_taint_module() <inline void add_taint_module (struct module *mod, unsigned flag, enum lockdep_ok lockdep_ok) at module.c:327>:
                                add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
                                    pr_warn()
                                    set_bit()
                        maybe_relocated() <unsigned long maybe_relocated (unsigned long crc, const struct module *crc_owner) at module.c:1256>:
                        pr_debug()
                        pr_warn()
                    ERR_PTR()
                    getname()
                    ref_module() <int ref_module (struct module *a, struct module *b) at module.c:1123>:
                        already_uses() <int already_uses (struct module *a, struct module *b) at module.c:788>:
                            list_for_each_entry()
                            pr_debug()
                        strong_try_module_get() <inline int strong_try_module_get (struct module *mod) at module.c:316>:
                            BUG_ON()
                            try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
                                preempt_disable()
                                likely()
                                module_is_live()
                                atomic_inc_not_zero()
                                trace_module_get()
                                preempt_enable()
                        add_module_usage() <int add_module_usage (struct module *a, struct module *b) at module.c:809>:
                            pr_debug()
                            kmalloc()
                            pr_warn()
                            list_add()
                        module_put() <void module_put (struct module *module) at module.c:1098>:
                            preempt_disable()
                            atomic_dec_if_positive()
                            WARN_ON()
                            trace_module_put()
                            preempt_enable()
                    module_name()
                    mutex_unlock()
                PTR_ERR()
                pr_warn()
            IS_ERR()
            ELF_ST_BIND()
            PTR_ERR()
            mod_percpu() <inline void __percpu *mod_percpu (struct module *mod) at module.c:699>:
        free_modinfo() <void free_modinfo (struct module *mod) at module.c:2345>:
        apply_relocations() <int apply_relocations (struct module *mod, const struct load_info *info) at module.c:2158>:
            apply_relocate()
            apply_relocate_add()
        post_relocation() <int post_relocation (struct module *mod, const struct load_info *info) at module.c:3157>:
            sort_extable()
            percpu_modcopy() <inline void percpu_modcopy (struct module *mod, const void *from, unsigned long size) at module.c:717>:
                for_each_possible_cpu()
                per_cpu_ptr()
                BUG_ON()
            add_kallsyms() <void add_kallsyms (struct module *mod, const struct load_info *info) at module.c:2545>:
                elf_type() <char elf_type (const Elf_Sym *sym, const struct load_info *info) at module.c:2379>:
                    ELF_ST_BIND()
                    ELF_ST_TYPE()
                    strstarts()
                is_core_symbol() <bool is_core_symbol (const Elf_Sym *src, const Elf_Shdr *sechdrs, unsigned int shnum, unsigned int pcpundx) at module.c:2419>:
                strlcpy()
            module_finalize() <int __weak module_finalize (const Elf_Ehdr *hdr, const Elf_Shdr *sechdrs, struct module *me) at module.c:3150>
        flush_module_icache() <void flush_module_icache (const struct module *mod) at module.c:3070>:
            get_fs()
            set_fs()
            flush_icache_range()
        strndup_user()
        dynamic_debug_setup() <void dynamic_debug_setup (struct _ddebug *debug, unsigned int num) at module.c:2550>:
            ddebug_add_module()
            pr_err()
        ftrace_module_init()
        complete_formation() <int complete_formation (struct module *mod, struct load_info *info) at module.c:3372>:
            mutex_lock()
            verify_export_symbols() <int verify_export_symbols (struct module *mod) at module.c:2063>:
                ARRAY_SIZE()
                find_symbol() <const struct kernel_symbol *find_symbol (const char *name, struct module **owner, const unsigned long **crc, bool gplok, bool warn) at module.c:559>:
                    each_symbol_section() <bool each_symbol_section (bool (*fn) (const struct symsearch *arr, struct module *owner, void *data), void *data) at module.c:424>:
                        module_assert_mutex_or_preempt() <void module_assert_mutex_or_preempt (void) at module.c:260>:
                            unlikely()
                            WARN_ON()
                            rcu_read_lock_sched_held()
                            lockdep_is_held()
                        each_symbol_in_section() <bool each_symbol_in_section (const struct symsearch *arr, unsigned int arrsize, struct module *owner, bool (*fn) (const struct symsearch *syms, struct module *owner, void *data), void *data) at module.c:405>:
                            fn()
                        ARRAY_SIZE()
                        fn()
                        list_for_each_entry_rcu()
                    find_symbol_in_section() <bool find_symbol_in_section (const struct symsearch *syms, struct module *owner, void *data) at module.c:541>:
                        cmp_name() <int cmp_name (const void *va, const void *vb) at module.c:533>:
                        check_symbol() <bool check_symbol (const struct symsearch *syms, struct module *owner, unsigned int symnum, void *data) at module.c:499>:
                            pr_warn()
                            symversion()
                    pr_debug()
                pr_err()
                module_name()
            module_bug_finalize()
            module_enable_ro() <void module_enable_ro (const struct module *mod) at module.c:1904>:
                frob_text() <void frob_text (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1866>:
                    BUG_ON()
                frob_rodata() <void frob_rodata (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1875>:
                    BUG_ON()
            module_enable_nx() <void module_enable_nx (const struct module *mod) at module.c:1970>:
                frob_rodata() <void frob_rodata (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1875>:
                    BUG_ON()
                frob_writable_data() <void frob_writable_data (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1885>:
                    BUG_ON()
            mutex_unlock()
            ftrace_module_enable()
            blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
        parse_args() <char *parse_args (const char *doing, char *args, const struct kernel_param *params, unsigned num, s16 min_level, s16 max_level, void *arg, int (*unknown) (char *param, char *val, const char *doing, void *arg)) at params.c:216>:
            skip_spaces()
            pr_debug()
            next_arg() <char *next_arg (char *args, char **param, char **val) at params.c:165>:
                skip_spaces()
            irqs_disabled()
            parse_one() <int parse_one (char *param, char *val, const char *doing, const struct kernel_param *params, unsigned num_params, s16 min_level, s16 max_level, void *arg, int (*handle_unknown) (char *param, char *val, const char *doing, void *arg)) at params.c:120>:
                parameq() <bool parameq (const char *a, const char *b) at params.c:106>:
                    parameqn() <bool parameqn (const char *a, const char *b, size_t n) at params.c:95>:
                        dash2underscore() <char dash2underscore (char c) at params.c:88>
                pr_debug()
                kernel_param_lock() <void kernel_param_lock (struct module *mod) at params.c:639>:
                    mutex_lock()
                    KPARAM_MUTEX()
                param_check_unsafe() <void param_check_unsafe (const struct kernel_param *kp) at params.c:111>:
                    pr_warn()
                    add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
                        pr_warn()
                        set_bit()
                kernel_param_unlock() <void kernel_param_unlock (struct module *mod) at params.c:644>:
                    mutex_unlock()
                    KPARAM_MUTEX()
            pr_warn()
            pr_err()
            ERR_PTR()
        unknown_module_param_cb() <int unknown_module_param_cb (char *param, char *val, const char *modname, void *arg) at module.c:3405>:
            ddebug_dyndbg_module_param_cb()
            pr_warn()
        pr_warn()
        mod_sysfs_setup() <int mod_sysfs_setup (struct module *mod, const struct load_info *info, struct kernel_param *kparam, unsigned int num_params) at module.c:1818>:
            mod_sysfs_init() <int mod_sysfs_init (struct module *mod) at module.c:1730>:
                pr_err()
                kset_find_obj()
                kobject_put()
                kobject_init_and_add()
                mod_kobject_put() <void mod_kobject_put (struct module *mod) at module.c:1722>:
                    DECLARE_COMPLETION_ONSTACK()
                    kobject_put()
                    wait_for_completion()
            kobject_create_and_add()
            module_param_sysfs_setup() <int module_param_sysfs_setup (struct module *mod, const struct kernel_param *kparam, unsigned int num_params) at params.c:743>:
                add_sysfs_param() <__modinit int add_sysfs_param (struct module_kobject *mk, const struct kernel_param *kp, const char *name) at params.c:662>:
                    BUG_ON()
                    kzalloc()
                    krealloc()
                    sysfs_attr_init()
                    param_attr_show() <ssize_t param_attr_show (struct module_attribute *mattr, struct module_kobject *mk, char *buf) at params.c:592>:
                        to_param_attr()
                        kernel_param_lock() <void kernel_param_lock (struct module *mod) at params.c:639>:
                            mutex_lock()
                            KPARAM_MUTEX()
                        kernel_param_unlock() <void kernel_param_unlock (struct module *mod) at params.c:644>:
                            mutex_unlock()
                            KPARAM_MUTEX()
                    param_attr_store() <ssize_t param_attr_store (struct module_attribute *mattr, struct module_kobject *mk, const char *buf, size_t len) at params.c:612>:
                        to_param_attr()
                        kernel_param_lock() <void kernel_param_lock (struct module *mod) at params.c:639>:
                            mutex_lock()
                            KPARAM_MUTEX()
                        param_check_unsafe() <void param_check_unsafe (const struct kernel_param *kp) at params.c:111>:
                            pr_warn()
                            add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
                                pr_warn()
                                set_bit()
                        kernel_param_unlock() <void kernel_param_unlock (struct module *mod) at params.c:644>:
                            mutex_unlock()
                            KPARAM_MUTEX()
                free_module_param_attrs() <void free_module_param_attrs (struct module_kobject *mk) at params.c:726>:
                    kfree()
                sysfs_create_group()
            module_add_modinfo_attrs() <int module_add_modinfo_attrs (struct module *mod) at module.c:1679>:
                kzalloc()
                ARRAY_SIZE()
                sysfs_attr_init()
                sysfs_create_file()
            add_usage_links() <void add_usage_links (struct module *mod) at module.c:1652>:
                mutex_lock()
                list_for_each_entry()
                sysfs_create_link()
                mutex_unlock()
            add_sect_attrs() <inline void add_sect_attrs (struct module *mod, const struct load_info *info) at module.c:1633>:
                sect_empty() <inline bool sect_empty (const Elf_Shdr *sect) at module.c:1433>:
                ALIGN()
                kzalloc()
                kstrdup()
                sysfs_attr_init()
                module_sect_show() <ssize_t module_sect_show (struct module_attribute *mattr, struct module_kobject *mk, char *buf) at module.c:1450>:
                    container_of()
                sysfs_create_group()
                free_sect_attrs() <void free_sect_attrs (struct module_sect_attrs *sect_attrs) at module.c:1458>:
                    kfree()
            add_notes_attrs() <inline void add_notes_attrs (struct module *mod, const struct load_info *info) at module.c:1642>:
                sect_empty() <inline bool sect_empty (const Elf_Shdr *sect) at module.c:1433>:
                kzalloc()
                sysfs_bin_attr_init()
                module_notes_read() <ssize_t module_notes_read (struct file *filp, struct kobject *kobj, struct bin_attribute *bin_attr, char *buf, loff_t pos, size_t count) at module.c:1543>:
                kobject_create_and_add()
                sysfs_create_bin_file()
                free_notes_attrs() <void free_notes_attrs (struct module_notes_attrs *notes_attrs, unsigned int i) at module.c:1554>:
                    sysfs_remove_bin_file()
                    kobject_put()
                    kfree()
            kobject_uevent()
            module_param_sysfs_remove() <void module_param_sysfs_remove (struct module *mod) at params.c:778>:
                sysfs_remove_group()
                free_module_param_attrs() <void free_module_param_attrs (struct module_kobject *mk) at params.c:726>:
                    kfree()
            kobject_put()
            mod_kobject_put() <void mod_kobject_put (struct module *mod) at module.c:1722>:
                DECLARE_COMPLETION_ONSTACK()
                kobject_put()
                wait_for_completion()
        trace_module_load()
        do_init_module() <noinline int do_init_module (struct module *mod) at module.c:3224>:
            kmalloc()
            do_mod_ctors() <void do_mod_ctors (struct module *mod) at module.c:3195>:
            do_one_initcall()
            pr_warn()
            dump_stack()
            blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
            async_synchronize_full() <void async_synchronize_full (void) at async.c:237>:
                async_synchronize_full_domain() <void async_synchronize_full_domain (struct async_domain *domain) at async.c:268>:
                    async_synchronize_cookie_domain() <void async_synchronize_cookie_domain (async_cookie_t cookie, struct async_domain *domain) at async.c:283>:
                        uninitialized_var()
                        pr_debug()
                        task_pid_nr()
                        ktime_get()
                        wait_event()
                        lowest_in_progress() <async_cookie_t lowest_in_progress (struct async_domain *domain) at async.c:85>:
                            spin_lock_irqsave()
                            list_empty()
                            list_first_entry()
                            spin_unlock_irqrestore()
                        ktime_sub()
                        ktime_to_ns()
            mutex_lock()
            module_put() <void module_put (struct module *module) at module.c:1098>:
                preempt_disable()
                atomic_dec_if_positive()
                WARN_ON()
                trace_module_put()
                preempt_enable()
            trim_init_extable()
            rcu_assign_pointer()
            mod_tree_remove_init() <void mod_tree_remove_init (struct module *mod) at module.c:212>:
            disable_ro_nx() <void disable_ro_nx (const struct module_layout *layout) at module.c:1969>:
                frob_text() <void frob_text (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1866>:
                    BUG_ON()
                frob_rodata() <void frob_rodata (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1875>:
                    BUG_ON()
                frob_writable_data() <void frob_writable_data (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1885>:
                    BUG_ON()
            module_arch_freeing_init() <void __weak module_arch_freeing_init (struct module *mod) at module.c:1983>
            call_rcu_sched()
            do_free_init() <void do_free_init (struct rcu_head *head) at module.c:3211>:
                container_of()
                module_memfree() <void __weak module_memfree (void *module_region) at module.c:1974>:
                    vfree()
                kfree()
            mutex_unlock()
            wake_up_all()
            kfree()
            synchronize_sched()
            ftrace_release_mod()
            free_module() <void free_module (struct module *mod) at module.c:1988>:
                trace_module_free()
                mod_sysfs_teardown() <void mod_sysfs_teardown (struct module *mod) at module.c:1843>:
                    del_usage_links() <void del_usage_links (struct module *mod) at module.c:1834>:
                        mutex_lock()
                        list_for_each_entry()
                        sysfs_remove_link()
                        mutex_unlock()
                    module_remove_modinfo_attrs() <void module_remove_modinfo_attrs (struct module *mod) at module.c:1830>:
                        sysfs_remove_file()
                        kfree()
                    module_param_sysfs_remove() <void module_param_sysfs_remove (struct module *mod) at params.c:778>:
                        sysfs_remove_group()
                        free_module_param_attrs() <void free_module_param_attrs (struct module_kobject *mk) at params.c:726>:
                            kfree()
                    kobject_put()
                    mod_sysfs_fini() <void mod_sysfs_fini (struct module *mod) at module.c:1826>:
                        remove_notes_attrs() <inline void remove_notes_attrs (struct module *mod) at module.c:1647>:
                            free_notes_attrs() <void free_notes_attrs (struct module_notes_attrs *notes_attrs, unsigned int i) at module.c:1554>:
                                sysfs_remove_bin_file()
                                kobject_put()
                                kfree()
                        remove_sect_attrs() <inline void remove_sect_attrs (struct module *mod) at module.c:1638>:
                            sysfs_remove_group()
                            free_sect_attrs() <void free_sect_attrs (struct module_sect_attrs *sect_attrs) at module.c:1458>:
                                kfree()
                        mod_kobject_put() <void mod_kobject_put (struct module *mod) at module.c:1722>:
                            DECLARE_COMPLETION_ONSTACK()
                            kobject_put()
                            wait_for_completion()
                mutex_lock()
                mutex_unlock()
                ddebug_remove_module()
                module_arch_cleanup() <void __weak module_arch_cleanup (struct module *mod) at module.c:1979>
                module_unload_free() <inline void module_unload_free (struct module *mod) at module.c:1119>:
                    mutex_lock()
                    list_for_each_entry_safe()
                    pr_debug()
                    module_put() <void module_put (struct module *module) at module.c:1098>:
                        preempt_disable()
                        atomic_dec_if_positive()
                        WARN_ON()
                        trace_module_put()
                        preempt_enable()
                    list_del()
                    kfree()
                    mutex_unlock()
                destroy_params() <void destroy_params (const struct kernel_param *params, unsigned num) at params.c:789>:
                list_del_rcu()
                mod_tree_remove() <void mod_tree_remove (struct module *mod) at module.c:213>:
                    mod_tree_remove_init() <void mod_tree_remove_init (struct module *mod) at module.c:212>:
                module_bug_cleanup()
                synchronize_sched()
                disable_ro_nx() <void disable_ro_nx (const struct module_layout *layout) at module.c:1969>:
                    frob_text() <void frob_text (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1866>:
                        BUG_ON()
                    frob_rodata() <void frob_rodata (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1875>:
                        BUG_ON()
                    frob_writable_data() <void frob_writable_data (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1885>:
                        BUG_ON()
                module_arch_freeing_init() <void __weak module_arch_freeing_init (struct module *mod) at module.c:1983>
                module_memfree() <void __weak module_memfree (void *module_region) at module.c:1974>:
                    vfree()
                kfree()
                percpu_modfree() <inline void percpu_modfree (struct module *mod) at module.c:710>:
                    free_percpu()
                lockdep_free_key_range()
                update_protections()
        mutex_lock()
        module_bug_cleanup()
        mutex_unlock()
        blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
        module_disable_ro() <void module_disable_ro (const struct module *mod) at module.c:1896>:
            frob_text() <void frob_text (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1866>:
                BUG_ON()
            frob_rodata() <void frob_rodata (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1875>:
                BUG_ON()
        module_disable_nx() <void module_disable_nx (const struct module *mod) at module.c:1971>:
            frob_rodata() <void frob_rodata (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1875>:
                BUG_ON()
            frob_writable_data() <void frob_writable_data (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1885>:
                BUG_ON()
        dynamic_debug_remove() <void dynamic_debug_remove (struct _ddebug *debug) at module.c:2561>:
            ddebug_remove_module()
        synchronize_sched()
        kfree()
        module_arch_cleanup() <void __weak module_arch_cleanup (struct module *mod) at module.c:1979>
        module_unload_free() <inline void module_unload_free (struct module *mod) at module.c:1119>:
            mutex_lock()
            list_for_each_entry_safe()
            pr_debug()
            module_put() <void module_put (struct module *module) at module.c:1098>:
                preempt_disable()
                atomic_dec_if_positive()
                WARN_ON()
                trace_module_put()
                preempt_enable()
            list_del()
            kfree()
            mutex_unlock()
        list_del_rcu()
        mod_tree_remove() <void mod_tree_remove (struct module *mod) at module.c:213>:
            mod_tree_remove_init() <void mod_tree_remove_init (struct module *mod) at module.c:212>:
        wake_up_all()
        ftrace_release_mod()
        lockdep_free_key_range()
        module_deallocate() <void module_deallocate (struct module *mod, struct load_info *info) at module.c:3142>:
            percpu_modfree() <inline void percpu_modfree (struct module *mod) at module.c:710>:
                free_percpu()
            module_arch_freeing_init() <void __weak module_arch_freeing_init (struct module *mod) at module.c:1983>
            module_memfree() <void __weak module_memfree (void *module_region) at module.c:1974>:
                vfree()
    copy_module_from_fd() <int copy_module_from_fd (int fd, struct load_info *info) at module.c:2697>:
        fdget()
        security_kernel_module_from_file()
        vfs_getattr()
        vmalloc()
        kernel_read()
        vfree()
        fdput()
    do_seccomp() <long do_seccomp (unsigned int op, unsigned int flags, const char __user *uargs) at seccomp.c:817>:
        seccomp_set_mode_strict() <long seccomp_set_mode_strict (void) at seccomp.c:728>:
            seccomp_mode()
            spin_lock_irq()
            seccomp_may_assign_mode() <inline bool seccomp_may_assign_mode (unsigned long seccomp_mode) at seccomp.c:207>:
                assert_spin_locked()
            disable_TSC()
            seccomp_assign_mode() <inline void seccomp_assign_mode (struct task_struct *task, unsigned long seccomp_mode) at seccomp.c:217>:
                assert_spin_locked()
                smp_mb__before_atomic()
                set_tsk_thread_flag()
            spin_unlock_irq()
        seccomp_set_mode_filter() <inline long seccomp_set_mode_filter (unsigned int flags, const char __user *filter) at seccomp.c:809>:
            seccomp_mode()
            seccomp_prepare_user_filter() <struct seccomp_filter *seccomp_prepare_user_filter (const char __user *user_filter) at seccomp.c:392>:
                ERR_PTR()
                is_compat_task()
                copy_from_user()
                compat_ptr()
                seccomp_prepare_filter() <struct seccomp_filter *seccomp_prepare_filter (struct sock_fprog *fprog) at seccomp.c:346>:
                    config_enabled()
                    ERR_PTR()
                    BUG_ON()
                    task_no_new_privs()
                    security_capable_noaudit()
                    current_cred()
                    current_user_ns()
                    kzalloc()
                    bpf_prog_create_from_user()
                    seccomp_check_filter() <int seccomp_check_filter (struct sock_filter *filter, unsigned int flen) at seccomp.c:100>:
                    kfree()
                    atomic_set()
            IS_ERR()
            PTR_ERR()
            mutex_lock_killable()
            spin_lock_irq()
            seccomp_may_assign_mode() <inline bool seccomp_may_assign_mode (unsigned long seccomp_mode) at seccomp.c:207>:
                assert_spin_locked()
            seccomp_attach_filter() <long seccomp_attach_filter (unsigned int flags, struct seccomp_filter *filter) at seccomp.c:422>:
                assert_spin_locked()
                seccomp_can_sync_threads() <inline pid_t seccomp_can_sync_threads (void) at seccomp.c:254>:
                    BUG_ON()
                    mutex_is_locked()
                    assert_spin_locked()
                    for_each_thread()
                    is_ancestor() <int is_ancestor (struct seccomp_filter *parent, struct seccomp_filter *child) at seccomp.c:233>:
                    task_pid_vnr()
                    unlikely()
                    WARN_ON()
                seccomp_sync_threads() <inline void seccomp_sync_threads (void) at seccomp.c:295>:
                    BUG_ON()
                    mutex_is_locked()
                    assert_spin_locked()
                    for_each_thread()
                    get_seccomp_filter() <void get_seccomp_filter (struct task_struct *tsk) at seccomp.c:461>:
                        atomic_inc()
                    put_seccomp_filter() <void put_seccomp_filter (struct task_struct *tsk) at seccomp.c:479>:
                        atomic_dec_and_test()
                        seccomp_filter_free() <inline void seccomp_filter_free (struct seccomp_filter *filter) at seccomp.c:470>:
                            bpf_prog_destroy()
                            kfree()
                    smp_store_release()
                    task_no_new_privs()
                    task_set_no_new_privs()
                    seccomp_assign_mode() <inline void seccomp_assign_mode (struct task_struct *task, unsigned long seccomp_mode) at seccomp.c:217>:
                        assert_spin_locked()
                        smp_mb__before_atomic()
                        set_tsk_thread_flag()
            seccomp_assign_mode() <inline void seccomp_assign_mode (struct task_struct *task, unsigned long seccomp_mode) at seccomp.c:217>:
                assert_spin_locked()
                smp_mb__before_atomic()
                set_tsk_thread_flag()
            spin_unlock_irq()
            mutex_unlock()
            seccomp_filter_free() <inline void seccomp_filter_free (struct seccomp_filter *filter) at seccomp.c:470>:
                bpf_prog_destroy()
                kfree()
    do_tkill() <int do_tkill (pid_t tgid, pid_t pid, int sig) at signal.c:2890>:
        task_tgid_vnr()
        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                    smp_rmb()
        current_user_ns()
        current_uid()
        do_send_specific() <int do_send_specific (pid_t tgid, pid_t pid, int sig, struct siginfo *info) at signal.c:2861>:
            rcu_read_lock()
            find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
                find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                    RCU_LOCKDEP_WARN()
                    rcu_read_lock_held()
                    pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                        rcu_dereference_check()
                        hlist_first_rcu()
                        lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                            lockdep_is_held()
                        hlist_entry()
                    find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                        hlist_for_each_entry_rcu()
                        pid_hashfn()
                        container_of()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
            task_tgid_vnr()
            check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                valid_signal()
                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                    SI_FROMUSER()
                audit_signal_info()
                same_thread_group()
                kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                    current_cred()
                    uid_eq()
                    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                        unlikely()
                        cap_valid()
                        pr_crit()
                        BUG()
                        security_capable()
                        current_cred()
                task_session()
                security_task_kill()
            do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                lock_task_sighand()
                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                        SI_FROMUSER()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                unlock_task_sighand()
            unlikely()
            rcu_read_unlock()
    copy_from_user()
    do_rt_sigqueueinfo() <int do_rt_sigqueueinfo (pid_t pid, int sig, siginfo_t *info) at signal.c:2938>:
        task_pid_vnr()
        kill_proc_info() <int kill_proc_info (int sig, struct siginfo *info, pid_t pid) at signal.c:1310>:
            rcu_read_lock()
            kill_pid_info() <int kill_pid_info (int sig, struct siginfo *info, struct pid *pid) at signal.c:1288>:
                rcu_read_lock()
                pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                    rcu_dereference_check()
                    hlist_first_rcu()
                    lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                        lockdep_is_held()
                    hlist_entry()
                group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                    rcu_read_lock()
                    check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                        valid_signal()
                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                            SI_FROMUSER()
                        audit_signal_info()
                        same_thread_group()
                        kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                            current_cred()
                            uid_eq()
                            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                unlikely()
                                cap_valid()
                                pr_crit()
                                BUG()
                                security_capable()
                                current_cred()
                        task_session()
                        security_task_kill()
                    rcu_read_unlock()
                    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                        lock_task_sighand()
                        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                SI_FROMUSER()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                        unlock_task_sighand()
                rcu_read_unlock()
                likely()
            find_vpid() <struct pid *find_vpid (int nr) at pid.c:380>:
                find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                    hlist_for_each_entry_rcu()
                    pid_hashfn()
                    container_of()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
            rcu_read_unlock()
    sigaddsetmask()
    sigdelsetmask()
    set_current_blocked() <void set_current_blocked (sigset_t *newset) at signal.c:2478>:
        sigdelsetmask()
    copy_to_user()
    access_ok()
    siginitset()
    do_sigaction() <int do_sigaction (int sig, struct k_sigaction *act, struct k_sigaction *oact) at signal.c:3047>:
        valid_signal()
        sig_kernel_only()
        spin_lock_irq()
        sigdelsetmask()
        sig_handler_ignored() <int sig_handler_ignored (void __user *handler, int sig) at signal.c:61>:
            sig_kernel_ignore()
        sig_handler() <void __user *sig_handler (struct task_struct *t, int sig) at signal.c:56>:
        flush_sigqueue_mask() <int flush_sigqueue_mask (sigset_t *mask, struct sigpending *s) at signal.c:659>:
            sigandsets()
            sigisemptyset()
            sigandnsets()
            list_for_each_entry_safe()
            list_del_init()
        for_each_thread()
        spin_unlock_irq()
    current_cred()
    read_lock()
    set_one_prio() <int set_one_prio (struct task_struct *p, int niceval, int error) at sys.c:151>:
        set_one_prio_perm() <bool set_one_prio_perm (struct task_struct *p) at sys.c:135>:
            current_cred()
            uid_eq()
            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                unlikely()
                cap_valid()
                pr_crit()
                BUG()
                security_capable()
                current_cred()
        task_nice()
        can_nice()
        security_task_setnice()
        set_user_nice()
    find_vpid() <struct pid *find_vpid (int nr) at pid.c:380>:
        find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
            hlist_for_each_entry_rcu()
            pid_hashfn()
            container_of()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
    task_pgrp()
    do_each_pid_thread()
    while_each_pid_thread()
    make_kuid() <kuid_t make_kuid (struct user_namespace *ns, uid_t uid) at user_namespace.c:239>:
        KUIDT_INIT()
        map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
            smp_rmb()
    uid_eq()
    find_user() <struct user_struct *find_user (kuid_t uid) at user.c:146>:
        spin_lock_irqsave()
        uid_hash_find() <struct user_struct *uid_hash_find (kuid_t uid, struct hlist_head *hashent) at user.c:112>:
            hlist_for_each_entry()
            uid_eq()
            atomic_inc()
        uidhashentry()
        spin_unlock_irqrestore()
    do_each_thread()
    task_uid()
    task_pid_vnr()
    while_each_thread()
    free_uid() <void free_uid (struct user_struct *up) at user.c:157>:
        local_irq_save()
        atomic_dec_and_lock()
        free_user() <void free_user (struct user_struct *up, unsigned long flags) at user.c:130>:
            uid_hash_remove() <void uid_hash_remove (struct user_struct *up) at user.c:107>:
                hlist_del_init()
            spin_unlock_irqrestore()
            key_put()
            kmem_cache_free()
        local_irq_restore()
    read_unlock()
    current_user_ns()
    uid_valid()
    prepare_creds() <struct cred *prepare_creds (void) at cred.c:243>:
        validate_process_creds()
        kmem_cache_alloc()
        kdebug()
        atomic_set()
        set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
            atomic_set()
        get_group_info()
        get_uid()
        get_user_ns()
        key_get()
        security_prepare_creds()
        validate_creds()
        abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
            BUG_ON()
            put_cred()
    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
        unlikely()
        cap_valid()
        pr_crit()
        BUG()
        security_capable()
        current_cred()
    set_user() <int set_user (struct cred *new) at sys.c:421>:
        alloc_uid() <struct user_struct *alloc_uid (kuid_t uid) at user.c:171>:
            uidhashentry()
            spin_lock_irq()
            uid_hash_find() <struct user_struct *uid_hash_find (kuid_t uid, struct hlist_head *hashent) at user.c:112>:
                hlist_for_each_entry()
                uid_eq()
                atomic_inc()
            spin_unlock_irq()
            kmem_cache_zalloc()
            atomic_set()
            key_put()
            kmem_cache_free()
            uid_hash_insert() <void uid_hash_insert (struct user_struct *up, struct hlist_head *hashent) at user.c:102>:
                hlist_add_head()
        atomic_read()
        rlimit()
        free_uid() <void free_uid (struct user_struct *up) at user.c:157>:
            local_irq_save()
            atomic_dec_and_lock()
            free_user() <void free_user (struct user_struct *up, unsigned long flags) at user.c:130>:
                uid_hash_remove() <void uid_hash_remove (struct user_struct *up) at user.c:107>:
                    hlist_del_init()
                spin_unlock_irqrestore()
                key_put()
                kmem_cache_free()
            local_irq_restore()
    security_task_fix_setuid()
    commit_creds() <int commit_creds (struct cred *new) at cred.c:422>:
        kdebug()
        atomic_read()
        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
            atomic_read()
        BUG_ON()
        validate_creds()
        get_cred()
        uid_eq()
        gid_eq()
        cred_cap_issubset() <bool cred_cap_issubset (const struct cred *set, const struct cred *subset) at cred.c:383>:
            cap_issubset()
            uid_eq()
        set_dumpable()
        smp_wmb()
        key_fsuid_changed()
        key_fsgid_changed()
        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
            atomic_add()
        atomic_inc()
        rcu_assign_pointer()
        atomic_dec()
        proc_id_connector()
        put_cred()
    abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
        kdebug()
        atomic_read()
        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
            atomic_read()
        BUG_ON()
        put_cred()
    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
    make_kgid() <kgid_t make_kgid (struct user_namespace *ns, gid_t gid) at user_namespace.c:307>:
        KGIDT_INIT()
        map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
            smp_rmb()
    gid_valid()
    gid_eq()
    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
    raw_smp_processor_id()
    cpu_to_node()
    sys_chown()
    low2highuid()
    low2highgid()
    sys_lchown()
    sys_fchown()
    sys_setresuid()
    high2lowuid()
    sys_setresgid()
    high2lowgid()
SYSCALL_DEFINE4() <SYSCALL_DEFINE4 (prlimit64, pid_t, pid, unsigned int, resource, const struct rlimit64 __user *, new_rlim, struct rlimit64 __user *, old_rlim) at sys.c:1448>:
    find_get_pid() <struct pid *find_get_pid (pid_t nr) at pid.c:488>:
        rcu_read_lock()
        get_pid()
        find_vpid() <struct pid *find_vpid (int nr) at pid.c:380>:
            find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                hlist_for_each_entry_rcu()
                pid_hashfn()
                container_of()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
        rcu_read_unlock()
    get_task_pid() <struct pid *get_task_pid (struct task_struct *task, enum pid_type type) at pid.c:464>:
        rcu_read_lock()
        get_pid()
        rcu_dereference()
        rcu_read_unlock()
    do_wait() <long do_wait (struct wait_opts *wo) at exit.c:1463>:
        trace_sched_process_wait()
        init_waitqueue_func_entry()
        child_wait_callback() <int child_wait_callback (wait_queue_t *wait, unsigned mode, int sync, void *key) at exit.c:1441>:
            container_of()
            eligible_pid() <int eligible_pid (struct wait_opts *wo, struct task_struct *p) at exit.c:913>:
                task_pid_type() <inline struct pid *task_pid_type (struct task_struct *task, enum pid_type type) at exit.c:906>:
            default_wake_function()
        add_wait_queue()
        hlist_empty()
        set_current_state()
        read_lock()
        do_wait_thread() <int do_wait_thread (struct wait_opts *wo, struct task_struct *tsk) at exit.c:1413>:
            list_for_each_entry()
            wait_consider_task() <int wait_consider_task (struct wait_opts *wo, int ptrace, struct task_struct *p) at exit.c:1287>:
                ACCESS_ONCE()
                unlikely()
                eligible_child() <int eligible_child (struct wait_opts *wo, struct task_struct *p) at exit.c:919>:
                    eligible_pid() <int eligible_pid (struct wait_opts *wo, struct task_struct *p) at exit.c:913>:
                        task_pid_type() <inline struct pid *task_pid_type (struct task_struct *task, enum pid_type type) at exit.c:906>:
                security_task_wait()
                likely()
                ptrace_reparented()
                delay_group_leader()
                wait_task_zombie() <int wait_task_zombie (struct wait_opts *wo, struct task_struct *p) at exit.c:969>:
                    task_pid_vnr()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    current_user_ns()
                    task_uid()
                    likely()
                    unlikely()
                    get_task_struct()
                    read_unlock()
                    sched_annotate_sleep()
                    wait_noreap_copyout() <int wait_noreap_copyout (struct wait_opts *wo, struct task_struct *p, pid_t pid, uid_t uid, int why, int status) at exit.c:935>:
                        getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                            k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                                task_cputime_adjusted()
                                accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                    task_io_get_inblock()
                                    task_io_get_oublock()
                                lock_task_sighand()
                                thread_group_cputime_adjusted()
                                while_each_thread()
                                BUG()
                                unlock_task_sighand()
                                cputime_to_timeval()
                                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                    task_lock()
                                    atomic_inc()
                                    task_unlock()
                                setmax_mm_hiwater_rss()
                                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                    might_sleep()
                                    atomic_dec_and_test()
                                    uprobe_clear_state()
                                    exit_aio()
                                    ksm_exit()
                                    khugepaged_exit()
                                    exit_mmap()
                                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                        rcu_dereference_raw()
                                        get_file()
                                        rcu_assign_pointer()
                                        fput()
                                    list_empty()
                                    spin_lock()
                                    list_del()
                                    spin_unlock()
                                    module_put() <void module_put (struct module *module) at module.c:1098>:
                                        preempt_disable()
                                        atomic_dec_if_positive()
                                        WARN_ON()
                                        trace_module_put()
                                        preempt_enable()
                                    mmdrop()
                            copy_to_user()
                        put_task_struct()
                        put_user()
                    ptrace_reparented()
                    thread_group_leader()
                    cmpxchg()
                    thread_group_cputime_adjusted()
                    spin_lock_irq()
                    write_seqlock()
                    task_gtime()
                    task_io_get_inblock()
                    task_io_get_oublock()
                    max()
                    task_io_accounting_add()
                    write_sequnlock()
                    spin_unlock_irq()
                    getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                        k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                            task_cputime_adjusted()
                            accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                task_io_get_inblock()
                                task_io_get_oublock()
                            lock_task_sighand()
                            thread_group_cputime_adjusted()
                            while_each_thread()
                            BUG()
                            unlock_task_sighand()
                            cputime_to_timeval()
                            get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                task_lock()
                                atomic_inc()
                                task_unlock()
                            setmax_mm_hiwater_rss()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                        copy_to_user()
                    put_user()
                    write_lock_irq()
                    ptrace_unlink()
                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                        BUG_ON()
                        task_is_stopped_or_traced()
                        thread_group_empty()
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        spin_lock_irqsave()
                        valid_signal()
                        spin_unlock_irqrestore()
                    write_unlock_irq()
                    release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                        rcu_read_lock()
                        atomic_dec()
                        rcu_read_unlock()
                        proc_flush_task()
                        write_lock_irq()
                        ptrace_release_task()
                        thread_group_empty()
                        do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                            BUG_ON()
                            task_is_stopped_or_traced()
                            thread_group_empty()
                            rcu_read_lock()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            task_cred_xxx()
                            task_uid()
                            rcu_read_unlock()
                            task_cputime()
                            cputime_to_clock_t()
                            spin_lock_irqsave()
                            valid_signal()
                            spin_unlock_irqrestore()
                        write_unlock_irq()
                        release_thread()
                        call_rcu()
                        delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                            container_of()
                            perf_event_delayed_put()
                            trace_sched_process_free()
                            put_task_struct()
                        unlikely()
                wait_task_stopped() <int wait_task_stopped (struct wait_opts *wo, int ptrace, struct task_struct *p) at exit.c:1148>:
                    task_stopped_code() <int *task_stopped_code (struct task_struct *p, bool ptrace) at exit.c:1118>:
                        task_is_traced()
                    spin_lock_irq()
                    unlikely()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    current_user_ns()
                    task_uid()
                    spin_unlock_irq()
                    get_task_struct()
                    task_pid_vnr()
                    read_unlock()
                    sched_annotate_sleep()
                    wait_noreap_copyout() <int wait_noreap_copyout (struct wait_opts *wo, struct task_struct *p, pid_t pid, uid_t uid, int why, int status) at exit.c:935>:
                        getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                            k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                                task_cputime_adjusted()
                                accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                    task_io_get_inblock()
                                    task_io_get_oublock()
                                lock_task_sighand()
                                thread_group_cputime_adjusted()
                                while_each_thread()
                                BUG()
                                unlock_task_sighand()
                                cputime_to_timeval()
                                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                    task_lock()
                                    atomic_inc()
                                    task_unlock()
                                setmax_mm_hiwater_rss()
                                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                    might_sleep()
                                    atomic_dec_and_test()
                                    uprobe_clear_state()
                                    exit_aio()
                                    ksm_exit()
                                    khugepaged_exit()
                                    exit_mmap()
                                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                        rcu_dereference_raw()
                                        get_file()
                                        rcu_assign_pointer()
                                        fput()
                                    list_empty()
                                    spin_lock()
                                    list_del()
                                    spin_unlock()
                                    module_put() <void module_put (struct module *module) at module.c:1098>:
                                        preempt_disable()
                                        atomic_dec_if_positive()
                                        WARN_ON()
                                        trace_module_put()
                                        preempt_enable()
                                    mmdrop()
                            copy_to_user()
                        put_task_struct()
                        put_user()
                    getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                        k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                            task_cputime_adjusted()
                            accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                task_io_get_inblock()
                                task_io_get_oublock()
                            lock_task_sighand()
                            thread_group_cputime_adjusted()
                            while_each_thread()
                            BUG()
                            unlock_task_sighand()
                            cputime_to_timeval()
                            get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                task_lock()
                                atomic_inc()
                                task_unlock()
                            setmax_mm_hiwater_rss()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                        copy_to_user()
                    put_user()
                    put_task_struct()
                    BUG_ON()
                wait_task_continued() <int wait_task_continued (struct wait_opts *wo, struct task_struct *p) at exit.c:1233>:
                    unlikely()
                    spin_lock_irq()
                    spin_unlock_irq()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    current_user_ns()
                    task_uid()
                    task_pid_vnr()
                    get_task_struct()
                    read_unlock()
                    sched_annotate_sleep()
                    getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                        k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                            task_cputime_adjusted()
                            accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                task_io_get_inblock()
                                task_io_get_oublock()
                            lock_task_sighand()
                            thread_group_cputime_adjusted()
                            while_each_thread()
                            BUG()
                            unlock_task_sighand()
                            cputime_to_timeval()
                            get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                task_lock()
                                atomic_inc()
                                task_unlock()
                            setmax_mm_hiwater_rss()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                        copy_to_user()
                    put_task_struct()
                    put_user()
                    wait_noreap_copyout() <int wait_noreap_copyout (struct wait_opts *wo, struct task_struct *p, pid_t pid, uid_t uid, int why, int status) at exit.c:935>:
                        getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                            k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                                task_cputime_adjusted()
                                accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                    task_io_get_inblock()
                                    task_io_get_oublock()
                                lock_task_sighand()
                                thread_group_cputime_adjusted()
                                while_each_thread()
                                BUG()
                                unlock_task_sighand()
                                cputime_to_timeval()
                                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                    task_lock()
                                    atomic_inc()
                                    task_unlock()
                                setmax_mm_hiwater_rss()
                                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                    might_sleep()
                                    atomic_dec_and_test()
                                    uprobe_clear_state()
                                    exit_aio()
                                    ksm_exit()
                                    khugepaged_exit()
                                    exit_mmap()
                                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                        rcu_dereference_raw()
                                        get_file()
                                        rcu_assign_pointer()
                                        fput()
                                    list_empty()
                                    spin_lock()
                                    list_del()
                                    spin_unlock()
                                    module_put() <void module_put (struct module *module) at module.c:1098>:
                                        preempt_disable()
                                        atomic_dec_if_positive()
                                        WARN_ON()
                                        trace_module_put()
                                        preempt_enable()
                                    mmdrop()
                            copy_to_user()
                        put_task_struct()
                        put_user()
                    BUG_ON()
        ptrace_do_wait() <int ptrace_do_wait (struct wait_opts *wo, struct task_struct *tsk) at exit.c:1427>:
            list_for_each_entry()
            wait_consider_task() <int wait_consider_task (struct wait_opts *wo, int ptrace, struct task_struct *p) at exit.c:1287>:
                ACCESS_ONCE()
                unlikely()
                eligible_child() <int eligible_child (struct wait_opts *wo, struct task_struct *p) at exit.c:919>:
                    eligible_pid() <int eligible_pid (struct wait_opts *wo, struct task_struct *p) at exit.c:913>:
                        task_pid_type() <inline struct pid *task_pid_type (struct task_struct *task, enum pid_type type) at exit.c:906>:
                security_task_wait()
                likely()
                ptrace_reparented()
                delay_group_leader()
                wait_task_zombie() <int wait_task_zombie (struct wait_opts *wo, struct task_struct *p) at exit.c:969>:
                    task_pid_vnr()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    current_user_ns()
                    task_uid()
                    likely()
                    unlikely()
                    get_task_struct()
                    read_unlock()
                    sched_annotate_sleep()
                    wait_noreap_copyout() <int wait_noreap_copyout (struct wait_opts *wo, struct task_struct *p, pid_t pid, uid_t uid, int why, int status) at exit.c:935>:
                        getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                            k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                                task_cputime_adjusted()
                                accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                    task_io_get_inblock()
                                    task_io_get_oublock()
                                lock_task_sighand()
                                thread_group_cputime_adjusted()
                                while_each_thread()
                                BUG()
                                unlock_task_sighand()
                                cputime_to_timeval()
                                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                    task_lock()
                                    atomic_inc()
                                    task_unlock()
                                setmax_mm_hiwater_rss()
                                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                    might_sleep()
                                    atomic_dec_and_test()
                                    uprobe_clear_state()
                                    exit_aio()
                                    ksm_exit()
                                    khugepaged_exit()
                                    exit_mmap()
                                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                        rcu_dereference_raw()
                                        get_file()
                                        rcu_assign_pointer()
                                        fput()
                                    list_empty()
                                    spin_lock()
                                    list_del()
                                    spin_unlock()
                                    module_put() <void module_put (struct module *module) at module.c:1098>:
                                        preempt_disable()
                                        atomic_dec_if_positive()
                                        WARN_ON()
                                        trace_module_put()
                                        preempt_enable()
                                    mmdrop()
                            copy_to_user()
                        put_task_struct()
                        put_user()
                    ptrace_reparented()
                    thread_group_leader()
                    cmpxchg()
                    thread_group_cputime_adjusted()
                    spin_lock_irq()
                    write_seqlock()
                    task_gtime()
                    task_io_get_inblock()
                    task_io_get_oublock()
                    max()
                    task_io_accounting_add()
                    write_sequnlock()
                    spin_unlock_irq()
                    getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                        k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                            task_cputime_adjusted()
                            accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                task_io_get_inblock()
                                task_io_get_oublock()
                            lock_task_sighand()
                            thread_group_cputime_adjusted()
                            while_each_thread()
                            BUG()
                            unlock_task_sighand()
                            cputime_to_timeval()
                            get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                task_lock()
                                atomic_inc()
                                task_unlock()
                            setmax_mm_hiwater_rss()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                        copy_to_user()
                    put_user()
                    write_lock_irq()
                    ptrace_unlink()
                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                        BUG_ON()
                        task_is_stopped_or_traced()
                        thread_group_empty()
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        spin_lock_irqsave()
                        valid_signal()
                        spin_unlock_irqrestore()
                    write_unlock_irq()
                    release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                        rcu_read_lock()
                        atomic_dec()
                        rcu_read_unlock()
                        proc_flush_task()
                        write_lock_irq()
                        ptrace_release_task()
                        thread_group_empty()
                        do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                            BUG_ON()
                            task_is_stopped_or_traced()
                            thread_group_empty()
                            rcu_read_lock()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            task_cred_xxx()
                            task_uid()
                            rcu_read_unlock()
                            task_cputime()
                            cputime_to_clock_t()
                            spin_lock_irqsave()
                            valid_signal()
                            spin_unlock_irqrestore()
                        write_unlock_irq()
                        release_thread()
                        call_rcu()
                        delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                            container_of()
                            perf_event_delayed_put()
                            trace_sched_process_free()
                            put_task_struct()
                        unlikely()
                wait_task_stopped() <int wait_task_stopped (struct wait_opts *wo, int ptrace, struct task_struct *p) at exit.c:1148>:
                    task_stopped_code() <int *task_stopped_code (struct task_struct *p, bool ptrace) at exit.c:1118>:
                        task_is_traced()
                    spin_lock_irq()
                    unlikely()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    current_user_ns()
                    task_uid()
                    spin_unlock_irq()
                    get_task_struct()
                    task_pid_vnr()
                    read_unlock()
                    sched_annotate_sleep()
                    wait_noreap_copyout() <int wait_noreap_copyout (struct wait_opts *wo, struct task_struct *p, pid_t pid, uid_t uid, int why, int status) at exit.c:935>:
                        getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                            k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                                task_cputime_adjusted()
                                accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                    task_io_get_inblock()
                                    task_io_get_oublock()
                                lock_task_sighand()
                                thread_group_cputime_adjusted()
                                while_each_thread()
                                BUG()
                                unlock_task_sighand()
                                cputime_to_timeval()
                                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                    task_lock()
                                    atomic_inc()
                                    task_unlock()
                                setmax_mm_hiwater_rss()
                                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                    might_sleep()
                                    atomic_dec_and_test()
                                    uprobe_clear_state()
                                    exit_aio()
                                    ksm_exit()
                                    khugepaged_exit()
                                    exit_mmap()
                                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                        rcu_dereference_raw()
                                        get_file()
                                        rcu_assign_pointer()
                                        fput()
                                    list_empty()
                                    spin_lock()
                                    list_del()
                                    spin_unlock()
                                    module_put() <void module_put (struct module *module) at module.c:1098>:
                                        preempt_disable()
                                        atomic_dec_if_positive()
                                        WARN_ON()
                                        trace_module_put()
                                        preempt_enable()
                                    mmdrop()
                            copy_to_user()
                        put_task_struct()
                        put_user()
                    getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                        k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                            task_cputime_adjusted()
                            accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                task_io_get_inblock()
                                task_io_get_oublock()
                            lock_task_sighand()
                            thread_group_cputime_adjusted()
                            while_each_thread()
                            BUG()
                            unlock_task_sighand()
                            cputime_to_timeval()
                            get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                task_lock()
                                atomic_inc()
                                task_unlock()
                            setmax_mm_hiwater_rss()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                        copy_to_user()
                    put_user()
                    put_task_struct()
                    BUG_ON()
                wait_task_continued() <int wait_task_continued (struct wait_opts *wo, struct task_struct *p) at exit.c:1233>:
                    unlikely()
                    spin_lock_irq()
                    spin_unlock_irq()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    current_user_ns()
                    task_uid()
                    task_pid_vnr()
                    get_task_struct()
                    read_unlock()
                    sched_annotate_sleep()
                    getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                        k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                            task_cputime_adjusted()
                            accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                task_io_get_inblock()
                                task_io_get_oublock()
                            lock_task_sighand()
                            thread_group_cputime_adjusted()
                            while_each_thread()
                            BUG()
                            unlock_task_sighand()
                            cputime_to_timeval()
                            get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                task_lock()
                                atomic_inc()
                                task_unlock()
                            setmax_mm_hiwater_rss()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                        copy_to_user()
                    put_task_struct()
                    put_user()
                    wait_noreap_copyout() <int wait_noreap_copyout (struct wait_opts *wo, struct task_struct *p, pid_t pid, uid_t uid, int why, int status) at exit.c:935>:
                        getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                            k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                                task_cputime_adjusted()
                                accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                    task_io_get_inblock()
                                    task_io_get_oublock()
                                lock_task_sighand()
                                thread_group_cputime_adjusted()
                                while_each_thread()
                                BUG()
                                unlock_task_sighand()
                                cputime_to_timeval()
                                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                    task_lock()
                                    atomic_inc()
                                    task_unlock()
                                setmax_mm_hiwater_rss()
                                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                    might_sleep()
                                    atomic_dec_and_test()
                                    uprobe_clear_state()
                                    exit_aio()
                                    ksm_exit()
                                    khugepaged_exit()
                                    exit_mmap()
                                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                        rcu_dereference_raw()
                                        get_file()
                                        rcu_assign_pointer()
                                        fput()
                                    list_empty()
                                    spin_lock()
                                    list_del()
                                    spin_unlock()
                                    module_put() <void module_put (struct module *module) at module.c:1098>:
                                        preempt_disable()
                                        atomic_dec_if_positive()
                                        WARN_ON()
                                        trace_module_put()
                                        preempt_enable()
                                    mmdrop()
                            copy_to_user()
                        put_task_struct()
                        put_user()
                    BUG_ON()
        while_each_thread()
        read_unlock()
        signal_pending()
        schedule()
        remove_wait_queue()
    put_pid() <void put_pid (struct pid *pid) at pid.c:237>:
        atomic_read()
        atomic_dec_and_test()
        kmem_cache_free()
        put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
            kref_put()
            free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                container_of()
                destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                    ns_free_inum()
                    kfree()
                    put_user_ns()
                    call_rcu()
                    delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                        kmem_cache_free()
                        container_of()
    capable() <bool capable (int cap) at capability.c:401>:
        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
            unlikely()
            cap_valid()
            pr_crit()
            BUG()
            security_capable()
            current_cred()
    mutex_trylock()
    kimage_free() <void kimage_free (struct kimage *image) at kexec_core.c:544>:
        kimage_free_extra_pages() <void kimage_free_extra_pages (struct kimage *image) at kexec_core.c:514>:
            kimage_free_page_list() <void kimage_free_page_list (struct list_head *list) at kexec_core.c:311>:
                list_for_each_entry_safe()
                list_del()
                kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                    page_private()
                    ClearPageReserved()
        for_each_kimage_entry()
        kimage_free_entry() <void kimage_free_entry (kimage_entry_t entry) at kexec_core.c:536>:
            pfn_to_page()
            kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                page_private()
                ClearPageReserved()
        machine_kexec_cleanup()
        kimage_free_page_list() <void kimage_free_page_list (struct list_head *list) at kexec_core.c:311>:
            list_for_each_entry_safe()
            list_del()
            kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                page_private()
                ClearPageReserved()
        kimage_file_post_load_cleanup() <void kimage_file_post_load_cleanup (struct kimage *image) at kexec_file.c:143>:
            vfree()
            kfree()
            arch_kimage_file_post_load_cleanup() <int __weak arch_kimage_file_post_load_cleanup (struct kimage *image) at kexec_file.c:107>:
        kfree()
    xchg()
    kimage_alloc_init() <int kimage_alloc_init (struct kimage **rimage, unsigned long entry, unsigned long nr_segments, struct kexec_segment __user *segments, unsigned long flags) at kexec.c:40>:
        do_kimage_alloc_init() <struct kimage *do_kimage_alloc_init (void) at kexec_core.c:237>:
            kzalloc()
            INIT_LIST_HEAD()
        copy_user_segment_list() <int copy_user_segment_list (struct kimage *image, unsigned long nr_segments, struct kexec_segment __user *segments) at kexec.c:23>:
            copy_from_user()
        sanity_check_segment_list() <int sanity_check_segment_list (struct kimage *image) at kexec_core.c:146>:
        kimage_alloc_control_pages() <struct page *kimage_alloc_control_pages (struct kimage *image, unsigned int order) at kexec_core.c:448>:
            kimage_alloc_normal_control_pages() <struct page *kimage_alloc_normal_control_pages (struct kimage *image, unsigned int order) at kexec_core.c:321>:
                INIT_LIST_HEAD()
                kimage_alloc_pages() <struct page *kimage_alloc_pages (gfp_t gfp_mask, unsigned int order) at kexec_core.c:282>:
                    alloc_pages()
                    set_page_private()
                    SetPageReserved()
                page_to_pfn()
                kimage_is_destination_range() <int kimage_is_destination_range (struct kimage *image, unsigned long start, unsigned long end) at kexec_core.c:264>:
                list_add()
                kimage_free_page_list() <void kimage_free_page_list (struct list_head *list) at kexec_core.c:311>:
                    list_for_each_entry_safe()
                    list_del()
                    kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                        page_private()
                        ClearPageReserved()
            kimage_alloc_crash_control_pages() <struct page *kimage_alloc_crash_control_pages (struct kimage *image, unsigned int order) at kexec_core.c:387>:
                pfn_to_page()
        get_order()
        pr_err()
        kimage_free_page_list() <void kimage_free_page_list (struct list_head *list) at kexec_core.c:311>:
            list_for_each_entry_safe()
            list_del()
            kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                page_private()
                ClearPageReserved()
        kfree()
    crash_map_reserved_pages() <void __weak crash_map_reserved_pages (void) at kexec_core.c:1555>
    machine_kexec_prepare()
    kimage_load_segment() <int kimage_load_segment (struct kimage *image, struct kexec_segment *segment) at kexec_core.c:832>:
        kimage_load_normal_segment() <int kimage_load_normal_segment (struct kimage *image, struct kexec_segment *segment) at kexec_core.c:701>:
            kimage_set_destination() <int kimage_set_destination (struct kimage *image, unsigned long destination) at kexec_core.c:491>:
                kimage_add_entry() <int kimage_add_entry (struct kimage *image, kimage_entry_t entry) at kexec_core.c:465>:
                    kimage_alloc_page() <struct page *kimage_alloc_page (struct kimage *image, gfp_t gfp_mask, unsigned long destination) at kexec_core.c:604>:
                        list_for_each_entry()
                        page_to_pfn()
                        list_del()
                        kimage_alloc_pages() <struct page *kimage_alloc_pages (gfp_t gfp_mask, unsigned int order) at kexec_core.c:282>:
                            alloc_pages()
                            set_page_private()
                            SetPageReserved()
                        list_add()
                        kimage_is_destination_range() <int kimage_is_destination_range (struct kimage *image, unsigned long start, unsigned long end) at kexec_core.c:264>:
                        kimage_dst_used() <kimage_entry_t *kimage_dst_used (struct kimage *image, unsigned long page) at kexec_core.c:585>:
                            for_each_kimage_entry()
                        pfn_to_page()
                        copy_highpage()
                        PageHighMem()
                        kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                            page_private()
                            ClearPageReserved()
                    page_address()
                    virt_to_phys()
            kimage_alloc_page() <struct page *kimage_alloc_page (struct kimage *image, gfp_t gfp_mask, unsigned long destination) at kexec_core.c:604>:
                list_for_each_entry()
                page_to_pfn()
                list_del()
                kimage_alloc_pages() <struct page *kimage_alloc_pages (gfp_t gfp_mask, unsigned int order) at kexec_core.c:282>:
                    alloc_pages()
                    set_page_private()
                    SetPageReserved()
                list_add()
                kimage_is_destination_range() <int kimage_is_destination_range (struct kimage *image, unsigned long start, unsigned long end) at kexec_core.c:264>:
                kimage_dst_used() <kimage_entry_t *kimage_dst_used (struct kimage *image, unsigned long page) at kexec_core.c:585>:
                    for_each_kimage_entry()
                pfn_to_page()
                copy_highpage()
                PageHighMem()
                kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                    page_private()
                    ClearPageReserved()
            kimage_add_page() <int kimage_add_page (struct kimage *image, unsigned long page) at kexec_core.c:503>:
                kimage_add_entry() <int kimage_add_entry (struct kimage *image, kimage_entry_t entry) at kexec_core.c:465>:
                    kimage_alloc_page() <struct page *kimage_alloc_page (struct kimage *image, gfp_t gfp_mask, unsigned long destination) at kexec_core.c:604>:
                        list_for_each_entry()
                        page_to_pfn()
                        list_del()
                        kimage_alloc_pages() <struct page *kimage_alloc_pages (gfp_t gfp_mask, unsigned int order) at kexec_core.c:282>:
                            alloc_pages()
                            set_page_private()
                            SetPageReserved()
                        list_add()
                        kimage_is_destination_range() <int kimage_is_destination_range (struct kimage *image, unsigned long start, unsigned long end) at kexec_core.c:264>:
                        kimage_dst_used() <kimage_entry_t *kimage_dst_used (struct kimage *image, unsigned long page) at kexec_core.c:585>:
                            for_each_kimage_entry()
                        pfn_to_page()
                        copy_highpage()
                        PageHighMem()
                        kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                            page_private()
                            ClearPageReserved()
                    page_address()
                    virt_to_phys()
            page_to_pfn()
            kmap()
            clear_page()
            min_t()
            min()
            copy_from_user()
            kunmap()
        kimage_load_crash_segment() <int kimage_load_crash_segment (struct kimage *image, struct kexec_segment *segment) at kexec_core.c:768>:
            pfn_to_page()
            kmap()
            min_t()
            min()
            copy_from_user()
            kexec_flush_icache_page()
            kunmap()
    kimage_terminate() <void kimage_terminate (struct kimage *image) at kexec_core.c:523>:
    crash_unmap_reserved_pages() <void __weak crash_unmap_reserved_pages (void) at kexec_core.c:1558>
    mutex_unlock()
    ptrace_traceme() <int ptrace_traceme (void) at ptrace.c:410>:
        write_lock_irq()
        security_ptrace_traceme()
        write_unlock_irq()
    arch_ptrace_attach()
    ptrace_get_task_struct() <struct task_struct *ptrace_get_task_struct (pid_t pid) at ptrace.c:1060>:
        rcu_read_lock()
        find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
            find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                RCU_LOCKDEP_WARN()
                rcu_read_lock_held()
                pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                    rcu_dereference_check()
                    hlist_first_rcu()
                    lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                        lockdep_is_held()
                    hlist_entry()
                find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                    hlist_for_each_entry_rcu()
                    pid_hashfn()
                    container_of()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
        get_task_struct()
        rcu_read_unlock()
        ERR_PTR()
    IS_ERR()
    PTR_ERR()
    ptrace_attach() <int ptrace_attach (struct task_struct *task, long request, unsigned long addr, unsigned long flags) at ptrace.c:296>:
        audit_ptrace()
        unlikely()
        same_thread_group()
        mutex_lock_interruptible()
        task_lock()
        task_unlock()
        write_lock_irq()
        rcu_read_lock()
        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
            unlikely()
            cap_valid()
            pr_crit()
            BUG()
            security_capable()
            current_cred()
        rcu_read_unlock()
        send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
            valid_signal()
            do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                lock_task_sighand()
                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                        SI_FROMUSER()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                unlock_task_sighand()
        spin_lock()
        task_is_stopped()
        task_set_jobctl_pending() <bool task_set_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:248>:
            BUG_ON()
            unlikely()
            fatal_signal_pending()
        signal_wake_up_state() <void signal_wake_up_state (struct task_struct *t, unsigned int state) at signal.c:639>:
            set_tsk_thread_flag()
            wake_up_state()
            kick_process()
        spin_unlock()
        write_unlock_irq()
        mutex_unlock()
        wait_on_bit()
        proc_ptrace_connector()
    ptrace_check_attach() <int ptrace_check_attach (struct task_struct *child, bool ignore_state) at ptrace.c:172>:
        read_lock()
        WARN_ON()
        ptrace_freeze_traced() <bool ptrace_freeze_traced (struct task_struct *task) at ptrace.c:122>:
            spin_lock_irq()
            task_is_traced()
            spin_unlock_irq()
        read_unlock()
        wait_task_inactive()
    arch_ptrace()
    ptrace_unfreeze_traced() <void ptrace_unfreeze_traced (struct task_struct *task) at ptrace.c:140>:
        WARN_ON()
        spin_lock_irq()
        wake_up_state()
        spin_unlock_irq()
    put_task_struct()
    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
        ns_of_pid()
        task_pid()
    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
        unlikely()
        cap_valid()
        pr_crit()
        BUG()
        security_capable()
        current_cred()
    reboot_pid_ns() <int reboot_pid_ns (struct pid_namespace *pid_ns, int cmd) at pid_namespace.c:308>:
        read_lock()
        force_sig() <void force_sig (int sig, struct task_struct *p) at signal.c:1435>:
            force_sig_info() <int force_sig_info (int sig, struct siginfo *info, struct task_struct *t) at signal.c:1160>:
                spin_lock_irqsave()
                recalc_sigpending_and_wake() <void recalc_sigpending_and_wake (struct task_struct *t) at signal.c:152>:
                    recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                        PENDING()
                        set_tsk_thread_flag()
                    signal_wake_up()
                specific_send_sig_info() <int specific_send_sig_info (int sig, struct siginfo *info, struct task_struct *t) at signal.c:1129>:
                    send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                            SI_FROMUSER()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                spin_unlock_irqrestore()
        read_unlock()
        do_exit() <void do_exit (long code) at exit.c:651>:
            TASKS_RCU()
            profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
                blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
            WARN_ON()
            blk_needs_flush_plug()
            unlikely()
            in_interrupt()
            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                local_irq_disable()
                raw_smp_processor_id()
                atomic_cmpxchg()
                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                    cpu_relax()
                console_verbose()
                bust_spinlocks()
                pr_emerg()
                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                    test_bit()
                dump_stack()
                smp_send_stop()
                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                kmsg_dump()
                debug_locks_off()
                console_flush_on_panic()
                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                no_blink() <long no_blink (int state) at panic.c:46>
                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                    raw_cpu_write()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
                mdelay()
                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                    kmsg_dump()
                    machine_emergency_restart()
                disabled_wait()
                local_irq_enable()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            set_fs()
            ptrace_event()
            validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
                kdebug()
                atomic_read()
                read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                    atomic_read()
            pr_alert()
            set_current_state()
            schedule()
            exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
                threadgroup_change_begin()
                thread_group_empty()
                signal_group_exit()
                threadgroup_change_end()
                spin_lock_irq()
                signal_pending()
                signotset()
                retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                    sigandsets()
                    sigisemptyset()
                    while_each_thread()
                    has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                    signal_pending()
                    signal_wake_up()
                unlikely()
                task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                    WARN_ON_ONCE()
                    task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                        BUG_ON()
                        task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                            unlikely()
                            smp_mb()
                            wake_up_bit()
                spin_unlock_irq()
                read_lock()
                do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                    rcu_read_lock()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_cred_xxx()
                    task_uid()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_clock_t()
                    BUG()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                read_unlock()
            smp_mb()
            raw_spin_unlock_wait()
            in_atomic()
            pr_info()
            task_pid_nr()
            preempt_count()
            preempt_count_set()
            sync_mm_rss()
            acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
                task_cputime()
            atomic_dec_and_test()
            hrtimer_cancel()
            exit_itimers()
            setmax_mm_hiwater_rss()
            acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
                down_read()
                up_read()
                spin_lock_irq()
                thread_group_leader()
                task_cputime()
                spin_unlock_irq()
            tty_audit_exit()
            audit_free()
            taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
                taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                    nla_total_size()
                taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                    thread_group_empty()
                    kmem_cache_zalloc()
                    spin_lock_irq()
                    spin_unlock_irq()
                    kmem_cache_free()
                fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                    spin_lock_irqsave()
                    delayacct_add_tsk()
                    spin_unlock_irqrestore()
                raw_cpu_ptr()
                list_empty()
                prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                    genlmsg_new()
                    this_cpu_inc_return()
                    genlmsg_put()
                    genlmsg_put_reply()
                    nlmsg_free()
                mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                    nla_put()
                    nla_nest_start()
                    nla_nest_cancel()
                    nla_reserve()
                    nla_nest_end()
                    nla_data()
                task_pid_nr_ns()
                fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                    delayacct_add_tsk()
                    bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                        BUILD_BUG_ON()
                        ktime_get_ns()
                        do_div()
                        get_seconds()
                        thread_group_leader()
                        task_nice()
                        task_pid_nr_ns()
                        rcu_read_lock()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                            from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        pid_alive()
                        task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                            pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                            task_tgid()
                        rcu_dereference()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_usecs()
                        task_cputime_scaled()
                    xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                        get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                            task_lock()
                            atomic_inc()
                            task_unlock()
                        get_mm_hiwater_rss()
                        get_mm_hiwater_vm()
                        mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                            might_sleep()
                            atomic_dec_and_test()
                            uprobe_clear_state()
                            exit_aio()
                            ksm_exit()
                            khugepaged_exit()
                            exit_mmap()
                            set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                rcu_dereference_raw()
                                get_file()
                                rcu_assign_pointer()
                                fput()
                            list_empty()
                            spin_lock()
                            list_del()
                            spin_unlock()
                            module_put() <void module_put (struct module *module) at module.c:1098>:
                                preempt_disable()
                                atomic_dec_if_positive()
                                WARN_ON()
                                trace_module_put()
                                preempt_enable()
                            mmdrop()
                task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                    pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                    task_tgid()
                send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                    nlmsg_data()
                    nlmsg_hdr()
                    genlmsg_data()
                    genlmsg_end()
                    down_read()
                    list_for_each_entry()
                    list_is_last()
                    skb_clone()
                    genlmsg_unicast()
                    up_read()
                    nlmsg_free()
                    down_write()
                    list_for_each_entry_safe()
                    list_del()
                    kfree()
                    up_write()
                nlmsg_free()
            exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
                mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                    unlikely()
                    exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                        uninitialized_var()
                        fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                            get_user()
                        get_user()
                        handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                            uninitialized_var()
                            get_user()
                            task_pid_vnr()
                            cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                pagefault_disable()
                                futex_atomic_cmpxchg_inatomic()
                                pagefault_enable()
                            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                down_read()
                                fixup_user_fault()
                                up_read()
                            futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                WAKE_Q()
                                get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                    unlikely()
                                    access_ok()
                                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                        should_fail()
                                    get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                        ihold()
                                        futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                            atomic_inc()
                                            smp_mb__after_atomic()
                                        smp_mb()
                                    get_user_pages_fast()
                                    lock_page()
                                    compound_head()
                                    PageSwapCache()
                                    unlock_page()
                                    put_page()
                                    PageAnon()
                                    basepage_index()
                                unlikely()
                                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                    jhash2()
                                hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                    atomic_read()
                                spin_lock()
                                plist_for_each_entry_safe()
                                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                    WARN()
                                    wake_q_add()
                                    smp_wmb()
                                spin_unlock()
                                wake_up_q()
                                put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                    drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                        WARN_ON_ONCE()
                                        iput()
                                        mmdrop()
                        cond_resched()
                    compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                        uninitialized_var()
                        fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                            get_user()
                            compat_ptr()
                        get_user()
                        futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                            ptr_to_compat()
                            compat_ptr()
                        handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                            uninitialized_var()
                            get_user()
                            task_pid_vnr()
                            cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                pagefault_disable()
                                futex_atomic_cmpxchg_inatomic()
                                pagefault_enable()
                            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                down_read()
                                fixup_user_fault()
                                up_read()
                            futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                WAKE_Q()
                                get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                    unlikely()
                                    access_ok()
                                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                        should_fail()
                                    get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                        ihold()
                                        futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                            atomic_inc()
                                            smp_mb__after_atomic()
                                        smp_mb()
                                    get_user_pages_fast()
                                    lock_page()
                                    compound_head()
                                    PageSwapCache()
                                    unlock_page()
                                    put_page()
                                    PageAnon()
                                    basepage_index()
                                unlikely()
                                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                    jhash2()
                                hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                    atomic_read()
                                spin_lock()
                                plist_for_each_entry_safe()
                                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                    WARN()
                                    wake_q_add()
                                    smp_wmb()
                                spin_unlock()
                                wake_up_q()
                                put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                    drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                        WARN_ON_ONCE()
                                        iput()
                                        mmdrop()
                        cond_resched()
                    list_empty()
                    exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                        raw_spin_lock_irq()
                        list_empty()
                        list_entry()
                        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                            jhash2()
                        raw_spin_unlock_irq()
                        spin_lock()
                        spin_unlock()
                        WARN_ON()
                        list_del_init()
                        rt_mutex_unlock()
                    uprobe_free_utask()
                    deactivate_mm()
                    atomic_read()
                    put_user()
                    sys_futex()
                    complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                        task_lock()
                        likely()
                        complete()
                        task_unlock()
                sync_mm_rss()
                down_read()
                up_read()
                xchg()
                atomic_dec_and_test()
                complete()
                set_task_state()
                freezable_schedule()
                atomic_inc()
                BUG_ON()
                task_lock()
                enter_lazy_tlb()
                task_unlock()
                mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                    atomic_read()
                    read_lock()
                    list_for_each_entry()
                    for_each_process()
                    for_each_thread()
                    read_unlock()
                    BUG_ON()
                    get_task_struct()
                    task_lock()
                    task_unlock()
                    put_task_struct()
                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                    might_sleep()
                    atomic_dec_and_test()
                    uprobe_clear_state()
                    exit_aio()
                    ksm_exit()
                    khugepaged_exit()
                    exit_mmap()
                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                        rcu_dereference_raw()
                        get_file()
                        rcu_assign_pointer()
                        fput()
                    list_empty()
                    spin_lock()
                    list_del()
                    spin_unlock()
                    module_put() <void module_put (struct module *module) at module.c:1098>:
                        preempt_disable()
                        atomic_dec_if_positive()
                        WARN_ON()
                        trace_module_put()
                        preempt_enable()
                    mmdrop()
                test_thread_flag()
                exit_oom_victim()
            acct_process() <void acct_process (void) at acct.c:587>:
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                unlikely()
                slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                    acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                        smp_rmb()
                        rcu_read_lock()
                        to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                            container_of()
                        ACCESS_ONCE()
                        rcu_read_unlock()
                        atomic_long_inc_not_zero()
                        cpu_relax()
                        mutex_lock()
                        mutex_unlock()
                        acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                            atomic_long_dec_and_test()
                            kfree_rcu()
                    do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                        override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                            kdebug()
                            atomic_read()
                            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                atomic_read()
                            validate_creds()
                            get_cred()
                            alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                atomic_add()
                            rcu_assign_pointer()
                        check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                            time_is_before_jiffies()
                            vfs_statfs()
                            do_div()
                            pr_info()
                        fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                            strlcpy()
                            ktime_get_ns()
                            nsec_to_AHZ()
                            encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                            encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                            encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                            do_div()
                            get_seconds()
                            spin_lock_irq()
                            old_encode_dev()
                            tty_devnum()
                            jiffies_to_AHZ()
                            cputime_to_jiffies()
                            spin_unlock_irq()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                            from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                            pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                            task_tgid()
                        rcu_read_lock()
                        rcu_dereference()
                        rcu_read_unlock()
                        file_start_write_trylock()
                        file_end_write()
                        revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                            kdebug()
                            atomic_read()
                            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                atomic_read()
                            validate_creds()
                            alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                atomic_add()
                            rcu_assign_pointer()
                            put_cred()
                    mutex_unlock()
                    acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                        atomic_long_dec_and_test()
                        kfree_rcu()
            trace_sched_process_exit()
            exit_sem()
            exit_shm()
            exit_files()
            exit_fs()
            disassociate_ctty()
            exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
                switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                    might_sleep()
                    task_lock()
                    task_unlock()
                    atomic_dec_and_test()
                    free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                        put_mnt_ns()
                        put_uts_ns()
                        put_ipc_ns()
                        put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                            kref_put()
                            free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                container_of()
                                destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                    ns_free_inum()
                                    kfree()
                                    put_user_ns()
                                    call_rcu()
                                    delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                        kmem_cache_free()
                                        container_of()
                        put_net()
                        kmem_cache_free()
            exit_task_work()
            exit_thread()
            perf_event_exit_task()
            cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
                task_css_set()
                list_empty()
                spin_lock_bh()
                css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                    lockdep_assert_held()
                    WARN_ON_ONCE()
                    list_empty()
                    list_for_each_entry_safe()
                    css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                        lockdep_assert_held()
                        WARN_ON_ONCE()
                        css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                            lockdep_assert_held()
                            container_of()
                            list_entry()
                            css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                lockdep_assert_held()
                                list_empty()
                            list_empty()
                            list_del()
                            put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                                lockdep_assert_held()
                                atomic_dec_and_test()
                                for_each_subsys()
                                list_del()
                                css_put()
                                hash_del()
                                list_for_each_entry_safe()
                                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                    container_of()
                                cgroup_put()
                                kfree()
                                kfree_rcu()
                            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                atomic_inc()
                            list_add()
                    list_del_init()
                    css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                        lockdep_assert_held()
                        list_empty()
                    css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                        lockdep_assert_held()
                        list_for_each_entry()
                        cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                            lockdep_assert_held()
                            check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                                notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                    test_bit()
                                cgroup_is_populated()
                                css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                    rcu_read_lock()
                                    css_for_each_child()
                                    rcu_read_unlock()
                                cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                                schedule_work()
                            cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                                spin_lock_irqsave()
                                kernfs_notify()
                                spin_unlock_irqrestore()
                            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                container_of()
                    rcu_assign_pointer()
                    list_add_tail()
                spin_unlock_bh()
                get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                    atomic_inc()
                for_each_subsys_which()
            flush_ptrace_hw_breakpoint()
            preempt_disable()
            preempt_enable()
            exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
                LIST_HEAD()
                write_lock_irq()
                forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                    unlikely()
                    list_empty()
                    exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                        list_for_each_entry_safe()
                        unlikely()
                        send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                            valid_signal()
                            do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                lock_task_sighand()
                                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                        SI_FROMUSER()
                                    task_pid_nr_ns()
                                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                        ns_of_pid()
                                        task_pid()
                                unlock_task_sighand()
                        list_add()
                    find_child_reaper()
                    find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                        find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                            for_each_thread()
                        same_thread_group()
                    list_for_each_entry()
                    for_each_thread()
                    BUG_ON()
                    likely()
                    group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                        rcu_read_lock()
                        check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                            valid_signal()
                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                SI_FROMUSER()
                            audit_signal_info()
                            same_thread_group()
                            kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                                current_cred()
                                uid_eq()
                                ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                    unlikely()
                                    cap_valid()
                                    pr_crit()
                                    BUG()
                                    security_capable()
                                    current_cred()
                            task_session()
                            security_task_kill()
                        rcu_read_unlock()
                        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                            lock_task_sighand()
                            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                    SI_FROMUSER()
                                task_pid_nr_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                            unlock_task_sighand()
                    same_thread_group()
                    reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                        unlikely()
                        thread_group_empty()
                        do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                            BUG_ON()
                            task_is_stopped_or_traced()
                            thread_group_empty()
                            rcu_read_lock()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            task_cred_xxx()
                            task_uid()
                            rcu_read_unlock()
                            task_cputime()
                            cputime_to_clock_t()
                            spin_lock_irqsave()
                            valid_signal()
                            spin_unlock_irqrestore()
                        list_add()
                        kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                            task_pgrp()
                            task_session()
                            will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                                do_each_pid_task()
                                thread_group_empty()
                                is_global_init()
                                task_pgrp()
                                task_session()
                                while_each_pid_task()
                            has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                                do_each_pid_task()
                                while_each_pid_task()
                    list_splice_tail_init()
                kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                    task_pgrp()
                    task_session()
                    will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                        do_each_pid_task()
                        thread_group_empty()
                        is_global_init()
                        task_pgrp()
                        task_session()
                        while_each_pid_task()
                    has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                        do_each_pid_task()
                        while_each_pid_task()
                unlikely()
                thread_group_leader()
                thread_group_empty()
                ptrace_reparented()
                do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                    BUG_ON()
                    task_is_stopped_or_traced()
                    thread_group_empty()
                    rcu_read_lock()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_cred_xxx()
                    task_uid()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_clock_t()
                    spin_lock_irqsave()
                    valid_signal()
                    spin_unlock_irqrestore()
                list_add()
                wake_up_process()
                write_unlock_irq()
                list_for_each_entry_safe()
                list_del_init()
                release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                    rcu_read_lock()
                    atomic_dec()
                    rcu_read_unlock()
                    proc_flush_task()
                    write_lock_irq()
                    ptrace_release_task()
                    thread_group_empty()
                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                        BUG_ON()
                        task_is_stopped_or_traced()
                        thread_group_empty()
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        spin_lock_irqsave()
                        valid_signal()
                        spin_unlock_irqrestore()
                    write_unlock_irq()
                    release_thread()
                    call_rcu()
                    delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                        container_of()
                        perf_event_delayed_put()
                        trace_sched_process_free()
                        put_task_struct()
                    unlikely()
            proc_exit_connector()
            task_lock()
            mpol_put()
            task_unlock()
            kfree()
            debug_check_no_locks_held()
            exit_io_context()
            free_pipe_info()
            put_page()
            check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
                stack_not_used()
                spin_lock()
                pr_warn()
                task_pid_nr()
                spin_unlock()
            exit_rcu()
            BUG()
            cpu_relax()
    mutex_lock()
    kernel_restart() <void kernel_restart (char *cmd) at reboot.c:214>:
        kernel_restart_prepare() <void kernel_restart_prepare (char *cmd) at reboot.c:68>:
            blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
            usermodehelper_disable()
            device_shutdown()
        migrate_to_reboot_cpu() <void migrate_to_reboot_cpu (void) at reboot.c:188>:
            cpu_hotplug_disable() <void cpu_hotplug_disable (void) at cpu.c:178>:
                cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
                    mutex_lock()
                cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
                    mutex_unlock()
            cpu_online()
            cpumask_first()
            set_cpus_allowed_ptr()
            cpumask_of()
        syscore_shutdown()
        pr_emerg()
        kmsg_dump()
        machine_restart()
    kernel_halt() <void kernel_halt (void) at reboot.c:241>:
        kernel_shutdown_prepare() <void kernel_shutdown_prepare (enum system_states state) at reboot.c:228>:
            blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
            usermodehelper_disable()
            device_shutdown()
        migrate_to_reboot_cpu() <void migrate_to_reboot_cpu (void) at reboot.c:188>:
            cpu_hotplug_disable() <void cpu_hotplug_disable (void) at cpu.c:178>:
                cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
                    mutex_lock()
                cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
                    mutex_unlock()
            cpu_online()
            cpumask_first()
            set_cpus_allowed_ptr()
            cpumask_of()
        syscore_shutdown()
        pr_emerg()
        kmsg_dump()
        machine_halt()
    do_exit() <void do_exit (long code) at exit.c:651>:
        TASKS_RCU()
        profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
            blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
        WARN_ON()
        blk_needs_flush_plug()
        unlikely()
        in_interrupt()
        panic() <void panic (const char *fmt, ...) at panic.c:83>:
            local_irq_disable()
            raw_smp_processor_id()
            atomic_cmpxchg()
            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                cpu_relax()
            console_verbose()
            bust_spinlocks()
            pr_emerg()
            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                test_bit()
            dump_stack()
            smp_send_stop()
            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
            kmsg_dump()
            debug_locks_off()
            console_flush_on_panic()
            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
            no_blink() <long no_blink (int state) at panic.c:46>
            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                raw_cpu_write()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            mdelay()
            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                kmsg_dump()
                machine_emergency_restart()
            disabled_wait()
            local_irq_enable()
            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                    raw_cpu_write()
                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                    per_cpu()
                raw_smp_processor_id()
        set_fs()
        ptrace_event()
        validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
        pr_alert()
        set_current_state()
        schedule()
        exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
            threadgroup_change_begin()
            thread_group_empty()
            signal_group_exit()
            threadgroup_change_end()
            spin_lock_irq()
            signal_pending()
            signotset()
            retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                sigandsets()
                sigisemptyset()
                while_each_thread()
                has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                signal_pending()
                signal_wake_up()
            unlikely()
            task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                WARN_ON_ONCE()
                task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                    BUG_ON()
                    task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                        unlikely()
                        smp_mb()
                        wake_up_bit()
            spin_unlock_irq()
            read_lock()
            do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                BUG()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
            read_unlock()
        smp_mb()
        raw_spin_unlock_wait()
        in_atomic()
        pr_info()
        task_pid_nr()
        preempt_count()
        preempt_count_set()
        sync_mm_rss()
        acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
            task_cputime()
        atomic_dec_and_test()
        hrtimer_cancel()
        exit_itimers()
        setmax_mm_hiwater_rss()
        acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
            down_read()
            up_read()
            spin_lock_irq()
            thread_group_leader()
            task_cputime()
            spin_unlock_irq()
        tty_audit_exit()
        audit_free()
        taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
            taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                nla_total_size()
            taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                thread_group_empty()
                kmem_cache_zalloc()
                spin_lock_irq()
                spin_unlock_irq()
                kmem_cache_free()
            fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                spin_lock_irqsave()
                delayacct_add_tsk()
                spin_unlock_irqrestore()
            raw_cpu_ptr()
            list_empty()
            prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                genlmsg_new()
                this_cpu_inc_return()
                genlmsg_put()
                genlmsg_put_reply()
                nlmsg_free()
            mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                nla_put()
                nla_nest_start()
                nla_nest_cancel()
                nla_reserve()
                nla_nest_end()
                nla_data()
            task_pid_nr_ns()
            fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                delayacct_add_tsk()
                bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                    BUILD_BUG_ON()
                    ktime_get_ns()
                    do_div()
                    get_seconds()
                    thread_group_leader()
                    task_nice()
                    task_pid_nr_ns()
                    rcu_read_lock()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    pid_alive()
                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                        task_tgid()
                    rcu_dereference()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_usecs()
                    task_cputime_scaled()
                xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                    get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                        task_lock()
                        atomic_inc()
                        task_unlock()
                    get_mm_hiwater_rss()
                    get_mm_hiwater_vm()
                    mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                        might_sleep()
                        atomic_dec_and_test()
                        uprobe_clear_state()
                        exit_aio()
                        ksm_exit()
                        khugepaged_exit()
                        exit_mmap()
                        set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                            rcu_dereference_raw()
                            get_file()
                            rcu_assign_pointer()
                            fput()
                        list_empty()
                        spin_lock()
                        list_del()
                        spin_unlock()
                        module_put() <void module_put (struct module *module) at module.c:1098>:
                            preempt_disable()
                            atomic_dec_if_positive()
                            WARN_ON()
                            trace_module_put()
                            preempt_enable()
                        mmdrop()
            task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                task_tgid()
            send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                nlmsg_data()
                nlmsg_hdr()
                genlmsg_data()
                genlmsg_end()
                down_read()
                list_for_each_entry()
                list_is_last()
                skb_clone()
                genlmsg_unicast()
                up_read()
                nlmsg_free()
                down_write()
                list_for_each_entry_safe()
                list_del()
                kfree()
                up_write()
            nlmsg_free()
        exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
            mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                unlikely()
                exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                    uninitialized_var()
                    fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                        get_user()
                    get_user()
                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                        uninitialized_var()
                        get_user()
                        task_pid_vnr()
                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                            pagefault_disable()
                            futex_atomic_cmpxchg_inatomic()
                            pagefault_enable()
                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                            down_read()
                            fixup_user_fault()
                            up_read()
                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                            WAKE_Q()
                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                unlikely()
                                access_ok()
                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                    should_fail()
                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                    ihold()
                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                        atomic_inc()
                                        smp_mb__after_atomic()
                                    smp_mb()
                                get_user_pages_fast()
                                lock_page()
                                compound_head()
                                PageSwapCache()
                                unlock_page()
                                put_page()
                                PageAnon()
                                basepage_index()
                            unlikely()
                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                jhash2()
                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                atomic_read()
                            spin_lock()
                            plist_for_each_entry_safe()
                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                WARN()
                                wake_q_add()
                                smp_wmb()
                            spin_unlock()
                            wake_up_q()
                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                    WARN_ON_ONCE()
                                    iput()
                                    mmdrop()
                    cond_resched()
                compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                    uninitialized_var()
                    fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                        get_user()
                        compat_ptr()
                    get_user()
                    futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                        ptr_to_compat()
                        compat_ptr()
                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                        uninitialized_var()
                        get_user()
                        task_pid_vnr()
                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                            pagefault_disable()
                            futex_atomic_cmpxchg_inatomic()
                            pagefault_enable()
                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                            down_read()
                            fixup_user_fault()
                            up_read()
                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                            WAKE_Q()
                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                unlikely()
                                access_ok()
                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                    should_fail()
                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                    ihold()
                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                        atomic_inc()
                                        smp_mb__after_atomic()
                                    smp_mb()
                                get_user_pages_fast()
                                lock_page()
                                compound_head()
                                PageSwapCache()
                                unlock_page()
                                put_page()
                                PageAnon()
                                basepage_index()
                            unlikely()
                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                jhash2()
                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                atomic_read()
                            spin_lock()
                            plist_for_each_entry_safe()
                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                WARN()
                                wake_q_add()
                                smp_wmb()
                            spin_unlock()
                            wake_up_q()
                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                    WARN_ON_ONCE()
                                    iput()
                                    mmdrop()
                    cond_resched()
                list_empty()
                exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                    raw_spin_lock_irq()
                    list_empty()
                    list_entry()
                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                        jhash2()
                    raw_spin_unlock_irq()
                    spin_lock()
                    spin_unlock()
                    WARN_ON()
                    list_del_init()
                    rt_mutex_unlock()
                uprobe_free_utask()
                deactivate_mm()
                atomic_read()
                put_user()
                sys_futex()
                complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                    task_lock()
                    likely()
                    complete()
                    task_unlock()
            sync_mm_rss()
            down_read()
            up_read()
            xchg()
            atomic_dec_and_test()
            complete()
            set_task_state()
            freezable_schedule()
            atomic_inc()
            BUG_ON()
            task_lock()
            enter_lazy_tlb()
            task_unlock()
            mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                atomic_read()
                read_lock()
                list_for_each_entry()
                for_each_process()
                for_each_thread()
                read_unlock()
                BUG_ON()
                get_task_struct()
                task_lock()
                task_unlock()
                put_task_struct()
            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                might_sleep()
                atomic_dec_and_test()
                uprobe_clear_state()
                exit_aio()
                ksm_exit()
                khugepaged_exit()
                exit_mmap()
                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                    rcu_dereference_raw()
                    get_file()
                    rcu_assign_pointer()
                    fput()
                list_empty()
                spin_lock()
                list_del()
                spin_unlock()
                module_put() <void module_put (struct module *module) at module.c:1098>:
                    preempt_disable()
                    atomic_dec_if_positive()
                    WARN_ON()
                    trace_module_put()
                    preempt_enable()
                mmdrop()
            test_thread_flag()
            exit_oom_victim()
        acct_process() <void acct_process (void) at acct.c:587>:
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
            unlikely()
            slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                    smp_rmb()
                    rcu_read_lock()
                    to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                        container_of()
                    ACCESS_ONCE()
                    rcu_read_unlock()
                    atomic_long_inc_not_zero()
                    cpu_relax()
                    mutex_lock()
                    mutex_unlock()
                    acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                        atomic_long_dec_and_test()
                        kfree_rcu()
                do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                    override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        validate_creds()
                        get_cred()
                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                            atomic_add()
                        rcu_assign_pointer()
                    check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                        time_is_before_jiffies()
                        vfs_statfs()
                        do_div()
                        pr_info()
                    fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                        strlcpy()
                        ktime_get_ns()
                        nsec_to_AHZ()
                        encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                        encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                        encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                        do_div()
                        get_seconds()
                        spin_lock_irq()
                        old_encode_dev()
                        tty_devnum()
                        jiffies_to_AHZ()
                        cputime_to_jiffies()
                        spin_unlock_irq()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                        task_tgid()
                    rcu_read_lock()
                    rcu_dereference()
                    rcu_read_unlock()
                    file_start_write_trylock()
                    file_end_write()
                    revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        validate_creds()
                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                            atomic_add()
                        rcu_assign_pointer()
                        put_cred()
                mutex_unlock()
                acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                    atomic_long_dec_and_test()
                    kfree_rcu()
        trace_sched_process_exit()
        exit_sem()
        exit_shm()
        exit_files()
        exit_fs()
        disassociate_ctty()
        exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
            switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                might_sleep()
                task_lock()
                task_unlock()
                atomic_dec_and_test()
                free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                    put_mnt_ns()
                    put_uts_ns()
                    put_ipc_ns()
                    put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                        kref_put()
                        free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                            container_of()
                            destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                ns_free_inum()
                                kfree()
                                put_user_ns()
                                call_rcu()
                                delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                    kmem_cache_free()
                                    container_of()
                    put_net()
                    kmem_cache_free()
        exit_task_work()
        exit_thread()
        perf_event_exit_task()
        cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
            task_css_set()
            list_empty()
            spin_lock_bh()
            css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                lockdep_assert_held()
                WARN_ON_ONCE()
                list_empty()
                list_for_each_entry_safe()
                css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                    lockdep_assert_held()
                    WARN_ON_ONCE()
                    css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                        lockdep_assert_held()
                        container_of()
                        list_entry()
                        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                            lockdep_assert_held()
                            list_empty()
                        list_empty()
                        list_del()
                        put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                            lockdep_assert_held()
                            atomic_dec_and_test()
                            for_each_subsys()
                            list_del()
                            css_put()
                            hash_del()
                            list_for_each_entry_safe()
                            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                container_of()
                            cgroup_put()
                            kfree()
                            kfree_rcu()
                        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                            atomic_inc()
                        list_add()
                list_del_init()
                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                    lockdep_assert_held()
                    list_empty()
                css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                    lockdep_assert_held()
                    list_for_each_entry()
                    cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                        lockdep_assert_held()
                        check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                            notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                test_bit()
                            cgroup_is_populated()
                            css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                rcu_read_lock()
                                css_for_each_child()
                                rcu_read_unlock()
                            cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                            schedule_work()
                        cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                            spin_lock_irqsave()
                            kernfs_notify()
                            spin_unlock_irqrestore()
                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                            container_of()
                rcu_assign_pointer()
                list_add_tail()
            spin_unlock_bh()
            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                atomic_inc()
            for_each_subsys_which()
        flush_ptrace_hw_breakpoint()
        preempt_disable()
        preempt_enable()
        exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
            LIST_HEAD()
            write_lock_irq()
            forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                unlikely()
                list_empty()
                exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                    list_for_each_entry_safe()
                    unlikely()
                    send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                        valid_signal()
                        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                            lock_task_sighand()
                            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                    SI_FROMUSER()
                                task_pid_nr_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                            unlock_task_sighand()
                    list_add()
                find_child_reaper()
                find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                    find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                        for_each_thread()
                    same_thread_group()
                list_for_each_entry()
                for_each_thread()
                BUG_ON()
                likely()
                group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                    rcu_read_lock()
                    check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                        valid_signal()
                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                            SI_FROMUSER()
                        audit_signal_info()
                        same_thread_group()
                        kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                            current_cred()
                            uid_eq()
                            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                unlikely()
                                cap_valid()
                                pr_crit()
                                BUG()
                                security_capable()
                                current_cred()
                        task_session()
                        security_task_kill()
                    rcu_read_unlock()
                    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                        lock_task_sighand()
                        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                SI_FROMUSER()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                        unlock_task_sighand()
                same_thread_group()
                reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                    unlikely()
                    thread_group_empty()
                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                        BUG_ON()
                        task_is_stopped_or_traced()
                        thread_group_empty()
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        spin_lock_irqsave()
                        valid_signal()
                        spin_unlock_irqrestore()
                    list_add()
                    kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                        task_pgrp()
                        task_session()
                        will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                            do_each_pid_task()
                            thread_group_empty()
                            is_global_init()
                            task_pgrp()
                            task_session()
                            while_each_pid_task()
                        has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                            do_each_pid_task()
                            while_each_pid_task()
                list_splice_tail_init()
            kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                task_pgrp()
                task_session()
                will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                    do_each_pid_task()
                    thread_group_empty()
                    is_global_init()
                    task_pgrp()
                    task_session()
                    while_each_pid_task()
                has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                    do_each_pid_task()
                    while_each_pid_task()
            unlikely()
            thread_group_leader()
            thread_group_empty()
            ptrace_reparented()
            do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                BUG_ON()
                task_is_stopped_or_traced()
                thread_group_empty()
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                spin_lock_irqsave()
                valid_signal()
                spin_unlock_irqrestore()
            list_add()
            wake_up_process()
            write_unlock_irq()
            list_for_each_entry_safe()
            list_del_init()
            release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                rcu_read_lock()
                atomic_dec()
                rcu_read_unlock()
                proc_flush_task()
                write_lock_irq()
                ptrace_release_task()
                thread_group_empty()
                do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                    BUG_ON()
                    task_is_stopped_or_traced()
                    thread_group_empty()
                    rcu_read_lock()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_cred_xxx()
                    task_uid()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_clock_t()
                    spin_lock_irqsave()
                    valid_signal()
                    spin_unlock_irqrestore()
                write_unlock_irq()
                release_thread()
                call_rcu()
                delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                    container_of()
                    perf_event_delayed_put()
                    trace_sched_process_free()
                    put_task_struct()
                unlikely()
        proc_exit_connector()
        task_lock()
        mpol_put()
        task_unlock()
        kfree()
        debug_check_no_locks_held()
        exit_io_context()
        free_pipe_info()
        put_page()
        check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
            stack_not_used()
            spin_lock()
            pr_warn()
            task_pid_nr()
            spin_unlock()
        exit_rcu()
        BUG()
        cpu_relax()
    panic() <void panic (const char *fmt, ...) at panic.c:83>:
        local_irq_disable()
        raw_smp_processor_id()
        atomic_cmpxchg()
        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
            cpu_relax()
        console_verbose()
        bust_spinlocks()
        pr_emerg()
        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
            test_bit()
        dump_stack()
        smp_send_stop()
        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
        kmsg_dump()
        debug_locks_off()
        console_flush_on_panic()
        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
        no_blink() <long no_blink (int state) at panic.c:46>
        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
            raw_cpu_write()
            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                    raw_cpu_write()
                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                    per_cpu()
                raw_smp_processor_id()
        mdelay()
        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
            kmsg_dump()
            machine_emergency_restart()
        disabled_wait()
        local_irq_enable()
        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                raw_cpu_write()
            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                per_cpu()
            raw_smp_processor_id()
    kernel_power_off() <void kernel_power_off (void) at reboot.c:257>:
        kernel_shutdown_prepare() <void kernel_shutdown_prepare (enum system_states state) at reboot.c:228>:
            blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
            usermodehelper_disable()
            device_shutdown()
        pm_power_off_prepare() <void (*pm_power_off_prepare) (void) at reboot.c:51>
        migrate_to_reboot_cpu() <void migrate_to_reboot_cpu (void) at reboot.c:188>:
            cpu_hotplug_disable() <void cpu_hotplug_disable (void) at cpu.c:178>:
                cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
                    mutex_lock()
                cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
                    mutex_unlock()
            cpu_online()
            cpumask_first()
            set_cpus_allowed_ptr()
            cpumask_of()
        syscore_shutdown()
        pr_emerg()
        kmsg_dump()
        machine_power_off()
    strncpy_from_user()
    kernel_kexec() <int kernel_kexec (void) at kexec_core.c:1464>:
        mutex_trylock()
        lock_system_sleep()
        pm_prepare_console()
        freeze_processes()
        suspend_console()
        dpm_suspend_start()
        dpm_suspend_end()
        disable_nonboot_cpus() <int disable_nonboot_cpus (void) at cpu.c:572>:
            cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
                mutex_lock()
            cpumask_first()
            cpumask_clear()
            pr_info()
            for_each_online_cpu()
            trace_suspend_resume()
            TPS()
            cpumask_set_cpu()
            pr_err()
            BUG_ON()
            num_online_cpus()
            cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
                mutex_unlock()
        local_irq_disable()
        syscore_suspend()
        kernel_restart_prepare() <void kernel_restart_prepare (char *cmd) at reboot.c:68>:
            blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
            usermodehelper_disable()
            device_shutdown()
        migrate_to_reboot_cpu() <void migrate_to_reboot_cpu (void) at reboot.c:188>:
            cpu_hotplug_disable() <void cpu_hotplug_disable (void) at cpu.c:178>:
                cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
                    mutex_lock()
                cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
                    mutex_unlock()
            cpu_online()
            cpumask_first()
            set_cpus_allowed_ptr()
            cpumask_of()
        cpu_hotplug_enable() <void cpu_hotplug_enable (void) at cpu.c:186>:
            cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
                mutex_lock()
            WARN_ON()
            cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
                mutex_unlock()
        pr_emerg()
        machine_shutdown()
        machine_kexec()
        syscore_resume()
        local_irq_enable()
        enable_nonboot_cpus() <void enable_nonboot_cpus (void) at cpu.c:623>:
            cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
                mutex_lock()
            WARN_ON()
            cpumask_empty()
            pr_info()
            arch_enable_nonboot_cpus_begin() <void __weak arch_enable_nonboot_cpus_begin (void) at cpu.c:615>
            for_each_cpu()
            trace_suspend_resume()
            TPS()
            pr_warn()
            arch_enable_nonboot_cpus_end() <void __weak arch_enable_nonboot_cpus_end (void) at cpu.c:619>
            cpumask_clear()
            cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
                mutex_unlock()
        dpm_resume_start()
        dpm_resume_end()
        resume_console()
        thaw_processes()
        pm_restore_console()
        unlock_system_sleep()
        mutex_unlock()
    hibernate()
    copy_from_user()
    sigdelsetmask()
    sigprocmask() <int sigprocmask (int how, sigset_t *set, sigset_t *oldset) at signal.c:2501>:
        sigorsets()
        sigandnsets()
    copy_to_user()
    do_sigtimedwait() <int do_sigtimedwait (const sigset_t *which, siginfo_t *info, const struct timespec *ts) at signal.c:2749>:
        timespec_valid()
        timespec_to_jiffies()
        sigdelsetmask()
        signotset()
        spin_lock_irq()
        dequeue_signal() <int dequeue_signal (struct task_struct *tsk, sigset_t *mask, siginfo_t *info) at signal.c:559>:
            unlikely()
            hrtimer_is_queued()
            hrtimer_forward()
            get_time()
            hrtimer_restart()
            recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
                recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                    PENDING()
                    set_tsk_thread_flag()
                freezing()
                clear_thread_flag()
            sig_kernel_stop()
            spin_unlock()
            do_schedule_next_timer()
            spin_lock()
        sigandsets()
        recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
            recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                PENDING()
                set_tsk_thread_flag()
            freezing()
            clear_thread_flag()
        spin_unlock_irq()
        freezable_schedule_timeout_interruptible()
    copy_siginfo_to_user() <int copy_siginfo_to_user (siginfo_t __user *to, const siginfo_t *from) at signal.c:2657>:
        access_ok()
    do_rt_tgsigqueueinfo() <int do_rt_tgsigqueueinfo (pid_t tgid, pid_t pid, int sig, siginfo_t *info) at signal.c:2982>:
        task_pid_vnr()
        do_send_specific() <int do_send_specific (pid_t tgid, pid_t pid, int sig, struct siginfo *info) at signal.c:2861>:
            rcu_read_lock()
            find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
                find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                    RCU_LOCKDEP_WARN()
                    rcu_read_lock_held()
                    pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                        rcu_dereference_check()
                        hlist_first_rcu()
                        lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                            lockdep_is_held()
                        hlist_entry()
                    find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                        hlist_for_each_entry_rcu()
                        pid_hashfn()
                        container_of()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
            task_tgid_vnr()
            check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                valid_signal()
                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                    SI_FROMUSER()
                audit_signal_info()
                same_thread_group()
                kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                    current_cred()
                    uid_eq()
                    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                        unlikely()
                        cap_valid()
                        pr_crit()
                        BUG()
                        security_capable()
                        current_cred()
                task_session()
                security_task_kill()
            do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                lock_task_sighand()
                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                        SI_FROMUSER()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                unlock_task_sighand()
            unlikely()
            rcu_read_unlock()
    do_sigaction() <int do_sigaction (int sig, struct k_sigaction *act, struct k_sigaction *oact) at signal.c:3047>:
        valid_signal()
        sig_kernel_only()
        spin_lock_irq()
        sigdelsetmask()
        sig_handler_ignored() <int sig_handler_ignored (void __user *handler, int sig) at signal.c:61>:
            sig_kernel_ignore()
        sig_handler() <void __user *sig_handler (struct task_struct *t, int sig) at signal.c:56>:
        flush_sigqueue_mask() <int flush_sigqueue_mask (sigset_t *mask, struct sigpending *s) at signal.c:659>:
            sigandsets()
            sigisemptyset()
            sigandnsets()
            list_for_each_entry_safe()
            list_del_init()
        for_each_thread()
        spin_unlock_irq()
    rlim64_to_rlim() <void rlim64_to_rlim (const struct rlimit64 *rlim64, struct rlimit *rlim) at sys.c:1347>:
        rlim64_is_infinity() <inline bool rlim64_is_infinity (__u64 rlim64) at sys.c:1326>:
    rcu_read_lock()
    find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
        find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
            RCU_LOCKDEP_WARN()
            rcu_read_lock_held()
            pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                rcu_dereference_check()
                hlist_first_rcu()
                lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                    lockdep_is_held()
                hlist_entry()
            find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                hlist_for_each_entry_rcu()
                pid_hashfn()
                container_of()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
    rcu_read_unlock()
    check_prlimit_permission() <int check_prlimit_permission (struct task_struct *task) at sys.c:1427>:
        current_cred()
        uid_eq()
        gid_eq()
        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
            unlikely()
            cap_valid()
            pr_crit()
            BUG()
            security_capable()
            current_cred()
    get_task_struct()
    do_prlimit() <int do_prlimit (struct task_struct *tsk, unsigned int resource, struct rlimit *new_rlim, struct rlimit *old_rlim) at sys.c:1360>:
        read_lock()
        task_lock()
        capable() <bool capable (int cap) at capability.c:401>:
            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                unlikely()
                cap_valid()
                pr_crit()
                BUG()
                security_capable()
                current_cred()
        security_task_setrlimit()
        task_unlock()
        update_rlimit_cpu()
        read_unlock()
    rlim_to_rlim64() <void rlim_to_rlim64 (const struct rlimit *rlim, struct rlimit64 *rlim64) at sys.c:1335>:
SYSCALL_DEFINE5() <SYSCALL_DEFINE5 (prctl, int, option, unsigned long, arg2, unsigned long, arg3, unsigned long, arg4, unsigned long, arg5) at sys.c:2075>:
    find_get_pid() <struct pid *find_get_pid (pid_t nr) at pid.c:488>:
        rcu_read_lock()
        get_pid()
        find_vpid() <struct pid *find_vpid (int nr) at pid.c:380>:
            find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                hlist_for_each_entry_rcu()
                pid_hashfn()
                container_of()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
        rcu_read_unlock()
    do_wait() <long do_wait (struct wait_opts *wo) at exit.c:1463>:
        trace_sched_process_wait()
        init_waitqueue_func_entry()
        child_wait_callback() <int child_wait_callback (wait_queue_t *wait, unsigned mode, int sync, void *key) at exit.c:1441>:
            container_of()
            eligible_pid() <int eligible_pid (struct wait_opts *wo, struct task_struct *p) at exit.c:913>:
                task_pid_type() <inline struct pid *task_pid_type (struct task_struct *task, enum pid_type type) at exit.c:906>:
            default_wake_function()
        add_wait_queue()
        hlist_empty()
        set_current_state()
        read_lock()
        do_wait_thread() <int do_wait_thread (struct wait_opts *wo, struct task_struct *tsk) at exit.c:1413>:
            list_for_each_entry()
            wait_consider_task() <int wait_consider_task (struct wait_opts *wo, int ptrace, struct task_struct *p) at exit.c:1287>:
                ACCESS_ONCE()
                unlikely()
                eligible_child() <int eligible_child (struct wait_opts *wo, struct task_struct *p) at exit.c:919>:
                    eligible_pid() <int eligible_pid (struct wait_opts *wo, struct task_struct *p) at exit.c:913>:
                        task_pid_type() <inline struct pid *task_pid_type (struct task_struct *task, enum pid_type type) at exit.c:906>:
                security_task_wait()
                likely()
                ptrace_reparented()
                delay_group_leader()
                wait_task_zombie() <int wait_task_zombie (struct wait_opts *wo, struct task_struct *p) at exit.c:969>:
                    task_pid_vnr()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    current_user_ns()
                    task_uid()
                    likely()
                    unlikely()
                    get_task_struct()
                    read_unlock()
                    sched_annotate_sleep()
                    wait_noreap_copyout() <int wait_noreap_copyout (struct wait_opts *wo, struct task_struct *p, pid_t pid, uid_t uid, int why, int status) at exit.c:935>:
                        getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                            k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                                task_cputime_adjusted()
                                accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                    task_io_get_inblock()
                                    task_io_get_oublock()
                                lock_task_sighand()
                                thread_group_cputime_adjusted()
                                while_each_thread()
                                BUG()
                                unlock_task_sighand()
                                cputime_to_timeval()
                                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                    task_lock()
                                    atomic_inc()
                                    task_unlock()
                                setmax_mm_hiwater_rss()
                                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                    might_sleep()
                                    atomic_dec_and_test()
                                    uprobe_clear_state()
                                    exit_aio()
                                    ksm_exit()
                                    khugepaged_exit()
                                    exit_mmap()
                                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                        rcu_dereference_raw()
                                        get_file()
                                        rcu_assign_pointer()
                                        fput()
                                    list_empty()
                                    spin_lock()
                                    list_del()
                                    spin_unlock()
                                    module_put() <void module_put (struct module *module) at module.c:1098>:
                                        preempt_disable()
                                        atomic_dec_if_positive()
                                        WARN_ON()
                                        trace_module_put()
                                        preempt_enable()
                                    mmdrop()
                            copy_to_user()
                        put_task_struct()
                        put_user()
                    ptrace_reparented()
                    thread_group_leader()
                    cmpxchg()
                    thread_group_cputime_adjusted()
                    spin_lock_irq()
                    write_seqlock()
                    task_gtime()
                    task_io_get_inblock()
                    task_io_get_oublock()
                    max()
                    task_io_accounting_add()
                    write_sequnlock()
                    spin_unlock_irq()
                    getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                        k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                            task_cputime_adjusted()
                            accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                task_io_get_inblock()
                                task_io_get_oublock()
                            lock_task_sighand()
                            thread_group_cputime_adjusted()
                            while_each_thread()
                            BUG()
                            unlock_task_sighand()
                            cputime_to_timeval()
                            get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                task_lock()
                                atomic_inc()
                                task_unlock()
                            setmax_mm_hiwater_rss()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                        copy_to_user()
                    put_user()
                    write_lock_irq()
                    ptrace_unlink()
                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                        BUG_ON()
                        task_is_stopped_or_traced()
                        thread_group_empty()
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        spin_lock_irqsave()
                        valid_signal()
                        spin_unlock_irqrestore()
                    write_unlock_irq()
                    release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                        rcu_read_lock()
                        atomic_dec()
                        rcu_read_unlock()
                        proc_flush_task()
                        write_lock_irq()
                        ptrace_release_task()
                        thread_group_empty()
                        do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                            BUG_ON()
                            task_is_stopped_or_traced()
                            thread_group_empty()
                            rcu_read_lock()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            task_cred_xxx()
                            task_uid()
                            rcu_read_unlock()
                            task_cputime()
                            cputime_to_clock_t()
                            spin_lock_irqsave()
                            valid_signal()
                            spin_unlock_irqrestore()
                        write_unlock_irq()
                        release_thread()
                        call_rcu()
                        delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                            container_of()
                            perf_event_delayed_put()
                            trace_sched_process_free()
                            put_task_struct()
                        unlikely()
                wait_task_stopped() <int wait_task_stopped (struct wait_opts *wo, int ptrace, struct task_struct *p) at exit.c:1148>:
                    task_stopped_code() <int *task_stopped_code (struct task_struct *p, bool ptrace) at exit.c:1118>:
                        task_is_traced()
                    spin_lock_irq()
                    unlikely()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    current_user_ns()
                    task_uid()
                    spin_unlock_irq()
                    get_task_struct()
                    task_pid_vnr()
                    read_unlock()
                    sched_annotate_sleep()
                    wait_noreap_copyout() <int wait_noreap_copyout (struct wait_opts *wo, struct task_struct *p, pid_t pid, uid_t uid, int why, int status) at exit.c:935>:
                        getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                            k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                                task_cputime_adjusted()
                                accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                    task_io_get_inblock()
                                    task_io_get_oublock()
                                lock_task_sighand()
                                thread_group_cputime_adjusted()
                                while_each_thread()
                                BUG()
                                unlock_task_sighand()
                                cputime_to_timeval()
                                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                    task_lock()
                                    atomic_inc()
                                    task_unlock()
                                setmax_mm_hiwater_rss()
                                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                    might_sleep()
                                    atomic_dec_and_test()
                                    uprobe_clear_state()
                                    exit_aio()
                                    ksm_exit()
                                    khugepaged_exit()
                                    exit_mmap()
                                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                        rcu_dereference_raw()
                                        get_file()
                                        rcu_assign_pointer()
                                        fput()
                                    list_empty()
                                    spin_lock()
                                    list_del()
                                    spin_unlock()
                                    module_put() <void module_put (struct module *module) at module.c:1098>:
                                        preempt_disable()
                                        atomic_dec_if_positive()
                                        WARN_ON()
                                        trace_module_put()
                                        preempt_enable()
                                    mmdrop()
                            copy_to_user()
                        put_task_struct()
                        put_user()
                    getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                        k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                            task_cputime_adjusted()
                            accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                task_io_get_inblock()
                                task_io_get_oublock()
                            lock_task_sighand()
                            thread_group_cputime_adjusted()
                            while_each_thread()
                            BUG()
                            unlock_task_sighand()
                            cputime_to_timeval()
                            get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                task_lock()
                                atomic_inc()
                                task_unlock()
                            setmax_mm_hiwater_rss()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                        copy_to_user()
                    put_user()
                    put_task_struct()
                    BUG_ON()
                wait_task_continued() <int wait_task_continued (struct wait_opts *wo, struct task_struct *p) at exit.c:1233>:
                    unlikely()
                    spin_lock_irq()
                    spin_unlock_irq()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    current_user_ns()
                    task_uid()
                    task_pid_vnr()
                    get_task_struct()
                    read_unlock()
                    sched_annotate_sleep()
                    getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                        k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                            task_cputime_adjusted()
                            accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                task_io_get_inblock()
                                task_io_get_oublock()
                            lock_task_sighand()
                            thread_group_cputime_adjusted()
                            while_each_thread()
                            BUG()
                            unlock_task_sighand()
                            cputime_to_timeval()
                            get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                task_lock()
                                atomic_inc()
                                task_unlock()
                            setmax_mm_hiwater_rss()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                        copy_to_user()
                    put_task_struct()
                    put_user()
                    wait_noreap_copyout() <int wait_noreap_copyout (struct wait_opts *wo, struct task_struct *p, pid_t pid, uid_t uid, int why, int status) at exit.c:935>:
                        getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                            k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                                task_cputime_adjusted()
                                accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                    task_io_get_inblock()
                                    task_io_get_oublock()
                                lock_task_sighand()
                                thread_group_cputime_adjusted()
                                while_each_thread()
                                BUG()
                                unlock_task_sighand()
                                cputime_to_timeval()
                                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                    task_lock()
                                    atomic_inc()
                                    task_unlock()
                                setmax_mm_hiwater_rss()
                                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                    might_sleep()
                                    atomic_dec_and_test()
                                    uprobe_clear_state()
                                    exit_aio()
                                    ksm_exit()
                                    khugepaged_exit()
                                    exit_mmap()
                                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                        rcu_dereference_raw()
                                        get_file()
                                        rcu_assign_pointer()
                                        fput()
                                    list_empty()
                                    spin_lock()
                                    list_del()
                                    spin_unlock()
                                    module_put() <void module_put (struct module *module) at module.c:1098>:
                                        preempt_disable()
                                        atomic_dec_if_positive()
                                        WARN_ON()
                                        trace_module_put()
                                        preempt_enable()
                                    mmdrop()
                            copy_to_user()
                        put_task_struct()
                        put_user()
                    BUG_ON()
        ptrace_do_wait() <int ptrace_do_wait (struct wait_opts *wo, struct task_struct *tsk) at exit.c:1427>:
            list_for_each_entry()
            wait_consider_task() <int wait_consider_task (struct wait_opts *wo, int ptrace, struct task_struct *p) at exit.c:1287>:
                ACCESS_ONCE()
                unlikely()
                eligible_child() <int eligible_child (struct wait_opts *wo, struct task_struct *p) at exit.c:919>:
                    eligible_pid() <int eligible_pid (struct wait_opts *wo, struct task_struct *p) at exit.c:913>:
                        task_pid_type() <inline struct pid *task_pid_type (struct task_struct *task, enum pid_type type) at exit.c:906>:
                security_task_wait()
                likely()
                ptrace_reparented()
                delay_group_leader()
                wait_task_zombie() <int wait_task_zombie (struct wait_opts *wo, struct task_struct *p) at exit.c:969>:
                    task_pid_vnr()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    current_user_ns()
                    task_uid()
                    likely()
                    unlikely()
                    get_task_struct()
                    read_unlock()
                    sched_annotate_sleep()
                    wait_noreap_copyout() <int wait_noreap_copyout (struct wait_opts *wo, struct task_struct *p, pid_t pid, uid_t uid, int why, int status) at exit.c:935>:
                        getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                            k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                                task_cputime_adjusted()
                                accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                    task_io_get_inblock()
                                    task_io_get_oublock()
                                lock_task_sighand()
                                thread_group_cputime_adjusted()
                                while_each_thread()
                                BUG()
                                unlock_task_sighand()
                                cputime_to_timeval()
                                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                    task_lock()
                                    atomic_inc()
                                    task_unlock()
                                setmax_mm_hiwater_rss()
                                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                    might_sleep()
                                    atomic_dec_and_test()
                                    uprobe_clear_state()
                                    exit_aio()
                                    ksm_exit()
                                    khugepaged_exit()
                                    exit_mmap()
                                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                        rcu_dereference_raw()
                                        get_file()
                                        rcu_assign_pointer()
                                        fput()
                                    list_empty()
                                    spin_lock()
                                    list_del()
                                    spin_unlock()
                                    module_put() <void module_put (struct module *module) at module.c:1098>:
                                        preempt_disable()
                                        atomic_dec_if_positive()
                                        WARN_ON()
                                        trace_module_put()
                                        preempt_enable()
                                    mmdrop()
                            copy_to_user()
                        put_task_struct()
                        put_user()
                    ptrace_reparented()
                    thread_group_leader()
                    cmpxchg()
                    thread_group_cputime_adjusted()
                    spin_lock_irq()
                    write_seqlock()
                    task_gtime()
                    task_io_get_inblock()
                    task_io_get_oublock()
                    max()
                    task_io_accounting_add()
                    write_sequnlock()
                    spin_unlock_irq()
                    getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                        k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                            task_cputime_adjusted()
                            accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                task_io_get_inblock()
                                task_io_get_oublock()
                            lock_task_sighand()
                            thread_group_cputime_adjusted()
                            while_each_thread()
                            BUG()
                            unlock_task_sighand()
                            cputime_to_timeval()
                            get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                task_lock()
                                atomic_inc()
                                task_unlock()
                            setmax_mm_hiwater_rss()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                        copy_to_user()
                    put_user()
                    write_lock_irq()
                    ptrace_unlink()
                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                        BUG_ON()
                        task_is_stopped_or_traced()
                        thread_group_empty()
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        spin_lock_irqsave()
                        valid_signal()
                        spin_unlock_irqrestore()
                    write_unlock_irq()
                    release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                        rcu_read_lock()
                        atomic_dec()
                        rcu_read_unlock()
                        proc_flush_task()
                        write_lock_irq()
                        ptrace_release_task()
                        thread_group_empty()
                        do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                            BUG_ON()
                            task_is_stopped_or_traced()
                            thread_group_empty()
                            rcu_read_lock()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            task_cred_xxx()
                            task_uid()
                            rcu_read_unlock()
                            task_cputime()
                            cputime_to_clock_t()
                            spin_lock_irqsave()
                            valid_signal()
                            spin_unlock_irqrestore()
                        write_unlock_irq()
                        release_thread()
                        call_rcu()
                        delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                            container_of()
                            perf_event_delayed_put()
                            trace_sched_process_free()
                            put_task_struct()
                        unlikely()
                wait_task_stopped() <int wait_task_stopped (struct wait_opts *wo, int ptrace, struct task_struct *p) at exit.c:1148>:
                    task_stopped_code() <int *task_stopped_code (struct task_struct *p, bool ptrace) at exit.c:1118>:
                        task_is_traced()
                    spin_lock_irq()
                    unlikely()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    current_user_ns()
                    task_uid()
                    spin_unlock_irq()
                    get_task_struct()
                    task_pid_vnr()
                    read_unlock()
                    sched_annotate_sleep()
                    wait_noreap_copyout() <int wait_noreap_copyout (struct wait_opts *wo, struct task_struct *p, pid_t pid, uid_t uid, int why, int status) at exit.c:935>:
                        getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                            k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                                task_cputime_adjusted()
                                accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                    task_io_get_inblock()
                                    task_io_get_oublock()
                                lock_task_sighand()
                                thread_group_cputime_adjusted()
                                while_each_thread()
                                BUG()
                                unlock_task_sighand()
                                cputime_to_timeval()
                                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                    task_lock()
                                    atomic_inc()
                                    task_unlock()
                                setmax_mm_hiwater_rss()
                                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                    might_sleep()
                                    atomic_dec_and_test()
                                    uprobe_clear_state()
                                    exit_aio()
                                    ksm_exit()
                                    khugepaged_exit()
                                    exit_mmap()
                                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                        rcu_dereference_raw()
                                        get_file()
                                        rcu_assign_pointer()
                                        fput()
                                    list_empty()
                                    spin_lock()
                                    list_del()
                                    spin_unlock()
                                    module_put() <void module_put (struct module *module) at module.c:1098>:
                                        preempt_disable()
                                        atomic_dec_if_positive()
                                        WARN_ON()
                                        trace_module_put()
                                        preempt_enable()
                                    mmdrop()
                            copy_to_user()
                        put_task_struct()
                        put_user()
                    getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                        k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                            task_cputime_adjusted()
                            accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                task_io_get_inblock()
                                task_io_get_oublock()
                            lock_task_sighand()
                            thread_group_cputime_adjusted()
                            while_each_thread()
                            BUG()
                            unlock_task_sighand()
                            cputime_to_timeval()
                            get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                task_lock()
                                atomic_inc()
                                task_unlock()
                            setmax_mm_hiwater_rss()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                        copy_to_user()
                    put_user()
                    put_task_struct()
                    BUG_ON()
                wait_task_continued() <int wait_task_continued (struct wait_opts *wo, struct task_struct *p) at exit.c:1233>:
                    unlikely()
                    spin_lock_irq()
                    spin_unlock_irq()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    current_user_ns()
                    task_uid()
                    task_pid_vnr()
                    get_task_struct()
                    read_unlock()
                    sched_annotate_sleep()
                    getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                        k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                            task_cputime_adjusted()
                            accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                task_io_get_inblock()
                                task_io_get_oublock()
                            lock_task_sighand()
                            thread_group_cputime_adjusted()
                            while_each_thread()
                            BUG()
                            unlock_task_sighand()
                            cputime_to_timeval()
                            get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                task_lock()
                                atomic_inc()
                                task_unlock()
                            setmax_mm_hiwater_rss()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                        copy_to_user()
                    put_task_struct()
                    put_user()
                    wait_noreap_copyout() <int wait_noreap_copyout (struct wait_opts *wo, struct task_struct *p, pid_t pid, uid_t uid, int why, int status) at exit.c:935>:
                        getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
                            k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
                                task_cputime_adjusted()
                                accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
                                    task_io_get_inblock()
                                    task_io_get_oublock()
                                lock_task_sighand()
                                thread_group_cputime_adjusted()
                                while_each_thread()
                                BUG()
                                unlock_task_sighand()
                                cputime_to_timeval()
                                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                    task_lock()
                                    atomic_inc()
                                    task_unlock()
                                setmax_mm_hiwater_rss()
                                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                    might_sleep()
                                    atomic_dec_and_test()
                                    uprobe_clear_state()
                                    exit_aio()
                                    ksm_exit()
                                    khugepaged_exit()
                                    exit_mmap()
                                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                        rcu_dereference_raw()
                                        get_file()
                                        rcu_assign_pointer()
                                        fput()
                                    list_empty()
                                    spin_lock()
                                    list_del()
                                    spin_unlock()
                                    module_put() <void module_put (struct module *module) at module.c:1098>:
                                        preempt_disable()
                                        atomic_dec_if_positive()
                                        WARN_ON()
                                        trace_module_put()
                                        preempt_enable()
                                    mmdrop()
                            copy_to_user()
                        put_task_struct()
                        put_user()
                    BUG_ON()
        while_each_thread()
        read_unlock()
        signal_pending()
        schedule()
        remove_wait_queue()
    put_user()
    put_pid() <void put_pid (struct pid *pid) at pid.c:237>:
        atomic_read()
        atomic_dec_and_test()
        kmem_cache_free()
        put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
            kref_put()
            free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                container_of()
                destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                    ns_free_inum()
                    kfree()
                    put_user_ns()
                    call_rcu()
                    delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                        kmem_cache_free()
                        container_of()
    rcu_read_lock()
    find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
        find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
            RCU_LOCKDEP_WARN()
            rcu_read_lock_held()
            pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                rcu_dereference_check()
                hlist_first_rcu()
                lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                    lockdep_is_held()
                hlist_entry()
            find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                hlist_for_each_entry_rcu()
                pid_hashfn()
                container_of()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
    get_task_struct()
    rcu_read_unlock()
    kcmp_lock() <int kcmp_lock (struct mutex *m1, struct mutex *m2) at kcmp.c:80>:
        swap()
        mutex_lock_killable()
        likely()
        mutex_lock_killable_nested()
        mutex_unlock()
    ptrace_may_access() <bool ptrace_may_access (struct task_struct *task, unsigned int mode) at ptrace.c:287>:
        task_lock()
        task_unlock()
    get_file_raw_ptr() <struct file *get_file_raw_ptr (struct task_struct *task, unsigned int idx) at kcmp.c:57>:
        task_lock()
        rcu_read_lock()
        fcheck_files()
        rcu_read_unlock()
        task_unlock()
    kcmp_ptr() <int kcmp_ptr (void *v1, void *v2, enum kcmp_type type) at kcmp.c:45>:
        kptr_obfuscate() <long kptr_obfuscate (long v, int type) at kcmp.c:34>:
    kcmp_unlock() <void kcmp_unlock (struct mutex *m1, struct mutex *m2) at kcmp.c:73>:
        likely()
        mutex_unlock()
    put_task_struct()
    capable() <bool capable (int cap) at capability.c:401>:
        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
            unlikely()
            cap_valid()
            pr_crit()
            BUG()
            security_capable()
            current_cred()
    mutex_trylock()
    kimage_free() <void kimage_free (struct kimage *image) at kexec_core.c:544>:
        kimage_free_extra_pages() <void kimage_free_extra_pages (struct kimage *image) at kexec_core.c:514>:
            kimage_free_page_list() <void kimage_free_page_list (struct list_head *list) at kexec_core.c:311>:
                list_for_each_entry_safe()
                list_del()
                kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                    page_private()
                    ClearPageReserved()
        for_each_kimage_entry()
        kimage_free_entry() <void kimage_free_entry (kimage_entry_t entry) at kexec_core.c:536>:
            pfn_to_page()
            kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                page_private()
                ClearPageReserved()
        machine_kexec_cleanup()
        kimage_free_page_list() <void kimage_free_page_list (struct list_head *list) at kexec_core.c:311>:
            list_for_each_entry_safe()
            list_del()
            kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                page_private()
                ClearPageReserved()
        kimage_file_post_load_cleanup() <void kimage_file_post_load_cleanup (struct kimage *image) at kexec_file.c:143>:
            vfree()
            kfree()
            arch_kimage_file_post_load_cleanup() <int __weak arch_kimage_file_post_load_cleanup (struct kimage *image) at kexec_file.c:107>:
        kfree()
    xchg()
    kimage_file_alloc_init() <int kimage_file_alloc_init (struct kimage **rimage, int kernel_fd, int initrd_fd, const char __user *cmdline_ptr, unsigned long cmdline_len, unsigned long flags) at kexec_file.c:255>:
        do_kimage_alloc_init() <struct kimage *do_kimage_alloc_init (void) at kexec_core.c:237>:
            kzalloc()
            INIT_LIST_HEAD()
        kimage_file_prepare_segments() <int kimage_file_prepare_segments (struct kimage *image, int kernel_fd, int initrd_fd, const char __user *cmdline_ptr, unsigned long cmdline_len, unsigned flags) at kexec_file.c:179>:
            copy_file_from_fd() <int copy_file_from_fd (int fd, void **buf, unsigned long *buf_len) at kexec_file.c:36>:
                fdget()
                vfs_getattr()
                vmalloc()
                kernel_read()
                vfree()
                fdput()
            arch_kexec_kernel_image_probe() <int __weak arch_kexec_kernel_image_probe (struct kimage *image, void *buf, unsigned long buf_len) at kexec_file.c:96>:
            arch_kexec_kernel_verify_sig() <int __weak arch_kexec_kernel_verify_sig (struct kimage *image, void *buf, unsigned long buf_len) at kexec_file.c:113>:
            pr_debug()
            kzalloc()
            copy_from_user()
            arch_kexec_kernel_image_load() <void *__weak arch_kexec_kernel_image_load (struct kimage *image) at kexec_file.c:102>:
                ERR_PTR()
            IS_ERR()
            PTR_ERR()
            kimage_file_post_load_cleanup() <void kimage_file_post_load_cleanup (struct kimage *image) at kexec_file.c:143>:
                vfree()
                kfree()
                arch_kimage_file_post_load_cleanup() <int __weak arch_kimage_file_post_load_cleanup (struct kimage *image) at kexec_file.c:107>:
        sanity_check_segment_list() <int sanity_check_segment_list (struct kimage *image) at kexec_core.c:146>:
        kimage_alloc_control_pages() <struct page *kimage_alloc_control_pages (struct kimage *image, unsigned int order) at kexec_core.c:448>:
            kimage_alloc_normal_control_pages() <struct page *kimage_alloc_normal_control_pages (struct kimage *image, unsigned int order) at kexec_core.c:321>:
                INIT_LIST_HEAD()
                kimage_alloc_pages() <struct page *kimage_alloc_pages (gfp_t gfp_mask, unsigned int order) at kexec_core.c:282>:
                    alloc_pages()
                    set_page_private()
                    SetPageReserved()
                page_to_pfn()
                kimage_is_destination_range() <int kimage_is_destination_range (struct kimage *image, unsigned long start, unsigned long end) at kexec_core.c:264>:
                list_add()
                kimage_free_page_list() <void kimage_free_page_list (struct list_head *list) at kexec_core.c:311>:
                    list_for_each_entry_safe()
                    list_del()
                    kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                        page_private()
                        ClearPageReserved()
            kimage_alloc_crash_control_pages() <struct page *kimage_alloc_crash_control_pages (struct kimage *image, unsigned int order) at kexec_core.c:387>:
                pfn_to_page()
        get_order()
        pr_err()
        kimage_free_page_list() <void kimage_free_page_list (struct list_head *list) at kexec_core.c:311>:
            list_for_each_entry_safe()
            list_del()
            kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                page_private()
                ClearPageReserved()
        kimage_file_post_load_cleanup() <void kimage_file_post_load_cleanup (struct kimage *image) at kexec_file.c:143>:
            vfree()
            kfree()
            arch_kimage_file_post_load_cleanup() <int __weak arch_kimage_file_post_load_cleanup (struct kimage *image) at kexec_file.c:107>:
        kfree()
    machine_kexec_prepare()
    kexec_calculate_store_digests() <int kexec_calculate_store_digests (struct kimage *image) at kexec_file.c:551>:
        page_to_pfn()
        ZERO_PAGE()
        crypto_alloc_shash()
        IS_ERR()
        PTR_ERR()
        crypto_shash_descsize()
        kzalloc()
        vzalloc()
        crypto_shash_init()
        crypto_shash_update()
        start()
        crypto_shash_final()
        kexec_purgatory_get_set_symbol() <int kexec_purgatory_get_set_symbol (struct kimage *image, const char *name, void *buf, unsigned int size, bool get_value) at kexec_file.c:1014>:
            kexec_purgatory_find_symbol() <Elf_Sym *kexec_purgatory_find_symbol (struct purgatory_info *pi, const char *name) at kexec_file.c:943>:
                ELF_ST_BIND()
                pr_debug()
            pr_err()
        kfree()
        vfree()
    pr_debug()
    kimage_load_segment() <int kimage_load_segment (struct kimage *image, struct kexec_segment *segment) at kexec_core.c:832>:
        kimage_load_normal_segment() <int kimage_load_normal_segment (struct kimage *image, struct kexec_segment *segment) at kexec_core.c:701>:
            kimage_set_destination() <int kimage_set_destination (struct kimage *image, unsigned long destination) at kexec_core.c:491>:
                kimage_add_entry() <int kimage_add_entry (struct kimage *image, kimage_entry_t entry) at kexec_core.c:465>:
                    kimage_alloc_page() <struct page *kimage_alloc_page (struct kimage *image, gfp_t gfp_mask, unsigned long destination) at kexec_core.c:604>:
                        list_for_each_entry()
                        page_to_pfn()
                        list_del()
                        kimage_alloc_pages() <struct page *kimage_alloc_pages (gfp_t gfp_mask, unsigned int order) at kexec_core.c:282>:
                            alloc_pages()
                            set_page_private()
                            SetPageReserved()
                        list_add()
                        kimage_is_destination_range() <int kimage_is_destination_range (struct kimage *image, unsigned long start, unsigned long end) at kexec_core.c:264>:
                        kimage_dst_used() <kimage_entry_t *kimage_dst_used (struct kimage *image, unsigned long page) at kexec_core.c:585>:
                            for_each_kimage_entry()
                        pfn_to_page()
                        copy_highpage()
                        PageHighMem()
                        kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                            page_private()
                            ClearPageReserved()
                    page_address()
                    virt_to_phys()
            kimage_alloc_page() <struct page *kimage_alloc_page (struct kimage *image, gfp_t gfp_mask, unsigned long destination) at kexec_core.c:604>:
                list_for_each_entry()
                page_to_pfn()
                list_del()
                kimage_alloc_pages() <struct page *kimage_alloc_pages (gfp_t gfp_mask, unsigned int order) at kexec_core.c:282>:
                    alloc_pages()
                    set_page_private()
                    SetPageReserved()
                list_add()
                kimage_is_destination_range() <int kimage_is_destination_range (struct kimage *image, unsigned long start, unsigned long end) at kexec_core.c:264>:
                kimage_dst_used() <kimage_entry_t *kimage_dst_used (struct kimage *image, unsigned long page) at kexec_core.c:585>:
                    for_each_kimage_entry()
                pfn_to_page()
                copy_highpage()
                PageHighMem()
                kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                    page_private()
                    ClearPageReserved()
            kimage_add_page() <int kimage_add_page (struct kimage *image, unsigned long page) at kexec_core.c:503>:
                kimage_add_entry() <int kimage_add_entry (struct kimage *image, kimage_entry_t entry) at kexec_core.c:465>:
                    kimage_alloc_page() <struct page *kimage_alloc_page (struct kimage *image, gfp_t gfp_mask, unsigned long destination) at kexec_core.c:604>:
                        list_for_each_entry()
                        page_to_pfn()
                        list_del()
                        kimage_alloc_pages() <struct page *kimage_alloc_pages (gfp_t gfp_mask, unsigned int order) at kexec_core.c:282>:
                            alloc_pages()
                            set_page_private()
                            SetPageReserved()
                        list_add()
                        kimage_is_destination_range() <int kimage_is_destination_range (struct kimage *image, unsigned long start, unsigned long end) at kexec_core.c:264>:
                        kimage_dst_used() <kimage_entry_t *kimage_dst_used (struct kimage *image, unsigned long page) at kexec_core.c:585>:
                            for_each_kimage_entry()
                        pfn_to_page()
                        copy_highpage()
                        PageHighMem()
                        kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                            page_private()
                            ClearPageReserved()
                    page_address()
                    virt_to_phys()
            page_to_pfn()
            kmap()
            clear_page()
            min_t()
            min()
            copy_from_user()
            kunmap()
        kimage_load_crash_segment() <int kimage_load_crash_segment (struct kimage *image, struct kexec_segment *segment) at kexec_core.c:768>:
            pfn_to_page()
            kmap()
            min_t()
            min()
            copy_from_user()
            kexec_flush_icache_page()
            kunmap()
    kimage_terminate() <void kimage_terminate (struct kimage *image) at kexec_core.c:523>:
    kimage_file_post_load_cleanup() <void kimage_file_post_load_cleanup (struct kimage *image) at kexec_file.c:143>:
        vfree()
        kfree()
        arch_kimage_file_post_load_cleanup() <int __weak arch_kimage_file_post_load_cleanup (struct kimage *image) at kexec_file.c:107>:
    mutex_unlock()
    security_task_prctl()
    valid_signal()
    get_dumpable()
    set_dumpable()
    SET_UNALIGN_CTL()
    GET_UNALIGN_CTL()
    SET_FPEMU_CTL()
    GET_FPEMU_CTL()
    SET_FPEXC_CTL()
    GET_FPEXC_CTL()
    strncpy_from_user()
    set_task_comm()
    proc_comm_connector()
    get_task_comm()
    copy_to_user()
    GET_ENDIAN()
    SET_ENDIAN()
    prctl_get_seccomp() <long prctl_get_seccomp (void) at seccomp.c:716>:
    prctl_set_seccomp() <long prctl_set_seccomp (unsigned long seccomp_mode, char __user *filter) at seccomp.c:845>:
        do_seccomp() <long do_seccomp (unsigned int op, unsigned int flags, const char __user *uargs) at seccomp.c:817>:
            seccomp_set_mode_strict() <long seccomp_set_mode_strict (void) at seccomp.c:728>:
                seccomp_mode()
                spin_lock_irq()
                seccomp_may_assign_mode() <inline bool seccomp_may_assign_mode (unsigned long seccomp_mode) at seccomp.c:207>:
                    assert_spin_locked()
                disable_TSC()
                seccomp_assign_mode() <inline void seccomp_assign_mode (struct task_struct *task, unsigned long seccomp_mode) at seccomp.c:217>:
                    assert_spin_locked()
                    smp_mb__before_atomic()
                    set_tsk_thread_flag()
                spin_unlock_irq()
            seccomp_set_mode_filter() <inline long seccomp_set_mode_filter (unsigned int flags, const char __user *filter) at seccomp.c:809>:
                seccomp_mode()
                seccomp_prepare_user_filter() <struct seccomp_filter *seccomp_prepare_user_filter (const char __user *user_filter) at seccomp.c:392>:
                    ERR_PTR()
                    is_compat_task()
                    copy_from_user()
                    compat_ptr()
                    seccomp_prepare_filter() <struct seccomp_filter *seccomp_prepare_filter (struct sock_fprog *fprog) at seccomp.c:346>:
                        config_enabled()
                        ERR_PTR()
                        BUG_ON()
                        task_no_new_privs()
                        security_capable_noaudit()
                        current_cred()
                        current_user_ns()
                        kzalloc()
                        bpf_prog_create_from_user()
                        seccomp_check_filter() <int seccomp_check_filter (struct sock_filter *filter, unsigned int flen) at seccomp.c:100>:
                        kfree()
                        atomic_set()
                IS_ERR()
                PTR_ERR()
                mutex_lock_killable()
                spin_lock_irq()
                seccomp_may_assign_mode() <inline bool seccomp_may_assign_mode (unsigned long seccomp_mode) at seccomp.c:207>:
                    assert_spin_locked()
                seccomp_attach_filter() <long seccomp_attach_filter (unsigned int flags, struct seccomp_filter *filter) at seccomp.c:422>:
                    assert_spin_locked()
                    seccomp_can_sync_threads() <inline pid_t seccomp_can_sync_threads (void) at seccomp.c:254>:
                        BUG_ON()
                        mutex_is_locked()
                        assert_spin_locked()
                        for_each_thread()
                        is_ancestor() <int is_ancestor (struct seccomp_filter *parent, struct seccomp_filter *child) at seccomp.c:233>:
                        task_pid_vnr()
                        unlikely()
                        WARN_ON()
                    seccomp_sync_threads() <inline void seccomp_sync_threads (void) at seccomp.c:295>:
                        BUG_ON()
                        mutex_is_locked()
                        assert_spin_locked()
                        for_each_thread()
                        get_seccomp_filter() <void get_seccomp_filter (struct task_struct *tsk) at seccomp.c:461>:
                            atomic_inc()
                        put_seccomp_filter() <void put_seccomp_filter (struct task_struct *tsk) at seccomp.c:479>:
                            atomic_dec_and_test()
                            seccomp_filter_free() <inline void seccomp_filter_free (struct seccomp_filter *filter) at seccomp.c:470>:
                                bpf_prog_destroy()
                                kfree()
                        smp_store_release()
                        task_no_new_privs()
                        task_set_no_new_privs()
                        seccomp_assign_mode() <inline void seccomp_assign_mode (struct task_struct *task, unsigned long seccomp_mode) at seccomp.c:217>:
                            assert_spin_locked()
                            smp_mb__before_atomic()
                            set_tsk_thread_flag()
                seccomp_assign_mode() <inline void seccomp_assign_mode (struct task_struct *task, unsigned long seccomp_mode) at seccomp.c:217>:
                    assert_spin_locked()
                    smp_mb__before_atomic()
                    set_tsk_thread_flag()
                spin_unlock_irq()
                mutex_unlock()
                seccomp_filter_free() <inline void seccomp_filter_free (struct seccomp_filter *filter) at seccomp.c:470>:
                    bpf_prog_destroy()
                    kfree()
    GET_TSC_CTL()
    SET_TSC_CTL()
    perf_event_task_disable()
    perf_event_task_enable()
    prctl_set_mm() <int prctl_set_mm (int opt, unsigned long addr, unsigned long arg4, unsigned long arg5) at sys.c:1934>:
        prctl_set_mm_map() <int prctl_set_mm_map (int opt, const void __user *addr, unsigned long data_size) at sys.c:1820>:
            BUILD_BUG_ON()
            put_user()
            copy_from_user()
            validate_prctl_map() <int validate_prctl_map (struct prctl_mm_map *prctl_map) at sys.c:1728>:
                ARRAY_SIZE()
                check_data_rlimit()
                rlimit()
                current_user_ns()
                current_cred()
                uid_eq()
                make_kuid() <kuid_t make_kuid (struct user_namespace *ns, uid_t uid) at user_namespace.c:239>:
                    KUIDT_INIT()
                    map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
                        smp_rmb()
                gid_eq()
                make_kgid() <kgid_t make_kgid (struct user_namespace *ns, gid_t gid) at user_namespace.c:307>:
                    KGIDT_INIT()
                    map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
                        smp_rmb()
            prctl_set_mm_exe_file() <int prctl_set_mm_exe_file (struct mm_struct *mm, unsigned int fd) at sys.c:1652>:
                fdget()
                file_inode()
                path_noexec()
                inode_permission()
                get_mm_exe_file() <struct file *get_mm_exe_file (struct mm_struct *mm) at fork.c:752>:
                    rcu_read_lock()
                    rcu_dereference()
                    get_file_rcu()
                    rcu_read_unlock()
                down_read()
                path_equal()
                up_read()
                fput()
                test_and_set_bit()
                get_file()
                xchg()
                fdput()
            down_write()
            up_write()
        capable() <bool capable (int cap) at capability.c:401>:
            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                unlikely()
                cap_valid()
                pr_crit()
                BUG()
                security_capable()
                current_cred()
        prctl_set_mm_exe_file() <int prctl_set_mm_exe_file (struct mm_struct *mm, unsigned int fd) at sys.c:1652>:
            fdget()
            file_inode()
            path_noexec()
            inode_permission()
            get_mm_exe_file() <struct file *get_mm_exe_file (struct mm_struct *mm) at fork.c:752>:
                rcu_read_lock()
                rcu_dereference()
                get_file_rcu()
                rcu_read_unlock()
            down_read()
            path_equal()
            up_read()
            fput()
            test_and_set_bit()
            get_file()
            xchg()
            fdput()
        prctl_set_auxv() <int prctl_set_auxv (struct mm_struct *mm, unsigned long addr, unsigned long len) at sys.c:1904>:
            copy_from_user()
            BUILD_BUG_ON()
            task_lock()
            task_unlock()
        down_write()
        find_vma()
        validate_prctl_map() <int validate_prctl_map (struct prctl_mm_map *prctl_map) at sys.c:1728>:
            ARRAY_SIZE()
            check_data_rlimit()
            rlimit()
            current_user_ns()
            current_cred()
            uid_eq()
            make_kuid() <kuid_t make_kuid (struct user_namespace *ns, uid_t uid) at user_namespace.c:239>:
                KUIDT_INIT()
                map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
                    smp_rmb()
            gid_eq()
            make_kgid() <kgid_t make_kgid (struct user_namespace *ns, gid_t gid) at user_namespace.c:307>:
                KGIDT_INIT()
                map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
                    smp_rmb()
        up_write()
    prctl_get_tid_address() <int prctl_get_tid_address (struct task_struct *me, int __user **tid_addr) at sys.c:2069>:
        put_user()
    task_set_no_new_privs()
    task_no_new_privs()
    down_write()
    up_write()
    MPX_ENABLE_MANAGEMENT()
    MPX_DISABLE_MANAGEMENT()
    SET_FP_MODE()
    GET_FP_MODE()
SYSCALL_DEFINE6() <SYSCALL_DEFINE6 (futex, u32 __user *, uaddr, int, op, u32, val, struct timespec __user *, utime, u32 __user *, uaddr2, u32, val3) at futex.c:3099>:
    unlikely()
    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
        should_fail()
    copy_from_user()
    timespec_valid()
    timespec_to_ktime()
    ktime_add_safe()
    ktime_get()
    do_futex() <long do_futex (u32 __user *uaddr, int op, u32 val, ktime_t *timeout, u32 __user *uaddr2, u32 val2, u32 val3) at futex.c:3041>:
        futex_wait() <int futex_wait (u32 __user *uaddr, unsigned int flags, u32 val, ktime_t *abs_time, u32 bitset) at futex.c:2267> (R):
            hrtimer_init_on_stack()
            hrtimer_init_sleeper()
            hrtimer_set_expires_range_ns()
            futex_wait_setup() <int futex_wait_setup (u32 __user *uaddr, u32 val, unsigned int flags, struct futex_q *q, struct futex_hash_bucket **hb) at futex.c:2208>:
                get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                    unlikely()
                    access_ok()
                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                        should_fail()
                    get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                        ihold()
                        futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                            atomic_inc()
                            smp_mb__after_atomic()
                        smp_mb()
                    get_user_pages_fast()
                    lock_page()
                    compound_head()
                    PageSwapCache()
                    unlock_page()
                    put_page()
                    PageAnon()
                    basepage_index()
                unlikely()
                queue_lock() <inline struct futex_hash_bucket *queue_lock (struct futex_q *q) at futex.c:1848>:
                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                        jhash2()
                    hb_waiters_inc() <inline void hb_waiters_inc (struct futex_hash_bucket *hb) at futex.c:345>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    spin_lock()
                get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                    pagefault_disable()
                    pagefault_enable()
                queue_unlock() <inline void queue_unlock (struct futex_hash_bucket *hb) at futex.c:1872>:
                    spin_unlock()
                    hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                        atomic_dec()
                get_user()
                put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                    drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                        WARN_ON_ONCE()
                        iput()
                        mmdrop()
            futex_wait_queue_me() <void futex_wait_queue_me (struct futex_hash_bucket *hb, struct futex_q *q, struct hrtimer_sleeper *timeout) at futex.c:2159>:
                set_current_state()
                queue_me() <inline void queue_me (struct futex_q *q, struct futex_hash_bucket *hb) at futex.c:1891>:
                    min()
                    plist_node_init()
                    plist_add()
                    spin_unlock()
                hrtimer_start_expires()
                likely()
                plist_node_empty()
                freezable_schedule()
            unqueue_me() <int unqueue_me (struct futex_q *q) at futex.c:1923>:
                barrier()
                spin_lock()
                unlikely()
                spin_unlock()
                BUG_ON()
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
            signal_pending()
            futex_wait_restart() <long futex_wait_restart (struct restart_block *restart) at futex.c:2342> (R):
                do_no_restart_syscall() <long do_no_restart_syscall (struct restart_block *param) at signal.c:2454>:
                futex_wait() <int futex_wait (u32 __user *uaddr, unsigned int flags, u32 val, ktime_t *abs_time, u32 bitset) at futex.c:2267> (recursive: see 9983)
            hrtimer_cancel()
            destroy_hrtimer_on_stack()
        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
            WAKE_Q()
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            unlikely()
            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                jhash2()
            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                atomic_read()
            spin_lock()
            plist_for_each_entry_safe()
            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                WARN()
                wake_q_add()
                smp_wmb()
            spin_unlock()
            wake_up_q()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
        futex_requeue() <int futex_requeue (u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2, int nr_wake, int nr_requeue, u32 *cmpval, int requeue_pi) at futex.c:1571>:
            WAKE_Q()
            refill_pi_state_cache() <int refill_pi_state_cache (void) at futex.c:659>:
                likely()
                kzalloc()
                INIT_LIST_HEAD()
                atomic_set()
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            unlikely()
            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                jhash2()
            hb_waiters_inc() <inline void hb_waiters_inc (struct futex_hash_bucket *hb) at futex.c:345>:
                atomic_inc()
                smp_mb__after_atomic()
            double_lock_hb() <inline void double_lock_hb (struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2) at futex.c:1257>:
                spin_lock()
                spin_lock_nested()
            likely()
            get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                pagefault_disable()
                pagefault_enable()
            double_unlock_hb() <inline void double_unlock_hb (struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2) at futex.c:1270>:
                spin_unlock()
            hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                atomic_dec()
            get_user()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
            futex_proxy_trylock_atomic() <int futex_proxy_trylock_atomic (u32 __user *pifutex, struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2, union futex_key *key1, union futex_key *key2, struct futex_pi_state **ps, int set_waiters) at futex.c:1504>:
                get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                    pagefault_disable()
                    pagefault_enable()
                unlikely()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                futex_top_waiter() <struct futex_q *futex_top_waiter (struct futex_hash_bucket *hb, union futex_key *key) at futex.c:620>:
                    plist_for_each_entry()
                    match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                task_pid_vnr()
                futex_lock_pi_atomic() <int futex_lock_pi_atomic (u32 __user *uaddr, struct futex_hash_bucket *hb, union futex_key *key, struct futex_pi_state **ps, struct task_struct *task, int set_waiters) at futex.c:1050>:
                    task_pid_vnr()
                    get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                        pagefault_disable()
                        pagefault_enable()
                    unlikely()
                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                        should_fail()
                    futex_top_waiter() <struct futex_q *futex_top_waiter (struct futex_hash_bucket *hb, union futex_key *key) at futex.c:620>:
                        plist_for_each_entry()
                        match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                    attach_to_pi_state() <int attach_to_pi_state (u32 uval, struct futex_pi_state *pi_state, struct futex_pi_state **ps) at futex.c:860>:
                        unlikely()
                        WARN_ON()
                        atomic_read()
                        task_pid_vnr()
                        atomic_inc()
                    lock_pi_update_atomic() <int lock_pi_update_atomic (u32 __user *uaddr, u32 uval, u32 newval) at futex.c:1018>:
                        uninitialized_var()
                        unlikely()
                        should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                            should_fail()
                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                            pagefault_disable()
                            futex_atomic_cmpxchg_inatomic()
                            pagefault_enable()
                    attach_to_pi_owner() <int attach_to_pi_owner (u32 uval, union futex_key *key, struct futex_pi_state **ps) at futex.c:931>:
                        futex_find_get_task() <struct task_struct *futex_find_get_task (pid_t pid) at futex.c:736>:
                            rcu_read_lock()
                            find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
                                find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                                    RCU_LOCKDEP_WARN()
                                    rcu_read_lock_held()
                                    pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                                        rcu_dereference_check()
                                        hlist_first_rcu()
                                        lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                                            lockdep_is_held()
                                        hlist_entry()
                                    find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                                        hlist_for_each_entry_rcu()
                                        pid_hashfn()
                                        container_of()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                            get_task_struct()
                            rcu_read_unlock()
                        unlikely()
                        put_task_struct()
                        raw_spin_lock_irq()
                        raw_spin_unlock_irq()
                        alloc_pi_state() <struct futex_pi_state *alloc_pi_state (void) at futex.c:682>:
                            WARN_ON()
                        rt_mutex_init_proxy_locked()
                        WARN_ON()
                        list_empty()
                        list_add()
                requeue_pi_wake_futex() <inline void requeue_pi_wake_futex (struct futex_q *q, union futex_key *key, struct futex_hash_bucket *hb) at futex.c:1468>:
                    get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                        ihold()
                        futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                            atomic_inc()
                            smp_mb__after_atomic()
                        smp_mb()
                    WARN_ON()
                    wake_up_state()
            WARN_ON()
            lookup_pi_state() <int lookup_pi_state (u32 uval, struct futex_hash_bucket *hb, union futex_key *key, struct futex_pi_state **ps) at futex.c:999>:
                futex_top_waiter() <struct futex_q *futex_top_waiter (struct futex_hash_bucket *hb, union futex_key *key) at futex.c:620>:
                    plist_for_each_entry()
                    match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                attach_to_pi_state() <int attach_to_pi_state (u32 uval, struct futex_pi_state *pi_state, struct futex_pi_state **ps) at futex.c:860>:
                    unlikely()
                    WARN_ON()
                    atomic_read()
                    task_pid_vnr()
                    atomic_inc()
                attach_to_pi_owner() <int attach_to_pi_owner (u32 uval, union futex_key *key, struct futex_pi_state **ps) at futex.c:931>:
                    futex_find_get_task() <struct task_struct *futex_find_get_task (pid_t pid) at futex.c:736>:
                        rcu_read_lock()
                        find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
                            find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                                RCU_LOCKDEP_WARN()
                                rcu_read_lock_held()
                                pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                                    rcu_dereference_check()
                                    hlist_first_rcu()
                                    lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                                        lockdep_is_held()
                                    hlist_entry()
                                find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                                    hlist_for_each_entry_rcu()
                                    pid_hashfn()
                                    container_of()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                        get_task_struct()
                        rcu_read_unlock()
                    unlikely()
                    put_task_struct()
                    raw_spin_lock_irq()
                    raw_spin_unlock_irq()
                    alloc_pi_state() <struct futex_pi_state *alloc_pi_state (void) at futex.c:682>:
                        WARN_ON()
                    rt_mutex_init_proxy_locked()
                    WARN_ON()
                    list_empty()
                    list_add()
            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                down_read()
                fixup_user_fault()
                up_read()
            cond_resched()
            plist_for_each_entry_safe()
            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                WARN()
                wake_q_add()
                smp_wmb()
            atomic_inc()
            rt_mutex_start_proxy_lock()
            requeue_pi_wake_futex() <inline void requeue_pi_wake_futex (struct futex_q *q, union futex_key *key, struct futex_hash_bucket *hb) at futex.c:1468>:
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                WARN_ON()
                wake_up_state()
            put_pi_state() <void put_pi_state (struct futex_pi_state *pi_state) at futex.c:698>:
                atomic_dec_and_test()
                raw_spin_lock_irq()
                list_del_init()
                raw_spin_unlock_irq()
                rt_mutex_proxy_unlock()
                kfree()
                atomic_set()
            requeue_futex() <inline void requeue_futex (struct futex_q *q, struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2, union futex_key *key2) at futex.c:1434>:
                likely()
                plist_del()
                hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                    atomic_dec()
                plist_add()
                hb_waiters_inc() <inline void hb_waiters_inc (struct futex_hash_bucket *hb) at futex.c:345>:
                    atomic_inc()
                    smp_mb__after_atomic()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
            wake_up_q()
            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                WARN_ON_ONCE()
                iput()
                mmdrop()
        futex_wake_op() <int futex_wake_op (u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2, int nr_wake, int nr_wake2, int op) at futex.c:1334>:
            WAKE_Q()
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            unlikely()
            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                jhash2()
            double_lock_hb() <inline void double_lock_hb (struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2) at futex.c:1257>:
                spin_lock()
                spin_lock_nested()
            futex_atomic_op_inuser()
            double_unlock_hb() <inline void double_unlock_hb (struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2) at futex.c:1270>:
                spin_unlock()
            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                down_read()
                fixup_user_fault()
                up_read()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
            plist_for_each_entry_safe()
            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                WARN()
                wake_q_add()
                smp_wmb()
            wake_up_q()
        futex_lock_pi() <int futex_lock_pi (u32 __user *uaddr, unsigned int flags, ktime_t *time, int trylock) at futex.c:2367>:
            refill_pi_state_cache() <int refill_pi_state_cache (void) at futex.c:659>:
                likely()
                kzalloc()
                INIT_LIST_HEAD()
                atomic_set()
            hrtimer_init_on_stack()
            hrtimer_init_sleeper()
            hrtimer_set_expires()
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            unlikely()
            queue_lock() <inline struct futex_hash_bucket *queue_lock (struct futex_q *q) at futex.c:1848>:
                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                    jhash2()
                hb_waiters_inc() <inline void hb_waiters_inc (struct futex_hash_bucket *hb) at futex.c:345>:
                    atomic_inc()
                    smp_mb__after_atomic()
                spin_lock()
            futex_lock_pi_atomic() <int futex_lock_pi_atomic (u32 __user *uaddr, struct futex_hash_bucket *hb, union futex_key *key, struct futex_pi_state **ps, struct task_struct *task, int set_waiters) at futex.c:1050>:
                task_pid_vnr()
                get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                    pagefault_disable()
                    pagefault_enable()
                unlikely()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                futex_top_waiter() <struct futex_q *futex_top_waiter (struct futex_hash_bucket *hb, union futex_key *key) at futex.c:620>:
                    plist_for_each_entry()
                    match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                attach_to_pi_state() <int attach_to_pi_state (u32 uval, struct futex_pi_state *pi_state, struct futex_pi_state **ps) at futex.c:860>:
                    unlikely()
                    WARN_ON()
                    atomic_read()
                    task_pid_vnr()
                    atomic_inc()
                lock_pi_update_atomic() <int lock_pi_update_atomic (u32 __user *uaddr, u32 uval, u32 newval) at futex.c:1018>:
                    uninitialized_var()
                    unlikely()
                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                        should_fail()
                    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                        pagefault_disable()
                        futex_atomic_cmpxchg_inatomic()
                        pagefault_enable()
                attach_to_pi_owner() <int attach_to_pi_owner (u32 uval, union futex_key *key, struct futex_pi_state **ps) at futex.c:931>:
                    futex_find_get_task() <struct task_struct *futex_find_get_task (pid_t pid) at futex.c:736>:
                        rcu_read_lock()
                        find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
                            find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                                RCU_LOCKDEP_WARN()
                                rcu_read_lock_held()
                                pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                                    rcu_dereference_check()
                                    hlist_first_rcu()
                                    lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                                        lockdep_is_held()
                                    hlist_entry()
                                find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                                    hlist_for_each_entry_rcu()
                                    pid_hashfn()
                                    container_of()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                        get_task_struct()
                        rcu_read_unlock()
                    unlikely()
                    put_task_struct()
                    raw_spin_lock_irq()
                    raw_spin_unlock_irq()
                    alloc_pi_state() <struct futex_pi_state *alloc_pi_state (void) at futex.c:682>:
                        WARN_ON()
                    rt_mutex_init_proxy_locked()
                    WARN_ON()
                    list_empty()
                    list_add()
            queue_unlock() <inline void queue_unlock (struct futex_hash_bucket *hb) at futex.c:1872>:
                spin_unlock()
                hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                    atomic_dec()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
            cond_resched()
            queue_me() <inline void queue_me (struct futex_q *q, struct futex_hash_bucket *hb) at futex.c:1891>:
                min()
                plist_node_init()
                plist_add()
                spin_unlock()
            WARN_ON()
            rt_mutex_timed_futex_lock()
            rt_mutex_trylock()
            spin_lock()
            fixup_owner() <int fixup_owner (u32 __user *uaddr, struct futex_q *q, int locked) at futex.c:2095>:
                fixup_pi_state_owner() <int fixup_pi_state_owner (u32 __user *uaddr, struct futex_q *q, struct task_struct *newowner) at futex.c:1986>:
                    task_pid_vnr()
                    uninitialized_var()
                    get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                        pagefault_disable()
                        pagefault_enable()
                    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                        pagefault_disable()
                        futex_atomic_cmpxchg_inatomic()
                        pagefault_enable()
                    raw_spin_lock_irq()
                    WARN_ON()
                    list_empty()
                    list_del_init()
                    raw_spin_unlock_irq()
                    list_add()
                    spin_unlock()
                    fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                        down_read()
                        fixup_user_fault()
                        up_read()
                    spin_lock()
                rt_mutex_trylock()
                raw_spin_lock_irq()
                rt_mutex_owner()
                rt_mutex_next_owner()
                raw_spin_unlock_irq()
                printk()
            rt_mutex_owner()
            rt_mutex_unlock()
            unqueue_me_pi() < at futex.c:1968>:
                BUG_ON()
                put_pi_state() <void put_pi_state (struct futex_pi_state *pi_state) at futex.c:698>:
                    atomic_dec_and_test()
                    raw_spin_lock_irq()
                    list_del_init()
                    raw_spin_unlock_irq()
                    rt_mutex_proxy_unlock()
                    kfree()
                    atomic_set()
                spin_unlock()
            destroy_hrtimer_on_stack()
            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                down_read()
                fixup_user_fault()
                up_read()
        futex_unlock_pi() <int futex_unlock_pi (u32 __user *uaddr, unsigned int flags) at futex.c:2494>:
            uninitialized_var()
            task_pid_vnr()
            get_user()
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                jhash2()
            spin_lock()
            futex_top_waiter() <struct futex_q *futex_top_waiter (struct futex_hash_bucket *hb, union futex_key *key) at futex.c:620>:
                plist_for_each_entry()
                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            wake_futex_pi() <int wake_futex_pi (u32 __user *uaddr, u32 uval, struct futex_q *this, struct futex_hash_bucket *hb) at futex.c:1174>:
                uninitialized_var()
                WAKE_Q()
                raw_spin_lock_irq()
                rt_mutex_next_owner()
                task_pid_vnr()
                unlikely()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                    pagefault_disable()
                    futex_atomic_cmpxchg_inatomic()
                    pagefault_enable()
                raw_spin_unlock_irq()
                raw_spin_lock()
                WARN_ON()
                list_empty()
                list_del_init()
                raw_spin_unlock()
                list_add()
                rt_mutex_futex_unlock()
                spin_unlock()
                wake_up_q()
                rt_mutex_adjust_prio()
            cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                pagefault_disable()
                futex_atomic_cmpxchg_inatomic()
                pagefault_enable()
            spin_unlock()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                down_read()
                fixup_user_fault()
                up_read()
        futex_wait_requeue_pi() <int futex_wait_requeue_pi (u32 __user *uaddr, unsigned int flags, u32 val, ktime_t *abs_time, u32 bitset, u32 __user *uaddr2) at futex.c:2666>:
            hrtimer_init_on_stack()
            hrtimer_init_sleeper()
            hrtimer_set_expires_range_ns()
            debug_rt_mutex_init_waiter()
            RB_CLEAR_NODE()
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            unlikely()
            futex_wait_setup() <int futex_wait_setup (u32 __user *uaddr, u32 val, unsigned int flags, struct futex_q *q, struct futex_hash_bucket **hb) at futex.c:2208>:
                get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                    unlikely()
                    access_ok()
                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                        should_fail()
                    get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                        ihold()
                        futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                            atomic_inc()
                            smp_mb__after_atomic()
                        smp_mb()
                    get_user_pages_fast()
                    lock_page()
                    compound_head()
                    PageSwapCache()
                    unlock_page()
                    put_page()
                    PageAnon()
                    basepage_index()
                unlikely()
                queue_lock() <inline struct futex_hash_bucket *queue_lock (struct futex_q *q) at futex.c:1848>:
                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                        jhash2()
                    hb_waiters_inc() <inline void hb_waiters_inc (struct futex_hash_bucket *hb) at futex.c:345>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    spin_lock()
                get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                    pagefault_disable()
                    pagefault_enable()
                queue_unlock() <inline void queue_unlock (struct futex_hash_bucket *hb) at futex.c:1872>:
                    spin_unlock()
                    hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                        atomic_dec()
                get_user()
                put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                    drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                        WARN_ON_ONCE()
                        iput()
                        mmdrop()
            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            queue_unlock() <inline void queue_unlock (struct futex_hash_bucket *hb) at futex.c:1872>:
                spin_unlock()
                hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                    atomic_dec()
            futex_wait_queue_me() <void futex_wait_queue_me (struct futex_hash_bucket *hb, struct futex_q *q, struct hrtimer_sleeper *timeout) at futex.c:2159>:
                set_current_state()
                queue_me() <inline void queue_me (struct futex_q *q, struct futex_hash_bucket *hb) at futex.c:1891>:
                    min()
                    plist_node_init()
                    plist_add()
                    spin_unlock()
                hrtimer_start_expires()
                likely()
                plist_node_empty()
                freezable_schedule()
            spin_lock()
            handle_early_requeue_pi_wakeup() <inline int handle_early_requeue_pi_wakeup (struct futex_hash_bucket *hb, struct futex_q *q, union futex_key *key2, struct hrtimer_sleeper *timeout) at futex.c:2594>:
                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                WARN_ON()
                plist_del()
                hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                    atomic_dec()
                signal_pending()
            spin_unlock()
            fixup_pi_state_owner() <int fixup_pi_state_owner (u32 __user *uaddr, struct futex_q *q, struct task_struct *newowner) at futex.c:1986>:
                task_pid_vnr()
                uninitialized_var()
                get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                    pagefault_disable()
                    pagefault_enable()
                cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                    pagefault_disable()
                    futex_atomic_cmpxchg_inatomic()
                    pagefault_enable()
                raw_spin_lock_irq()
                WARN_ON()
                list_empty()
                list_del_init()
                raw_spin_unlock_irq()
                list_add()
                spin_unlock()
                fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                    down_read()
                    fixup_user_fault()
                    up_read()
                spin_lock()
            put_pi_state() <void put_pi_state (struct futex_pi_state *pi_state) at futex.c:698>:
                atomic_dec_and_test()
                raw_spin_lock_irq()
                list_del_init()
                raw_spin_unlock_irq()
                rt_mutex_proxy_unlock()
                kfree()
                atomic_set()
            WARN_ON()
            rt_mutex_finish_proxy_lock()
            debug_rt_mutex_free_waiter()
            fixup_owner() <int fixup_owner (u32 __user *uaddr, struct futex_q *q, int locked) at futex.c:2095>:
                fixup_pi_state_owner() <int fixup_pi_state_owner (u32 __user *uaddr, struct futex_q *q, struct task_struct *newowner) at futex.c:1986>:
                    task_pid_vnr()
                    uninitialized_var()
                    get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                        pagefault_disable()
                        pagefault_enable()
                    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                        pagefault_disable()
                        futex_atomic_cmpxchg_inatomic()
                        pagefault_enable()
                    raw_spin_lock_irq()
                    WARN_ON()
                    list_empty()
                    list_del_init()
                    raw_spin_unlock_irq()
                    list_add()
                    spin_unlock()
                    fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                        down_read()
                        fixup_user_fault()
                        up_read()
                    spin_lock()
                rt_mutex_trylock()
                raw_spin_lock_irq()
                rt_mutex_owner()
                rt_mutex_next_owner()
                raw_spin_unlock_irq()
                printk()
            unqueue_me_pi() < at futex.c:1968>:
                BUG_ON()
                put_pi_state() <void put_pi_state (struct futex_pi_state *pi_state) at futex.c:698>:
                    atomic_dec_and_test()
                    raw_spin_lock_irq()
                    list_del_init()
                    raw_spin_unlock_irq()
                    rt_mutex_proxy_unlock()
                    kfree()
                    atomic_set()
                spin_unlock()
            rt_mutex_owner()
            rt_mutex_unlock()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
            hrtimer_cancel()
            destroy_hrtimer_on_stack()
abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
    kdebug()
    atomic_read()
    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
        atomic_read()
    BUG_ON()
    put_cred()
acct_account_cputime() <void acct_account_cputime (struct task_struct *tsk) at tsacct.c:165>:
acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
    down_read()
    up_read()
    spin_lock_irq()
    thread_group_leader()
    task_cputime()
    spin_unlock_irq()
acct_exit_ns() <void acct_exit_ns (struct pid_namespace *ns) at acct.c:294>:
    rcu_read_lock()
    pin_kill()
acct_process() <void acct_process (void) at acct.c:587>:
    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
        ns_of_pid()
        task_pid()
    unlikely()
    slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
        acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
            smp_rmb()
            rcu_read_lock()
            to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                container_of()
            ACCESS_ONCE()
            rcu_read_unlock()
            atomic_long_inc_not_zero()
            cpu_relax()
            mutex_lock()
            mutex_unlock()
            acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                atomic_long_dec_and_test()
                kfree_rcu()
        do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
            override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                kdebug()
                atomic_read()
                read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                    atomic_read()
                validate_creds()
                get_cred()
                alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                    atomic_add()
                rcu_assign_pointer()
            check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                time_is_before_jiffies()
                vfs_statfs()
                do_div()
                pr_info()
            fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                strlcpy()
                ktime_get_ns()
                nsec_to_AHZ()
                encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                do_div()
                get_seconds()
                spin_lock_irq()
                old_encode_dev()
                tty_devnum()
                jiffies_to_AHZ()
                cputime_to_jiffies()
                spin_unlock_irq()
            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                        smp_rmb()
            from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                        smp_rmb()
            task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                task_tgid()
            rcu_read_lock()
            rcu_dereference()
            rcu_read_unlock()
            file_start_write_trylock()
            file_end_write()
            revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                kdebug()
                atomic_read()
                read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                    atomic_read()
                validate_creds()
                alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                    atomic_add()
                rcu_assign_pointer()
                put_cred()
        mutex_unlock()
        acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
            atomic_long_dec_and_test()
            kfree_rcu()
acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
    task_cputime()
add_range_with_merge() <int add_range_with_merge (struct range *range, int az, int nr_range, u64 start, u64 end) at range.c:27>:
    max()
    min()
    add_range() <int add_range (struct range *range, int az, int nr_range, u64 start, u64 end) at range.c:10>
add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
    pr_warn()
    set_bit()
adjust_resource() <int adjust_resource (struct resource *res, resource_size_t start, resource_size_t size) at resource.c:923>:
    write_lock()
    write_unlock()
alloc_pid() <struct pid *alloc_pid (struct pid_namespace *ns) at pid.c:297>:
    kmem_cache_alloc()
    ERR_PTR()
    alloc_pidmap() <int alloc_pidmap (struct pid_namespace *pid_ns) at pid.c:154>:
        DIV_ROUND_UP()
        unlikely()
        kzalloc()
        spin_lock_irq()
        spin_unlock_irq()
        kfree()
        likely()
        atomic_read()
        test_and_set_bit()
        atomic_dec()
        set_last_pid() <void set_last_pid (struct pid_namespace *pid_ns, int base, int pid) at pid.c:144>:
            cmpxchg()
            pid_before() <int pid_before (int base, int a, int b) at pid.c:118>
        find_next_offset()
        mk_pid() <inline int mk_pid (struct pid_namespace *pid_ns, struct pidmap *map, int off) at pid.c:55>:
    IS_ERR_VALUE()
    unlikely()
    is_child_reaper()
    pid_ns_prepare_proc()
    get_pid_ns()
    atomic_set()
    INIT_HLIST_HEAD()
    spin_lock_irq()
    hlist_add_head_rcu()
    pid_hashfn()
    spin_unlock_irq()
    put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
        kref_put()
        free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
            container_of()
            destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                ns_free_inum()
                kfree()
                put_user_ns()
                call_rcu()
                delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                    kmem_cache_free()
                    container_of()
    free_pidmap() <void free_pidmap (struct upid *upid) at pid.c:105>:
        clear_bit()
        atomic_inc()
    kmem_cache_free()
alloc_uid() <struct user_struct *alloc_uid (kuid_t uid) at user.c:171>:
    uidhashentry()
    spin_lock_irq()
    uid_hash_find() <struct user_struct *uid_hash_find (kuid_t uid, struct hlist_head *hashent) at user.c:112>:
        hlist_for_each_entry()
        uid_eq()
        atomic_inc()
    spin_unlock_irq()
    kmem_cache_zalloc()
    atomic_set()
    key_put()
    kmem_cache_free()
    uid_hash_insert() <void uid_hash_insert (struct user_struct *up, struct hlist_head *hashent) at user.c:102>:
        hlist_add_head()
alloc_workqueue_attrs() <struct workqueue_attrs *alloc_workqueue_attrs (gfp_t gfp_mask) at workqueue.c:3112>:
    kzalloc()
    alloc_cpumask_var()
    cpumask_copy()
    free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
        free_cpumask_var()
        kfree()
allocate_resource() <int allocate_resource (struct resource *root, struct resource *new, resource_size_t size, resource_size_t min, resource_size_t max, resource_size_t align, resource_size_t (*alignf) (void *, const struct resource *, resource_size_t, resource_size_t), void *alignf_data) at resource.c:693>:
    simple_align_resource() <resource_size_t simple_align_resource (void *data, const struct resource *avail, resource_size_t size, resource_size_t align) at resource.c:546>
    reallocate_resource() <int reallocate_resource (struct resource *root, struct resource *old, resource_size_t newsize, struct resource_constraint *constraint) at resource.c:642>:
        write_lock()
        resource_contains()
        BUG_ON()
        write_unlock()
    write_lock()
    find_resource() <int find_resource (struct resource *root, struct resource *new, resource_size_t size, struct resource_constraint *constraint) at resource.c:625>:
    write_unlock()
apply_workqueue_attrs() <int apply_workqueue_attrs (struct workqueue_struct *wq, const struct workqueue_attrs *attrs) at workqueue.c:3750>:
    apply_wqattrs_lock() <void apply_wqattrs_lock (void) at workqueue.c:3697>:
        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
            might_sleep()
            cpuhp_lock_acquire_read()
            mutex_lock()
            atomic_inc()
            mutex_unlock()
        mutex_lock()
    apply_workqueue_attrs_locked() <int apply_workqueue_attrs_locked (struct workqueue_struct *wq, const struct workqueue_attrs *attrs) at workqueue.c:3710>:
        WARN_ON()
        list_empty()
        apply_wqattrs_prepare() <struct apply_wqattrs_ctx *apply_wqattrs_prepare (struct workqueue_struct *wq, const struct workqueue_attrs *attrs) at workqueue.c:3605>:
            lockdep_assert_held()
            kzalloc()
            alloc_workqueue_attrs() <struct workqueue_attrs *alloc_workqueue_attrs (gfp_t gfp_mask) at workqueue.c:3112>:
                kzalloc()
                alloc_cpumask_var()
                cpumask_copy()
                free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                    free_cpumask_var()
                    kfree()
            copy_workqueue_attrs() <void copy_workqueue_attrs (struct workqueue_attrs *to, const struct workqueue_attrs *from) at workqueue.c:3129>:
                cpumask_copy()
            cpumask_and()
            unlikely()
            cpumask_empty()
            cpumask_copy()
            alloc_unbound_pwq() <struct pool_workqueue *alloc_unbound_pwq (struct workqueue_struct *wq, const struct workqueue_attrs *attrs) at workqueue.c:3493>:
                lockdep_assert_held()
                get_unbound_pool() <struct worker_pool *get_unbound_pool (const struct workqueue_attrs *attrs) at workqueue.c:3307>:
                    wqattrs_hash() <u32 wqattrs_hash (const struct workqueue_attrs *attrs) at workqueue.c:3143>:
                        jhash_1word()
                        jhash()
                        cpumask_bits()
                        BITS_TO_LONGS()
                    lockdep_assert_held()
                    hash_for_each_possible()
                    wqattrs_equal() <bool wqattrs_equal (const struct workqueue_attrs *a, const struct workqueue_attrs *b) at workqueue.c:3154>:
                        cpumask_equal()
                    for_each_node()
                    cpumask_subset()
                    kzalloc_node()
                    init_worker_pool() <int init_worker_pool (struct worker_pool *pool) at workqueue.c:3174>:
                        spin_lock_init()
                        INIT_LIST_HEAD()
                        hash_init()
                        init_timer_deferrable()
                        idle_worker_timeout() <void idle_worker_timeout (unsigned long __pool) at workqueue.c:1833>:
                            spin_lock_irq()
                            too_many_workers() <bool too_many_workers (struct worker_pool *pool) at workqueue.c:798>:
                                mutex_is_locked()
                            list_entry()
                            time_before()
                            mod_timer()
                            destroy_worker() <void destroy_worker (struct worker *worker) at workqueue.c:1813>:
                                lockdep_assert_held()
                                WARN_ON()
                                list_empty()
                                list_del_init()
                                wake_up_process()
                            spin_unlock_irq()
                        setup_timer()
                        pool_mayday_timeout() <void pool_mayday_timeout (unsigned long __pool) at workqueue.c:1881>:
                            spin_lock_irq()
                            spin_lock()
                            need_to_create_worker() <bool need_to_create_worker (struct worker_pool *pool) at workqueue.c:792>:
                                need_more_worker() <bool need_more_worker (struct worker_pool *pool) at workqueue.c:773>:
                                    list_empty()
                                may_start_working() <bool may_start_working (struct worker_pool *pool) at workqueue.c:779>
                            list_for_each_entry()
                            send_mayday() <void send_mayday (struct work_struct *work) at workqueue.c:1858>:
                                get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                                    atomic_long_read()
                                lockdep_assert_held()
                                list_empty()
                                get_pwq() <void get_pwq (struct pool_workqueue *pwq) at workqueue.c:1058>:
                                    lockdep_assert_held()
                                    WARN_ON_ONCE()
                                list_add_tail()
                                wake_up_process()
                            spin_unlock()
                            spin_unlock_irq()
                            mod_timer()
                        mutex_init()
                        ida_init()
                        INIT_HLIST_NODE()
                        alloc_workqueue_attrs() <struct workqueue_attrs *alloc_workqueue_attrs (gfp_t gfp_mask) at workqueue.c:3112>:
                            kzalloc()
                            alloc_cpumask_var()
                            cpumask_copy()
                            free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                                free_cpumask_var()
                                kfree()
                    lockdep_set_subclass()
                    copy_workqueue_attrs() <void copy_workqueue_attrs (struct workqueue_attrs *to, const struct workqueue_attrs *from) at workqueue.c:3129>:
                        cpumask_copy()
                    worker_pool_assign_id() <int worker_pool_assign_id (struct worker_pool *pool) at workqueue.c:558>:
                        lockdep_assert_held()
                        idr_alloc()
                    create_worker() <struct worker *create_worker (struct worker_pool *pool) at workqueue.c:1752>:
                        ida_simple_get()
                        alloc_worker() <struct worker *alloc_worker (int node) at workqueue.c:1665>:
                            kzalloc_node()
                            INIT_LIST_HEAD()
                        kthread_create_on_node() <struct task_struct *kthread_create_on_node (int (*threadfn) (void *data), void *data, int node, const char namefmt[], ...) at kthread.c:270>:
                            DECLARE_COMPLETION_ONSTACK()
                            kmalloc()
                            ERR_PTR()
                            spin_lock()
                            list_add_tail()
                            spin_unlock()
                            wake_up_process()
                            unlikely()
                            wait_for_completion_killable()
                            xchg()
                            wait_for_completion()
                            IS_ERR()
                            sched_setscheduler_nocheck()
                            set_cpus_allowed_ptr()
                            kfree()
                        worker_thread() <int worker_thread (void *__worker) at workqueue.c:2171>:
                            spin_lock_irq()
                            unlikely()
                            spin_unlock_irq()
                            WARN_ON_ONCE()
                            list_empty()
                            set_task_comm()
                            ida_simple_remove()
                            worker_detach_from_pool() <void worker_detach_from_pool (struct worker *worker, struct worker_pool *pool) at workqueue.c:1722>:
                                mutex_lock()
                                list_del()
                                list_empty()
                                mutex_unlock()
                                complete()
                            kfree()
                            worker_leave_idle() <void worker_leave_idle (struct worker *worker) at workqueue.c:1654>:
                                WARN_ON_ONCE()
                                worker_clr_flags() <inline void worker_clr_flags (struct worker *worker, unsigned int flags) at workqueue.c:944>:
                                    WARN_ON_ONCE()
                                    atomic_inc()
                                list_del_init()
                            need_more_worker() <bool need_more_worker (struct worker_pool *pool) at workqueue.c:773>:
                                list_empty()
                            may_start_working() <bool may_start_working (struct worker_pool *pool) at workqueue.c:779>
                            manage_workers() <bool manage_workers (struct worker *worker) at workqueue.c:1977>:
                                mutex_trylock()
                                maybe_create_worker()
                                mutex_unlock()
                            worker_clr_flags() <inline void worker_clr_flags (struct worker *worker, unsigned int flags) at workqueue.c:944>:
                                WARN_ON_ONCE()
                                atomic_inc()
                            list_first_entry()
                            likely()
                            work_data_bits()
                            process_one_work() <void process_one_work (struct worker *worker, struct work_struct *work) at workqueue.c:2016>:
                                get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                                    atomic_long_read()
                                lockdep_copy_map()
                                WARN_ON_ONCE()
                                raw_smp_processor_id()
                                find_worker_executing_work() <struct worker *find_worker_executing_work (struct worker_pool *pool, struct work_struct *work) at workqueue.c:996>:
                                    hash_for_each_possible()
                                unlikely()
                                move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                                    list_for_each_entry_safe_from()
                                    list_move_tail()
                                    work_data_bits()
                                debug_work_deactivate() <inline void debug_work_deactivate (struct work_struct *work) at workqueue.c:548>:
                                    debug_object_deactivate()
                                hash_add()
                                get_work_color() <int get_work_color (struct work_struct *work) at workqueue.c:607>:
                                    work_data_bits()
                                list_del_init()
                                worker_set_flags() <inline void worker_set_flags (struct worker *worker, unsigned int flags) at workqueue.c:919>:
                                    WARN_ON_ONCE()
                                    atomic_dec()
                                need_more_worker() <bool need_more_worker (struct worker_pool *pool) at workqueue.c:773>:
                                    list_empty()
                                wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
                                    first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                                        unlikely()
                                        list_empty()
                                        list_first_entry()
                                    likely()
                                    wake_up_process()
                                set_work_pool_and_clear_pending() <void set_work_pool_and_clear_pending (struct work_struct *work, int pool_id) at workqueue.c:659>:
                                    smp_wmb()
                                    set_work_data() <inline void set_work_data (struct work_struct *work, unsigned long data, unsigned long flags) at workqueue.c:638>:
                                        WARN_ON_ONCE()
                                        work_pending()
                                        atomic_long_set()
                                        work_static()
                                spin_unlock_irq()
                                lock_map_acquire_read()
                                lock_map_acquire()
                                trace_workqueue_execute_start()
                                trace_workqueue_execute_end()
                                lock_map_release()
                                in_atomic()
                                lockdep_depth()
                                pr_err()
                                preempt_count()
                                task_pid_nr()
                                debug_show_held_locks()
                                dump_stack()
                                cond_resched_rcu_qs()
                                spin_lock_irq()
                                worker_clr_flags() <inline void worker_clr_flags (struct worker *worker, unsigned int flags) at workqueue.c:944>:
                                    WARN_ON_ONCE()
                                    atomic_inc()
                                hash_del()
                                pwq_dec_nr_in_flight() <void pwq_dec_nr_in_flight (struct pool_workqueue *pwq, int color) at workqueue.c:1140>:
                                    list_empty()
                                    pwq_activate_first_delayed() <void pwq_activate_first_delayed (struct pool_workqueue *pwq) at workqueue.c:1121>:
                                        list_first_entry()
                                        pwq_activate_delayed_work() <void pwq_activate_delayed_work (struct work_struct *work) at workqueue.c:1109>:
                                            get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                                                atomic_long_read()
                                            trace_workqueue_activate_work()
                                            list_empty()
                                            move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                                                list_for_each_entry_safe_from()
                                                list_move_tail()
                                                work_data_bits()
                                            work_data_bits()
                                    likely()
                                    atomic_dec_and_test()
                                    complete()
                                    put_pwq() <void put_pwq (struct pool_workqueue *pwq) at workqueue.c:1072>:
                                        lockdep_assert_held()
                                        likely()
                                        WARN_ON_ONCE()
                                        schedule_work()
                            process_scheduled_works() <void process_scheduled_works (struct worker *worker) at workqueue.c:2150>:
                                list_empty()
                                list_first_entry()
                                process_one_work() <void process_one_work (struct worker *worker, struct work_struct *work) at workqueue.c:2016>:
                                    get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                                        atomic_long_read()
                                    lockdep_copy_map()
                                    WARN_ON_ONCE()
                                    raw_smp_processor_id()
                                    find_worker_executing_work() <struct worker *find_worker_executing_work (struct worker_pool *pool, struct work_struct *work) at workqueue.c:996>:
                                        hash_for_each_possible()
                                    unlikely()
                                    move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                                        list_for_each_entry_safe_from()
                                        list_move_tail()
                                        work_data_bits()
                                    debug_work_deactivate() <inline void debug_work_deactivate (struct work_struct *work) at workqueue.c:548>:
                                        debug_object_deactivate()
                                    hash_add()
                                    get_work_color() <int get_work_color (struct work_struct *work) at workqueue.c:607>:
                                        work_data_bits()
                                    list_del_init()
                                    worker_set_flags() <inline void worker_set_flags (struct worker *worker, unsigned int flags) at workqueue.c:919>:
                                        WARN_ON_ONCE()
                                        atomic_dec()
                                    need_more_worker() <bool need_more_worker (struct worker_pool *pool) at workqueue.c:773>:
                                        list_empty()
                                    wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
                                        first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                                            unlikely()
                                            list_empty()
                                            list_first_entry()
                                        likely()
                                        wake_up_process()
                                    set_work_pool_and_clear_pending() <void set_work_pool_and_clear_pending (struct work_struct *work, int pool_id) at workqueue.c:659>:
                                        smp_wmb()
                                        set_work_data() <inline void set_work_data (struct work_struct *work, unsigned long data, unsigned long flags) at workqueue.c:638>:
                                            WARN_ON_ONCE()
                                            work_pending()
                                            atomic_long_set()
                                            work_static()
                                    spin_unlock_irq()
                                    lock_map_acquire_read()
                                    lock_map_acquire()
                                    trace_workqueue_execute_start()
                                    trace_workqueue_execute_end()
                                    lock_map_release()
                                    in_atomic()
                                    lockdep_depth()
                                    pr_err()
                                    preempt_count()
                                    task_pid_nr()
                                    debug_show_held_locks()
                                    dump_stack()
                                    cond_resched_rcu_qs()
                                    spin_lock_irq()
                                    worker_clr_flags() <inline void worker_clr_flags (struct worker *worker, unsigned int flags) at workqueue.c:944>:
                                        WARN_ON_ONCE()
                                        atomic_inc()
                                    hash_del()
                                    pwq_dec_nr_in_flight() <void pwq_dec_nr_in_flight (struct pool_workqueue *pwq, int color) at workqueue.c:1140>:
                                        list_empty()
                                        pwq_activate_first_delayed() <void pwq_activate_first_delayed (struct pool_workqueue *pwq) at workqueue.c:1121>:
                                            list_first_entry()
                                            pwq_activate_delayed_work() <void pwq_activate_delayed_work (struct work_struct *work) at workqueue.c:1109>:
                                                get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                                                    atomic_long_read()
                                                trace_workqueue_activate_work()
                                                list_empty()
                                                move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                                                    list_for_each_entry_safe_from()
                                                    list_move_tail()
                                                    work_data_bits()
                                                work_data_bits()
                                        likely()
                                        atomic_dec_and_test()
                                        complete()
                                        put_pwq() <void put_pwq (struct pool_workqueue *pwq) at workqueue.c:1072>:
                                            lockdep_assert_held()
                                            likely()
                                            WARN_ON_ONCE()
                                            schedule_work()
                            move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                                list_for_each_entry_safe_from()
                                list_move_tail()
                                work_data_bits()
                            keep_working() <bool keep_working (struct worker_pool *pool) at workqueue.c:785>:
                                list_empty()
                                atomic_read()
                            worker_set_flags() <inline void worker_set_flags (struct worker *worker, unsigned int flags) at workqueue.c:919>:
                                WARN_ON_ONCE()
                                atomic_dec()
                            worker_enter_idle() <void worker_enter_idle (struct worker *worker) at workqueue.c:1614>:
                                WARN_ON_ONCE()
                                list_empty()
                                list_add()
                                too_many_workers() <bool too_many_workers (struct worker_pool *pool) at workqueue.c:798>:
                                    mutex_is_locked()
                                timer_pending()
                                mod_timer()
                                atomic_read()
                            schedule()
                        IS_ERR()
                        set_user_nice()
                        kthread_bind_mask() <void kthread_bind_mask (struct task_struct *p, const struct cpumask *mask) at kthread.c:352>:
                        worker_attach_to_pool() <void worker_attach_to_pool (struct worker *worker, struct worker_pool *pool) at workqueue.c:1689>:
                            mutex_lock()
                            set_cpus_allowed_ptr()
                            list_add_tail()
                            mutex_unlock()
                        spin_lock_irq()
                        worker_enter_idle() <void worker_enter_idle (struct worker *worker) at workqueue.c:1614>:
                            WARN_ON_ONCE()
                            list_empty()
                            list_add()
                            too_many_workers() <bool too_many_workers (struct worker_pool *pool) at workqueue.c:798>:
                                mutex_is_locked()
                            timer_pending()
                            mod_timer()
                            atomic_read()
                        wake_up_process()
                        spin_unlock_irq()
                        ida_simple_remove()
                        kfree()
                    hash_add()
                    put_unbound_pool() <void put_unbound_pool (struct worker_pool *pool) at workqueue.c:3242>:
                        DECLARE_COMPLETION_ONSTACK()
                        lockdep_assert_held()
                        WARN_ON()
                        list_empty()
                        idr_remove()
                        hash_del()
                        mutex_lock()
                        spin_lock_irq()
                        first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                            unlikely()
                            list_empty()
                            list_first_entry()
                        destroy_worker() <void destroy_worker (struct worker *worker) at workqueue.c:1813>:
                            lockdep_assert_held()
                            WARN_ON()
                            list_empty()
                            list_del_init()
                            wake_up_process()
                        spin_unlock_irq()
                        mutex_unlock()
                        wait_for_completion()
                        del_timer_sync()
                        call_rcu_sched()
                        rcu_free_pool() <void rcu_free_pool (struct rcu_head *rcu) at workqueue.c:3222>:
                            container_of()
                            ida_destroy()
                            free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                                free_cpumask_var()
                                kfree()
                            kfree()
                kmem_cache_alloc_node()
                put_unbound_pool() <void put_unbound_pool (struct worker_pool *pool) at workqueue.c:3242>:
                    DECLARE_COMPLETION_ONSTACK()
                    lockdep_assert_held()
                    WARN_ON()
                    list_empty()
                    idr_remove()
                    hash_del()
                    mutex_lock()
                    spin_lock_irq()
                    first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                        unlikely()
                        list_empty()
                        list_first_entry()
                    destroy_worker() <void destroy_worker (struct worker *worker) at workqueue.c:1813>:
                        lockdep_assert_held()
                        WARN_ON()
                        list_empty()
                        list_del_init()
                        wake_up_process()
                    spin_unlock_irq()
                    mutex_unlock()
                    wait_for_completion()
                    del_timer_sync()
                    call_rcu_sched()
                    rcu_free_pool() <void rcu_free_pool (struct rcu_head *rcu) at workqueue.c:3222>:
                        container_of()
                        ida_destroy()
                        free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                            free_cpumask_var()
                            kfree()
                        kfree()
                init_pwq() <void init_pwq (struct pool_workqueue *pwq, struct workqueue_struct *wq, struct worker_pool *pool) at workqueue.c:3454>:
                    BUG_ON()
                    INIT_LIST_HEAD()
                    INIT_WORK()
                    pwq_unbound_release_workfn() <void pwq_unbound_release_workfn (struct work_struct *work) at workqueue.c:3377>:
                        container_of()
                        WARN_ON_ONCE()
                        mutex_lock()
                        list_del_rcu()
                        list_empty()
                        mutex_unlock()
                        put_unbound_pool() <void put_unbound_pool (struct worker_pool *pool) at workqueue.c:3242>:
                            DECLARE_COMPLETION_ONSTACK()
                            lockdep_assert_held()
                            WARN_ON()
                            list_empty()
                            idr_remove()
                            hash_del()
                            mutex_lock()
                            spin_lock_irq()
                            first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                                unlikely()
                                list_empty()
                                list_first_entry()
                            destroy_worker() <void destroy_worker (struct worker *worker) at workqueue.c:1813>:
                                lockdep_assert_held()
                                WARN_ON()
                                list_empty()
                                list_del_init()
                                wake_up_process()
                            spin_unlock_irq()
                            mutex_unlock()
                            wait_for_completion()
                            del_timer_sync()
                            call_rcu_sched()
                            rcu_free_pool() <void rcu_free_pool (struct rcu_head *rcu) at workqueue.c:3222>:
                                container_of()
                                ida_destroy()
                                free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                                    free_cpumask_var()
                                    kfree()
                                kfree()
                        call_rcu_sched()
                        rcu_free_pwq() <void rcu_free_pwq (struct rcu_head *rcu) at workqueue.c:3367>:
                            kmem_cache_free()
                            container_of()
                        rcu_free_wq() <void rcu_free_wq (struct rcu_head *rcu) at workqueue.c:3208>:
                            container_of()
                            free_percpu()
                            free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                                free_cpumask_var()
                                kfree()
                            kfree()
            for_each_node()
            wq_calc_node_cpumask() <bool wq_calc_node_cpumask (const struct workqueue_attrs *attrs, int node, int cpu_going_down, cpumask_t *cpumask) at workqueue.c:3537>:
                cpumask_and()
                cpumask_of_node()
                cpumask_clear_cpu()
                cpumask_empty()
                cpumask_equal()
                cpumask_copy()
            free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                free_cpumask_var()
                kfree()
            apply_wqattrs_cleanup() <void apply_wqattrs_cleanup (struct apply_wqattrs_ctx *ctx) at workqueue.c:3588>:
                for_each_node()
                put_pwq_unlocked() <void put_pwq_unlocked (struct pool_workqueue *pwq) at workqueue.c:1096>:
                    spin_lock_irq()
                    put_pwq() <void put_pwq (struct pool_workqueue *pwq) at workqueue.c:1072>:
                        lockdep_assert_held()
                        likely()
                        WARN_ON_ONCE()
                        schedule_work()
                    spin_unlock_irq()
                free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                    free_cpumask_var()
                    kfree()
                kfree()
        apply_wqattrs_commit() <void apply_wqattrs_commit (struct apply_wqattrs_ctx *ctx) at workqueue.c:3676>:
            mutex_lock()
            copy_workqueue_attrs() <void copy_workqueue_attrs (struct workqueue_attrs *to, const struct workqueue_attrs *from) at workqueue.c:3129>:
                cpumask_copy()
            for_each_node()
            numa_pwq_tbl_install() <struct pool_workqueue *numa_pwq_tbl_install (struct workqueue_struct *wq, int node, struct pool_workqueue *pwq) at workqueue.c:3561>:
                lockdep_assert_held()
                link_pwq() <void link_pwq (struct pool_workqueue *pwq) at workqueue.c:3472>:
                    lockdep_assert_held()
                    list_empty()
                    pwq_adjust_max_active() <void pwq_adjust_max_active (struct pool_workqueue *pwq) at workqueue.c:3415>:
                        lockdep_assert_held()
                        spin_lock_irq()
                        list_empty()
                        pwq_activate_first_delayed() <void pwq_activate_first_delayed (struct pool_workqueue *pwq) at workqueue.c:1121>:
                            list_first_entry()
                            pwq_activate_delayed_work() <void pwq_activate_delayed_work (struct work_struct *work) at workqueue.c:1109>:
                                get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                                    atomic_long_read()
                                trace_workqueue_activate_work()
                                list_empty()
                                move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                                    list_for_each_entry_safe_from()
                                    list_move_tail()
                                    work_data_bits()
                                work_data_bits()
                        wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
                            first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                                unlikely()
                                list_empty()
                                list_first_entry()
                            likely()
                            wake_up_process()
                        spin_unlock_irq()
                    list_add_rcu()
                rcu_access_pointer()
                rcu_assign_pointer()
            link_pwq() <void link_pwq (struct pool_workqueue *pwq) at workqueue.c:3472>:
                lockdep_assert_held()
                list_empty()
                pwq_adjust_max_active() <void pwq_adjust_max_active (struct pool_workqueue *pwq) at workqueue.c:3415>:
                    lockdep_assert_held()
                    spin_lock_irq()
                    list_empty()
                    pwq_activate_first_delayed() <void pwq_activate_first_delayed (struct pool_workqueue *pwq) at workqueue.c:1121>:
                        list_first_entry()
                        pwq_activate_delayed_work() <void pwq_activate_delayed_work (struct work_struct *work) at workqueue.c:1109>:
                            get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                                atomic_long_read()
                            trace_workqueue_activate_work()
                            list_empty()
                            move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                                list_for_each_entry_safe_from()
                                list_move_tail()
                                work_data_bits()
                            work_data_bits()
                    wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
                        first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                            unlikely()
                            list_empty()
                            list_first_entry()
                        likely()
                        wake_up_process()
                    spin_unlock_irq()
                list_add_rcu()
            swap()
            mutex_unlock()
        apply_wqattrs_cleanup() <void apply_wqattrs_cleanup (struct apply_wqattrs_ctx *ctx) at workqueue.c:3588>:
            for_each_node()
            put_pwq_unlocked() <void put_pwq_unlocked (struct pool_workqueue *pwq) at workqueue.c:1096>:
                spin_lock_irq()
                put_pwq() <void put_pwq (struct pool_workqueue *pwq) at workqueue.c:1072>:
                    lockdep_assert_held()
                    likely()
                    WARN_ON_ONCE()
                    schedule_work()
                spin_unlock_irq()
            free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                free_cpumask_var()
                kfree()
            kfree()
    apply_wqattrs_unlock() <void apply_wqattrs_unlock (void) at workqueue.c:3704>:
        mutex_unlock()
        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
            atomic_dec_return()
            WARN_ON()
            atomic_inc()
            waitqueue_active()
            wake_up()
            cpuhp_lock_release()
arch_check_ftrace_location() <int __weak arch_check_ftrace_location (struct kprobe *p) at kprobes.c:1414>:
    ftrace_location()
arch_jump_label_transform_static() <void __weak __init_or_module arch_jump_label_transform_static (struct jump_entry *entry, enum jump_label_type type) at jump_label.c:150>:
    arch_jump_label_transform()
arch_kexec_apply_relocations() <int __weak arch_kexec_apply_relocations (const Elf_Ehdr *ehdr, Elf_Shdr *sechdrs, unsigned int relsec) at kexec_file.c:131>:
    pr_err()
arch_kexec_apply_relocations_add() <int __weak arch_kexec_apply_relocations_add (const Elf_Ehdr *ehdr, Elf_Shdr *sechdrs, unsigned int relsec) at kexec_file.c:122>:
    pr_err()
arch_kexec_kernel_image_load() <void *__weak arch_kexec_kernel_image_load (struct kimage *image) at kexec_file.c:102>:
    ERR_PTR()
arch_kexec_kernel_image_probe() <int __weak arch_kexec_kernel_image_probe (struct kimage *image, void *buf, unsigned long buf_len) at kexec_file.c:96>:
arch_kexec_kernel_verify_sig() <int __weak arch_kexec_kernel_verify_sig (struct kimage *image, void *buf, unsigned long buf_len) at kexec_file.c:113>:
arch_kimage_file_post_load_cleanup() <int __weak arch_kimage_file_post_load_cleanup (struct kimage *image) at kexec_file.c:107>:
arch_probe_nr_irqs() <int __init __weak arch_probe_nr_irqs (void) at softirq.c:774>:
arch_vma_name() <__weak const char *arch_vma_name (struct vm_area_struct *vma) at signal.c:3577>:
arch_within_kprobe_blacklist() <bool __weak arch_within_kprobe_blacklist (unsigned long addr) at kprobes.c:1328>:
async_schedule() <async_cookie_t async_schedule (async_func_t func, void *data) at async.c:207>:
async_schedule_domain() <async_cookie_t async_schedule_domain (async_func_t func, void *data, struct async_domain *domain) at async.c:225>:
async_synchronize_cookie() <void async_synchronize_cookie (async_cookie_t cookie) at async.c:312>:
    async_synchronize_cookie_domain() <void async_synchronize_cookie_domain (async_cookie_t cookie, struct async_domain *domain) at async.c:283>:
        uninitialized_var()
        pr_debug()
        task_pid_nr()
        ktime_get()
        wait_event()
        lowest_in_progress() <async_cookie_t lowest_in_progress (struct async_domain *domain) at async.c:85>:
            spin_lock_irqsave()
            list_empty()
            list_first_entry()
            spin_unlock_irqrestore()
        ktime_sub()
        ktime_to_ns()
async_synchronize_cookie_domain() <void async_synchronize_cookie_domain (async_cookie_t cookie, struct async_domain *domain) at async.c:283>:
    uninitialized_var()
    pr_debug()
    task_pid_nr()
    ktime_get()
    wait_event()
    lowest_in_progress() <async_cookie_t lowest_in_progress (struct async_domain *domain) at async.c:85>:
        spin_lock_irqsave()
        list_empty()
        list_first_entry()
        spin_unlock_irqrestore()
    ktime_sub()
    ktime_to_ns()
async_synchronize_full() <void async_synchronize_full (void) at async.c:237>:
    async_synchronize_full_domain() <void async_synchronize_full_domain (struct async_domain *domain) at async.c:268>:
        async_synchronize_cookie_domain() <void async_synchronize_cookie_domain (async_cookie_t cookie, struct async_domain *domain) at async.c:283>:
            uninitialized_var()
            pr_debug()
            task_pid_nr()
            ktime_get()
            wait_event()
            lowest_in_progress() <async_cookie_t lowest_in_progress (struct async_domain *domain) at async.c:85>:
                spin_lock_irqsave()
                list_empty()
                list_first_entry()
                spin_unlock_irqrestore()
            ktime_sub()
            ktime_to_ns()
async_synchronize_full_domain() <void async_synchronize_full_domain (struct async_domain *domain) at async.c:268>:
    async_synchronize_cookie_domain() <void async_synchronize_cookie_domain (async_cookie_t cookie, struct async_domain *domain) at async.c:283>:
        uninitialized_var()
        pr_debug()
        task_pid_nr()
        ktime_get()
        wait_event()
        lowest_in_progress() <async_cookie_t lowest_in_progress (struct async_domain *domain) at async.c:85>:
            spin_lock_irqsave()
            list_empty()
            list_first_entry()
            spin_unlock_irqrestore()
        ktime_sub()
        ktime_to_ns()
async_unregister_domain() <void async_unregister_domain (struct async_domain *domain) at async.c:252>:
    spin_lock_irq()
    WARN_ON()
    list_empty()
    spin_unlock_irq()
atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
atomic_notifier_chain_register() <int atomic_notifier_chain_register (struct atomic_notifier_head *nh, struct notifier_block *n) at notifier.c:121>:
    spin_lock_irqsave()
    notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
        rcu_assign_pointer()
    spin_unlock_irqrestore()
atomic_notifier_chain_unregister() <int atomic_notifier_chain_unregister (struct atomic_notifier_head *nh, struct notifier_block *n) at notifier.c:143>:
    spin_lock_irqsave()
    notifier_chain_unregister() <int notifier_chain_unregister (struct notifier_block **nl, struct notifier_block *n) at notifier.c:49>:
        rcu_assign_pointer()
    spin_unlock_irqrestore()
    synchronize_rcu()
attach_pid() <void attach_pid (struct task_struct *task, enum pid_type type) at pid.c:389>:
    hlist_add_head_rcu()
audit_add_tree_rule() <int audit_add_tree_rule (struct audit_krule *rule) at audit_tree.c:709>:
    list_for_each_entry()
    put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
        atomic_dec_and_test()
        kfree_rcu()
    list_add()
    mutex_unlock()
    unlikely()
    audit_launch_prune() <int audit_launch_prune (void) at audit_tree.c:692>:
        kthread_create()
        prune_tree_thread() <int prune_tree_thread (void *unused) at audit_tree.c:661>:
            set_current_state()
            list_empty()
            schedule()
            mutex_lock()
            list_entry()
            list_del_init()
            mutex_unlock()
            prune_one() <void prune_one (struct audit_tree *victim) at audit_tree.c:495>:
                spin_lock()
                list_empty()
                list_entry()
                untag_chunk() <void untag_chunk (struct node *p) at audit_tree.c:218>:
                    find_chunk() <struct audit_chunk *find_chunk (struct node *p) at audit_tree.c:211>:
                        container_of()
                    fsnotify_get_mark()
                    spin_unlock()
                    alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                        kzalloc()
                        INIT_LIST_HEAD()
                        atomic_long_set()
                        fsnotify_init_mark()
                        audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                            container_of()
                            call_rcu()
                    spin_lock()
                    free_chunk() <void free_chunk (struct audit_chunk *chunk) at audit_tree.c:109>:
                        put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                            atomic_dec_and_test()
                            kfree_rcu()
                        kfree()
                    list_del_init()
                    list_del_rcu()
                    fsnotify_destroy_mark()
                    fsnotify_duplicate_mark()
                    fsnotify_add_mark()
                    fsnotify_put_mark()
                    list_replace_init()
                    get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                        atomic_inc()
                    list_replace_rcu()
                    list_for_each_entry()
                    put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                        atomic_dec_and_test()
                        kfree_rcu()
                spin_unlock()
                put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                    atomic_dec_and_test()
                    kfree_rcu()
        IS_ERR()
        pr_err()
        wake_up_process()
    collect_mounts()
    path_put()
    IS_ERR()
    PTR_ERR()
    get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
        atomic_inc()
    iterate_mounts()
    tag_mount() <int tag_mount (struct vfsmount *mnt, void *arg) at audit_tree.c:652>:
        tag_chunk() <int tag_chunk (struct inode *inode, struct audit_tree *tree) at audit_tree.c:356>:
            fsnotify_find_inode_mark()
            create_chunk() <int create_chunk (struct inode *inode, struct audit_tree *tree) at audit_tree.c:317>:
                alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                    kzalloc()
                    INIT_LIST_HEAD()
                    atomic_long_set()
                    fsnotify_init_mark()
                    audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                        container_of()
                        call_rcu()
                fsnotify_add_mark()
                fsnotify_put_mark()
                spin_lock()
                spin_unlock()
                fsnotify_destroy_mark()
                get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                    atomic_inc()
                list_add()
                insert_hash() <void insert_hash (struct audit_chunk *chunk) at audit_tree.c:173>:
                    chunk_hash() <inline struct list_head *chunk_hash (const struct inode *inode) at audit_tree.c:166>:
                    list_add_rcu()
            container_of()
            spin_lock()
            spin_unlock()
            fsnotify_put_mark()
            alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                kzalloc()
                INIT_LIST_HEAD()
                atomic_long_set()
                fsnotify_init_mark()
                audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                    container_of()
                    call_rcu()
            free_chunk() <void free_chunk (struct audit_chunk *chunk) at audit_tree.c:109>:
                put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                    atomic_dec_and_test()
                    kfree_rcu()
                kfree()
            fsnotify_duplicate_mark()
            fsnotify_add_mark()
            fsnotify_destroy_mark()
            list_replace_init()
            get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                atomic_inc()
            list_add()
            list_replace_rcu()
            list_for_each_entry()
        d_backing_inode()
    drop_collected_mounts()
    spin_lock()
    spin_unlock()
    trim_marked() <void trim_marked (struct audit_tree *tree) at audit_tree.c:511>:
        spin_lock()
        spin_unlock()
        list_entry()
        list_del_init()
        list_add()
        list_empty()
        untag_chunk() <void untag_chunk (struct node *p) at audit_tree.c:218>:
            find_chunk() <struct audit_chunk *find_chunk (struct node *p) at audit_tree.c:211>:
                container_of()
            fsnotify_get_mark()
            spin_unlock()
            alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                kzalloc()
                INIT_LIST_HEAD()
                atomic_long_set()
                fsnotify_init_mark()
                audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                    container_of()
                    call_rcu()
            spin_lock()
            free_chunk() <void free_chunk (struct audit_chunk *chunk) at audit_tree.c:109>:
                put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                    atomic_dec_and_test()
                    kfree_rcu()
                kfree()
            list_del_init()
            list_del_rcu()
            fsnotify_destroy_mark()
            fsnotify_duplicate_mark()
            fsnotify_add_mark()
            fsnotify_put_mark()
            list_replace_init()
            get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                atomic_inc()
            list_replace_rcu()
            list_for_each_entry()
            put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                atomic_dec_and_test()
                kfree_rcu()
        mutex_lock()
        kill_rules() <void kill_rules (struct audit_tree *tree) at audit_tree.c:470>:
            list_for_each_entry_safe()
            container_of()
            list_del_init()
            audit_tree_log_remove_rule() <void audit_tree_log_remove_rule (struct audit_krule *rule) at audit_tree.c:454>:
                audit_log_start() <struct audit_buffer *audit_log_start (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1355>:
                    uninitialized_var()
                    unlikely()
                    audit_filter_type() <int audit_filter_type (int type) at auditfilter.c:1374>:
                        rcu_read_lock()
                        list_empty()
                        list_for_each_entry_rcu()
                        audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                            BUG()
                        rcu_read_unlock()
                    skb_queue_len()
                    wait_for_auditd() <long wait_for_auditd (long sleep_time) at audit.c:1324>:
                        DECLARE_WAITQUEUE()
                        set_current_state()
                        add_wait_queue_exclusive()
                        skb_queue_len()
                        schedule_timeout()
                        remove_wait_queue()
                    audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                    wake_up()
                    audit_buffer_alloc() <struct audit_buffer *audit_buffer_alloc (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1245>:
                        spin_lock_irqsave()
                        list_empty()
                        list_entry()
                        list_del()
                        spin_unlock_irqrestore()
                        kmalloc()
                        nlmsg_new()
                        nlmsg_put()
                        kfree_skb()
                        audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                            kfree_skb()
                            spin_lock_irqsave()
                            kfree()
                            list_add()
                            spin_unlock_irqrestore()
                    audit_get_stamp() <inline void audit_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at audit.c:1312>:
                        auditsc_get_stamp() <int auditsc_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at auditsc.c:1940>:
                            audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                                ATOMIC_INIT()
                                atomic_add_return()
                        audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                            ATOMIC_INIT()
                            atomic_add_return()
                    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            max_t()
                            skb_put()
                unlikely()
                audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                    audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        max_t()
                        skb_put()
                audit_log_string()
                audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
                    audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                        audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                        audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            hex_byte_pack_upper()
                            skb_put()
                        audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            skb_put()
                audit_log_key() <void audit_log_key (struct audit_buffer *ab, char *key) at audit.c:1658>:
                    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            max_t()
                            skb_put()
                    audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
                        audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                            audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                            audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                                BUG_ON()
                                skb_tailroom()
                                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                    skb_tailroom()
                                    pskb_expand_head()
                                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                        atomic_inc()
                                        spin_lock_irqsave()
                                        spin_unlock_irqrestore()
                                        printk_ratelimit()
                                        pr_warn()
                                        atomic_read()
                                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                            printk_ratelimit()
                                            pr_err()
                                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                                local_irq_disable()
                                                raw_smp_processor_id()
                                                atomic_cmpxchg()
                                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                    cpu_relax()
                                                console_verbose()
                                                bust_spinlocks()
                                                pr_emerg()
                                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                    test_bit()
                                                dump_stack()
                                                smp_send_stop()
                                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                                kmsg_dump()
                                                debug_locks_off()
                                                console_flush_on_panic()
                                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                                no_blink() <long no_blink (int state) at panic.c:46>
                                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                    raw_cpu_write()
                                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                            raw_cpu_write()
                                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                            per_cpu()
                                                        raw_smp_processor_id()
                                                mdelay()
                                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                    kmsg_dump()
                                                    machine_emergency_restart()
                                                disabled_wait()
                                                local_irq_enable()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                skb_tail_pointer()
                                hex_byte_pack_upper()
                                skb_put()
                            audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                                BUG_ON()
                                skb_tailroom()
                                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                    skb_tailroom()
                                    pskb_expand_head()
                                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                        atomic_inc()
                                        spin_lock_irqsave()
                                        spin_unlock_irqrestore()
                                        printk_ratelimit()
                                        pr_warn()
                                        atomic_read()
                                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                            printk_ratelimit()
                                            pr_err()
                                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                                local_irq_disable()
                                                raw_smp_processor_id()
                                                atomic_cmpxchg()
                                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                    cpu_relax()
                                                console_verbose()
                                                bust_spinlocks()
                                                pr_emerg()
                                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                    test_bit()
                                                dump_stack()
                                                smp_send_stop()
                                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                                kmsg_dump()
                                                debug_locks_off()
                                                console_flush_on_panic()
                                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                                no_blink() <long no_blink (int state) at panic.c:46>
                                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                    raw_cpu_write()
                                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                            raw_cpu_write()
                                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                            per_cpu()
                                                        raw_smp_processor_id()
                                                mdelay()
                                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                    kmsg_dump()
                                                    machine_emergency_restart()
                                                disabled_wait()
                                                local_irq_enable()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                skb_tail_pointer()
                                skb_put()
                audit_log_end() <void audit_log_end (struct audit_buffer *ab) at audit.c:1957>:
                    audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                    nlmsg_hdr()
                    kauditd_send_multicast_skb() <void kauditd_send_multicast_skb (struct sk_buff *skb, gfp_t gfp_mask) at audit.c:450>:
                        net_generic()
                        netlink_has_listeners()
                        skb_copy()
                        nlmsg_multicast()
                    skb_queue_tail()
                    wake_up_interruptible()
                    audit_printk_skb() <void audit_printk_skb (struct sk_buff *skb) at audit.c:391>:
                        nlmsg_hdr()
                        nlmsg_data()
                        printk_ratelimit()
                        pr_notice()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                        audit_hold_skb() <void audit_hold_skb (struct sk_buff *skb) at audit.c:377>:
                            skb_queue_len()
                            skb_queue_tail()
                            kfree_skb()
                    audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                        kfree_skb()
                        spin_lock_irqsave()
                        kfree()
                        list_add()
                        spin_unlock_irqrestore()
            audit_remove_mark() <void audit_remove_mark (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:144>:
                fsnotify_destroy_mark()
                fsnotify_put_mark()
            list_del_rcu()
            list_del()
            call_rcu()
            audit_free_rule_rcu() <void audit_free_rule_rcu (struct rcu_head *head) at auditfilter.c:108>:
                container_of()
                audit_free_rule() <inline void audit_free_rule (struct audit_entry *e) at auditfilter.c:92>:
                    audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
                        atomic_dec_and_test()
                        WARN_ON()
                        list_empty()
                        kfree()
                    audit_free_lsm_field() <void audit_free_lsm_field (struct audit_field *f) at auditfilter.c:74>:
                        kfree()
                        security_audit_rule_free()
                    kfree()
        mutex_unlock()
        prune_one() <void prune_one (struct audit_tree *victim) at audit_tree.c:495>:
            spin_lock()
            list_empty()
            list_entry()
            untag_chunk() <void untag_chunk (struct node *p) at audit_tree.c:218>:
                find_chunk() <struct audit_chunk *find_chunk (struct node *p) at audit_tree.c:211>:
                    container_of()
                fsnotify_get_mark()
                spin_unlock()
                alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                    kzalloc()
                    INIT_LIST_HEAD()
                    atomic_long_set()
                    fsnotify_init_mark()
                    audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                        container_of()
                        call_rcu()
                spin_lock()
                free_chunk() <void free_chunk (struct audit_chunk *chunk) at audit_tree.c:109>:
                    put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                        atomic_dec_and_test()
                        kfree_rcu()
                    kfree()
                list_del_init()
                list_del_rcu()
                fsnotify_destroy_mark()
                fsnotify_duplicate_mark()
                fsnotify_add_mark()
                fsnotify_put_mark()
                list_replace_init()
                get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                    atomic_inc()
                list_replace_rcu()
                list_for_each_entry()
                put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                    atomic_dec_and_test()
                    kfree_rcu()
            spin_unlock()
            put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                atomic_dec_and_test()
                kfree_rcu()
    mutex_lock()
    list_empty()
    list_del_init()
audit_add_watch() <int audit_add_watch (struct audit_krule *krule, struct list_head **list) at audit_watch.c:414>:
    mutex_unlock()
    audit_get_nd() <int audit_get_nd (struct audit_watch *watch, struct path *parent) at audit_watch.c:362>:
        kern_path_locked()
        IS_ERR()
        PTR_ERR()
        inode_unlock()
        d_backing_inode()
        d_is_positive()
        dput()
    mutex_lock()
    audit_find_parent() <inline struct audit_parent *audit_find_parent (struct inode *inode) at audit_watch.c:99>:
        fsnotify_find_inode_mark()
        container_of()
    d_backing_inode()
    audit_init_parent() <struct audit_parent *audit_init_parent (struct path *path) at audit_watch.c:147>:
        d_backing_inode()
        kzalloc()
        unlikely()
        ERR_PTR()
        INIT_LIST_HEAD()
        fsnotify_init_mark()
        audit_watch_free_mark() <void audit_watch_free_mark (struct fsnotify_mark *entry) at audit_watch.c:75>:
            container_of()
            audit_free_parent() <void audit_free_parent (struct audit_parent *parent) at audit_watch.c:69>:
                WARN_ON()
                list_empty()
                kfree()
        fsnotify_add_mark()
        audit_free_parent() <void audit_free_parent (struct audit_parent *parent) at audit_watch.c:69>:
            WARN_ON()
            list_empty()
            kfree()
    IS_ERR()
    PTR_ERR()
    audit_add_to_parent() <void audit_add_to_parent (struct audit_krule *krule, struct audit_parent *parent) at audit_watch.c:379>:
        BUG_ON()
        mutex_is_locked()
        list_for_each_entry()
        audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
            atomic_dec_and_test()
            WARN_ON()
            list_empty()
            kfree()
        audit_get_watch() <void audit_get_watch (struct audit_watch *watch) at audit_watch.c:111>:
            atomic_inc()
        audit_put_parent() <void audit_put_parent (struct audit_parent *parent) at audit_watch.c:89>:
            likely()
            fsnotify_put_mark()
        list_add()
    audit_hash_ino()
    path_put()
audit_alloc() <int audit_alloc (struct task_struct *tsk) at auditsc.c:920>:
    likely()
    audit_filter_task() <enum audit_state audit_filter_task (struct task_struct *tsk, char **key) at auditsc.c:708>:
        rcu_read_lock()
        list_for_each_entry_rcu()
        audit_filter_rules() <int audit_filter_rules (struct task_struct *tsk, struct audit_krule *rule, struct audit_context *ctx, struct audit_names *name, enum audit_state *state, bool task_creation) at auditsc.c:438>:
            rcu_dereference_check()
            task_pid_nr()
            audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                BUG()
            task_ppid_nr()
            audit_exe_compare() <int audit_exe_compare (struct task_struct *tsk, struct audit_fsnotify_mark *mark) at audit_watch.c:541>:
                rcu_read_lock()
                rcu_dereference()
                rcu_read_unlock()
                audit_mark_compare() <int audit_mark_compare (struct audit_fsnotify_mark *mark, unsigned long ino, dev_t dev) at audit_fsnotify.c:69>:
            audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
                uid_eq()
                uid_lt()
                uid_lte()
                uid_gt()
                uid_gte()
                BUG()
            audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
                gid_eq()
                gid_lt()
                gid_lte()
                gid_gt()
                gid_gte()
                BUG()
            in_group_p() <int in_group_p (kgid_t grp) at groups.c:255>:
                current_cred()
                gid_eq()
                groups_search() <int groups_search (const struct group_info *group_info, kgid_t grp) at groups.c:133>:
                    gid_gt()
                    GROUP_AT()
                    gid_lt()
            in_egroup_p() <int in_egroup_p (kgid_t grp) at groups.c:267>:
                current_cred()
                gid_eq()
                groups_search() <int groups_search (const struct group_info *group_info, kgid_t grp) at groups.c:133>:
                    gid_gt()
                    GROUP_AT()
                    gid_lt()
            MAJOR()
            list_for_each_entry()
            MINOR()
            audit_watch_compare() <int audit_watch_compare (struct audit_watch *watch, unsigned long ino, dev_t dev) at audit_watch.c:139>:
            match_tree_refs() <int match_tree_refs (struct audit_context *ctx, struct audit_tree *tree) at auditsc.c:287>:
                audit_tree_match() <bool audit_tree_match (struct audit_chunk *chunk, struct audit_tree *tree) at audit_tree.c:200>:
            audit_loginuid_set()
            security_task_getsecid()
            security_audit_rule_match()
            audit_match_perm() <int audit_match_perm (struct audit_context *ctx, int mask) at auditsc.c:131>:
                unlikely()
                audit_classify_syscall()
                audit_match_class() <int audit_match_class (int class, unsigned syscall) at auditfilter.c:197>:
                    unlikely()
                    AUDIT_WORD()
                    AUDIT_BIT()
                ACC_MODE()
            audit_match_filetype() <int audit_match_filetype (struct audit_context *ctx, int val) at auditsc.c:174>:
                unlikely()
                list_for_each_entry()
            audit_field_compare() <int audit_field_compare (struct task_struct *tsk, const struct cred *cred, struct audit_field *f, struct audit_context *ctx, struct audit_names *name) at auditsc.c:358>:
                audit_compare_uid() <int audit_compare_uid (kuid_t uid, struct audit_names *name, struct audit_field *f, struct audit_context *ctx) at auditsc.c:310>:
                    audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
                        uid_eq()
                        uid_lt()
                        uid_lte()
                        uid_gt()
                        uid_gte()
                        BUG()
                    list_for_each_entry()
                audit_compare_gid() <int audit_compare_gid (kgid_t gid, struct audit_names *name, struct audit_field *f, struct audit_context *ctx) at auditsc.c:334>:
                    audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
                        gid_eq()
                        gid_lt()
                        gid_lte()
                        gid_gt()
                        gid_gte()
                        BUG()
                    list_for_each_entry()
                audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
                    uid_eq()
                    uid_lt()
                    uid_lte()
                    uid_gt()
                    uid_gte()
                    BUG()
                audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
                    gid_eq()
                    gid_lt()
                    gid_lte()
                    gid_gt()
                    gid_gte()
                    BUG()
                WARN()
            kfree()
            kstrdup()
        kstrdup()
        rcu_read_unlock()
    clear_tsk_thread_flag()
    audit_alloc_context() <inline struct audit_context *audit_alloc_context (enum audit_state state) at auditsc.c:897>:
        kzalloc()
        INIT_LIST_HEAD()
    kfree()
    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
        atomic_inc()
        spin_lock_irqsave()
        spin_unlock_irqrestore()
        printk_ratelimit()
        pr_warn()
        atomic_read()
        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
            printk_ratelimit()
            pr_err()
            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                local_irq_disable()
                raw_smp_processor_id()
                atomic_cmpxchg()
                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                    cpu_relax()
                console_verbose()
                bust_spinlocks()
                pr_emerg()
                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                    test_bit()
                dump_stack()
                smp_send_stop()
                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                kmsg_dump()
                debug_locks_off()
                console_flush_on_panic()
                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                no_blink() <long no_blink (int state) at panic.c:46>
                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                    raw_cpu_write()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
                mdelay()
                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                    kmsg_dump()
                    machine_emergency_restart()
                disabled_wait()
                local_irq_enable()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
    set_tsk_thread_flag()
audit_alloc_mark() <struct audit_fsnotify_mark *audit_alloc_mark (struct audit_krule *krule, char *pathname, int len) at audit_fsnotify.c:83>:
    ERR_PTR()
    kern_path_locked()
    IS_ERR()
    d_inode()
    inode_unlock()
    kzalloc()
    unlikely()
    fsnotify_init_mark()
    audit_fsnotify_free_mark() <void audit_fsnotify_free_mark (struct fsnotify_mark *mark) at audit_fsnotify.c:56>:
        container_of()
        audit_fsnotify_mark_free() <void audit_fsnotify_mark_free (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:50>:
            kfree()
    audit_update_mark() <void audit_update_mark (struct audit_fsnotify_mark *audit_mark, struct inode *inode) at audit_fsnotify.c:76>:
    fsnotify_add_mark()
    audit_fsnotify_mark_free() <void audit_fsnotify_mark_free (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:50>:
        kfree()
    dput()
    path_put()
audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
    BUG()
audit_compare_dname_path() <int audit_compare_dname_path (const char *dname, const char *path, int parentlen) at auditfilter.c:1274>:
    parent_len() <int parent_len (const char *path) at auditfilter.c:1240>:
audit_copy_inode() <void audit_copy_inode (struct audit_names *name, const struct dentry *dentry, struct inode *inode) at audit.c:1721>:
    security_inode_getsecid()
    audit_copy_fcaps() <inline int audit_copy_fcaps (struct audit_names *name, const struct dentry *dentry) at audit.c:1698>:
        get_vfs_caps_from_disk()
audit_core_dumps() <void audit_core_dumps (long signr) at auditsc.c:2388>:
    audit_log_start() <struct audit_buffer *audit_log_start (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1355>:
        uninitialized_var()
        unlikely()
        audit_filter_type() <int audit_filter_type (int type) at auditfilter.c:1374>:
            rcu_read_lock()
            list_empty()
            list_for_each_entry_rcu()
            audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                BUG()
            rcu_read_unlock()
        skb_queue_len()
        wait_for_auditd() <long wait_for_auditd (long sleep_time) at audit.c:1324>:
            DECLARE_WAITQUEUE()
            set_current_state()
            add_wait_queue_exclusive()
            skb_queue_len()
            schedule_timeout()
            remove_wait_queue()
        audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
            spin_lock_irqsave()
            spin_unlock_irqrestore()
        printk_ratelimit()
        pr_warn()
        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
            atomic_inc()
            spin_lock_irqsave()
            spin_unlock_irqrestore()
            printk_ratelimit()
            pr_warn()
            atomic_read()
            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                printk_ratelimit()
                pr_err()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
        wake_up()
        audit_buffer_alloc() <struct audit_buffer *audit_buffer_alloc (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1245>:
            spin_lock_irqsave()
            list_empty()
            list_entry()
            list_del()
            spin_unlock_irqrestore()
            kmalloc()
            nlmsg_new()
            nlmsg_put()
            kfree_skb()
            audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                kfree_skb()
                spin_lock_irqsave()
                kfree()
                list_add()
                spin_unlock_irqrestore()
        audit_get_stamp() <inline void audit_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at audit.c:1312>:
            auditsc_get_stamp() <int auditsc_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at auditsc.c:1940>:
                audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                    ATOMIC_INIT()
                    atomic_add_return()
            audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                ATOMIC_INIT()
                atomic_add_return()
        audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
            audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                max_t()
                skb_put()
    unlikely()
    audit_log_task() <void audit_log_task (struct audit_buffer *ab) at auditsc.c:2359>:
        audit_get_loginuid()
        audit_get_sessionid()
        current_uid_gid()
        audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
            audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                max_t()
                skb_put()
        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
        audit_log_task_context() <int audit_log_task_context (struct audit_buffer *ab) at audit.c:1825>:
            security_task_getsecid()
            security_secid_to_secctx()
            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    max_t()
                    skb_put()
            security_release_secctx()
            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                printk_ratelimit()
                pr_err()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
        task_pid_nr()
        audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
            audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    hex_byte_pack_upper()
                    skb_put()
                audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    skb_put()
        get_task_comm()
        audit_log_d_path_exe() <void audit_log_d_path_exe (struct audit_buffer *ab, struct mm_struct *mm) at audit.c:1853>:
            get_mm_exe_file() <struct file *get_mm_exe_file (struct mm_struct *mm) at fork.c:752>:
                rcu_read_lock()
                rcu_dereference()
                get_file_rcu()
                rcu_read_unlock()
            audit_log_d_path() <void audit_log_d_path (struct audit_buffer *ab, const char *prefix, const struct path *path) at audit.c:1627>:
                audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                    audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        max_t()
                        skb_put()
                kmalloc()
                audit_log_string()
                d_path()
                IS_ERR()
                audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
                    audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                        audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                        audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            hex_byte_pack_upper()
                            skb_put()
                        audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            skb_put()
                kfree()
            fput()
            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    max_t()
                    skb_put()
    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            max_t()
            skb_put()
    audit_log_end() <void audit_log_end (struct audit_buffer *ab) at audit.c:1957>:
        audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
            spin_lock_irqsave()
            spin_unlock_irqrestore()
        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
            atomic_inc()
            spin_lock_irqsave()
            spin_unlock_irqrestore()
            printk_ratelimit()
            pr_warn()
            atomic_read()
            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                printk_ratelimit()
                pr_err()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
        nlmsg_hdr()
        kauditd_send_multicast_skb() <void kauditd_send_multicast_skb (struct sk_buff *skb, gfp_t gfp_mask) at audit.c:450>:
            net_generic()
            netlink_has_listeners()
            skb_copy()
            nlmsg_multicast()
        skb_queue_tail()
        wake_up_interruptible()
        audit_printk_skb() <void audit_printk_skb (struct sk_buff *skb) at audit.c:391>:
            nlmsg_hdr()
            nlmsg_data()
            printk_ratelimit()
            pr_notice()
            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                atomic_inc()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                atomic_read()
                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                    printk_ratelimit()
                    pr_err()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
            audit_hold_skb() <void audit_hold_skb (struct sk_buff *skb) at audit.c:377>:
                skb_queue_len()
                skb_queue_tail()
                kfree_skb()
        audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
            kfree_skb()
            spin_lock_irqsave()
            kfree()
            list_add()
            spin_unlock_irqrestore()
audit_del_rule() <int audit_del_rule (struct audit_entry *entry) at auditfilter.c:981>:
    mutex_lock()
    audit_find_rule() <struct audit_entry *audit_find_rule (struct audit_entry *entry, struct list_head **p) at auditfilter.c:862>:
        audit_hash_ino()
        list_for_each_entry()
        audit_compare_rule() <int audit_compare_rule (struct audit_krule *a, struct audit_krule *b) at auditfilter.c:667>:
            audit_watch_path() <char *audit_watch_path (struct audit_watch *watch) at audit_watch.c:134>
            audit_tree_path() <const char *audit_tree_path (struct audit_tree *tree) at audit_tree.c:104>
            audit_mark_path() <char *audit_mark_path (struct audit_fsnotify_mark *mark) at audit_fsnotify.c:64>
            uid_eq()
            gid_eq()
    audit_remove_watch_rule() <void audit_remove_watch_rule (struct audit_krule *krule) at audit_watch.c:451>:
        list_del()
        list_empty()
        audit_remove_watch() <void audit_remove_watch (struct audit_watch *watch) at audit_watch.c:126>:
            list_del()
            audit_put_parent() <void audit_put_parent (struct audit_parent *parent) at audit_watch.c:89>:
                likely()
                fsnotify_put_mark()
            audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
                atomic_dec_and_test()
                WARN_ON()
                list_empty()
                kfree()
        audit_get_parent() <void audit_get_parent (struct audit_parent *parent) at audit_watch.c:83>:
            likely()
            fsnotify_get_mark()
        fsnotify_destroy_mark()
        audit_put_parent() <void audit_put_parent (struct audit_parent *parent) at audit_watch.c:89>:
            likely()
            fsnotify_put_mark()
    audit_remove_tree_rule() <int audit_remove_tree_rule (struct audit_krule *rule) at audit_tree.c:556>:
        spin_lock()
        list_del_init()
        list_empty()
        list_move()
        spin_unlock()
        audit_schedule_prune() <void audit_schedule_prune (void) at audit_tree.c:875>:
            wake_up_process()
    audit_remove_mark_rule() <void audit_remove_mark_rule (struct audit_krule *krule) at audit_fsnotify.c:150>:
        audit_remove_mark() <void audit_remove_mark (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:144>:
            fsnotify_destroy_mark()
            fsnotify_put_mark()
    audit_match_signal() <int audit_match_signal (struct audit_entry *entry) at auditfilter.c:219>:
        audit_match_class_bits() <inline int audit_match_class_bits (int class, u32 *mask) at auditfilter.c:207>:
        audit_classify_arch()
    list_del_rcu()
    list_del()
    call_rcu()
    audit_free_rule_rcu() <void audit_free_rule_rcu (struct rcu_head *head) at auditfilter.c:108>:
        container_of()
        audit_free_rule() <inline void audit_free_rule (struct audit_entry *e) at auditfilter.c:92>:
            audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
                atomic_dec_and_test()
                WARN_ON()
                list_empty()
                kfree()
            audit_free_lsm_field() <void audit_free_lsm_field (struct audit_field *f) at auditfilter.c:74>:
                kfree()
                security_audit_rule_free()
            kfree()
    mutex_unlock()
    audit_put_tree() <void audit_put_tree (struct audit_tree *tree) at audit_tree.c:647>:
        put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
            atomic_dec_and_test()
            kfree_rcu()
audit_dupe_exe() <int audit_dupe_exe (struct audit_krule *new, struct audit_krule *old) at audit_watch.c:522>:
    kstrdup()
    audit_mark_path() <char *audit_mark_path (struct audit_fsnotify_mark *mark) at audit_fsnotify.c:64>
    audit_alloc_mark() <struct audit_fsnotify_mark *audit_alloc_mark (struct audit_krule *krule, char *pathname, int len) at audit_fsnotify.c:83>:
        ERR_PTR()
        kern_path_locked()
        IS_ERR()
        d_inode()
        inode_unlock()
        kzalloc()
        unlikely()
        fsnotify_init_mark()
        audit_fsnotify_free_mark() <void audit_fsnotify_free_mark (struct fsnotify_mark *mark) at audit_fsnotify.c:56>:
            container_of()
            audit_fsnotify_mark_free() <void audit_fsnotify_mark_free (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:50>:
                kfree()
        audit_update_mark() <void audit_update_mark (struct audit_fsnotify_mark *audit_mark, struct inode *inode) at audit_fsnotify.c:76>:
        fsnotify_add_mark()
        audit_fsnotify_mark_free() <void audit_fsnotify_mark_free (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:50>:
            kfree()
        dput()
        path_put()
    IS_ERR()
    kfree()
    PTR_ERR()
audit_dupe_rule() <struct audit_entry *audit_dupe_rule (struct audit_krule *old) at auditfilter.c:782>:
    audit_init_entry() <inline struct audit_entry *audit_init_entry (u32 field_count) at auditfilter.c:115>:
        kzalloc()
        unlikely()
        kcalloc()
        kfree()
    unlikely()
    ERR_PTR()
    audit_dupe_lsm_field() <inline int audit_dupe_lsm_field (struct audit_field *df, struct audit_field *sf) at auditfilter.c:750>:
        kstrdup()
        unlikely()
        security_audit_rule_init()
        pr_warn()
    kstrdup()
    audit_dupe_exe() <int audit_dupe_exe (struct audit_krule *new, struct audit_krule *old) at audit_watch.c:522>:
        kstrdup()
        audit_mark_path() <char *audit_mark_path (struct audit_fsnotify_mark *mark) at audit_fsnotify.c:64>
        audit_alloc_mark() <struct audit_fsnotify_mark *audit_alloc_mark (struct audit_krule *krule, char *pathname, int len) at audit_fsnotify.c:83>:
            ERR_PTR()
            kern_path_locked()
            IS_ERR()
            d_inode()
            inode_unlock()
            kzalloc()
            unlikely()
            fsnotify_init_mark()
            audit_fsnotify_free_mark() <void audit_fsnotify_free_mark (struct fsnotify_mark *mark) at audit_fsnotify.c:56>:
                container_of()
                audit_fsnotify_mark_free() <void audit_fsnotify_mark_free (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:50>:
                    kfree()
            audit_update_mark() <void audit_update_mark (struct audit_fsnotify_mark *audit_mark, struct inode *inode) at audit_fsnotify.c:76>:
            fsnotify_add_mark()
            audit_fsnotify_mark_free() <void audit_fsnotify_mark_free (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:50>:
                kfree()
            dput()
            path_put()
        IS_ERR()
        kfree()
        PTR_ERR()
    audit_remove_mark() <void audit_remove_mark (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:144>:
        fsnotify_destroy_mark()
        fsnotify_put_mark()
    audit_free_rule() <inline void audit_free_rule (struct audit_entry *e) at auditfilter.c:92>:
        audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
            atomic_dec_and_test()
            WARN_ON()
            list_empty()
            kfree()
        audit_free_lsm_field() <void audit_free_lsm_field (struct audit_field *f) at auditfilter.c:74>:
            kfree()
            security_audit_rule_free()
        kfree()
    audit_get_watch() <void audit_get_watch (struct audit_watch *watch) at audit_watch.c:111>:
        atomic_inc()
audit_exe_compare() <int audit_exe_compare (struct task_struct *tsk, struct audit_fsnotify_mark *mark) at audit_watch.c:541>:
    rcu_read_lock()
    rcu_dereference()
    rcu_read_unlock()
    audit_mark_compare() <int audit_mark_compare (struct audit_fsnotify_mark *mark, unsigned long ino, dev_t dev) at audit_fsnotify.c:69>:
audit_filter_inodes() <void audit_filter_inodes (struct task_struct *tsk, struct audit_context *ctx) at auditsc.c:805>:
    rcu_read_lock()
    list_for_each_entry()
    audit_filter_inode_name() <int audit_filter_inode_name (struct task_struct *tsk, struct audit_names *n, struct audit_context *ctx) at auditsc.c:778>:
        audit_hash_ino()
        list_empty()
        list_for_each_entry_rcu()
        audit_in_mask() <int audit_in_mask (const struct audit_krule *rule, unsigned long val) at auditsc.c:727>:
            AUDIT_WORD()
            AUDIT_BIT()
        audit_filter_rules() <int audit_filter_rules (struct task_struct *tsk, struct audit_krule *rule, struct audit_context *ctx, struct audit_names *name, enum audit_state *state, bool task_creation) at auditsc.c:438>:
            rcu_dereference_check()
            task_pid_nr()
            audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                BUG()
            task_ppid_nr()
            audit_exe_compare() <int audit_exe_compare (struct task_struct *tsk, struct audit_fsnotify_mark *mark) at audit_watch.c:541>:
                rcu_read_lock()
                rcu_dereference()
                rcu_read_unlock()
                audit_mark_compare() <int audit_mark_compare (struct audit_fsnotify_mark *mark, unsigned long ino, dev_t dev) at audit_fsnotify.c:69>:
            audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
                uid_eq()
                uid_lt()
                uid_lte()
                uid_gt()
                uid_gte()
                BUG()
            audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
                gid_eq()
                gid_lt()
                gid_lte()
                gid_gt()
                gid_gte()
                BUG()
            in_group_p() <int in_group_p (kgid_t grp) at groups.c:255>:
                current_cred()
                gid_eq()
                groups_search() <int groups_search (const struct group_info *group_info, kgid_t grp) at groups.c:133>:
                    gid_gt()
                    GROUP_AT()
                    gid_lt()
            in_egroup_p() <int in_egroup_p (kgid_t grp) at groups.c:267>:
                current_cred()
                gid_eq()
                groups_search() <int groups_search (const struct group_info *group_info, kgid_t grp) at groups.c:133>:
                    gid_gt()
                    GROUP_AT()
                    gid_lt()
            MAJOR()
            list_for_each_entry()
            MINOR()
            audit_watch_compare() <int audit_watch_compare (struct audit_watch *watch, unsigned long ino, dev_t dev) at audit_watch.c:139>:
            match_tree_refs() <int match_tree_refs (struct audit_context *ctx, struct audit_tree *tree) at auditsc.c:287>:
                audit_tree_match() <bool audit_tree_match (struct audit_chunk *chunk, struct audit_tree *tree) at audit_tree.c:200>:
            audit_loginuid_set()
            security_task_getsecid()
            security_audit_rule_match()
            audit_match_perm() <int audit_match_perm (struct audit_context *ctx, int mask) at auditsc.c:131>:
                unlikely()
                audit_classify_syscall()
                audit_match_class() <int audit_match_class (int class, unsigned syscall) at auditfilter.c:197>:
                    unlikely()
                    AUDIT_WORD()
                    AUDIT_BIT()
                ACC_MODE()
            audit_match_filetype() <int audit_match_filetype (struct audit_context *ctx, int val) at auditsc.c:174>:
                unlikely()
                list_for_each_entry()
            audit_field_compare() <int audit_field_compare (struct task_struct *tsk, const struct cred *cred, struct audit_field *f, struct audit_context *ctx, struct audit_names *name) at auditsc.c:358>:
                audit_compare_uid() <int audit_compare_uid (kuid_t uid, struct audit_names *name, struct audit_field *f, struct audit_context *ctx) at auditsc.c:310>:
                    audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
                        uid_eq()
                        uid_lt()
                        uid_lte()
                        uid_gt()
                        uid_gte()
                        BUG()
                    list_for_each_entry()
                audit_compare_gid() <int audit_compare_gid (kgid_t gid, struct audit_names *name, struct audit_field *f, struct audit_context *ctx) at auditsc.c:334>:
                    audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
                        gid_eq()
                        gid_lt()
                        gid_lte()
                        gid_gt()
                        gid_gte()
                        BUG()
                    list_for_each_entry()
                audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
                    uid_eq()
                    uid_lt()
                    uid_lte()
                    uid_gt()
                    uid_gte()
                    BUG()
                audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
                    gid_eq()
                    gid_lt()
                    gid_lte()
                    gid_gt()
                    gid_gte()
                    BUG()
                WARN()
            kfree()
            kstrdup()
    rcu_read_unlock()
audit_filter_type() <int audit_filter_type (int type) at auditfilter.c:1374>:
    rcu_read_lock()
    list_empty()
    list_for_each_entry_rcu()
    audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
        BUG()
    rcu_read_unlock()
audit_filter_user() <int audit_filter_user (int type) at auditfilter.c:1352>:
    rcu_read_lock()
    list_for_each_entry_rcu()
    audit_filter_user_rules() <int audit_filter_user_rules (struct audit_krule *rule, int type, enum audit_state *state) at auditfilter.c:1293>:
        task_pid_nr()
        audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
            BUG()
        audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
            uid_eq()
            uid_lt()
            uid_lte()
            uid_gt()
            uid_gte()
            BUG()
        current_uid()
        audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
            gid_eq()
            gid_lt()
            gid_lte()
            gid_gt()
            gid_gte()
            BUG()
        current_gid()
        audit_get_loginuid()
        audit_loginuid_set()
        security_task_getsecid()
        security_audit_rule_match()
    rcu_read_unlock()
audit_free_rule_rcu() <void audit_free_rule_rcu (struct rcu_head *head) at auditfilter.c:108>:
    container_of()
    audit_free_rule() <inline void audit_free_rule (struct audit_entry *e) at auditfilter.c:92>:
        audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
            atomic_dec_and_test()
            WARN_ON()
            list_empty()
            kfree()
        audit_free_lsm_field() <void audit_free_lsm_field (struct audit_field *f) at auditfilter.c:74>:
            kfree()
            security_audit_rule_free()
        kfree()
audit_get_watch() <void audit_get_watch (struct audit_watch *watch) at audit_watch.c:111>:
    atomic_inc()
audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
    gid_eq()
    gid_lt()
    gid_lte()
    gid_gt()
    gid_gte()
    BUG()
audit_kill_trees() <void audit_kill_trees (struct list_head *list) at audit_tree.c:884>:
    mutex_lock()
    list_empty()
    list_entry()
    kill_rules() <void kill_rules (struct audit_tree *tree) at audit_tree.c:470>:
        list_for_each_entry_safe()
        container_of()
        list_del_init()
        audit_tree_log_remove_rule() <void audit_tree_log_remove_rule (struct audit_krule *rule) at audit_tree.c:454>:
            audit_log_start() <struct audit_buffer *audit_log_start (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1355>:
                uninitialized_var()
                unlikely()
                audit_filter_type() <int audit_filter_type (int type) at auditfilter.c:1374>:
                    rcu_read_lock()
                    list_empty()
                    list_for_each_entry_rcu()
                    audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                        BUG()
                    rcu_read_unlock()
                skb_queue_len()
                wait_for_auditd() <long wait_for_auditd (long sleep_time) at audit.c:1324>:
                    DECLARE_WAITQUEUE()
                    set_current_state()
                    add_wait_queue_exclusive()
                    skb_queue_len()
                    schedule_timeout()
                    remove_wait_queue()
                audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                wake_up()
                audit_buffer_alloc() <struct audit_buffer *audit_buffer_alloc (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1245>:
                    spin_lock_irqsave()
                    list_empty()
                    list_entry()
                    list_del()
                    spin_unlock_irqrestore()
                    kmalloc()
                    nlmsg_new()
                    nlmsg_put()
                    kfree_skb()
                    audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                        kfree_skb()
                        spin_lock_irqsave()
                        kfree()
                        list_add()
                        spin_unlock_irqrestore()
                audit_get_stamp() <inline void audit_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at audit.c:1312>:
                    auditsc_get_stamp() <int auditsc_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at auditsc.c:1940>:
                        audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                            ATOMIC_INIT()
                            atomic_add_return()
                    audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                        ATOMIC_INIT()
                        atomic_add_return()
                audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                    audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        max_t()
                        skb_put()
            unlikely()
            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    max_t()
                    skb_put()
            audit_log_string()
            audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
                audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                    audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                    audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        hex_byte_pack_upper()
                        skb_put()
                    audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        skb_put()
            audit_log_key() <void audit_log_key (struct audit_buffer *ab, char *key) at audit.c:1658>:
                audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                    audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        max_t()
                        skb_put()
                audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
                    audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                        audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                        audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            hex_byte_pack_upper()
                            skb_put()
                        audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            skb_put()
            audit_log_end() <void audit_log_end (struct audit_buffer *ab) at audit.c:1957>:
                audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                nlmsg_hdr()
                kauditd_send_multicast_skb() <void kauditd_send_multicast_skb (struct sk_buff *skb, gfp_t gfp_mask) at audit.c:450>:
                    net_generic()
                    netlink_has_listeners()
                    skb_copy()
                    nlmsg_multicast()
                skb_queue_tail()
                wake_up_interruptible()
                audit_printk_skb() <void audit_printk_skb (struct sk_buff *skb) at audit.c:391>:
                    nlmsg_hdr()
                    nlmsg_data()
                    printk_ratelimit()
                    pr_notice()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                    audit_hold_skb() <void audit_hold_skb (struct sk_buff *skb) at audit.c:377>:
                        skb_queue_len()
                        skb_queue_tail()
                        kfree_skb()
                audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                    kfree_skb()
                    spin_lock_irqsave()
                    kfree()
                    list_add()
                    spin_unlock_irqrestore()
        audit_remove_mark() <void audit_remove_mark (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:144>:
            fsnotify_destroy_mark()
            fsnotify_put_mark()
        list_del_rcu()
        list_del()
        call_rcu()
        audit_free_rule_rcu() <void audit_free_rule_rcu (struct rcu_head *head) at auditfilter.c:108>:
            container_of()
            audit_free_rule() <inline void audit_free_rule (struct audit_entry *e) at auditfilter.c:92>:
                audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
                    atomic_dec_and_test()
                    WARN_ON()
                    list_empty()
                    kfree()
                audit_free_lsm_field() <void audit_free_lsm_field (struct audit_field *f) at auditfilter.c:74>:
                    kfree()
                    security_audit_rule_free()
                kfree()
    list_del_init()
    mutex_unlock()
    prune_one() <void prune_one (struct audit_tree *victim) at audit_tree.c:495>:
        spin_lock()
        list_empty()
        list_entry()
        untag_chunk() <void untag_chunk (struct node *p) at audit_tree.c:218>:
            find_chunk() <struct audit_chunk *find_chunk (struct node *p) at audit_tree.c:211>:
                container_of()
            fsnotify_get_mark()
            spin_unlock()
            alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                kzalloc()
                INIT_LIST_HEAD()
                atomic_long_set()
                fsnotify_init_mark()
                audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                    container_of()
                    call_rcu()
            spin_lock()
            free_chunk() <void free_chunk (struct audit_chunk *chunk) at audit_tree.c:109>:
                put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                    atomic_dec_and_test()
                    kfree_rcu()
                kfree()
            list_del_init()
            list_del_rcu()
            fsnotify_destroy_mark()
            fsnotify_duplicate_mark()
            fsnotify_add_mark()
            fsnotify_put_mark()
            list_replace_init()
            get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                atomic_inc()
            list_replace_rcu()
            list_for_each_entry()
            put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                atomic_dec_and_test()
                kfree_rcu()
        spin_unlock()
        put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
            atomic_dec_and_test()
            kfree_rcu()
audit_killed_trees() <struct list_head *audit_killed_trees (void) at auditsc.c:2420>:
    likely()
audit_list_rules_send() <int audit_list_rules_send (struct sk_buff *request_skb, int seq) at auditfilter.c:1130>:
    NETLINK_CB()
    sock_net()
    kmalloc()
    get_net()
    skb_queue_head_init()
    mutex_lock()
    audit_list_rules() <void audit_list_rules (__u32 portid, int seq, struct sk_buff_head *q) at auditfilter.c:1034>:
        list_for_each_entry()
        audit_krule_to_data() <struct audit_rule_data *audit_krule_to_data (struct audit_krule *krule) at auditfilter.c:597>:
            kmalloc()
            unlikely()
            audit_pack_string() <inline size_t audit_pack_string (void **bufp, const char *str) at auditfilter.c:586>:
            audit_watch_path() <char *audit_watch_path (struct audit_watch *watch) at audit_watch.c:134>
            audit_tree_path() <const char *audit_tree_path (struct audit_tree *tree) at audit_tree.c:104>
            audit_mark_path() <char *audit_mark_path (struct audit_fsnotify_mark *mark) at audit_fsnotify.c:64>
        unlikely()
        audit_make_reply() <struct sk_buff *audit_make_reply (__u32 portid, int seq, int type, int done, int multi, const void *payload, int size) at audit.c:560>:
            nlmsg_new()
            nlmsg_put()
            nlmsg_data()
            kfree_skb()
        skb_queue_tail()
        kfree()
    mutex_unlock()
    kthread_run()
    audit_send_list() <int audit_send_list (void *_dest) at audit.c:540>:
        net_generic()
        mutex_lock()
        mutex_unlock()
        netlink_unicast()
        put_net()
        kfree()
    IS_ERR()
    skb_queue_purge()
    kfree()
    PTR_ERR()
audit_log() <void audit_log (struct audit_context *ctx, gfp_t gfp_mask, int type, const char *fmt, ...) at audit.c:2003>:
    audit_log_start() <struct audit_buffer *audit_log_start (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1355>:
        uninitialized_var()
        unlikely()
        audit_filter_type() <int audit_filter_type (int type) at auditfilter.c:1374>:
            rcu_read_lock()
            list_empty()
            list_for_each_entry_rcu()
            audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                BUG()
            rcu_read_unlock()
        skb_queue_len()
        wait_for_auditd() <long wait_for_auditd (long sleep_time) at audit.c:1324>:
            DECLARE_WAITQUEUE()
            set_current_state()
            add_wait_queue_exclusive()
            skb_queue_len()
            schedule_timeout()
            remove_wait_queue()
        audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
            spin_lock_irqsave()
            spin_unlock_irqrestore()
        printk_ratelimit()
        pr_warn()
        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
            atomic_inc()
            spin_lock_irqsave()
            spin_unlock_irqrestore()
            printk_ratelimit()
            pr_warn()
            atomic_read()
            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                printk_ratelimit()
                pr_err()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
        wake_up()
        audit_buffer_alloc() <struct audit_buffer *audit_buffer_alloc (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1245>:
            spin_lock_irqsave()
            list_empty()
            list_entry()
            list_del()
            spin_unlock_irqrestore()
            kmalloc()
            nlmsg_new()
            nlmsg_put()
            kfree_skb()
            audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                kfree_skb()
                spin_lock_irqsave()
                kfree()
                list_add()
                spin_unlock_irqrestore()
        audit_get_stamp() <inline void audit_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at audit.c:1312>:
            auditsc_get_stamp() <int auditsc_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at auditsc.c:1940>:
                audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                    ATOMIC_INIT()
                    atomic_add_return()
            audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                ATOMIC_INIT()
                atomic_add_return()
        audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
            audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                max_t()
                skb_put()
    audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
        BUG_ON()
        skb_tailroom()
        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
            skb_tailroom()
            pskb_expand_head()
            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                atomic_inc()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                atomic_read()
                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                    printk_ratelimit()
                    pr_err()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
        skb_tail_pointer()
        max_t()
        skb_put()
    audit_log_end() <void audit_log_end (struct audit_buffer *ab) at audit.c:1957>:
        audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
            spin_lock_irqsave()
            spin_unlock_irqrestore()
        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
            atomic_inc()
            spin_lock_irqsave()
            spin_unlock_irqrestore()
            printk_ratelimit()
            pr_warn()
            atomic_read()
            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                printk_ratelimit()
                pr_err()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
        nlmsg_hdr()
        kauditd_send_multicast_skb() <void kauditd_send_multicast_skb (struct sk_buff *skb, gfp_t gfp_mask) at audit.c:450>:
            net_generic()
            netlink_has_listeners()
            skb_copy()
            nlmsg_multicast()
        skb_queue_tail()
        wake_up_interruptible()
        audit_printk_skb() <void audit_printk_skb (struct sk_buff *skb) at audit.c:391>:
            nlmsg_hdr()
            nlmsg_data()
            printk_ratelimit()
            pr_notice()
            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                atomic_inc()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                atomic_read()
                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                    printk_ratelimit()
                    pr_err()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
            audit_hold_skb() <void audit_hold_skb (struct sk_buff *skb) at audit.c:377>:
                skb_queue_len()
                skb_queue_tail()
                kfree_skb()
        audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
            kfree_skb()
            spin_lock_irqsave()
            kfree()
            list_add()
            spin_unlock_irqrestore()
audit_log_cap() <void audit_log_cap (struct audit_buffer *ab, char *prefix, kernel_cap_t *cap) at audit.c:1667>:
    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            max_t()
            skb_put()
    CAP_FOR_EACH_U32()
audit_log_d_path() <void audit_log_d_path (struct audit_buffer *ab, const char *prefix, const struct path *path) at audit.c:1627>:
    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            max_t()
            skb_put()
    kmalloc()
    audit_log_string()
    d_path()
    IS_ERR()
    audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
        audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
            audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
            audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                hex_byte_pack_upper()
                skb_put()
            audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                skb_put()
    kfree()
audit_log_d_path_exe() <void audit_log_d_path_exe (struct audit_buffer *ab, struct mm_struct *mm) at audit.c:1853>:
    get_mm_exe_file() <struct file *get_mm_exe_file (struct mm_struct *mm) at fork.c:752>:
        rcu_read_lock()
        rcu_dereference()
        get_file_rcu()
        rcu_read_unlock()
    audit_log_d_path() <void audit_log_d_path (struct audit_buffer *ab, const char *prefix, const struct path *path) at audit.c:1627>:
        audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
            audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                max_t()
                skb_put()
        kmalloc()
        audit_log_string()
        d_path()
        IS_ERR()
        audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
            audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    hex_byte_pack_upper()
                    skb_put()
                audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    skb_put()
        kfree()
    fput()
    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            max_t()
            skb_put()
audit_log_end() <void audit_log_end (struct audit_buffer *ab) at audit.c:1957>:
    audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
        spin_lock_irqsave()
        spin_unlock_irqrestore()
    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
        atomic_inc()
        spin_lock_irqsave()
        spin_unlock_irqrestore()
        printk_ratelimit()
        pr_warn()
        atomic_read()
        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
            printk_ratelimit()
            pr_err()
            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                local_irq_disable()
                raw_smp_processor_id()
                atomic_cmpxchg()
                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                    cpu_relax()
                console_verbose()
                bust_spinlocks()
                pr_emerg()
                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                    test_bit()
                dump_stack()
                smp_send_stop()
                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                kmsg_dump()
                debug_locks_off()
                console_flush_on_panic()
                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                no_blink() <long no_blink (int state) at panic.c:46>
                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                    raw_cpu_write()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
                mdelay()
                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                    kmsg_dump()
                    machine_emergency_restart()
                disabled_wait()
                local_irq_enable()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
    nlmsg_hdr()
    kauditd_send_multicast_skb() <void kauditd_send_multicast_skb (struct sk_buff *skb, gfp_t gfp_mask) at audit.c:450>:
        net_generic()
        netlink_has_listeners()
        skb_copy()
        nlmsg_multicast()
    skb_queue_tail()
    wake_up_interruptible()
    audit_printk_skb() <void audit_printk_skb (struct sk_buff *skb) at audit.c:391>:
        nlmsg_hdr()
        nlmsg_data()
        printk_ratelimit()
        pr_notice()
        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
            atomic_inc()
            spin_lock_irqsave()
            spin_unlock_irqrestore()
            printk_ratelimit()
            pr_warn()
            atomic_read()
            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                printk_ratelimit()
                pr_err()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
        audit_hold_skb() <void audit_hold_skb (struct sk_buff *skb) at audit.c:377>:
            skb_queue_len()
            skb_queue_tail()
            kfree_skb()
    audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
        kfree_skb()
        spin_lock_irqsave()
        kfree()
        list_add()
        spin_unlock_irqrestore()
audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
    audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
        BUG_ON()
        skb_tailroom()
        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
            skb_tailroom()
            pskb_expand_head()
            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                atomic_inc()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                atomic_read()
                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                    printk_ratelimit()
                    pr_err()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
        skb_tail_pointer()
        max_t()
        skb_put()
audit_log_key() <void audit_log_key (struct audit_buffer *ab, char *key) at audit.c:1658>:
    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            max_t()
            skb_put()
    audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
        audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
            audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
            audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                hex_byte_pack_upper()
                skb_put()
            audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                skb_put()
audit_log_link_denied() <void audit_log_link_denied (const char *operation, struct path *link) at audit.c:1921>:
    kzalloc()
    audit_log_start() <struct audit_buffer *audit_log_start (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1355>:
        uninitialized_var()
        unlikely()
        audit_filter_type() <int audit_filter_type (int type) at auditfilter.c:1374>:
            rcu_read_lock()
            list_empty()
            list_for_each_entry_rcu()
            audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                BUG()
            rcu_read_unlock()
        skb_queue_len()
        wait_for_auditd() <long wait_for_auditd (long sleep_time) at audit.c:1324>:
            DECLARE_WAITQUEUE()
            set_current_state()
            add_wait_queue_exclusive()
            skb_queue_len()
            schedule_timeout()
            remove_wait_queue()
        audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
            spin_lock_irqsave()
            spin_unlock_irqrestore()
        printk_ratelimit()
        pr_warn()
        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
            atomic_inc()
            spin_lock_irqsave()
            spin_unlock_irqrestore()
            printk_ratelimit()
            pr_warn()
            atomic_read()
            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                printk_ratelimit()
                pr_err()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
        wake_up()
        audit_buffer_alloc() <struct audit_buffer *audit_buffer_alloc (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1245>:
            spin_lock_irqsave()
            list_empty()
            list_entry()
            list_del()
            spin_unlock_irqrestore()
            kmalloc()
            nlmsg_new()
            nlmsg_put()
            kfree_skb()
            audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                kfree_skb()
                spin_lock_irqsave()
                kfree()
                list_add()
                spin_unlock_irqrestore()
        audit_get_stamp() <inline void audit_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at audit.c:1312>:
            auditsc_get_stamp() <int auditsc_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at auditsc.c:1940>:
                audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                    ATOMIC_INIT()
                    atomic_add_return()
            audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                ATOMIC_INIT()
                atomic_add_return()
        audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
            audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                max_t()
                skb_put()
    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            max_t()
            skb_put()
    audit_log_task_info() <void audit_log_task_info (struct audit_buffer *ab, struct task_struct *tsk) at audit.c:1872>:
        current_cred()
        spin_lock_irq()
        spin_unlock_irq()
        audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
            audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                max_t()
                skb_put()
        task_ppid_nr()
        task_pid_nr()
        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
        audit_get_loginuid()
        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
        audit_get_sessionid()
        audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
            audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    hex_byte_pack_upper()
                    skb_put()
                audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    skb_put()
        get_task_comm()
        audit_log_d_path_exe() <void audit_log_d_path_exe (struct audit_buffer *ab, struct mm_struct *mm) at audit.c:1853>:
            get_mm_exe_file() <struct file *get_mm_exe_file (struct mm_struct *mm) at fork.c:752>:
                rcu_read_lock()
                rcu_dereference()
                get_file_rcu()
                rcu_read_unlock()
            audit_log_d_path() <void audit_log_d_path (struct audit_buffer *ab, const char *prefix, const struct path *path) at audit.c:1627>:
                audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                    audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        max_t()
                        skb_put()
                kmalloc()
                audit_log_string()
                d_path()
                IS_ERR()
                audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
                    audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                        audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                        audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            hex_byte_pack_upper()
                            skb_put()
                        audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            skb_put()
                kfree()
            fput()
            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    max_t()
                    skb_put()
        audit_log_task_context() <int audit_log_task_context (struct audit_buffer *ab) at audit.c:1825>:
            security_task_getsecid()
            security_secid_to_secctx()
            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    max_t()
                    skb_put()
            security_release_secctx()
            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                printk_ratelimit()
                pr_err()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
    audit_log_end() <void audit_log_end (struct audit_buffer *ab) at audit.c:1957>:
        audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
            spin_lock_irqsave()
            spin_unlock_irqrestore()
        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
            atomic_inc()
            spin_lock_irqsave()
            spin_unlock_irqrestore()
            printk_ratelimit()
            pr_warn()
            atomic_read()
            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                printk_ratelimit()
                pr_err()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
        nlmsg_hdr()
        kauditd_send_multicast_skb() <void kauditd_send_multicast_skb (struct sk_buff *skb, gfp_t gfp_mask) at audit.c:450>:
            net_generic()
            netlink_has_listeners()
            skb_copy()
            nlmsg_multicast()
        skb_queue_tail()
        wake_up_interruptible()
        audit_printk_skb() <void audit_printk_skb (struct sk_buff *skb) at audit.c:391>:
            nlmsg_hdr()
            nlmsg_data()
            printk_ratelimit()
            pr_notice()
            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                atomic_inc()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                atomic_read()
                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                    printk_ratelimit()
                    pr_err()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
            audit_hold_skb() <void audit_hold_skb (struct sk_buff *skb) at audit.c:377>:
                skb_queue_len()
                skb_queue_tail()
                kfree_skb()
        audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
            kfree_skb()
            spin_lock_irqsave()
            kfree()
            list_add()
            spin_unlock_irqrestore()
    audit_copy_inode() <void audit_copy_inode (struct audit_names *name, const struct dentry *dentry, struct inode *inode) at audit.c:1721>:
        security_inode_getsecid()
        audit_copy_fcaps() <inline int audit_copy_fcaps (struct audit_names *name, const struct dentry *dentry) at audit.c:1698>:
            get_vfs_caps_from_disk()
    d_backing_inode()
    audit_log_name() <void audit_log_name (struct audit_context *context, struct audit_names *n, struct path *path, int record_num, int *call_panic) at audit.c:1742>:
        audit_log_start() <struct audit_buffer *audit_log_start (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1355>:
            uninitialized_var()
            unlikely()
            audit_filter_type() <int audit_filter_type (int type) at auditfilter.c:1374>:
                rcu_read_lock()
                list_empty()
                list_for_each_entry_rcu()
                audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                    BUG()
                rcu_read_unlock()
            skb_queue_len()
            wait_for_auditd() <long wait_for_auditd (long sleep_time) at audit.c:1324>:
                DECLARE_WAITQUEUE()
                set_current_state()
                add_wait_queue_exclusive()
                skb_queue_len()
                schedule_timeout()
                remove_wait_queue()
            audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                spin_lock_irqsave()
                spin_unlock_irqrestore()
            printk_ratelimit()
            pr_warn()
            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                atomic_inc()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                atomic_read()
                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                    printk_ratelimit()
                    pr_err()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
            wake_up()
            audit_buffer_alloc() <struct audit_buffer *audit_buffer_alloc (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1245>:
                spin_lock_irqsave()
                list_empty()
                list_entry()
                list_del()
                spin_unlock_irqrestore()
                kmalloc()
                nlmsg_new()
                nlmsg_put()
                kfree_skb()
                audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                    kfree_skb()
                    spin_lock_irqsave()
                    kfree()
                    list_add()
                    spin_unlock_irqrestore()
            audit_get_stamp() <inline void audit_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at audit.c:1312>:
                auditsc_get_stamp() <int auditsc_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at auditsc.c:1940>:
                    audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                        ATOMIC_INIT()
                        atomic_add_return()
                audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                    ATOMIC_INIT()
                    atomic_add_return()
            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    max_t()
                    skb_put()
        audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
            audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                max_t()
                skb_put()
        audit_log_d_path() <void audit_log_d_path (struct audit_buffer *ab, const char *prefix, const struct path *path) at audit.c:1627>:
            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    max_t()
                    skb_put()
            kmalloc()
            audit_log_string()
            d_path()
            IS_ERR()
            audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
                audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                    audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                    audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        hex_byte_pack_upper()
                        skb_put()
                    audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        skb_put()
            kfree()
        audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
            audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    hex_byte_pack_upper()
                    skb_put()
                audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    skb_put()
        audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
            audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
            audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                hex_byte_pack_upper()
                skb_put()
            audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                skb_put()
        MAJOR()
        MINOR()
        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
        security_secid_to_secctx()
        security_release_secctx()
        audit_log_fcaps() <void audit_log_fcaps (struct audit_buffer *ab, struct audit_names *name) at audit.c:1678>:
            cap_isclear()
            audit_log_cap() <void audit_log_cap (struct audit_buffer *ab, char *prefix, kernel_cap_t *cap) at audit.c:1667>:
                audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                    audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        max_t()
                        skb_put()
                CAP_FOR_EACH_U32()
            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    max_t()
                    skb_put()
        audit_log_end() <void audit_log_end (struct audit_buffer *ab) at audit.c:1957>:
            audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                spin_lock_irqsave()
                spin_unlock_irqrestore()
            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                atomic_inc()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                atomic_read()
                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                    printk_ratelimit()
                    pr_err()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
            nlmsg_hdr()
            kauditd_send_multicast_skb() <void kauditd_send_multicast_skb (struct sk_buff *skb, gfp_t gfp_mask) at audit.c:450>:
                net_generic()
                netlink_has_listeners()
                skb_copy()
                nlmsg_multicast()
            skb_queue_tail()
            wake_up_interruptible()
            audit_printk_skb() <void audit_printk_skb (struct sk_buff *skb) at audit.c:391>:
                nlmsg_hdr()
                nlmsg_data()
                printk_ratelimit()
                pr_notice()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                audit_hold_skb() <void audit_hold_skb (struct sk_buff *skb) at audit.c:377>:
                    skb_queue_len()
                    skb_queue_tail()
                    kfree_skb()
            audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                kfree_skb()
                spin_lock_irqsave()
                kfree()
                list_add()
                spin_unlock_irqrestore()
    kfree()
audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
    atomic_inc()
    spin_lock_irqsave()
    spin_unlock_irqrestore()
    printk_ratelimit()
    pr_warn()
    atomic_read()
    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
        printk_ratelimit()
        pr_err()
        panic() <void panic (const char *fmt, ...) at panic.c:83>:
            local_irq_disable()
            raw_smp_processor_id()
            atomic_cmpxchg()
            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                cpu_relax()
            console_verbose()
            bust_spinlocks()
            pr_emerg()
            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                test_bit()
            dump_stack()
            smp_send_stop()
            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
            kmsg_dump()
            debug_locks_off()
            console_flush_on_panic()
            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
            no_blink() <long no_blink (int state) at panic.c:46>
            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                raw_cpu_write()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            mdelay()
            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                kmsg_dump()
                machine_emergency_restart()
            disabled_wait()
            local_irq_enable()
            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                    raw_cpu_write()
                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                    per_cpu()
                raw_smp_processor_id()
audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
    BUG_ON()
    skb_tailroom()
    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
        skb_tailroom()
        pskb_expand_head()
        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
            atomic_inc()
            spin_lock_irqsave()
            spin_unlock_irqrestore()
            printk_ratelimit()
            pr_warn()
            atomic_read()
            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                printk_ratelimit()
                pr_err()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
    skb_tail_pointer()
    hex_byte_pack_upper()
    skb_put()
audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
    BUG_ON()
    skb_tailroom()
    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
        skb_tailroom()
        pskb_expand_head()
        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
            atomic_inc()
            spin_lock_irqsave()
            spin_unlock_irqrestore()
            printk_ratelimit()
            pr_warn()
            atomic_read()
            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                printk_ratelimit()
                pr_err()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
    skb_tail_pointer()
    skb_put()
audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
    audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
    audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
        BUG_ON()
        skb_tailroom()
        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
            skb_tailroom()
            pskb_expand_head()
            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                atomic_inc()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                atomic_read()
                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                    printk_ratelimit()
                    pr_err()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
        skb_tail_pointer()
        hex_byte_pack_upper()
        skb_put()
    audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
        BUG_ON()
        skb_tailroom()
        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
            skb_tailroom()
            pskb_expand_head()
            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                atomic_inc()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                atomic_read()
                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                    printk_ratelimit()
                    pr_err()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
        skb_tail_pointer()
        skb_put()
audit_log_name() <void audit_log_name (struct audit_context *context, struct audit_names *n, struct path *path, int record_num, int *call_panic) at audit.c:1742>:
    audit_log_start() <struct audit_buffer *audit_log_start (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1355>:
        uninitialized_var()
        unlikely()
        audit_filter_type() <int audit_filter_type (int type) at auditfilter.c:1374>:
            rcu_read_lock()
            list_empty()
            list_for_each_entry_rcu()
            audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                BUG()
            rcu_read_unlock()
        skb_queue_len()
        wait_for_auditd() <long wait_for_auditd (long sleep_time) at audit.c:1324>:
            DECLARE_WAITQUEUE()
            set_current_state()
            add_wait_queue_exclusive()
            skb_queue_len()
            schedule_timeout()
            remove_wait_queue()
        audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
            spin_lock_irqsave()
            spin_unlock_irqrestore()
        printk_ratelimit()
        pr_warn()
        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
            atomic_inc()
            spin_lock_irqsave()
            spin_unlock_irqrestore()
            printk_ratelimit()
            pr_warn()
            atomic_read()
            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                printk_ratelimit()
                pr_err()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
        wake_up()
        audit_buffer_alloc() <struct audit_buffer *audit_buffer_alloc (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1245>:
            spin_lock_irqsave()
            list_empty()
            list_entry()
            list_del()
            spin_unlock_irqrestore()
            kmalloc()
            nlmsg_new()
            nlmsg_put()
            kfree_skb()
            audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                kfree_skb()
                spin_lock_irqsave()
                kfree()
                list_add()
                spin_unlock_irqrestore()
        audit_get_stamp() <inline void audit_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at audit.c:1312>:
            auditsc_get_stamp() <int auditsc_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at auditsc.c:1940>:
                audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                    ATOMIC_INIT()
                    atomic_add_return()
            audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                ATOMIC_INIT()
                atomic_add_return()
        audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
            audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                max_t()
                skb_put()
    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            max_t()
            skb_put()
    audit_log_d_path() <void audit_log_d_path (struct audit_buffer *ab, const char *prefix, const struct path *path) at audit.c:1627>:
        audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
            audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                max_t()
                skb_put()
        kmalloc()
        audit_log_string()
        d_path()
        IS_ERR()
        audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
            audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    hex_byte_pack_upper()
                    skb_put()
                audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    skb_put()
        kfree()
    audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
        audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
            audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
            audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                hex_byte_pack_upper()
                skb_put()
            audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                skb_put()
    audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
        audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
        audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            hex_byte_pack_upper()
            skb_put()
        audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            skb_put()
    MAJOR()
    MINOR()
    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
            smp_rmb()
    from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
            smp_rmb()
    security_secid_to_secctx()
    security_release_secctx()
    audit_log_fcaps() <void audit_log_fcaps (struct audit_buffer *ab, struct audit_names *name) at audit.c:1678>:
        cap_isclear()
        audit_log_cap() <void audit_log_cap (struct audit_buffer *ab, char *prefix, kernel_cap_t *cap) at audit.c:1667>:
            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    max_t()
                    skb_put()
            CAP_FOR_EACH_U32()
        audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
            audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                max_t()
                skb_put()
    audit_log_end() <void audit_log_end (struct audit_buffer *ab) at audit.c:1957>:
        audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
            spin_lock_irqsave()
            spin_unlock_irqrestore()
        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
            atomic_inc()
            spin_lock_irqsave()
            spin_unlock_irqrestore()
            printk_ratelimit()
            pr_warn()
            atomic_read()
            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                printk_ratelimit()
                pr_err()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
        nlmsg_hdr()
        kauditd_send_multicast_skb() <void kauditd_send_multicast_skb (struct sk_buff *skb, gfp_t gfp_mask) at audit.c:450>:
            net_generic()
            netlink_has_listeners()
            skb_copy()
            nlmsg_multicast()
        skb_queue_tail()
        wake_up_interruptible()
        audit_printk_skb() <void audit_printk_skb (struct sk_buff *skb) at audit.c:391>:
            nlmsg_hdr()
            nlmsg_data()
            printk_ratelimit()
            pr_notice()
            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                atomic_inc()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                atomic_read()
                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                    printk_ratelimit()
                    pr_err()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
            audit_hold_skb() <void audit_hold_skb (struct sk_buff *skb) at audit.c:377>:
                skb_queue_len()
                skb_queue_tail()
                kfree_skb()
        audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
            kfree_skb()
            spin_lock_irqsave()
            kfree()
            list_add()
            spin_unlock_irqrestore()
audit_log_secctx() <void audit_log_secctx (struct audit_buffer *ab, u32 secid) at audit.c:2029>:
    security_secid_to_secctx()
    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
        printk_ratelimit()
        pr_err()
        panic() <void panic (const char *fmt, ...) at panic.c:83>:
            local_irq_disable()
            raw_smp_processor_id()
            atomic_cmpxchg()
            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                cpu_relax()
            console_verbose()
            bust_spinlocks()
            pr_emerg()
            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                test_bit()
            dump_stack()
            smp_send_stop()
            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
            kmsg_dump()
            debug_locks_off()
            console_flush_on_panic()
            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
            no_blink() <long no_blink (int state) at panic.c:46>
            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                raw_cpu_write()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            mdelay()
            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                kmsg_dump()
                machine_emergency_restart()
            disabled_wait()
            local_irq_enable()
            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                    raw_cpu_write()
                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                    per_cpu()
                raw_smp_processor_id()
    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            max_t()
            skb_put()
    security_release_secctx()
audit_log_session_info() <void audit_log_session_info (struct audit_buffer *ab) at audit.c:1650>:
    audit_get_sessionid()
    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
            smp_rmb()
    audit_get_loginuid()
    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            max_t()
            skb_put()
audit_log_start() <struct audit_buffer *audit_log_start (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1355>:
    uninitialized_var()
    unlikely()
    audit_filter_type() <int audit_filter_type (int type) at auditfilter.c:1374>:
        rcu_read_lock()
        list_empty()
        list_for_each_entry_rcu()
        audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
            BUG()
        rcu_read_unlock()
    skb_queue_len()
    wait_for_auditd() <long wait_for_auditd (long sleep_time) at audit.c:1324>:
        DECLARE_WAITQUEUE()
        set_current_state()
        add_wait_queue_exclusive()
        skb_queue_len()
        schedule_timeout()
        remove_wait_queue()
    audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
        spin_lock_irqsave()
        spin_unlock_irqrestore()
    printk_ratelimit()
    pr_warn()
    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
        atomic_inc()
        spin_lock_irqsave()
        spin_unlock_irqrestore()
        printk_ratelimit()
        pr_warn()
        atomic_read()
        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
            printk_ratelimit()
            pr_err()
            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                local_irq_disable()
                raw_smp_processor_id()
                atomic_cmpxchg()
                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                    cpu_relax()
                console_verbose()
                bust_spinlocks()
                pr_emerg()
                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                    test_bit()
                dump_stack()
                smp_send_stop()
                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                kmsg_dump()
                debug_locks_off()
                console_flush_on_panic()
                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                no_blink() <long no_blink (int state) at panic.c:46>
                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                    raw_cpu_write()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
                mdelay()
                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                    kmsg_dump()
                    machine_emergency_restart()
                disabled_wait()
                local_irq_enable()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
    wake_up()
    audit_buffer_alloc() <struct audit_buffer *audit_buffer_alloc (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1245>:
        spin_lock_irqsave()
        list_empty()
        list_entry()
        list_del()
        spin_unlock_irqrestore()
        kmalloc()
        nlmsg_new()
        nlmsg_put()
        kfree_skb()
        audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
            kfree_skb()
            spin_lock_irqsave()
            kfree()
            list_add()
            spin_unlock_irqrestore()
    audit_get_stamp() <inline void audit_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at audit.c:1312>:
        auditsc_get_stamp() <int auditsc_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at auditsc.c:1940>:
            audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                ATOMIC_INIT()
                atomic_add_return()
        audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
            ATOMIC_INIT()
            atomic_add_return()
    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            max_t()
            skb_put()
audit_log_task_context() <int audit_log_task_context (struct audit_buffer *ab) at audit.c:1825>:
    security_task_getsecid()
    security_secid_to_secctx()
    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            max_t()
            skb_put()
    security_release_secctx()
    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
        printk_ratelimit()
        pr_err()
        panic() <void panic (const char *fmt, ...) at panic.c:83>:
            local_irq_disable()
            raw_smp_processor_id()
            atomic_cmpxchg()
            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                cpu_relax()
            console_verbose()
            bust_spinlocks()
            pr_emerg()
            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                test_bit()
            dump_stack()
            smp_send_stop()
            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
            kmsg_dump()
            debug_locks_off()
            console_flush_on_panic()
            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
            no_blink() <long no_blink (int state) at panic.c:46>
            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                raw_cpu_write()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            mdelay()
            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                kmsg_dump()
                machine_emergency_restart()
            disabled_wait()
            local_irq_enable()
            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                    raw_cpu_write()
                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                    per_cpu()
                raw_smp_processor_id()
audit_log_task_info() <void audit_log_task_info (struct audit_buffer *ab, struct task_struct *tsk) at audit.c:1872>:
    current_cred()
    spin_lock_irq()
    spin_unlock_irq()
    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            max_t()
            skb_put()
    task_ppid_nr()
    task_pid_nr()
    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
            smp_rmb()
    audit_get_loginuid()
    from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
            smp_rmb()
    audit_get_sessionid()
    audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
        audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
            audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
            audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                hex_byte_pack_upper()
                skb_put()
            audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                skb_put()
    get_task_comm()
    audit_log_d_path_exe() <void audit_log_d_path_exe (struct audit_buffer *ab, struct mm_struct *mm) at audit.c:1853>:
        get_mm_exe_file() <struct file *get_mm_exe_file (struct mm_struct *mm) at fork.c:752>:
            rcu_read_lock()
            rcu_dereference()
            get_file_rcu()
            rcu_read_unlock()
        audit_log_d_path() <void audit_log_d_path (struct audit_buffer *ab, const char *prefix, const struct path *path) at audit.c:1627>:
            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    max_t()
                    skb_put()
            kmalloc()
            audit_log_string()
            d_path()
            IS_ERR()
            audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
                audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                    audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                    audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        hex_byte_pack_upper()
                        skb_put()
                    audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        skb_put()
            kfree()
        fput()
        audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
            audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                max_t()
                skb_put()
    audit_log_task_context() <int audit_log_task_context (struct audit_buffer *ab) at audit.c:1825>:
        security_task_getsecid()
        security_secid_to_secctx()
        audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
            audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                max_t()
                skb_put()
        security_release_secctx()
        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
            printk_ratelimit()
            pr_err()
            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                local_irq_disable()
                raw_smp_processor_id()
                atomic_cmpxchg()
                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                    cpu_relax()
                console_verbose()
                bust_spinlocks()
                pr_emerg()
                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                    test_bit()
                dump_stack()
                smp_send_stop()
                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                kmsg_dump()
                debug_locks_off()
                console_flush_on_panic()
                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                no_blink() <long no_blink (int state) at panic.c:46>
                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                    raw_cpu_write()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
                mdelay()
                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                    kmsg_dump()
                    machine_emergency_restart()
                disabled_wait()
                local_irq_enable()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
    audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
        audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
        audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            hex_byte_pack_upper()
            skb_put()
        audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
            BUG_ON()
            skb_tailroom()
            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                skb_tailroom()
                pskb_expand_head()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
            skb_tail_pointer()
            skb_put()
audit_make_reply() <struct sk_buff *audit_make_reply (__u32 portid, int seq, int type, int done, int multi, const void *payload, int size) at audit.c:560>:
    nlmsg_new()
    nlmsg_put()
    nlmsg_data()
    kfree_skb()
audit_make_tree() <int audit_make_tree (struct audit_krule *rule, char *pathname, u32 op) at audit_tree.c:633>:
    alloc_tree() <struct audit_tree *alloc_tree (const char *s) at audit_tree.c:74>:
        kmalloc()
        atomic_set()
        INIT_LIST_HEAD()
audit_mark_compare() <int audit_mark_compare (struct audit_fsnotify_mark *mark, unsigned long ino, dev_t dev) at audit_fsnotify.c:69>:
audit_match_class() <int audit_match_class (int class, unsigned syscall) at auditfilter.c:197>:
    unlikely()
    AUDIT_WORD()
    AUDIT_BIT()
audit_panic() <void audit_panic (const char *message) at audit.c:198>:
    printk_ratelimit()
    pr_err()
    panic() <void panic (const char *fmt, ...) at panic.c:83>:
        local_irq_disable()
        raw_smp_processor_id()
        atomic_cmpxchg()
        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
            cpu_relax()
        console_verbose()
        bust_spinlocks()
        pr_emerg()
        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
            test_bit()
        dump_stack()
        smp_send_stop()
        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
        kmsg_dump()
        debug_locks_off()
        console_flush_on_panic()
        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
        no_blink() <long no_blink (int state) at panic.c:46>
        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
            raw_cpu_write()
            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                    raw_cpu_write()
                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                    per_cpu()
                raw_smp_processor_id()
        mdelay()
        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
            kmsg_dump()
            machine_emergency_restart()
        disabled_wait()
        local_irq_enable()
        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                raw_cpu_write()
            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                per_cpu()
            raw_smp_processor_id()
audit_put_chunk() <void audit_put_chunk (struct audit_chunk *chunk) at audit_tree.c:120>:
    atomic_long_dec_and_test()
    free_chunk() <void free_chunk (struct audit_chunk *chunk) at audit_tree.c:109>:
        put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
            atomic_dec_and_test()
            kfree_rcu()
        kfree()
audit_put_tree() <void audit_put_tree (struct audit_tree *tree) at audit_tree.c:647>:
    put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
        atomic_dec_and_test()
        kfree_rcu()
audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
    atomic_dec_and_test()
    WARN_ON()
    list_empty()
    kfree()
audit_register_class() <int __init audit_register_class (int class, unsigned *list) at auditfilter.c:176>:
    kcalloc()
    kfree()
    AUDIT_WORD()
    AUDIT_BIT()
audit_remove_mark() <void audit_remove_mark (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:144>:
    fsnotify_destroy_mark()
    fsnotify_put_mark()
audit_remove_mark_rule() <void audit_remove_mark_rule (struct audit_krule *krule) at audit_fsnotify.c:150>:
    audit_remove_mark() <void audit_remove_mark (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:144>:
        fsnotify_destroy_mark()
        fsnotify_put_mark()
audit_remove_tree_rule() <int audit_remove_tree_rule (struct audit_krule *rule) at audit_tree.c:556>:
    spin_lock()
    list_del_init()
    list_empty()
    list_move()
    spin_unlock()
    audit_schedule_prune() <void audit_schedule_prune (void) at audit_tree.c:875>:
        wake_up_process()
audit_remove_watch_rule() <void audit_remove_watch_rule (struct audit_krule *krule) at audit_watch.c:451>:
    list_del()
    list_empty()
    audit_remove_watch() <void audit_remove_watch (struct audit_watch *watch) at audit_watch.c:126>:
        list_del()
        audit_put_parent() <void audit_put_parent (struct audit_parent *parent) at audit_watch.c:89>:
            likely()
            fsnotify_put_mark()
        audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
            atomic_dec_and_test()
            WARN_ON()
            list_empty()
            kfree()
    audit_get_parent() <void audit_get_parent (struct audit_parent *parent) at audit_watch.c:83>:
        likely()
        fsnotify_get_mark()
    fsnotify_destroy_mark()
    audit_put_parent() <void audit_put_parent (struct audit_parent *parent) at audit_watch.c:89>:
        likely()
        fsnotify_put_mark()
audit_rule_change() <int audit_rule_change (int type, __u32 portid, int seq, void *data, size_t datasz) at auditfilter.c:1092>:
    audit_data_to_entry() <struct audit_entry *audit_data_to_entry (struct audit_rule_data *data, size_t datasz) at auditfilter.c:419>:
        audit_to_entry_common() <inline struct audit_entry *audit_to_entry_common (struct audit_rule_data *rule) at auditfilter.c:246>:
            unlikely()
            pr_err()
            audit_init_entry() <inline struct audit_entry *audit_init_entry (u32 field_count) at auditfilter.c:115>:
                kzalloc()
                unlikely()
                kcalloc()
                kfree()
            AUDIT_WORD()
            AUDIT_BIT()
            ERR_PTR()
        IS_ERR()
        audit_to_op() <u32 audit_to_op (u32 op) at auditfilter.c:324>:
        audit_field_valid() <int audit_field_valid (struct audit_entry *entry, struct audit_field *f) at auditfilter.c:333>:
        make_kuid() <kuid_t make_kuid (struct user_namespace *ns, uid_t uid) at user_namespace.c:239>:
            KUIDT_INIT()
            map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
                smp_rmb()
        current_user_ns()
        uid_valid()
        make_kgid() <kgid_t make_kgid (struct user_namespace *ns, gid_t gid) at user_namespace.c:307>:
            KGIDT_INIT()
            map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
                smp_rmb()
        gid_valid()
        audit_unpack_string() <char *audit_unpack_string (void **bufp, size_t *remain, size_t len) at auditfilter.c:136>:
            ERR_PTR()
            kmalloc()
            unlikely()
        security_audit_rule_init()
        pr_warn()
        kfree()
        audit_to_watch() <int audit_to_watch (struct audit_krule *krule, char *path, int len, u32 op) at audit_watch.c:189>:
            audit_init_watch() <struct audit_watch *audit_init_watch (char *path) at audit_watch.c:171>:
                kzalloc()
                unlikely()
                ERR_PTR()
                INIT_LIST_HEAD()
                atomic_set()
            IS_ERR()
            PTR_ERR()
        audit_make_tree() <int audit_make_tree (struct audit_krule *rule, char *pathname, u32 op) at audit_tree.c:633>:
            alloc_tree() <struct audit_tree *alloc_tree (const char *s) at audit_tree.c:74>:
                kmalloc()
                atomic_set()
                INIT_LIST_HEAD()
        audit_to_inode() <inline int audit_to_inode (struct audit_krule *krule, struct audit_field *f) at auditfilter.c:162>:
        PTR_ERR()
        audit_alloc_mark() <struct audit_fsnotify_mark *audit_alloc_mark (struct audit_krule *krule, char *pathname, int len) at audit_fsnotify.c:83>:
            ERR_PTR()
            kern_path_locked()
            IS_ERR()
            d_inode()
            inode_unlock()
            kzalloc()
            unlikely()
            fsnotify_init_mark()
            audit_fsnotify_free_mark() <void audit_fsnotify_free_mark (struct fsnotify_mark *mark) at audit_fsnotify.c:56>:
                container_of()
                audit_fsnotify_mark_free() <void audit_fsnotify_mark_free (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:50>:
                    kfree()
            audit_update_mark() <void audit_update_mark (struct audit_fsnotify_mark *audit_mark, struct inode *inode) at audit_fsnotify.c:76>:
            fsnotify_add_mark()
            audit_fsnotify_mark_free() <void audit_fsnotify_mark_free (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:50>:
                kfree()
            dput()
            path_put()
        audit_put_tree() <void audit_put_tree (struct audit_tree *tree) at audit_tree.c:647>:
            put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                atomic_dec_and_test()
                kfree_rcu()
        audit_remove_mark() <void audit_remove_mark (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:144>:
            fsnotify_destroy_mark()
            fsnotify_put_mark()
        audit_free_rule() <inline void audit_free_rule (struct audit_entry *e) at auditfilter.c:92>:
            audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
                atomic_dec_and_test()
                WARN_ON()
                list_empty()
                kfree()
            audit_free_lsm_field() <void audit_free_lsm_field (struct audit_field *f) at auditfilter.c:74>:
                kfree()
                security_audit_rule_free()
            kfree()
        ERR_PTR()
    IS_ERR()
    PTR_ERR()
    audit_add_rule() <inline int audit_add_rule (struct audit_entry *entry) at auditfilter.c:901>:
        mutex_lock()
        audit_find_rule() <struct audit_entry *audit_find_rule (struct audit_entry *entry, struct list_head **p) at auditfilter.c:862>:
            audit_hash_ino()
            list_for_each_entry()
            audit_compare_rule() <int audit_compare_rule (struct audit_krule *a, struct audit_krule *b) at auditfilter.c:667>:
                audit_watch_path() <char *audit_watch_path (struct audit_watch *watch) at audit_watch.c:134>
                audit_tree_path() <const char *audit_tree_path (struct audit_tree *tree) at audit_tree.c:104>
                audit_mark_path() <char *audit_mark_path (struct audit_fsnotify_mark *mark) at audit_fsnotify.c:64>
                uid_eq()
                gid_eq()
        mutex_unlock()
        audit_put_tree() <void audit_put_tree (struct audit_tree *tree) at audit_tree.c:647>:
            put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                atomic_dec_and_test()
                kfree_rcu()
        audit_add_watch() <int audit_add_watch (struct audit_krule *krule, struct list_head **list) at audit_watch.c:414>:
            mutex_unlock()
            audit_get_nd() <int audit_get_nd (struct audit_watch *watch, struct path *parent) at audit_watch.c:362>:
                kern_path_locked()
                IS_ERR()
                PTR_ERR()
                inode_unlock()
                d_backing_inode()
                d_is_positive()
                dput()
            mutex_lock()
            audit_find_parent() <inline struct audit_parent *audit_find_parent (struct inode *inode) at audit_watch.c:99>:
                fsnotify_find_inode_mark()
                container_of()
            d_backing_inode()
            audit_init_parent() <struct audit_parent *audit_init_parent (struct path *path) at audit_watch.c:147>:
                d_backing_inode()
                kzalloc()
                unlikely()
                ERR_PTR()
                INIT_LIST_HEAD()
                fsnotify_init_mark()
                audit_watch_free_mark() <void audit_watch_free_mark (struct fsnotify_mark *entry) at audit_watch.c:75>:
                    container_of()
                    audit_free_parent() <void audit_free_parent (struct audit_parent *parent) at audit_watch.c:69>:
                        WARN_ON()
                        list_empty()
                        kfree()
                fsnotify_add_mark()
                audit_free_parent() <void audit_free_parent (struct audit_parent *parent) at audit_watch.c:69>:
                    WARN_ON()
                    list_empty()
                    kfree()
            IS_ERR()
            PTR_ERR()
            audit_add_to_parent() <void audit_add_to_parent (struct audit_krule *krule, struct audit_parent *parent) at audit_watch.c:379>:
                BUG_ON()
                mutex_is_locked()
                list_for_each_entry()
                audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
                    atomic_dec_and_test()
                    WARN_ON()
                    list_empty()
                    kfree()
                audit_get_watch() <void audit_get_watch (struct audit_watch *watch) at audit_watch.c:111>:
                    atomic_inc()
                audit_put_parent() <void audit_put_parent (struct audit_parent *parent) at audit_watch.c:89>:
                    likely()
                    fsnotify_put_mark()
                list_add()
            audit_hash_ino()
            path_put()
        audit_add_tree_rule() <int audit_add_tree_rule (struct audit_krule *rule) at audit_tree.c:709>:
            list_for_each_entry()
            put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                atomic_dec_and_test()
                kfree_rcu()
            list_add()
            mutex_unlock()
            unlikely()
            audit_launch_prune() <int audit_launch_prune (void) at audit_tree.c:692>:
                kthread_create()
                prune_tree_thread() <int prune_tree_thread (void *unused) at audit_tree.c:661>:
                    set_current_state()
                    list_empty()
                    schedule()
                    mutex_lock()
                    list_entry()
                    list_del_init()
                    mutex_unlock()
                    prune_one() <void prune_one (struct audit_tree *victim) at audit_tree.c:495>:
                        spin_lock()
                        list_empty()
                        list_entry()
                        untag_chunk() <void untag_chunk (struct node *p) at audit_tree.c:218>:
                            find_chunk() <struct audit_chunk *find_chunk (struct node *p) at audit_tree.c:211>:
                                container_of()
                            fsnotify_get_mark()
                            spin_unlock()
                            alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                                kzalloc()
                                INIT_LIST_HEAD()
                                atomic_long_set()
                                fsnotify_init_mark()
                                audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                                    container_of()
                                    call_rcu()
                            spin_lock()
                            free_chunk() <void free_chunk (struct audit_chunk *chunk) at audit_tree.c:109>:
                                put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                                    atomic_dec_and_test()
                                    kfree_rcu()
                                kfree()
                            list_del_init()
                            list_del_rcu()
                            fsnotify_destroy_mark()
                            fsnotify_duplicate_mark()
                            fsnotify_add_mark()
                            fsnotify_put_mark()
                            list_replace_init()
                            get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                                atomic_inc()
                            list_replace_rcu()
                            list_for_each_entry()
                            put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                                atomic_dec_and_test()
                                kfree_rcu()
                        spin_unlock()
                        put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                            atomic_dec_and_test()
                            kfree_rcu()
                IS_ERR()
                pr_err()
                wake_up_process()
            collect_mounts()
            path_put()
            IS_ERR()
            PTR_ERR()
            get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                atomic_inc()
            iterate_mounts()
            tag_mount() <int tag_mount (struct vfsmount *mnt, void *arg) at audit_tree.c:652>:
                tag_chunk() <int tag_chunk (struct inode *inode, struct audit_tree *tree) at audit_tree.c:356>:
                    fsnotify_find_inode_mark()
                    create_chunk() <int create_chunk (struct inode *inode, struct audit_tree *tree) at audit_tree.c:317>:
                        alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                            kzalloc()
                            INIT_LIST_HEAD()
                            atomic_long_set()
                            fsnotify_init_mark()
                            audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                                container_of()
                                call_rcu()
                        fsnotify_add_mark()
                        fsnotify_put_mark()
                        spin_lock()
                        spin_unlock()
                        fsnotify_destroy_mark()
                        get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                            atomic_inc()
                        list_add()
                        insert_hash() <void insert_hash (struct audit_chunk *chunk) at audit_tree.c:173>:
                            chunk_hash() <inline struct list_head *chunk_hash (const struct inode *inode) at audit_tree.c:166>:
                            list_add_rcu()
                    container_of()
                    spin_lock()
                    spin_unlock()
                    fsnotify_put_mark()
                    alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                        kzalloc()
                        INIT_LIST_HEAD()
                        atomic_long_set()
                        fsnotify_init_mark()
                        audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                            container_of()
                            call_rcu()
                    free_chunk() <void free_chunk (struct audit_chunk *chunk) at audit_tree.c:109>:
                        put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                            atomic_dec_and_test()
                            kfree_rcu()
                        kfree()
                    fsnotify_duplicate_mark()
                    fsnotify_add_mark()
                    fsnotify_destroy_mark()
                    list_replace_init()
                    get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                        atomic_inc()
                    list_add()
                    list_replace_rcu()
                    list_for_each_entry()
                d_backing_inode()
            drop_collected_mounts()
            spin_lock()
            spin_unlock()
            trim_marked() <void trim_marked (struct audit_tree *tree) at audit_tree.c:511>:
                spin_lock()
                spin_unlock()
                list_entry()
                list_del_init()
                list_add()
                list_empty()
                untag_chunk() <void untag_chunk (struct node *p) at audit_tree.c:218>:
                    find_chunk() <struct audit_chunk *find_chunk (struct node *p) at audit_tree.c:211>:
                        container_of()
                    fsnotify_get_mark()
                    spin_unlock()
                    alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                        kzalloc()
                        INIT_LIST_HEAD()
                        atomic_long_set()
                        fsnotify_init_mark()
                        audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                            container_of()
                            call_rcu()
                    spin_lock()
                    free_chunk() <void free_chunk (struct audit_chunk *chunk) at audit_tree.c:109>:
                        put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                            atomic_dec_and_test()
                            kfree_rcu()
                        kfree()
                    list_del_init()
                    list_del_rcu()
                    fsnotify_destroy_mark()
                    fsnotify_duplicate_mark()
                    fsnotify_add_mark()
                    fsnotify_put_mark()
                    list_replace_init()
                    get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                        atomic_inc()
                    list_replace_rcu()
                    list_for_each_entry()
                    put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                        atomic_dec_and_test()
                        kfree_rcu()
                mutex_lock()
                kill_rules() <void kill_rules (struct audit_tree *tree) at audit_tree.c:470>:
                    list_for_each_entry_safe()
                    container_of()
                    list_del_init()
                    audit_tree_log_remove_rule() <void audit_tree_log_remove_rule (struct audit_krule *rule) at audit_tree.c:454>:
                        audit_log_start() <struct audit_buffer *audit_log_start (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1355>:
                            uninitialized_var()
                            unlikely()
                            audit_filter_type() <int audit_filter_type (int type) at auditfilter.c:1374>:
                                rcu_read_lock()
                                list_empty()
                                list_for_each_entry_rcu()
                                audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                                    BUG()
                                rcu_read_unlock()
                            skb_queue_len()
                            wait_for_auditd() <long wait_for_auditd (long sleep_time) at audit.c:1324>:
                                DECLARE_WAITQUEUE()
                                set_current_state()
                                add_wait_queue_exclusive()
                                skb_queue_len()
                                schedule_timeout()
                                remove_wait_queue()
                            audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                            wake_up()
                            audit_buffer_alloc() <struct audit_buffer *audit_buffer_alloc (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1245>:
                                spin_lock_irqsave()
                                list_empty()
                                list_entry()
                                list_del()
                                spin_unlock_irqrestore()
                                kmalloc()
                                nlmsg_new()
                                nlmsg_put()
                                kfree_skb()
                                audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                                    kfree_skb()
                                    spin_lock_irqsave()
                                    kfree()
                                    list_add()
                                    spin_unlock_irqrestore()
                            audit_get_stamp() <inline void audit_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at audit.c:1312>:
                                auditsc_get_stamp() <int auditsc_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at auditsc.c:1940>:
                                    audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                                        ATOMIC_INIT()
                                        atomic_add_return()
                                audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                                    ATOMIC_INIT()
                                    atomic_add_return()
                            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                                    BUG_ON()
                                    skb_tailroom()
                                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                        skb_tailroom()
                                        pskb_expand_head()
                                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                            atomic_inc()
                                            spin_lock_irqsave()
                                            spin_unlock_irqrestore()
                                            printk_ratelimit()
                                            pr_warn()
                                            atomic_read()
                                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                                printk_ratelimit()
                                                pr_err()
                                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                                    local_irq_disable()
                                                    raw_smp_processor_id()
                                                    atomic_cmpxchg()
                                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                        cpu_relax()
                                                    console_verbose()
                                                    bust_spinlocks()
                                                    pr_emerg()
                                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                        test_bit()
                                                    dump_stack()
                                                    smp_send_stop()
                                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                                    kmsg_dump()
                                                    debug_locks_off()
                                                    console_flush_on_panic()
                                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                                    no_blink() <long no_blink (int state) at panic.c:46>
                                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                        raw_cpu_write()
                                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                                raw_cpu_write()
                                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                                per_cpu()
                                                            raw_smp_processor_id()
                                                    mdelay()
                                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                        kmsg_dump()
                                                        machine_emergency_restart()
                                                    disabled_wait()
                                                    local_irq_enable()
                                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                            raw_cpu_write()
                                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                            per_cpu()
                                                        raw_smp_processor_id()
                                    skb_tail_pointer()
                                    max_t()
                                    skb_put()
                        unlikely()
                        audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                            audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                                BUG_ON()
                                skb_tailroom()
                                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                    skb_tailroom()
                                    pskb_expand_head()
                                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                        atomic_inc()
                                        spin_lock_irqsave()
                                        spin_unlock_irqrestore()
                                        printk_ratelimit()
                                        pr_warn()
                                        atomic_read()
                                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                            printk_ratelimit()
                                            pr_err()
                                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                                local_irq_disable()
                                                raw_smp_processor_id()
                                                atomic_cmpxchg()
                                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                    cpu_relax()
                                                console_verbose()
                                                bust_spinlocks()
                                                pr_emerg()
                                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                    test_bit()
                                                dump_stack()
                                                smp_send_stop()
                                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                                kmsg_dump()
                                                debug_locks_off()
                                                console_flush_on_panic()
                                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                                no_blink() <long no_blink (int state) at panic.c:46>
                                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                    raw_cpu_write()
                                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                            raw_cpu_write()
                                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                            per_cpu()
                                                        raw_smp_processor_id()
                                                mdelay()
                                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                    kmsg_dump()
                                                    machine_emergency_restart()
                                                disabled_wait()
                                                local_irq_enable()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                skb_tail_pointer()
                                max_t()
                                skb_put()
                        audit_log_string()
                        audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
                            audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                                audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                                audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                                    BUG_ON()
                                    skb_tailroom()
                                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                        skb_tailroom()
                                        pskb_expand_head()
                                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                            atomic_inc()
                                            spin_lock_irqsave()
                                            spin_unlock_irqrestore()
                                            printk_ratelimit()
                                            pr_warn()
                                            atomic_read()
                                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                                printk_ratelimit()
                                                pr_err()
                                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                                    local_irq_disable()
                                                    raw_smp_processor_id()
                                                    atomic_cmpxchg()
                                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                        cpu_relax()
                                                    console_verbose()
                                                    bust_spinlocks()
                                                    pr_emerg()
                                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                        test_bit()
                                                    dump_stack()
                                                    smp_send_stop()
                                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                                    kmsg_dump()
                                                    debug_locks_off()
                                                    console_flush_on_panic()
                                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                                    no_blink() <long no_blink (int state) at panic.c:46>
                                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                        raw_cpu_write()
                                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                                raw_cpu_write()
                                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                                per_cpu()
                                                            raw_smp_processor_id()
                                                    mdelay()
                                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                        kmsg_dump()
                                                        machine_emergency_restart()
                                                    disabled_wait()
                                                    local_irq_enable()
                                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                            raw_cpu_write()
                                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                            per_cpu()
                                                        raw_smp_processor_id()
                                    skb_tail_pointer()
                                    hex_byte_pack_upper()
                                    skb_put()
                                audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                                    BUG_ON()
                                    skb_tailroom()
                                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                        skb_tailroom()
                                        pskb_expand_head()
                                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                            atomic_inc()
                                            spin_lock_irqsave()
                                            spin_unlock_irqrestore()
                                            printk_ratelimit()
                                            pr_warn()
                                            atomic_read()
                                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                                printk_ratelimit()
                                                pr_err()
                                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                                    local_irq_disable()
                                                    raw_smp_processor_id()
                                                    atomic_cmpxchg()
                                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                        cpu_relax()
                                                    console_verbose()
                                                    bust_spinlocks()
                                                    pr_emerg()
                                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                        test_bit()
                                                    dump_stack()
                                                    smp_send_stop()
                                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                                    kmsg_dump()
                                                    debug_locks_off()
                                                    console_flush_on_panic()
                                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                                    no_blink() <long no_blink (int state) at panic.c:46>
                                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                        raw_cpu_write()
                                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                                raw_cpu_write()
                                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                                per_cpu()
                                                            raw_smp_processor_id()
                                                    mdelay()
                                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                        kmsg_dump()
                                                        machine_emergency_restart()
                                                    disabled_wait()
                                                    local_irq_enable()
                                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                            raw_cpu_write()
                                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                            per_cpu()
                                                        raw_smp_processor_id()
                                    skb_tail_pointer()
                                    skb_put()
                        audit_log_key() <void audit_log_key (struct audit_buffer *ab, char *key) at audit.c:1658>:
                            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                                    BUG_ON()
                                    skb_tailroom()
                                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                        skb_tailroom()
                                        pskb_expand_head()
                                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                            atomic_inc()
                                            spin_lock_irqsave()
                                            spin_unlock_irqrestore()
                                            printk_ratelimit()
                                            pr_warn()
                                            atomic_read()
                                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                                printk_ratelimit()
                                                pr_err()
                                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                                    local_irq_disable()
                                                    raw_smp_processor_id()
                                                    atomic_cmpxchg()
                                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                        cpu_relax()
                                                    console_verbose()
                                                    bust_spinlocks()
                                                    pr_emerg()
                                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                        test_bit()
                                                    dump_stack()
                                                    smp_send_stop()
                                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                                    kmsg_dump()
                                                    debug_locks_off()
                                                    console_flush_on_panic()
                                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                                    no_blink() <long no_blink (int state) at panic.c:46>
                                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                        raw_cpu_write()
                                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                                raw_cpu_write()
                                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                                per_cpu()
                                                            raw_smp_processor_id()
                                                    mdelay()
                                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                        kmsg_dump()
                                                        machine_emergency_restart()
                                                    disabled_wait()
                                                    local_irq_enable()
                                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                            raw_cpu_write()
                                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                            per_cpu()
                                                        raw_smp_processor_id()
                                    skb_tail_pointer()
                                    max_t()
                                    skb_put()
                            audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
                                audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                                    audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                                    audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                                        BUG_ON()
                                        skb_tailroom()
                                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                            skb_tailroom()
                                            pskb_expand_head()
                                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                                atomic_inc()
                                                spin_lock_irqsave()
                                                spin_unlock_irqrestore()
                                                printk_ratelimit()
                                                pr_warn()
                                                atomic_read()
                                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                                    printk_ratelimit()
                                                    pr_err()
                                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                                        local_irq_disable()
                                                        raw_smp_processor_id()
                                                        atomic_cmpxchg()
                                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                            cpu_relax()
                                                        console_verbose()
                                                        bust_spinlocks()
                                                        pr_emerg()
                                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                            test_bit()
                                                        dump_stack()
                                                        smp_send_stop()
                                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                                        kmsg_dump()
                                                        debug_locks_off()
                                                        console_flush_on_panic()
                                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                                        no_blink() <long no_blink (int state) at panic.c:46>
                                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                            raw_cpu_write()
                                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                                    raw_cpu_write()
                                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                                    per_cpu()
                                                                raw_smp_processor_id()
                                                        mdelay()
                                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                            kmsg_dump()
                                                            machine_emergency_restart()
                                                        disabled_wait()
                                                        local_irq_enable()
                                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                                raw_cpu_write()
                                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                                per_cpu()
                                                            raw_smp_processor_id()
                                        skb_tail_pointer()
                                        hex_byte_pack_upper()
                                        skb_put()
                                    audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                                        BUG_ON()
                                        skb_tailroom()
                                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                            skb_tailroom()
                                            pskb_expand_head()
                                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                                atomic_inc()
                                                spin_lock_irqsave()
                                                spin_unlock_irqrestore()
                                                printk_ratelimit()
                                                pr_warn()
                                                atomic_read()
                                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                                    printk_ratelimit()
                                                    pr_err()
                                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                                        local_irq_disable()
                                                        raw_smp_processor_id()
                                                        atomic_cmpxchg()
                                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                            cpu_relax()
                                                        console_verbose()
                                                        bust_spinlocks()
                                                        pr_emerg()
                                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                            test_bit()
                                                        dump_stack()
                                                        smp_send_stop()
                                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                                        kmsg_dump()
                                                        debug_locks_off()
                                                        console_flush_on_panic()
                                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                                        no_blink() <long no_blink (int state) at panic.c:46>
                                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                            raw_cpu_write()
                                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                                    raw_cpu_write()
                                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                                    per_cpu()
                                                                raw_smp_processor_id()
                                                        mdelay()
                                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                            kmsg_dump()
                                                            machine_emergency_restart()
                                                        disabled_wait()
                                                        local_irq_enable()
                                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                                raw_cpu_write()
                                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                                per_cpu()
                                                            raw_smp_processor_id()
                                        skb_tail_pointer()
                                        skb_put()
                        audit_log_end() <void audit_log_end (struct audit_buffer *ab) at audit.c:1957>:
                            audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                            nlmsg_hdr()
                            kauditd_send_multicast_skb() <void kauditd_send_multicast_skb (struct sk_buff *skb, gfp_t gfp_mask) at audit.c:450>:
                                net_generic()
                                netlink_has_listeners()
                                skb_copy()
                                nlmsg_multicast()
                            skb_queue_tail()
                            wake_up_interruptible()
                            audit_printk_skb() <void audit_printk_skb (struct sk_buff *skb) at audit.c:391>:
                                nlmsg_hdr()
                                nlmsg_data()
                                printk_ratelimit()
                                pr_notice()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                audit_hold_skb() <void audit_hold_skb (struct sk_buff *skb) at audit.c:377>:
                                    skb_queue_len()
                                    skb_queue_tail()
                                    kfree_skb()
                            audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                                kfree_skb()
                                spin_lock_irqsave()
                                kfree()
                                list_add()
                                spin_unlock_irqrestore()
                    audit_remove_mark() <void audit_remove_mark (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:144>:
                        fsnotify_destroy_mark()
                        fsnotify_put_mark()
                    list_del_rcu()
                    list_del()
                    call_rcu()
                    audit_free_rule_rcu() <void audit_free_rule_rcu (struct rcu_head *head) at auditfilter.c:108>:
                        container_of()
                        audit_free_rule() <inline void audit_free_rule (struct audit_entry *e) at auditfilter.c:92>:
                            audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
                                atomic_dec_and_test()
                                WARN_ON()
                                list_empty()
                                kfree()
                            audit_free_lsm_field() <void audit_free_lsm_field (struct audit_field *f) at auditfilter.c:74>:
                                kfree()
                                security_audit_rule_free()
                            kfree()
                mutex_unlock()
                prune_one() <void prune_one (struct audit_tree *victim) at audit_tree.c:495>:
                    spin_lock()
                    list_empty()
                    list_entry()
                    untag_chunk() <void untag_chunk (struct node *p) at audit_tree.c:218>:
                        find_chunk() <struct audit_chunk *find_chunk (struct node *p) at audit_tree.c:211>:
                            container_of()
                        fsnotify_get_mark()
                        spin_unlock()
                        alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                            kzalloc()
                            INIT_LIST_HEAD()
                            atomic_long_set()
                            fsnotify_init_mark()
                            audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                                container_of()
                                call_rcu()
                        spin_lock()
                        free_chunk() <void free_chunk (struct audit_chunk *chunk) at audit_tree.c:109>:
                            put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                                atomic_dec_and_test()
                                kfree_rcu()
                            kfree()
                        list_del_init()
                        list_del_rcu()
                        fsnotify_destroy_mark()
                        fsnotify_duplicate_mark()
                        fsnotify_add_mark()
                        fsnotify_put_mark()
                        list_replace_init()
                        get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                            atomic_inc()
                        list_replace_rcu()
                        list_for_each_entry()
                        put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                            atomic_dec_and_test()
                            kfree_rcu()
                    spin_unlock()
                    put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                        atomic_dec_and_test()
                        kfree_rcu()
            mutex_lock()
            list_empty()
            list_del_init()
        list_add()
        list_add_rcu()
        list_add_tail()
        list_add_tail_rcu()
        audit_match_signal() <int audit_match_signal (struct audit_entry *entry) at auditfilter.c:219>:
            audit_match_class_bits() <inline int audit_match_class_bits (int class, u32 *mask) at auditfilter.c:207>:
            audit_classify_arch()
    audit_log_rule_change() <void audit_log_rule_change (char *action, struct audit_krule *rule, int res) at auditfilter.c:1063>:
        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
        audit_get_loginuid()
        audit_get_sessionid()
        audit_log_start() <struct audit_buffer *audit_log_start (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1355>:
            uninitialized_var()
            unlikely()
            audit_filter_type() <int audit_filter_type (int type) at auditfilter.c:1374>:
                rcu_read_lock()
                list_empty()
                list_for_each_entry_rcu()
                audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                    BUG()
                rcu_read_unlock()
            skb_queue_len()
            wait_for_auditd() <long wait_for_auditd (long sleep_time) at audit.c:1324>:
                DECLARE_WAITQUEUE()
                set_current_state()
                add_wait_queue_exclusive()
                skb_queue_len()
                schedule_timeout()
                remove_wait_queue()
            audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                spin_lock_irqsave()
                spin_unlock_irqrestore()
            printk_ratelimit()
            pr_warn()
            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                atomic_inc()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                atomic_read()
                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                    printk_ratelimit()
                    pr_err()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
            wake_up()
            audit_buffer_alloc() <struct audit_buffer *audit_buffer_alloc (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1245>:
                spin_lock_irqsave()
                list_empty()
                list_entry()
                list_del()
                spin_unlock_irqrestore()
                kmalloc()
                nlmsg_new()
                nlmsg_put()
                kfree_skb()
                audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                    kfree_skb()
                    spin_lock_irqsave()
                    kfree()
                    list_add()
                    spin_unlock_irqrestore()
            audit_get_stamp() <inline void audit_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at audit.c:1312>:
                auditsc_get_stamp() <int auditsc_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at auditsc.c:1940>:
                    audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                        ATOMIC_INIT()
                        atomic_add_return()
                audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                    ATOMIC_INIT()
                    atomic_add_return()
            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    max_t()
                    skb_put()
        audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
            audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                max_t()
                skb_put()
        audit_log_task_context() <int audit_log_task_context (struct audit_buffer *ab) at audit.c:1825>:
            security_task_getsecid()
            security_secid_to_secctx()
            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    max_t()
                    skb_put()
            security_release_secctx()
            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                printk_ratelimit()
                pr_err()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
        audit_log_string()
        audit_log_key() <void audit_log_key (struct audit_buffer *ab, char *key) at audit.c:1658>:
            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    max_t()
                    skb_put()
            audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
                audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                    audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                    audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        hex_byte_pack_upper()
                        skb_put()
                    audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        skb_put()
        audit_log_end() <void audit_log_end (struct audit_buffer *ab) at audit.c:1957>:
            audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                spin_lock_irqsave()
                spin_unlock_irqrestore()
            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                atomic_inc()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                atomic_read()
                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                    printk_ratelimit()
                    pr_err()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
            nlmsg_hdr()
            kauditd_send_multicast_skb() <void kauditd_send_multicast_skb (struct sk_buff *skb, gfp_t gfp_mask) at audit.c:450>:
                net_generic()
                netlink_has_listeners()
                skb_copy()
                nlmsg_multicast()
            skb_queue_tail()
            wake_up_interruptible()
            audit_printk_skb() <void audit_printk_skb (struct sk_buff *skb) at audit.c:391>:
                nlmsg_hdr()
                nlmsg_data()
                printk_ratelimit()
                pr_notice()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                audit_hold_skb() <void audit_hold_skb (struct sk_buff *skb) at audit.c:377>:
                    skb_queue_len()
                    skb_queue_tail()
                    kfree_skb()
            audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                kfree_skb()
                spin_lock_irqsave()
                kfree()
                list_add()
                spin_unlock_irqrestore()
    audit_del_rule() <int audit_del_rule (struct audit_entry *entry) at auditfilter.c:981>:
        mutex_lock()
        audit_find_rule() <struct audit_entry *audit_find_rule (struct audit_entry *entry, struct list_head **p) at auditfilter.c:862>:
            audit_hash_ino()
            list_for_each_entry()
            audit_compare_rule() <int audit_compare_rule (struct audit_krule *a, struct audit_krule *b) at auditfilter.c:667>:
                audit_watch_path() <char *audit_watch_path (struct audit_watch *watch) at audit_watch.c:134>
                audit_tree_path() <const char *audit_tree_path (struct audit_tree *tree) at audit_tree.c:104>
                audit_mark_path() <char *audit_mark_path (struct audit_fsnotify_mark *mark) at audit_fsnotify.c:64>
                uid_eq()
                gid_eq()
        audit_remove_watch_rule() <void audit_remove_watch_rule (struct audit_krule *krule) at audit_watch.c:451>:
            list_del()
            list_empty()
            audit_remove_watch() <void audit_remove_watch (struct audit_watch *watch) at audit_watch.c:126>:
                list_del()
                audit_put_parent() <void audit_put_parent (struct audit_parent *parent) at audit_watch.c:89>:
                    likely()
                    fsnotify_put_mark()
                audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
                    atomic_dec_and_test()
                    WARN_ON()
                    list_empty()
                    kfree()
            audit_get_parent() <void audit_get_parent (struct audit_parent *parent) at audit_watch.c:83>:
                likely()
                fsnotify_get_mark()
            fsnotify_destroy_mark()
            audit_put_parent() <void audit_put_parent (struct audit_parent *parent) at audit_watch.c:89>:
                likely()
                fsnotify_put_mark()
        audit_remove_tree_rule() <int audit_remove_tree_rule (struct audit_krule *rule) at audit_tree.c:556>:
            spin_lock()
            list_del_init()
            list_empty()
            list_move()
            spin_unlock()
            audit_schedule_prune() <void audit_schedule_prune (void) at audit_tree.c:875>:
                wake_up_process()
        audit_remove_mark_rule() <void audit_remove_mark_rule (struct audit_krule *krule) at audit_fsnotify.c:150>:
            audit_remove_mark() <void audit_remove_mark (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:144>:
                fsnotify_destroy_mark()
                fsnotify_put_mark()
        audit_match_signal() <int audit_match_signal (struct audit_entry *entry) at auditfilter.c:219>:
            audit_match_class_bits() <inline int audit_match_class_bits (int class, u32 *mask) at auditfilter.c:207>:
            audit_classify_arch()
        list_del_rcu()
        list_del()
        call_rcu()
        audit_free_rule_rcu() <void audit_free_rule_rcu (struct rcu_head *head) at auditfilter.c:108>:
            container_of()
            audit_free_rule() <inline void audit_free_rule (struct audit_entry *e) at auditfilter.c:92>:
                audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
                    atomic_dec_and_test()
                    WARN_ON()
                    list_empty()
                    kfree()
                audit_free_lsm_field() <void audit_free_lsm_field (struct audit_field *f) at auditfilter.c:74>:
                    kfree()
                    security_audit_rule_free()
                kfree()
        mutex_unlock()
        audit_put_tree() <void audit_put_tree (struct audit_tree *tree) at audit_tree.c:647>:
            put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                atomic_dec_and_test()
                kfree_rcu()
    WARN_ON()
    audit_remove_mark() <void audit_remove_mark (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:144>:
        fsnotify_destroy_mark()
        fsnotify_put_mark()
    audit_free_rule() <inline void audit_free_rule (struct audit_entry *e) at auditfilter.c:92>:
        audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
            atomic_dec_and_test()
            WARN_ON()
            list_empty()
            kfree()
        audit_free_lsm_field() <void audit_free_lsm_field (struct audit_field *f) at auditfilter.c:74>:
            kfree()
            security_audit_rule_free()
        kfree()
audit_send_list() <int audit_send_list (void *_dest) at audit.c:540>:
    net_generic()
    mutex_lock()
    mutex_unlock()
    netlink_unicast()
    put_net()
    kfree()
audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
    ATOMIC_INIT()
    atomic_add_return()
audit_set_loginuid() <int audit_set_loginuid (kuid_t loginuid) at auditsc.c:2009>:
    audit_get_loginuid()
    audit_get_sessionid()
    audit_set_loginuid_perm() <int audit_set_loginuid_perm (kuid_t loginuid) at auditsc.c:1960>:
        audit_loginuid_set()
        is_audit_feature_set() <int is_audit_feature_set (int i) at audit.c:721>:
            AUDIT_FEATURE_TO_MASK()
        capable() <bool capable (int cap) at capability.c:401>:
            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                unlikely()
                cap_valid()
                pr_crit()
                BUG()
                security_capable()
                current_cred()
        uid_valid()
    uid_valid()
    atomic_inc_return()
    audit_log_set_loginuid() <void audit_log_set_loginuid (kuid_t koldloginuid, kuid_t kloginuid, unsigned int oldsessionid, unsigned int sessionid, int rc) at auditsc.c:1977>:
        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
        task_uid()
        audit_log_start() <struct audit_buffer *audit_log_start (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1355>:
            uninitialized_var()
            unlikely()
            audit_filter_type() <int audit_filter_type (int type) at auditfilter.c:1374>:
                rcu_read_lock()
                list_empty()
                list_for_each_entry_rcu()
                audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                    BUG()
                rcu_read_unlock()
            skb_queue_len()
            wait_for_auditd() <long wait_for_auditd (long sleep_time) at audit.c:1324>:
                DECLARE_WAITQUEUE()
                set_current_state()
                add_wait_queue_exclusive()
                skb_queue_len()
                schedule_timeout()
                remove_wait_queue()
            audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                spin_lock_irqsave()
                spin_unlock_irqrestore()
            printk_ratelimit()
            pr_warn()
            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                atomic_inc()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                atomic_read()
                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                    printk_ratelimit()
                    pr_err()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
            wake_up()
            audit_buffer_alloc() <struct audit_buffer *audit_buffer_alloc (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1245>:
                spin_lock_irqsave()
                list_empty()
                list_entry()
                list_del()
                spin_unlock_irqrestore()
                kmalloc()
                nlmsg_new()
                nlmsg_put()
                kfree_skb()
                audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                    kfree_skb()
                    spin_lock_irqsave()
                    kfree()
                    list_add()
                    spin_unlock_irqrestore()
            audit_get_stamp() <inline void audit_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at audit.c:1312>:
                auditsc_get_stamp() <int auditsc_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at auditsc.c:1940>:
                    audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                        ATOMIC_INIT()
                        atomic_add_return()
                audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                    ATOMIC_INIT()
                    atomic_add_return()
            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    max_t()
                    skb_put()
        audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
            audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                BUG_ON()
                skb_tailroom()
                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                    skb_tailroom()
                    pskb_expand_head()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                skb_tail_pointer()
                max_t()
                skb_put()
        task_pid_nr()
        audit_log_task_context() <int audit_log_task_context (struct audit_buffer *ab) at audit.c:1825>:
            security_task_getsecid()
            security_secid_to_secctx()
            audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                    BUG_ON()
                    skb_tailroom()
                    audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                        skb_tailroom()
                        pskb_expand_head()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                    skb_tail_pointer()
                    max_t()
                    skb_put()
            security_release_secctx()
            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                printk_ratelimit()
                pr_err()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
        audit_log_end() <void audit_log_end (struct audit_buffer *ab) at audit.c:1957>:
            audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                spin_lock_irqsave()
                spin_unlock_irqrestore()
            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                atomic_inc()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                atomic_read()
                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                    printk_ratelimit()
                    pr_err()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
            nlmsg_hdr()
            kauditd_send_multicast_skb() <void kauditd_send_multicast_skb (struct sk_buff *skb, gfp_t gfp_mask) at audit.c:450>:
                net_generic()
                netlink_has_listeners()
                skb_copy()
                nlmsg_multicast()
            skb_queue_tail()
            wake_up_interruptible()
            audit_printk_skb() <void audit_printk_skb (struct sk_buff *skb) at audit.c:391>:
                nlmsg_hdr()
                nlmsg_data()
                printk_ratelimit()
                pr_notice()
                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                    atomic_inc()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    atomic_read()
                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                        printk_ratelimit()
                        pr_err()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                audit_hold_skb() <void audit_hold_skb (struct sk_buff *skb) at audit.c:377>:
                    skb_queue_len()
                    skb_queue_tail()
                    kfree_skb()
            audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                kfree_skb()
                spin_lock_irqsave()
                kfree()
                list_add()
                spin_unlock_irqrestore()
audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
audit_tag_tree() <int audit_tag_tree (char *old, char *new) at audit_tree.c:779>:
    collect_mounts()
    path_put()
    IS_ERR()
    PTR_ERR()
    drop_collected_mounts()
    mutex_lock()
    list_add()
    container_of()
    get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
        atomic_inc()
    list_del()
    mutex_unlock()
    path_is_under()
    put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
        atomic_dec_and_test()
        kfree_rcu()
    iterate_mounts()
    tag_mount() <int tag_mount (struct vfsmount *mnt, void *arg) at audit_tree.c:652>:
        tag_chunk() <int tag_chunk (struct inode *inode, struct audit_tree *tree) at audit_tree.c:356>:
            fsnotify_find_inode_mark()
            create_chunk() <int create_chunk (struct inode *inode, struct audit_tree *tree) at audit_tree.c:317>:
                alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                    kzalloc()
                    INIT_LIST_HEAD()
                    atomic_long_set()
                    fsnotify_init_mark()
                    audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                        container_of()
                        call_rcu()
                fsnotify_add_mark()
                fsnotify_put_mark()
                spin_lock()
                spin_unlock()
                fsnotify_destroy_mark()
                get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                    atomic_inc()
                list_add()
                insert_hash() <void insert_hash (struct audit_chunk *chunk) at audit_tree.c:173>:
                    chunk_hash() <inline struct list_head *chunk_hash (const struct inode *inode) at audit_tree.c:166>:
                    list_add_rcu()
            container_of()
            spin_lock()
            spin_unlock()
            fsnotify_put_mark()
            alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                kzalloc()
                INIT_LIST_HEAD()
                atomic_long_set()
                fsnotify_init_mark()
                audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                    container_of()
                    call_rcu()
            free_chunk() <void free_chunk (struct audit_chunk *chunk) at audit_tree.c:109>:
                put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                    atomic_dec_and_test()
                    kfree_rcu()
                kfree()
            fsnotify_duplicate_mark()
            fsnotify_add_mark()
            fsnotify_destroy_mark()
            list_replace_init()
            get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                atomic_inc()
            list_add()
            list_replace_rcu()
            list_for_each_entry()
        d_backing_inode()
    spin_lock()
    spin_unlock()
    list_for_each_entry()
    trim_marked() <void trim_marked (struct audit_tree *tree) at audit_tree.c:511>:
        spin_lock()
        spin_unlock()
        list_entry()
        list_del_init()
        list_add()
        list_empty()
        untag_chunk() <void untag_chunk (struct node *p) at audit_tree.c:218>:
            find_chunk() <struct audit_chunk *find_chunk (struct node *p) at audit_tree.c:211>:
                container_of()
            fsnotify_get_mark()
            spin_unlock()
            alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                kzalloc()
                INIT_LIST_HEAD()
                atomic_long_set()
                fsnotify_init_mark()
                audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                    container_of()
                    call_rcu()
            spin_lock()
            free_chunk() <void free_chunk (struct audit_chunk *chunk) at audit_tree.c:109>:
                put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                    atomic_dec_and_test()
                    kfree_rcu()
                kfree()
            list_del_init()
            list_del_rcu()
            fsnotify_destroy_mark()
            fsnotify_duplicate_mark()
            fsnotify_add_mark()
            fsnotify_put_mark()
            list_replace_init()
            get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                atomic_inc()
            list_replace_rcu()
            list_for_each_entry()
            put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                atomic_dec_and_test()
                kfree_rcu()
        mutex_lock()
        kill_rules() <void kill_rules (struct audit_tree *tree) at audit_tree.c:470>:
            list_for_each_entry_safe()
            container_of()
            list_del_init()
            audit_tree_log_remove_rule() <void audit_tree_log_remove_rule (struct audit_krule *rule) at audit_tree.c:454>:
                audit_log_start() <struct audit_buffer *audit_log_start (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1355>:
                    uninitialized_var()
                    unlikely()
                    audit_filter_type() <int audit_filter_type (int type) at auditfilter.c:1374>:
                        rcu_read_lock()
                        list_empty()
                        list_for_each_entry_rcu()
                        audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                            BUG()
                        rcu_read_unlock()
                    skb_queue_len()
                    wait_for_auditd() <long wait_for_auditd (long sleep_time) at audit.c:1324>:
                        DECLARE_WAITQUEUE()
                        set_current_state()
                        add_wait_queue_exclusive()
                        skb_queue_len()
                        schedule_timeout()
                        remove_wait_queue()
                    audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                    wake_up()
                    audit_buffer_alloc() <struct audit_buffer *audit_buffer_alloc (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1245>:
                        spin_lock_irqsave()
                        list_empty()
                        list_entry()
                        list_del()
                        spin_unlock_irqrestore()
                        kmalloc()
                        nlmsg_new()
                        nlmsg_put()
                        kfree_skb()
                        audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                            kfree_skb()
                            spin_lock_irqsave()
                            kfree()
                            list_add()
                            spin_unlock_irqrestore()
                    audit_get_stamp() <inline void audit_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at audit.c:1312>:
                        auditsc_get_stamp() <int auditsc_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at auditsc.c:1940>:
                            audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                                ATOMIC_INIT()
                                atomic_add_return()
                        audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                            ATOMIC_INIT()
                            atomic_add_return()
                    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            max_t()
                            skb_put()
                unlikely()
                audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                    audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        max_t()
                        skb_put()
                audit_log_string()
                audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
                    audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                        audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                        audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            hex_byte_pack_upper()
                            skb_put()
                        audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            skb_put()
                audit_log_key() <void audit_log_key (struct audit_buffer *ab, char *key) at audit.c:1658>:
                    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            max_t()
                            skb_put()
                    audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
                        audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                            audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                            audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                                BUG_ON()
                                skb_tailroom()
                                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                    skb_tailroom()
                                    pskb_expand_head()
                                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                        atomic_inc()
                                        spin_lock_irqsave()
                                        spin_unlock_irqrestore()
                                        printk_ratelimit()
                                        pr_warn()
                                        atomic_read()
                                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                            printk_ratelimit()
                                            pr_err()
                                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                                local_irq_disable()
                                                raw_smp_processor_id()
                                                atomic_cmpxchg()
                                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                    cpu_relax()
                                                console_verbose()
                                                bust_spinlocks()
                                                pr_emerg()
                                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                    test_bit()
                                                dump_stack()
                                                smp_send_stop()
                                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                                kmsg_dump()
                                                debug_locks_off()
                                                console_flush_on_panic()
                                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                                no_blink() <long no_blink (int state) at panic.c:46>
                                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                    raw_cpu_write()
                                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                            raw_cpu_write()
                                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                            per_cpu()
                                                        raw_smp_processor_id()
                                                mdelay()
                                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                    kmsg_dump()
                                                    machine_emergency_restart()
                                                disabled_wait()
                                                local_irq_enable()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                skb_tail_pointer()
                                hex_byte_pack_upper()
                                skb_put()
                            audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                                BUG_ON()
                                skb_tailroom()
                                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                    skb_tailroom()
                                    pskb_expand_head()
                                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                        atomic_inc()
                                        spin_lock_irqsave()
                                        spin_unlock_irqrestore()
                                        printk_ratelimit()
                                        pr_warn()
                                        atomic_read()
                                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                            printk_ratelimit()
                                            pr_err()
                                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                                local_irq_disable()
                                                raw_smp_processor_id()
                                                atomic_cmpxchg()
                                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                    cpu_relax()
                                                console_verbose()
                                                bust_spinlocks()
                                                pr_emerg()
                                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                    test_bit()
                                                dump_stack()
                                                smp_send_stop()
                                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                                kmsg_dump()
                                                debug_locks_off()
                                                console_flush_on_panic()
                                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                                no_blink() <long no_blink (int state) at panic.c:46>
                                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                    raw_cpu_write()
                                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                            raw_cpu_write()
                                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                            per_cpu()
                                                        raw_smp_processor_id()
                                                mdelay()
                                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                    kmsg_dump()
                                                    machine_emergency_restart()
                                                disabled_wait()
                                                local_irq_enable()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                skb_tail_pointer()
                                skb_put()
                audit_log_end() <void audit_log_end (struct audit_buffer *ab) at audit.c:1957>:
                    audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                    nlmsg_hdr()
                    kauditd_send_multicast_skb() <void kauditd_send_multicast_skb (struct sk_buff *skb, gfp_t gfp_mask) at audit.c:450>:
                        net_generic()
                        netlink_has_listeners()
                        skb_copy()
                        nlmsg_multicast()
                    skb_queue_tail()
                    wake_up_interruptible()
                    audit_printk_skb() <void audit_printk_skb (struct sk_buff *skb) at audit.c:391>:
                        nlmsg_hdr()
                        nlmsg_data()
                        printk_ratelimit()
                        pr_notice()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                        audit_hold_skb() <void audit_hold_skb (struct sk_buff *skb) at audit.c:377>:
                            skb_queue_len()
                            skb_queue_tail()
                            kfree_skb()
                    audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                        kfree_skb()
                        spin_lock_irqsave()
                        kfree()
                        list_add()
                        spin_unlock_irqrestore()
            audit_remove_mark() <void audit_remove_mark (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:144>:
                fsnotify_destroy_mark()
                fsnotify_put_mark()
            list_del_rcu()
            list_del()
            call_rcu()
            audit_free_rule_rcu() <void audit_free_rule_rcu (struct rcu_head *head) at auditfilter.c:108>:
                container_of()
                audit_free_rule() <inline void audit_free_rule (struct audit_entry *e) at auditfilter.c:92>:
                    audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
                        atomic_dec_and_test()
                        WARN_ON()
                        list_empty()
                        kfree()
                    audit_free_lsm_field() <void audit_free_lsm_field (struct audit_field *f) at auditfilter.c:74>:
                        kfree()
                        security_audit_rule_free()
                    kfree()
        mutex_unlock()
        prune_one() <void prune_one (struct audit_tree *victim) at audit_tree.c:495>:
            spin_lock()
            list_empty()
            list_entry()
            untag_chunk() <void untag_chunk (struct node *p) at audit_tree.c:218>:
                find_chunk() <struct audit_chunk *find_chunk (struct node *p) at audit_tree.c:211>:
                    container_of()
                fsnotify_get_mark()
                spin_unlock()
                alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                    kzalloc()
                    INIT_LIST_HEAD()
                    atomic_long_set()
                    fsnotify_init_mark()
                    audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                        container_of()
                        call_rcu()
                spin_lock()
                free_chunk() <void free_chunk (struct audit_chunk *chunk) at audit_tree.c:109>:
                    put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                        atomic_dec_and_test()
                        kfree_rcu()
                    kfree()
                list_del_init()
                list_del_rcu()
                fsnotify_destroy_mark()
                fsnotify_duplicate_mark()
                fsnotify_add_mark()
                fsnotify_put_mark()
                list_replace_init()
                get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                    atomic_inc()
                list_replace_rcu()
                list_for_each_entry()
                put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                    atomic_dec_and_test()
                    kfree_rcu()
            spin_unlock()
            put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                atomic_dec_and_test()
                kfree_rcu()
audit_to_watch() <int audit_to_watch (struct audit_krule *krule, char *path, int len, u32 op) at audit_watch.c:189>:
    audit_init_watch() <struct audit_watch *audit_init_watch (char *path) at audit_watch.c:171>:
        kzalloc()
        unlikely()
        ERR_PTR()
        INIT_LIST_HEAD()
        atomic_set()
    IS_ERR()
    PTR_ERR()
audit_tree_lookup() <struct audit_chunk *audit_tree_lookup (const struct inode *inode) at audit_tree.c:185>:
    chunk_hash() <inline struct list_head *chunk_hash (const struct inode *inode) at audit_tree.c:166>:
    list_for_each_entry_rcu()
    atomic_long_inc()
audit_tree_match() <bool audit_tree_match (struct audit_chunk *chunk, struct audit_tree *tree) at audit_tree.c:200>:
audit_trim_trees() <void audit_trim_trees (void) at audit_tree.c:585>:
    mutex_lock()
    list_add()
    container_of()
    get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
        atomic_inc()
    list_del()
    mutex_unlock()
    collect_mounts()
    path_put()
    IS_ERR()
    spin_lock()
    list_for_each_entry()
    find_chunk() <struct audit_chunk *find_chunk (struct node *p) at audit_tree.c:211>:
        container_of()
    iterate_mounts()
    compare_root() <int compare_root (struct vfsmount *mnt, void *arg) at audit_tree.c:580>:
        d_backing_inode()
    spin_unlock()
    trim_marked() <void trim_marked (struct audit_tree *tree) at audit_tree.c:511>:
        spin_lock()
        spin_unlock()
        list_entry()
        list_del_init()
        list_add()
        list_empty()
        untag_chunk() <void untag_chunk (struct node *p) at audit_tree.c:218>:
            find_chunk() <struct audit_chunk *find_chunk (struct node *p) at audit_tree.c:211>:
                container_of()
            fsnotify_get_mark()
            spin_unlock()
            alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                kzalloc()
                INIT_LIST_HEAD()
                atomic_long_set()
                fsnotify_init_mark()
                audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                    container_of()
                    call_rcu()
            spin_lock()
            free_chunk() <void free_chunk (struct audit_chunk *chunk) at audit_tree.c:109>:
                put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                    atomic_dec_and_test()
                    kfree_rcu()
                kfree()
            list_del_init()
            list_del_rcu()
            fsnotify_destroy_mark()
            fsnotify_duplicate_mark()
            fsnotify_add_mark()
            fsnotify_put_mark()
            list_replace_init()
            get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                atomic_inc()
            list_replace_rcu()
            list_for_each_entry()
            put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                atomic_dec_and_test()
                kfree_rcu()
        mutex_lock()
        kill_rules() <void kill_rules (struct audit_tree *tree) at audit_tree.c:470>:
            list_for_each_entry_safe()
            container_of()
            list_del_init()
            audit_tree_log_remove_rule() <void audit_tree_log_remove_rule (struct audit_krule *rule) at audit_tree.c:454>:
                audit_log_start() <struct audit_buffer *audit_log_start (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1355>:
                    uninitialized_var()
                    unlikely()
                    audit_filter_type() <int audit_filter_type (int type) at auditfilter.c:1374>:
                        rcu_read_lock()
                        list_empty()
                        list_for_each_entry_rcu()
                        audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                            BUG()
                        rcu_read_unlock()
                    skb_queue_len()
                    wait_for_auditd() <long wait_for_auditd (long sleep_time) at audit.c:1324>:
                        DECLARE_WAITQUEUE()
                        set_current_state()
                        add_wait_queue_exclusive()
                        skb_queue_len()
                        schedule_timeout()
                        remove_wait_queue()
                    audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                    printk_ratelimit()
                    pr_warn()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                    wake_up()
                    audit_buffer_alloc() <struct audit_buffer *audit_buffer_alloc (struct audit_context *ctx, gfp_t gfp_mask, int type) at audit.c:1245>:
                        spin_lock_irqsave()
                        list_empty()
                        list_entry()
                        list_del()
                        spin_unlock_irqrestore()
                        kmalloc()
                        nlmsg_new()
                        nlmsg_put()
                        kfree_skb()
                        audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                            kfree_skb()
                            spin_lock_irqsave()
                            kfree()
                            list_add()
                            spin_unlock_irqrestore()
                    audit_get_stamp() <inline void audit_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at audit.c:1312>:
                        auditsc_get_stamp() <int auditsc_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at auditsc.c:1940>:
                            audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                                ATOMIC_INIT()
                                atomic_add_return()
                        audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
                            ATOMIC_INIT()
                            atomic_add_return()
                    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            max_t()
                            skb_put()
                unlikely()
                audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                    audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                        BUG_ON()
                        skb_tailroom()
                        audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                            skb_tailroom()
                            pskb_expand_head()
                            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                atomic_inc()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                                printk_ratelimit()
                                pr_warn()
                                atomic_read()
                                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                    printk_ratelimit()
                                    pr_err()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                        skb_tail_pointer()
                        max_t()
                        skb_put()
                audit_log_string()
                audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
                    audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                        audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                        audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            hex_byte_pack_upper()
                            skb_put()
                        audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            skb_put()
                audit_log_key() <void audit_log_key (struct audit_buffer *ab, char *key) at audit.c:1658>:
                    audit_log_format() <void audit_log_format (struct audit_buffer *ab, const char *fmt, ...) at audit.c:1492>:
                        audit_log_vformat() <void audit_log_vformat (struct audit_buffer *ab, const char *fmt, va_list args) at audit.c:1446>:
                            BUG_ON()
                            skb_tailroom()
                            audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                skb_tailroom()
                                pskb_expand_head()
                                audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                    atomic_inc()
                                    spin_lock_irqsave()
                                    spin_unlock_irqrestore()
                                    printk_ratelimit()
                                    pr_warn()
                                    atomic_read()
                                    audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                        printk_ratelimit()
                                        pr_err()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                            skb_tail_pointer()
                            max_t()
                            skb_put()
                    audit_log_untrustedstring() <void audit_log_untrustedstring (struct audit_buffer *ab, const char *string) at audit.c:1621>:
                        audit_log_n_untrustedstring() <void audit_log_n_untrustedstring (struct audit_buffer *ab, const char *string, size_t len) at audit.c:1604>:
                            audit_string_contains_control() <bool audit_string_contains_control (const char *string, size_t len) at audit.c:1580>:
                            audit_log_n_hex() <void audit_log_n_hex (struct audit_buffer *ab, const unsigned char *buf, size_t len) at audit.c:1514>:
                                BUG_ON()
                                skb_tailroom()
                                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                    skb_tailroom()
                                    pskb_expand_head()
                                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                        atomic_inc()
                                        spin_lock_irqsave()
                                        spin_unlock_irqrestore()
                                        printk_ratelimit()
                                        pr_warn()
                                        atomic_read()
                                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                            printk_ratelimit()
                                            pr_err()
                                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                                local_irq_disable()
                                                raw_smp_processor_id()
                                                atomic_cmpxchg()
                                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                    cpu_relax()
                                                console_verbose()
                                                bust_spinlocks()
                                                pr_emerg()
                                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                    test_bit()
                                                dump_stack()
                                                smp_send_stop()
                                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                                kmsg_dump()
                                                debug_locks_off()
                                                console_flush_on_panic()
                                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                                no_blink() <long no_blink (int state) at panic.c:46>
                                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                    raw_cpu_write()
                                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                            raw_cpu_write()
                                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                            per_cpu()
                                                        raw_smp_processor_id()
                                                mdelay()
                                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                    kmsg_dump()
                                                    machine_emergency_restart()
                                                disabled_wait()
                                                local_irq_enable()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                skb_tail_pointer()
                                hex_byte_pack_upper()
                                skb_put()
                            audit_log_n_string() <void audit_log_n_string (struct audit_buffer *ab, const char *string, size_t slen) at audit.c:1547>:
                                BUG_ON()
                                skb_tailroom()
                                audit_expand() <inline int audit_expand (struct audit_buffer *ab, int extra) at audit.c:1424>:
                                    skb_tailroom()
                                    pskb_expand_head()
                                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                                        atomic_inc()
                                        spin_lock_irqsave()
                                        spin_unlock_irqrestore()
                                        printk_ratelimit()
                                        pr_warn()
                                        atomic_read()
                                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                            printk_ratelimit()
                                            pr_err()
                                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                                local_irq_disable()
                                                raw_smp_processor_id()
                                                atomic_cmpxchg()
                                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                    cpu_relax()
                                                console_verbose()
                                                bust_spinlocks()
                                                pr_emerg()
                                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                    test_bit()
                                                dump_stack()
                                                smp_send_stop()
                                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                                kmsg_dump()
                                                debug_locks_off()
                                                console_flush_on_panic()
                                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                                no_blink() <long no_blink (int state) at panic.c:46>
                                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                    raw_cpu_write()
                                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                            raw_cpu_write()
                                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                            per_cpu()
                                                        raw_smp_processor_id()
                                                mdelay()
                                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                    kmsg_dump()
                                                    machine_emergency_restart()
                                                disabled_wait()
                                                local_irq_enable()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                skb_tail_pointer()
                                skb_put()
                audit_log_end() <void audit_log_end (struct audit_buffer *ab) at audit.c:1957>:
                    audit_rate_check() <inline int audit_rate_check (void) at audit.c:215>:
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                    nlmsg_hdr()
                    kauditd_send_multicast_skb() <void kauditd_send_multicast_skb (struct sk_buff *skb, gfp_t gfp_mask) at audit.c:450>:
                        net_generic()
                        netlink_has_listeners()
                        skb_copy()
                        nlmsg_multicast()
                    skb_queue_tail()
                    wake_up_interruptible()
                    audit_printk_skb() <void audit_printk_skb (struct sk_buff *skb) at audit.c:391>:
                        nlmsg_hdr()
                        nlmsg_data()
                        printk_ratelimit()
                        pr_notice()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                        audit_hold_skb() <void audit_hold_skb (struct sk_buff *skb) at audit.c:377>:
                            skb_queue_len()
                            skb_queue_tail()
                            kfree_skb()
                    audit_buffer_free() <void audit_buffer_free (struct audit_buffer *ab) at audit.c:1227>:
                        kfree_skb()
                        spin_lock_irqsave()
                        kfree()
                        list_add()
                        spin_unlock_irqrestore()
            audit_remove_mark() <void audit_remove_mark (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:144>:
                fsnotify_destroy_mark()
                fsnotify_put_mark()
            list_del_rcu()
            list_del()
            call_rcu()
            audit_free_rule_rcu() <void audit_free_rule_rcu (struct rcu_head *head) at auditfilter.c:108>:
                container_of()
                audit_free_rule() <inline void audit_free_rule (struct audit_entry *e) at auditfilter.c:92>:
                    audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
                        atomic_dec_and_test()
                        WARN_ON()
                        list_empty()
                        kfree()
                    audit_free_lsm_field() <void audit_free_lsm_field (struct audit_field *f) at auditfilter.c:74>:
                        kfree()
                        security_audit_rule_free()
                    kfree()
        mutex_unlock()
        prune_one() <void prune_one (struct audit_tree *victim) at audit_tree.c:495>:
            spin_lock()
            list_empty()
            list_entry()
            untag_chunk() <void untag_chunk (struct node *p) at audit_tree.c:218>:
                find_chunk() <struct audit_chunk *find_chunk (struct node *p) at audit_tree.c:211>:
                    container_of()
                fsnotify_get_mark()
                spin_unlock()
                alloc_chunk() <struct audit_chunk *alloc_chunk (int count) at audit_tree.c:138>:
                    kzalloc()
                    INIT_LIST_HEAD()
                    atomic_long_set()
                    fsnotify_init_mark()
                    audit_tree_destroy_watch() <void audit_tree_destroy_watch (struct fsnotify_mark *entry) at audit_tree.c:132>:
                        container_of()
                        call_rcu()
                spin_lock()
                free_chunk() <void free_chunk (struct audit_chunk *chunk) at audit_tree.c:109>:
                    put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                        atomic_dec_and_test()
                        kfree_rcu()
                    kfree()
                list_del_init()
                list_del_rcu()
                fsnotify_destroy_mark()
                fsnotify_duplicate_mark()
                fsnotify_add_mark()
                fsnotify_put_mark()
                list_replace_init()
                get_tree() <inline void get_tree (struct audit_tree *tree) at audit_tree.c:92>:
                    atomic_inc()
                list_replace_rcu()
                list_for_each_entry()
                put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                    atomic_dec_and_test()
                    kfree_rcu()
            spin_unlock()
            put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
                atomic_dec_and_test()
                kfree_rcu()
    drop_collected_mounts()
    put_tree() <inline void put_tree (struct audit_tree *tree) at audit_tree.c:97>:
        atomic_dec_and_test()
        kfree_rcu()
audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
    uid_eq()
    uid_lt()
    uid_lte()
    uid_gt()
    uid_gte()
    BUG()
audit_unpack_string() <char *audit_unpack_string (void **bufp, size_t *remain, size_t len) at auditfilter.c:136>:
    ERR_PTR()
    kmalloc()
    unlikely()
audit_update_lsm_rules() <int audit_update_lsm_rules (void) at auditfilter.c:1439>:
    mutex_lock()
    list_for_each_entry_safe()
    update_lsm_rule() <int update_lsm_rule (struct audit_krule *r) at auditfilter.c:1402>:
        container_of()
        security_audit_rule_known()
        audit_dupe_rule() <struct audit_entry *audit_dupe_rule (struct audit_krule *old) at auditfilter.c:782>:
            audit_init_entry() <inline struct audit_entry *audit_init_entry (u32 field_count) at auditfilter.c:115>:
                kzalloc()
                unlikely()
                kcalloc()
                kfree()
            unlikely()
            ERR_PTR()
            audit_dupe_lsm_field() <inline int audit_dupe_lsm_field (struct audit_field *df, struct audit_field *sf) at auditfilter.c:750>:
                kstrdup()
                unlikely()
                security_audit_rule_init()
                pr_warn()
            kstrdup()
            audit_dupe_exe() <int audit_dupe_exe (struct audit_krule *new, struct audit_krule *old) at audit_watch.c:522>:
                kstrdup()
                audit_mark_path() <char *audit_mark_path (struct audit_fsnotify_mark *mark) at audit_fsnotify.c:64>
                audit_alloc_mark() <struct audit_fsnotify_mark *audit_alloc_mark (struct audit_krule *krule, char *pathname, int len) at audit_fsnotify.c:83>:
                    ERR_PTR()
                    kern_path_locked()
                    IS_ERR()
                    d_inode()
                    inode_unlock()
                    kzalloc()
                    unlikely()
                    fsnotify_init_mark()
                    audit_fsnotify_free_mark() <void audit_fsnotify_free_mark (struct fsnotify_mark *mark) at audit_fsnotify.c:56>:
                        container_of()
                        audit_fsnotify_mark_free() <void audit_fsnotify_mark_free (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:50>:
                            kfree()
                    audit_update_mark() <void audit_update_mark (struct audit_fsnotify_mark *audit_mark, struct inode *inode) at audit_fsnotify.c:76>:
                    fsnotify_add_mark()
                    audit_fsnotify_mark_free() <void audit_fsnotify_mark_free (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:50>:
                        kfree()
                    dput()
                    path_put()
                IS_ERR()
                kfree()
                PTR_ERR()
            audit_remove_mark() <void audit_remove_mark (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:144>:
                fsnotify_destroy_mark()
                fsnotify_put_mark()
            audit_free_rule() <inline void audit_free_rule (struct audit_entry *e) at auditfilter.c:92>:
                audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
                    atomic_dec_and_test()
                    WARN_ON()
                    list_empty()
                    kfree()
                audit_free_lsm_field() <void audit_free_lsm_field (struct audit_field *f) at auditfilter.c:74>:
                    kfree()
                    security_audit_rule_free()
                kfree()
            audit_get_watch() <void audit_get_watch (struct audit_watch *watch) at audit_watch.c:111>:
                atomic_inc()
        audit_remove_mark() <void audit_remove_mark (struct audit_fsnotify_mark *audit_mark) at audit_fsnotify.c:144>:
            fsnotify_destroy_mark()
            fsnotify_put_mark()
        IS_ERR()
        PTR_ERR()
        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
            printk_ratelimit()
            pr_err()
            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                local_irq_disable()
                raw_smp_processor_id()
                atomic_cmpxchg()
                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                    cpu_relax()
                console_verbose()
                bust_spinlocks()
                pr_emerg()
                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                    test_bit()
                dump_stack()
                smp_send_stop()
                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                kmsg_dump()
                debug_locks_off()
                console_flush_on_panic()
                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                no_blink() <long no_blink (int state) at panic.c:46>
                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                    raw_cpu_write()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
                mdelay()
                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                    kmsg_dump()
                    machine_emergency_restart()
                disabled_wait()
                local_irq_enable()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
        list_del()
        list_del_rcu()
        list_replace_init()
        list_replace_rcu()
        list_replace()
        call_rcu()
        audit_free_rule_rcu() <void audit_free_rule_rcu (struct rcu_head *head) at auditfilter.c:108>:
            container_of()
            audit_free_rule() <inline void audit_free_rule (struct audit_entry *e) at auditfilter.c:92>:
                audit_put_watch() <void audit_put_watch (struct audit_watch *watch) at audit_watch.c:116>:
                    atomic_dec_and_test()
                    WARN_ON()
                    list_empty()
                    kfree()
                audit_free_lsm_field() <void audit_free_lsm_field (struct audit_field *f) at auditfilter.c:74>:
                    kfree()
                    security_audit_rule_free()
                kfree()
    mutex_unlock()
audit_watch_compare() <int audit_watch_compare (struct audit_watch *watch, unsigned long ino, dev_t dev) at audit_watch.c:139>:
auditsc_get_stamp() <int auditsc_get_stamp (struct audit_context *ctx, struct timespec *t, unsigned int *serial) at auditsc.c:1940>:
    audit_serial() <unsigned int audit_serial (void) at audit.c:1305>:
        ATOMIC_INIT()
        atomic_add_return()
bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
    BUILD_BUG_ON()
    ktime_get_ns()
    do_div()
    get_seconds()
    thread_group_leader()
    task_nice()
    task_pid_nr_ns()
    rcu_read_lock()
    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
    pid_alive()
    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
        task_tgid()
    rcu_dereference()
    rcu_read_unlock()
    task_cputime()
    cputime_to_usecs()
    task_cputime_scaled()
blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
blocking_notifier_chain_cond_register() <int blocking_notifier_chain_cond_register (struct blocking_notifier_head *nh, struct notifier_block *n) at notifier.c:244>:
    down_write()
    notifier_chain_cond_register() <int notifier_chain_cond_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:34>:
        rcu_assign_pointer()
    up_write()
blocking_notifier_chain_register() <int blocking_notifier_chain_register (struct blocking_notifier_head *nh, struct notifier_block *n) at notifier.c:213>:
    unlikely()
    notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
        rcu_assign_pointer()
    down_write()
    up_write()
blocking_notifier_chain_unregister() <int blocking_notifier_chain_unregister (struct blocking_notifier_head *nh, struct notifier_block *n) at notifier.c:266>:
    unlikely()
    notifier_chain_unregister() <int notifier_chain_unregister (struct notifier_block **nl, struct notifier_block *n) at notifier.c:49>:
        rcu_assign_pointer()
    down_write()
    up_write()
call_function_init() <void __init call_function_init (void) at smp.c:89>:
    smp_processor_id()
    for_each_possible_cpu()
    init_llist_head()
    per_cpu()
    hotplug_cfd() <int hotplug_cfd (struct notifier_block *nfb, unsigned long action, void *hcpu) at smp.c:37>:
        per_cpu()
        zalloc_cpumask_var_node()
        cpu_to_node()
        notifier_from_errno()
        alloc_percpu()
        free_cpumask_var()
        free_percpu()
        flush_smp_call_function_queue() <void flush_smp_call_function_queue (bool warn_cpu_offline) at smp.c:212>:
            WARN_ON()
            irqs_disabled()
            this_cpu_ptr()
            llist_del_all()
            llist_reverse_order()
            unlikely()
            cpu_online()
            smp_processor_id()
            llist_empty()
            WARN()
            llist_for_each_entry()
            pr_warn()
            llist_for_each_entry_safe()
            func()
            csd_unlock() <void csd_unlock (struct call_single_data *csd) at smp.c:127>:
                WARN_ON()
                smp_store_release()
            irq_work_run() <void irq_work_run (void) at irq_work.c:169>:
                irq_work_run_list() <void irq_work_run_list (struct llist_head *list) at irq_work.c:129>:
                    BUG_ON()
                    irqs_disabled()
                    llist_empty()
                    llist_del_all()
                    llist_entry()
                    llist_next()
                    xchg()
                    cmpxchg()
                this_cpu_ptr()
    register_cpu_notifier() <int register_cpu_notifier (struct notifier_block *nb) at cpu.c:196>:
        cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
            mutex_lock()
        raw_notifier_chain_register() <int raw_notifier_chain_register (struct raw_notifier_head *nh, struct notifier_block *n) at notifier.c:347>:
            notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
                rcu_assign_pointer()
        cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
            mutex_unlock()
call_usermodehelper() <int call_usermodehelper (char *path, char **argv, char **envp, int wait) at kmod.c:616>:
    call_usermodehelper_setup() <struct subprocess_info *call_usermodehelper_setup (char *path, char **argv, char **envp, gfp_t gfp_mask, int (*init) (struct subprocess_info *info, struct cred *new), void (*cleanup) (struct subprocess_info *info), void *data) at kmod.c:519>:
        kzalloc()
        INIT_WORK()
        call_usermodehelper_exec_work() <void call_usermodehelper_exec_work (struct work_struct *work) at kmod.c:321>:
            container_of()
            call_usermodehelper_exec_sync() <void call_usermodehelper_exec_sync (struct subprocess_info *sub_info) at kmod.c:269>:
                kernel_sigaction() <void kernel_sigaction (int sig, __sighandler_t action) at signal.c:3029>:
                    spin_lock_irq()
                    flush_sigqueue_mask() <int flush_sigqueue_mask (sigset_t *mask, struct sigpending *s) at signal.c:659>:
                        sigandsets()
                        sigisemptyset()
                        sigandnsets()
                        list_for_each_entry_safe()
                        list_del_init()
                    recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
                        recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                            PENDING()
                            set_tsk_thread_flag()
                        freezing()
                        clear_thread_flag()
                    spin_unlock_irq()
                kernel_thread() <pid_t kernel_thread (int (*fn) (void *), void *arg, unsigned long flags) at fork.c:1779>:
                call_usermodehelper_exec_async() <int call_usermodehelper_exec_async (void *data) at kmod.c:215>:
                    spin_lock_irq()
                    flush_signal_handlers() <void flush_signal_handlers (struct task_struct *t, int force_default) at signal.c:479>:
                    spin_unlock_irq()
                    set_user_nice()
                    prepare_kernel_cred() <struct cred *prepare_kernel_cred (struct task_struct *daemon) at cred.c:594>:
                        kmem_cache_alloc()
                        kdebug()
                        get_task_cred() <const struct cred *get_task_cred (struct task_struct *task) at cred.c:187>:
                            rcu_read_lock()
                            BUG_ON()
                            atomic_inc_not_zero()
                            rcu_read_unlock()
                        get_cred()
                        validate_creds()
                        atomic_set()
                        set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
                            atomic_set()
                        get_uid()
                        get_user_ns()
                        get_group_info()
                        security_prepare_creds()
                        put_cred()
                    spin_lock()
                    cap_intersect()
                    spin_unlock()
                    abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        BUG_ON()
                        put_cred()
                    commit_creds() <int commit_creds (struct cred *new) at cred.c:422>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        BUG_ON()
                        validate_creds()
                        get_cred()
                        uid_eq()
                        gid_eq()
                        cred_cap_issubset() <bool cred_cap_issubset (const struct cred *set, const struct cred *subset) at cred.c:383>:
                            cap_issubset()
                            uid_eq()
                        set_dumpable()
                        smp_wmb()
                        key_fsuid_changed()
                        key_fsgid_changed()
                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                            atomic_add()
                        atomic_inc()
                        rcu_assign_pointer()
                        atomic_dec()
                        proc_id_connector()
                        put_cred()
                    do_execve()
                    getname_kernel()
                    umh_complete() <void umh_complete (struct subprocess_info *sub_info) at kmod.c:198>:
                        xchg()
                        complete()
                        call_usermodehelper_freeinfo() <void call_usermodehelper_freeinfo (struct subprocess_info *info) at kmod.c:191>:
                            kfree()
                    do_exit() <void do_exit (long code) at exit.c:651>:
                        TASKS_RCU()
                        profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
                            blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
                        WARN_ON()
                        blk_needs_flush_plug()
                        unlikely()
                        in_interrupt()
                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                            local_irq_disable()
                            raw_smp_processor_id()
                            atomic_cmpxchg()
                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                cpu_relax()
                            console_verbose()
                            bust_spinlocks()
                            pr_emerg()
                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                test_bit()
                            dump_stack()
                            smp_send_stop()
                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                            kmsg_dump()
                            debug_locks_off()
                            console_flush_on_panic()
                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                            no_blink() <long no_blink (int state) at panic.c:46>
                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                raw_cpu_write()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                            mdelay()
                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                kmsg_dump()
                                machine_emergency_restart()
                            disabled_wait()
                            local_irq_enable()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        set_fs()
                        ptrace_event()
                        validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
                            kdebug()
                            atomic_read()
                            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                atomic_read()
                        pr_alert()
                        set_current_state()
                        schedule()
                        exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
                            threadgroup_change_begin()
                            thread_group_empty()
                            signal_group_exit()
                            threadgroup_change_end()
                            spin_lock_irq()
                            signal_pending()
                            signotset()
                            retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                                sigandsets()
                                sigisemptyset()
                                while_each_thread()
                                has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                                signal_pending()
                                signal_wake_up()
                            unlikely()
                            task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                                WARN_ON_ONCE()
                                task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                                    BUG_ON()
                                    task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                                        unlikely()
                                        smp_mb()
                                        wake_up_bit()
                            spin_unlock_irq()
                            read_lock()
                            do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                                rcu_read_lock()
                                task_pid_nr_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                            smp_rmb()
                                task_cred_xxx()
                                task_uid()
                                rcu_read_unlock()
                                task_cputime()
                                cputime_to_clock_t()
                                BUG()
                                spin_lock_irqsave()
                                spin_unlock_irqrestore()
                            read_unlock()
                        smp_mb()
                        raw_spin_unlock_wait()
                        in_atomic()
                        pr_info()
                        task_pid_nr()
                        preempt_count()
                        preempt_count_set()
                        sync_mm_rss()
                        acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
                            task_cputime()
                        atomic_dec_and_test()
                        hrtimer_cancel()
                        exit_itimers()
                        setmax_mm_hiwater_rss()
                        acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
                            down_read()
                            up_read()
                            spin_lock_irq()
                            thread_group_leader()
                            task_cputime()
                            spin_unlock_irq()
                        tty_audit_exit()
                        audit_free()
                        taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
                            taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                                nla_total_size()
                            taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                                thread_group_empty()
                                kmem_cache_zalloc()
                                spin_lock_irq()
                                spin_unlock_irq()
                                kmem_cache_free()
                            fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                                spin_lock_irqsave()
                                delayacct_add_tsk()
                                spin_unlock_irqrestore()
                            raw_cpu_ptr()
                            list_empty()
                            prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                                genlmsg_new()
                                this_cpu_inc_return()
                                genlmsg_put()
                                genlmsg_put_reply()
                                nlmsg_free()
                            mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                                nla_put()
                                nla_nest_start()
                                nla_nest_cancel()
                                nla_reserve()
                                nla_nest_end()
                                nla_data()
                            task_pid_nr_ns()
                            fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                                delayacct_add_tsk()
                                bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                                    BUILD_BUG_ON()
                                    ktime_get_ns()
                                    do_div()
                                    get_seconds()
                                    thread_group_leader()
                                    task_nice()
                                    task_pid_nr_ns()
                                    rcu_read_lock()
                                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                smp_rmb()
                                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                smp_rmb()
                                    pid_alive()
                                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                        task_tgid()
                                    rcu_dereference()
                                    rcu_read_unlock()
                                    task_cputime()
                                    cputime_to_usecs()
                                    task_cputime_scaled()
                                xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                                    get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                        task_lock()
                                        atomic_inc()
                                        task_unlock()
                                    get_mm_hiwater_rss()
                                    get_mm_hiwater_vm()
                                    mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                        might_sleep()
                                        atomic_dec_and_test()
                                        uprobe_clear_state()
                                        exit_aio()
                                        ksm_exit()
                                        khugepaged_exit()
                                        exit_mmap()
                                        set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                            rcu_dereference_raw()
                                            get_file()
                                            rcu_assign_pointer()
                                            fput()
                                        list_empty()
                                        spin_lock()
                                        list_del()
                                        spin_unlock()
                                        module_put() <void module_put (struct module *module) at module.c:1098>:
                                            preempt_disable()
                                            atomic_dec_if_positive()
                                            WARN_ON()
                                            trace_module_put()
                                            preempt_enable()
                                        mmdrop()
                            task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                task_tgid()
                            send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                                nlmsg_data()
                                nlmsg_hdr()
                                genlmsg_data()
                                genlmsg_end()
                                down_read()
                                list_for_each_entry()
                                list_is_last()
                                skb_clone()
                                genlmsg_unicast()
                                up_read()
                                nlmsg_free()
                                down_write()
                                list_for_each_entry_safe()
                                list_del()
                                kfree()
                                up_write()
                            nlmsg_free()
                        exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
                            mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                                unlikely()
                                exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                                    uninitialized_var()
                                    fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                                        get_user()
                                    get_user()
                                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                                        uninitialized_var()
                                        get_user()
                                        task_pid_vnr()
                                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                            pagefault_disable()
                                            futex_atomic_cmpxchg_inatomic()
                                            pagefault_enable()
                                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                            down_read()
                                            fixup_user_fault()
                                            up_read()
                                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                            WAKE_Q()
                                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                                unlikely()
                                                access_ok()
                                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                                    should_fail()
                                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                                    ihold()
                                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                                        atomic_inc()
                                                        smp_mb__after_atomic()
                                                    smp_mb()
                                                get_user_pages_fast()
                                                lock_page()
                                                compound_head()
                                                PageSwapCache()
                                                unlock_page()
                                                put_page()
                                                PageAnon()
                                                basepage_index()
                                            unlikely()
                                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                                jhash2()
                                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                                atomic_read()
                                            spin_lock()
                                            plist_for_each_entry_safe()
                                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                                WARN()
                                                wake_q_add()
                                                smp_wmb()
                                            spin_unlock()
                                            wake_up_q()
                                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                                    WARN_ON_ONCE()
                                                    iput()
                                                    mmdrop()
                                    cond_resched()
                                compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                                    uninitialized_var()
                                    fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                                        get_user()
                                        compat_ptr()
                                    get_user()
                                    futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                                        ptr_to_compat()
                                        compat_ptr()
                                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                                        uninitialized_var()
                                        get_user()
                                        task_pid_vnr()
                                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                            pagefault_disable()
                                            futex_atomic_cmpxchg_inatomic()
                                            pagefault_enable()
                                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                            down_read()
                                            fixup_user_fault()
                                            up_read()
                                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                            WAKE_Q()
                                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                                unlikely()
                                                access_ok()
                                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                                    should_fail()
                                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                                    ihold()
                                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                                        atomic_inc()
                                                        smp_mb__after_atomic()
                                                    smp_mb()
                                                get_user_pages_fast()
                                                lock_page()
                                                compound_head()
                                                PageSwapCache()
                                                unlock_page()
                                                put_page()
                                                PageAnon()
                                                basepage_index()
                                            unlikely()
                                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                                jhash2()
                                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                                atomic_read()
                                            spin_lock()
                                            plist_for_each_entry_safe()
                                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                                WARN()
                                                wake_q_add()
                                                smp_wmb()
                                            spin_unlock()
                                            wake_up_q()
                                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                                    WARN_ON_ONCE()
                                                    iput()
                                                    mmdrop()
                                    cond_resched()
                                list_empty()
                                exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                                    raw_spin_lock_irq()
                                    list_empty()
                                    list_entry()
                                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                        jhash2()
                                    raw_spin_unlock_irq()
                                    spin_lock()
                                    spin_unlock()
                                    WARN_ON()
                                    list_del_init()
                                    rt_mutex_unlock()
                                uprobe_free_utask()
                                deactivate_mm()
                                atomic_read()
                                put_user()
                                sys_futex()
                                complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                                    task_lock()
                                    likely()
                                    complete()
                                    task_unlock()
                            sync_mm_rss()
                            down_read()
                            up_read()
                            xchg()
                            atomic_dec_and_test()
                            complete()
                            set_task_state()
                            freezable_schedule()
                            atomic_inc()
                            BUG_ON()
                            task_lock()
                            enter_lazy_tlb()
                            task_unlock()
                            mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                                atomic_read()
                                read_lock()
                                list_for_each_entry()
                                for_each_process()
                                for_each_thread()
                                read_unlock()
                                BUG_ON()
                                get_task_struct()
                                task_lock()
                                task_unlock()
                                put_task_struct()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                            test_thread_flag()
                            exit_oom_victim()
                        acct_process() <void acct_process (void) at acct.c:587>:
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                            unlikely()
                            slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                                acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                                    smp_rmb()
                                    rcu_read_lock()
                                    to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                                        container_of()
                                    ACCESS_ONCE()
                                    rcu_read_unlock()
                                    atomic_long_inc_not_zero()
                                    cpu_relax()
                                    mutex_lock()
                                    mutex_unlock()
                                    acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                                        atomic_long_dec_and_test()
                                        kfree_rcu()
                                do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                                    override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                                        kdebug()
                                        atomic_read()
                                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                            atomic_read()
                                        validate_creds()
                                        get_cred()
                                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                            atomic_add()
                                        rcu_assign_pointer()
                                    check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                                        time_is_before_jiffies()
                                        vfs_statfs()
                                        do_div()
                                        pr_info()
                                    fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                                        strlcpy()
                                        ktime_get_ns()
                                        nsec_to_AHZ()
                                        encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                                        encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                                        encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                                        do_div()
                                        get_seconds()
                                        spin_lock_irq()
                                        old_encode_dev()
                                        tty_devnum()
                                        jiffies_to_AHZ()
                                        cputime_to_jiffies()
                                        spin_unlock_irq()
                                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                smp_rmb()
                                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                smp_rmb()
                                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                        task_tgid()
                                    rcu_read_lock()
                                    rcu_dereference()
                                    rcu_read_unlock()
                                    file_start_write_trylock()
                                    file_end_write()
                                    revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                                        kdebug()
                                        atomic_read()
                                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                            atomic_read()
                                        validate_creds()
                                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                            atomic_add()
                                        rcu_assign_pointer()
                                        put_cred()
                                mutex_unlock()
                                acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                                    atomic_long_dec_and_test()
                                    kfree_rcu()
                        trace_sched_process_exit()
                        exit_sem()
                        exit_shm()
                        exit_files()
                        exit_fs()
                        disassociate_ctty()
                        exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
                            switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                                might_sleep()
                                task_lock()
                                task_unlock()
                                atomic_dec_and_test()
                                free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                                    put_mnt_ns()
                                    put_uts_ns()
                                    put_ipc_ns()
                                    put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                                        kref_put()
                                        free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                            container_of()
                                            destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                                ns_free_inum()
                                                kfree()
                                                put_user_ns()
                                                call_rcu()
                                                delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                                    kmem_cache_free()
                                                    container_of()
                                    put_net()
                                    kmem_cache_free()
                        exit_task_work()
                        exit_thread()
                        perf_event_exit_task()
                        cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
                            task_css_set()
                            list_empty()
                            spin_lock_bh()
                            css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                                lockdep_assert_held()
                                WARN_ON_ONCE()
                                list_empty()
                                list_for_each_entry_safe()
                                css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                                    lockdep_assert_held()
                                    WARN_ON_ONCE()
                                    css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                                        lockdep_assert_held()
                                        container_of()
                                        list_entry()
                                        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                            lockdep_assert_held()
                                            list_empty()
                                        list_empty()
                                        list_del()
                                        put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                                            lockdep_assert_held()
                                            atomic_dec_and_test()
                                            for_each_subsys()
                                            list_del()
                                            css_put()
                                            hash_del()
                                            list_for_each_entry_safe()
                                            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                                container_of()
                                            cgroup_put()
                                            kfree()
                                            kfree_rcu()
                                        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                            atomic_inc()
                                        list_add()
                                list_del_init()
                                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                    lockdep_assert_held()
                                    list_empty()
                                css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                                    lockdep_assert_held()
                                    list_for_each_entry()
                                    cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                                        lockdep_assert_held()
                                        check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                                            notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                                test_bit()
                                            cgroup_is_populated()
                                            css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                                rcu_read_lock()
                                                css_for_each_child()
                                                rcu_read_unlock()
                                            cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                                            schedule_work()
                                        cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                                            spin_lock_irqsave()
                                            kernfs_notify()
                                            spin_unlock_irqrestore()
                                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                            container_of()
                                rcu_assign_pointer()
                                list_add_tail()
                            spin_unlock_bh()
                            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                atomic_inc()
                            for_each_subsys_which()
                        flush_ptrace_hw_breakpoint()
                        preempt_disable()
                        preempt_enable()
                        exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
                            LIST_HEAD()
                            write_lock_irq()
                            forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                                unlikely()
                                list_empty()
                                exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                                    list_for_each_entry_safe()
                                    unlikely()
                                    send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                                        valid_signal()
                                        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                            lock_task_sighand()
                                            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                                    SI_FROMUSER()
                                                task_pid_nr_ns()
                                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                    ns_of_pid()
                                                    task_pid()
                                            unlock_task_sighand()
                                    list_add()
                                find_child_reaper()
                                find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                                    find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                                        for_each_thread()
                                    same_thread_group()
                                list_for_each_entry()
                                for_each_thread()
                                BUG_ON()
                                likely()
                                group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                                    rcu_read_lock()
                                    check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                                        valid_signal()
                                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                            SI_FROMUSER()
                                        audit_signal_info()
                                        same_thread_group()
                                        kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                                            current_cred()
                                            uid_eq()
                                            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                                unlikely()
                                                cap_valid()
                                                pr_crit()
                                                BUG()
                                                security_capable()
                                                current_cred()
                                        task_session()
                                        security_task_kill()
                                    rcu_read_unlock()
                                    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                        lock_task_sighand()
                                        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                                SI_FROMUSER()
                                            task_pid_nr_ns()
                                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                ns_of_pid()
                                                task_pid()
                                        unlock_task_sighand()
                                same_thread_group()
                                reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                                    unlikely()
                                    thread_group_empty()
                                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                                        BUG_ON()
                                        task_is_stopped_or_traced()
                                        thread_group_empty()
                                        rcu_read_lock()
                                        task_pid_nr_ns()
                                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                            ns_of_pid()
                                            task_pid()
                                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                    smp_rmb()
                                        task_cred_xxx()
                                        task_uid()
                                        rcu_read_unlock()
                                        task_cputime()
                                        cputime_to_clock_t()
                                        spin_lock_irqsave()
                                        valid_signal()
                                        spin_unlock_irqrestore()
                                    list_add()
                                    kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                                        task_pgrp()
                                        task_session()
                                        will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                                            do_each_pid_task()
                                            thread_group_empty()
                                            is_global_init()
                                            task_pgrp()
                                            task_session()
                                            while_each_pid_task()
                                        has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                                            do_each_pid_task()
                                            while_each_pid_task()
                                list_splice_tail_init()
                            kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                                task_pgrp()
                                task_session()
                                will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                                    do_each_pid_task()
                                    thread_group_empty()
                                    is_global_init()
                                    task_pgrp()
                                    task_session()
                                    while_each_pid_task()
                                has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                                    do_each_pid_task()
                                    while_each_pid_task()
                            unlikely()
                            thread_group_leader()
                            thread_group_empty()
                            ptrace_reparented()
                            do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                                BUG_ON()
                                task_is_stopped_or_traced()
                                thread_group_empty()
                                rcu_read_lock()
                                task_pid_nr_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                            smp_rmb()
                                task_cred_xxx()
                                task_uid()
                                rcu_read_unlock()
                                task_cputime()
                                cputime_to_clock_t()
                                spin_lock_irqsave()
                                valid_signal()
                                spin_unlock_irqrestore()
                            list_add()
                            wake_up_process()
                            write_unlock_irq()
                            list_for_each_entry_safe()
                            list_del_init()
                            release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                                rcu_read_lock()
                                atomic_dec()
                                rcu_read_unlock()
                                proc_flush_task()
                                write_lock_irq()
                                ptrace_release_task()
                                thread_group_empty()
                                do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                                    BUG_ON()
                                    task_is_stopped_or_traced()
                                    thread_group_empty()
                                    rcu_read_lock()
                                    task_pid_nr_ns()
                                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                        ns_of_pid()
                                        task_pid()
                                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                smp_rmb()
                                    task_cred_xxx()
                                    task_uid()
                                    rcu_read_unlock()
                                    task_cputime()
                                    cputime_to_clock_t()
                                    spin_lock_irqsave()
                                    valid_signal()
                                    spin_unlock_irqrestore()
                                write_unlock_irq()
                                release_thread()
                                call_rcu()
                                delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                                    container_of()
                                    perf_event_delayed_put()
                                    trace_sched_process_free()
                                    put_task_struct()
                                unlikely()
                        proc_exit_connector()
                        task_lock()
                        mpol_put()
                        task_unlock()
                        kfree()
                        debug_check_no_locks_held()
                        exit_io_context()
                        free_pipe_info()
                        put_page()
                        check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
                            stack_not_used()
                            spin_lock()
                            pr_warn()
                            task_pid_nr()
                            spin_unlock()
                        exit_rcu()
                        BUG()
                        cpu_relax()
                sys_wait4()
                umh_complete() <void umh_complete (struct subprocess_info *sub_info) at kmod.c:198>:
                    xchg()
                    complete()
                    call_usermodehelper_freeinfo() <void call_usermodehelper_freeinfo (struct subprocess_info *info) at kmod.c:191>:
                        kfree()
            kernel_thread() <pid_t kernel_thread (int (*fn) (void *), void *arg, unsigned long flags) at fork.c:1779>:
            call_usermodehelper_exec_async() <int call_usermodehelper_exec_async (void *data) at kmod.c:215>:
                spin_lock_irq()
                flush_signal_handlers() <void flush_signal_handlers (struct task_struct *t, int force_default) at signal.c:479>:
                spin_unlock_irq()
                set_user_nice()
                prepare_kernel_cred() <struct cred *prepare_kernel_cred (struct task_struct *daemon) at cred.c:594>:
                    kmem_cache_alloc()
                    kdebug()
                    get_task_cred() <const struct cred *get_task_cred (struct task_struct *task) at cred.c:187>:
                        rcu_read_lock()
                        BUG_ON()
                        atomic_inc_not_zero()
                        rcu_read_unlock()
                    get_cred()
                    validate_creds()
                    atomic_set()
                    set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
                        atomic_set()
                    get_uid()
                    get_user_ns()
                    get_group_info()
                    security_prepare_creds()
                    put_cred()
                spin_lock()
                cap_intersect()
                spin_unlock()
                abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
                    kdebug()
                    atomic_read()
                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                        atomic_read()
                    BUG_ON()
                    put_cred()
                commit_creds() <int commit_creds (struct cred *new) at cred.c:422>:
                    kdebug()
                    atomic_read()
                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                        atomic_read()
                    BUG_ON()
                    validate_creds()
                    get_cred()
                    uid_eq()
                    gid_eq()
                    cred_cap_issubset() <bool cred_cap_issubset (const struct cred *set, const struct cred *subset) at cred.c:383>:
                        cap_issubset()
                        uid_eq()
                    set_dumpable()
                    smp_wmb()
                    key_fsuid_changed()
                    key_fsgid_changed()
                    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                        atomic_add()
                    atomic_inc()
                    rcu_assign_pointer()
                    atomic_dec()
                    proc_id_connector()
                    put_cred()
                do_execve()
                getname_kernel()
                umh_complete() <void umh_complete (struct subprocess_info *sub_info) at kmod.c:198>:
                    xchg()
                    complete()
                    call_usermodehelper_freeinfo() <void call_usermodehelper_freeinfo (struct subprocess_info *info) at kmod.c:191>:
                        kfree()
                do_exit() <void do_exit (long code) at exit.c:651>:
                    TASKS_RCU()
                    profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
                        blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
                    WARN_ON()
                    blk_needs_flush_plug()
                    unlikely()
                    in_interrupt()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    set_fs()
                    ptrace_event()
                    validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                    pr_alert()
                    set_current_state()
                    schedule()
                    exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
                        threadgroup_change_begin()
                        thread_group_empty()
                        signal_group_exit()
                        threadgroup_change_end()
                        spin_lock_irq()
                        signal_pending()
                        signotset()
                        retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                            sigandsets()
                            sigisemptyset()
                            while_each_thread()
                            has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                            signal_pending()
                            signal_wake_up()
                        unlikely()
                        task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                            WARN_ON_ONCE()
                            task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                                BUG_ON()
                                task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                                    unlikely()
                                    smp_mb()
                                    wake_up_bit()
                        spin_unlock_irq()
                        read_lock()
                        do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                            rcu_read_lock()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            task_cred_xxx()
                            task_uid()
                            rcu_read_unlock()
                            task_cputime()
                            cputime_to_clock_t()
                            BUG()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                        read_unlock()
                    smp_mb()
                    raw_spin_unlock_wait()
                    in_atomic()
                    pr_info()
                    task_pid_nr()
                    preempt_count()
                    preempt_count_set()
                    sync_mm_rss()
                    acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
                        task_cputime()
                    atomic_dec_and_test()
                    hrtimer_cancel()
                    exit_itimers()
                    setmax_mm_hiwater_rss()
                    acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
                        down_read()
                        up_read()
                        spin_lock_irq()
                        thread_group_leader()
                        task_cputime()
                        spin_unlock_irq()
                    tty_audit_exit()
                    audit_free()
                    taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
                        taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                            nla_total_size()
                        taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                            thread_group_empty()
                            kmem_cache_zalloc()
                            spin_lock_irq()
                            spin_unlock_irq()
                            kmem_cache_free()
                        fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                            spin_lock_irqsave()
                            delayacct_add_tsk()
                            spin_unlock_irqrestore()
                        raw_cpu_ptr()
                        list_empty()
                        prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                            genlmsg_new()
                            this_cpu_inc_return()
                            genlmsg_put()
                            genlmsg_put_reply()
                            nlmsg_free()
                        mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                            nla_put()
                            nla_nest_start()
                            nla_nest_cancel()
                            nla_reserve()
                            nla_nest_end()
                            nla_data()
                        task_pid_nr_ns()
                        fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                            delayacct_add_tsk()
                            bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                                BUILD_BUG_ON()
                                ktime_get_ns()
                                do_div()
                                get_seconds()
                                thread_group_leader()
                                task_nice()
                                task_pid_nr_ns()
                                rcu_read_lock()
                                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                            smp_rmb()
                                from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                                    from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                            smp_rmb()
                                pid_alive()
                                task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                    pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                    task_tgid()
                                rcu_dereference()
                                rcu_read_unlock()
                                task_cputime()
                                cputime_to_usecs()
                                task_cputime_scaled()
                            xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                    task_lock()
                                    atomic_inc()
                                    task_unlock()
                                get_mm_hiwater_rss()
                                get_mm_hiwater_vm()
                                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                    might_sleep()
                                    atomic_dec_and_test()
                                    uprobe_clear_state()
                                    exit_aio()
                                    ksm_exit()
                                    khugepaged_exit()
                                    exit_mmap()
                                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                        rcu_dereference_raw()
                                        get_file()
                                        rcu_assign_pointer()
                                        fput()
                                    list_empty()
                                    spin_lock()
                                    list_del()
                                    spin_unlock()
                                    module_put() <void module_put (struct module *module) at module.c:1098>:
                                        preempt_disable()
                                        atomic_dec_if_positive()
                                        WARN_ON()
                                        trace_module_put()
                                        preempt_enable()
                                    mmdrop()
                        task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                            pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                            task_tgid()
                        send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                            nlmsg_data()
                            nlmsg_hdr()
                            genlmsg_data()
                            genlmsg_end()
                            down_read()
                            list_for_each_entry()
                            list_is_last()
                            skb_clone()
                            genlmsg_unicast()
                            up_read()
                            nlmsg_free()
                            down_write()
                            list_for_each_entry_safe()
                            list_del()
                            kfree()
                            up_write()
                        nlmsg_free()
                    exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
                        mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                            unlikely()
                            exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                                uninitialized_var()
                                fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                                    get_user()
                                get_user()
                                handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                                    uninitialized_var()
                                    get_user()
                                    task_pid_vnr()
                                    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                        pagefault_disable()
                                        futex_atomic_cmpxchg_inatomic()
                                        pagefault_enable()
                                    fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                        down_read()
                                        fixup_user_fault()
                                        up_read()
                                    futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                        WAKE_Q()
                                        get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                            unlikely()
                                            access_ok()
                                            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                                should_fail()
                                            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                                ihold()
                                                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                                    atomic_inc()
                                                    smp_mb__after_atomic()
                                                smp_mb()
                                            get_user_pages_fast()
                                            lock_page()
                                            compound_head()
                                            PageSwapCache()
                                            unlock_page()
                                            put_page()
                                            PageAnon()
                                            basepage_index()
                                        unlikely()
                                        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                            jhash2()
                                        hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                            atomic_read()
                                        spin_lock()
                                        plist_for_each_entry_safe()
                                        match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                        mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                            WARN()
                                            wake_q_add()
                                            smp_wmb()
                                        spin_unlock()
                                        wake_up_q()
                                        put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                                WARN_ON_ONCE()
                                                iput()
                                                mmdrop()
                                cond_resched()
                            compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                                uninitialized_var()
                                fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                                    get_user()
                                    compat_ptr()
                                get_user()
                                futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                                    ptr_to_compat()
                                    compat_ptr()
                                handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                                    uninitialized_var()
                                    get_user()
                                    task_pid_vnr()
                                    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                        pagefault_disable()
                                        futex_atomic_cmpxchg_inatomic()
                                        pagefault_enable()
                                    fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                        down_read()
                                        fixup_user_fault()
                                        up_read()
                                    futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                        WAKE_Q()
                                        get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                            unlikely()
                                            access_ok()
                                            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                                should_fail()
                                            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                                ihold()
                                                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                                    atomic_inc()
                                                    smp_mb__after_atomic()
                                                smp_mb()
                                            get_user_pages_fast()
                                            lock_page()
                                            compound_head()
                                            PageSwapCache()
                                            unlock_page()
                                            put_page()
                                            PageAnon()
                                            basepage_index()
                                        unlikely()
                                        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                            jhash2()
                                        hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                            atomic_read()
                                        spin_lock()
                                        plist_for_each_entry_safe()
                                        match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                        mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                            WARN()
                                            wake_q_add()
                                            smp_wmb()
                                        spin_unlock()
                                        wake_up_q()
                                        put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                                WARN_ON_ONCE()
                                                iput()
                                                mmdrop()
                                cond_resched()
                            list_empty()
                            exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                                raw_spin_lock_irq()
                                list_empty()
                                list_entry()
                                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                    jhash2()
                                raw_spin_unlock_irq()
                                spin_lock()
                                spin_unlock()
                                WARN_ON()
                                list_del_init()
                                rt_mutex_unlock()
                            uprobe_free_utask()
                            deactivate_mm()
                            atomic_read()
                            put_user()
                            sys_futex()
                            complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                                task_lock()
                                likely()
                                complete()
                                task_unlock()
                        sync_mm_rss()
                        down_read()
                        up_read()
                        xchg()
                        atomic_dec_and_test()
                        complete()
                        set_task_state()
                        freezable_schedule()
                        atomic_inc()
                        BUG_ON()
                        task_lock()
                        enter_lazy_tlb()
                        task_unlock()
                        mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                            atomic_read()
                            read_lock()
                            list_for_each_entry()
                            for_each_process()
                            for_each_thread()
                            read_unlock()
                            BUG_ON()
                            get_task_struct()
                            task_lock()
                            task_unlock()
                            put_task_struct()
                        mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                            might_sleep()
                            atomic_dec_and_test()
                            uprobe_clear_state()
                            exit_aio()
                            ksm_exit()
                            khugepaged_exit()
                            exit_mmap()
                            set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                rcu_dereference_raw()
                                get_file()
                                rcu_assign_pointer()
                                fput()
                            list_empty()
                            spin_lock()
                            list_del()
                            spin_unlock()
                            module_put() <void module_put (struct module *module) at module.c:1098>:
                                preempt_disable()
                                atomic_dec_if_positive()
                                WARN_ON()
                                trace_module_put()
                                preempt_enable()
                            mmdrop()
                        test_thread_flag()
                        exit_oom_victim()
                    acct_process() <void acct_process (void) at acct.c:587>:
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        unlikely()
                        slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                            acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                                smp_rmb()
                                rcu_read_lock()
                                to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                                    container_of()
                                ACCESS_ONCE()
                                rcu_read_unlock()
                                atomic_long_inc_not_zero()
                                cpu_relax()
                                mutex_lock()
                                mutex_unlock()
                                acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                                    atomic_long_dec_and_test()
                                    kfree_rcu()
                            do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                                override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                                    kdebug()
                                    atomic_read()
                                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                        atomic_read()
                                    validate_creds()
                                    get_cred()
                                    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                        atomic_add()
                                    rcu_assign_pointer()
                                check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                                    time_is_before_jiffies()
                                    vfs_statfs()
                                    do_div()
                                    pr_info()
                                fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                                    strlcpy()
                                    ktime_get_ns()
                                    nsec_to_AHZ()
                                    encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                                    encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                                    encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                                    do_div()
                                    get_seconds()
                                    spin_lock_irq()
                                    old_encode_dev()
                                    tty_devnum()
                                    jiffies_to_AHZ()
                                    cputime_to_jiffies()
                                    spin_unlock_irq()
                                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                            smp_rmb()
                                from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                                    from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                            smp_rmb()
                                task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                    pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                    task_tgid()
                                rcu_read_lock()
                                rcu_dereference()
                                rcu_read_unlock()
                                file_start_write_trylock()
                                file_end_write()
                                revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                                    kdebug()
                                    atomic_read()
                                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                        atomic_read()
                                    validate_creds()
                                    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                        atomic_add()
                                    rcu_assign_pointer()
                                    put_cred()
                            mutex_unlock()
                            acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                                atomic_long_dec_and_test()
                                kfree_rcu()
                    trace_sched_process_exit()
                    exit_sem()
                    exit_shm()
                    exit_files()
                    exit_fs()
                    disassociate_ctty()
                    exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
                        switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                            might_sleep()
                            task_lock()
                            task_unlock()
                            atomic_dec_and_test()
                            free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                                put_mnt_ns()
                                put_uts_ns()
                                put_ipc_ns()
                                put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                                    kref_put()
                                    free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                        container_of()
                                        destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                            ns_free_inum()
                                            kfree()
                                            put_user_ns()
                                            call_rcu()
                                            delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                                kmem_cache_free()
                                                container_of()
                                put_net()
                                kmem_cache_free()
                    exit_task_work()
                    exit_thread()
                    perf_event_exit_task()
                    cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
                        task_css_set()
                        list_empty()
                        spin_lock_bh()
                        css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                            lockdep_assert_held()
                            WARN_ON_ONCE()
                            list_empty()
                            list_for_each_entry_safe()
                            css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                                lockdep_assert_held()
                                WARN_ON_ONCE()
                                css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                                    lockdep_assert_held()
                                    container_of()
                                    list_entry()
                                    css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                        lockdep_assert_held()
                                        list_empty()
                                    list_empty()
                                    list_del()
                                    put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                                        lockdep_assert_held()
                                        atomic_dec_and_test()
                                        for_each_subsys()
                                        list_del()
                                        css_put()
                                        hash_del()
                                        list_for_each_entry_safe()
                                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                            container_of()
                                        cgroup_put()
                                        kfree()
                                        kfree_rcu()
                                    get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                        atomic_inc()
                                    list_add()
                            list_del_init()
                            css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                lockdep_assert_held()
                                list_empty()
                            css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                                lockdep_assert_held()
                                list_for_each_entry()
                                cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                                    lockdep_assert_held()
                                    check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                                        notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                            test_bit()
                                        cgroup_is_populated()
                                        css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                            rcu_read_lock()
                                            css_for_each_child()
                                            rcu_read_unlock()
                                        cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                                        schedule_work()
                                    cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                                        spin_lock_irqsave()
                                        kernfs_notify()
                                        spin_unlock_irqrestore()
                                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                        container_of()
                            rcu_assign_pointer()
                            list_add_tail()
                        spin_unlock_bh()
                        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                            atomic_inc()
                        for_each_subsys_which()
                    flush_ptrace_hw_breakpoint()
                    preempt_disable()
                    preempt_enable()
                    exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
                        LIST_HEAD()
                        write_lock_irq()
                        forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                            unlikely()
                            list_empty()
                            exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                                list_for_each_entry_safe()
                                unlikely()
                                send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                                    valid_signal()
                                    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                        lock_task_sighand()
                                        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                                SI_FROMUSER()
                                            task_pid_nr_ns()
                                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                ns_of_pid()
                                                task_pid()
                                        unlock_task_sighand()
                                list_add()
                            find_child_reaper()
                            find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                                find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                                    for_each_thread()
                                same_thread_group()
                            list_for_each_entry()
                            for_each_thread()
                            BUG_ON()
                            likely()
                            group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                                rcu_read_lock()
                                check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                                    valid_signal()
                                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                        SI_FROMUSER()
                                    audit_signal_info()
                                    same_thread_group()
                                    kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                                        current_cred()
                                        uid_eq()
                                        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                            unlikely()
                                            cap_valid()
                                            pr_crit()
                                            BUG()
                                            security_capable()
                                            current_cred()
                                    task_session()
                                    security_task_kill()
                                rcu_read_unlock()
                                do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                    lock_task_sighand()
                                    send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                            SI_FROMUSER()
                                        task_pid_nr_ns()
                                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                            ns_of_pid()
                                            task_pid()
                                    unlock_task_sighand()
                            same_thread_group()
                            reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                                unlikely()
                                thread_group_empty()
                                do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                                    BUG_ON()
                                    task_is_stopped_or_traced()
                                    thread_group_empty()
                                    rcu_read_lock()
                                    task_pid_nr_ns()
                                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                        ns_of_pid()
                                        task_pid()
                                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                smp_rmb()
                                    task_cred_xxx()
                                    task_uid()
                                    rcu_read_unlock()
                                    task_cputime()
                                    cputime_to_clock_t()
                                    spin_lock_irqsave()
                                    valid_signal()
                                    spin_unlock_irqrestore()
                                list_add()
                                kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                                    task_pgrp()
                                    task_session()
                                    will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                                        do_each_pid_task()
                                        thread_group_empty()
                                        is_global_init()
                                        task_pgrp()
                                        task_session()
                                        while_each_pid_task()
                                    has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                                        do_each_pid_task()
                                        while_each_pid_task()
                            list_splice_tail_init()
                        kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                            task_pgrp()
                            task_session()
                            will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                                do_each_pid_task()
                                thread_group_empty()
                                is_global_init()
                                task_pgrp()
                                task_session()
                                while_each_pid_task()
                            has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                                do_each_pid_task()
                                while_each_pid_task()
                        unlikely()
                        thread_group_leader()
                        thread_group_empty()
                        ptrace_reparented()
                        do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                            BUG_ON()
                            task_is_stopped_or_traced()
                            thread_group_empty()
                            rcu_read_lock()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            task_cred_xxx()
                            task_uid()
                            rcu_read_unlock()
                            task_cputime()
                            cputime_to_clock_t()
                            spin_lock_irqsave()
                            valid_signal()
                            spin_unlock_irqrestore()
                        list_add()
                        wake_up_process()
                        write_unlock_irq()
                        list_for_each_entry_safe()
                        list_del_init()
                        release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                            rcu_read_lock()
                            atomic_dec()
                            rcu_read_unlock()
                            proc_flush_task()
                            write_lock_irq()
                            ptrace_release_task()
                            thread_group_empty()
                            do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                                BUG_ON()
                                task_is_stopped_or_traced()
                                thread_group_empty()
                                rcu_read_lock()
                                task_pid_nr_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                            smp_rmb()
                                task_cred_xxx()
                                task_uid()
                                rcu_read_unlock()
                                task_cputime()
                                cputime_to_clock_t()
                                spin_lock_irqsave()
                                valid_signal()
                                spin_unlock_irqrestore()
                            write_unlock_irq()
                            release_thread()
                            call_rcu()
                            delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                                container_of()
                                perf_event_delayed_put()
                                trace_sched_process_free()
                                put_task_struct()
                            unlikely()
                    proc_exit_connector()
                    task_lock()
                    mpol_put()
                    task_unlock()
                    kfree()
                    debug_check_no_locks_held()
                    exit_io_context()
                    free_pipe_info()
                    put_page()
                    check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
                        stack_not_used()
                        spin_lock()
                        pr_warn()
                        task_pid_nr()
                        spin_unlock()
                    exit_rcu()
                    BUG()
                    cpu_relax()
            umh_complete() <void umh_complete (struct subprocess_info *sub_info) at kmod.c:198>:
                xchg()
                complete()
                call_usermodehelper_freeinfo() <void call_usermodehelper_freeinfo (struct subprocess_info *info) at kmod.c:191>:
                    kfree()
    call_usermodehelper_exec() <int call_usermodehelper_exec (struct subprocess_info *sub_info, int wait) at kmod.c:555>:
        DECLARE_COMPLETION_ONSTACK()
        call_usermodehelper_freeinfo() <void call_usermodehelper_freeinfo (struct subprocess_info *info) at kmod.c:191>:
            kfree()
        helper_lock() <void helper_lock (void) at kmod.c:484>:
            atomic_inc()
            smp_mb__after_atomic()
        queue_work()
        wait_for_completion_killable()
        xchg()
        wait_for_completion()
        helper_unlock() <void helper_unlock (void) at kmod.c:490>:
            atomic_dec_and_test()
            wake_up()
call_usermodehelper_exec() <int call_usermodehelper_exec (struct subprocess_info *sub_info, int wait) at kmod.c:555>:
    DECLARE_COMPLETION_ONSTACK()
    call_usermodehelper_freeinfo() <void call_usermodehelper_freeinfo (struct subprocess_info *info) at kmod.c:191>:
        kfree()
    helper_lock() <void helper_lock (void) at kmod.c:484>:
        atomic_inc()
        smp_mb__after_atomic()
    queue_work()
    wait_for_completion_killable()
    xchg()
    wait_for_completion()
    helper_unlock() <void helper_unlock (void) at kmod.c:490>:
        atomic_dec_and_test()
        wake_up()
call_usermodehelper_setup() <struct subprocess_info *call_usermodehelper_setup (char *path, char **argv, char **envp, gfp_t gfp_mask, int (*init) (struct subprocess_info *info, struct cred *new), void (*cleanup) (struct subprocess_info *info), void *data) at kmod.c:519>:
    kzalloc()
    INIT_WORK()
    call_usermodehelper_exec_work() <void call_usermodehelper_exec_work (struct work_struct *work) at kmod.c:321>:
        container_of()
        call_usermodehelper_exec_sync() <void call_usermodehelper_exec_sync (struct subprocess_info *sub_info) at kmod.c:269>:
            kernel_sigaction() <void kernel_sigaction (int sig, __sighandler_t action) at signal.c:3029>:
                spin_lock_irq()
                flush_sigqueue_mask() <int flush_sigqueue_mask (sigset_t *mask, struct sigpending *s) at signal.c:659>:
                    sigandsets()
                    sigisemptyset()
                    sigandnsets()
                    list_for_each_entry_safe()
                    list_del_init()
                recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
                    recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                        PENDING()
                        set_tsk_thread_flag()
                    freezing()
                    clear_thread_flag()
                spin_unlock_irq()
            kernel_thread() <pid_t kernel_thread (int (*fn) (void *), void *arg, unsigned long flags) at fork.c:1779>:
            call_usermodehelper_exec_async() <int call_usermodehelper_exec_async (void *data) at kmod.c:215>:
                spin_lock_irq()
                flush_signal_handlers() <void flush_signal_handlers (struct task_struct *t, int force_default) at signal.c:479>:
                spin_unlock_irq()
                set_user_nice()
                prepare_kernel_cred() <struct cred *prepare_kernel_cred (struct task_struct *daemon) at cred.c:594>:
                    kmem_cache_alloc()
                    kdebug()
                    get_task_cred() <const struct cred *get_task_cred (struct task_struct *task) at cred.c:187>:
                        rcu_read_lock()
                        BUG_ON()
                        atomic_inc_not_zero()
                        rcu_read_unlock()
                    get_cred()
                    validate_creds()
                    atomic_set()
                    set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
                        atomic_set()
                    get_uid()
                    get_user_ns()
                    get_group_info()
                    security_prepare_creds()
                    put_cred()
                spin_lock()
                cap_intersect()
                spin_unlock()
                abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
                    kdebug()
                    atomic_read()
                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                        atomic_read()
                    BUG_ON()
                    put_cred()
                commit_creds() <int commit_creds (struct cred *new) at cred.c:422>:
                    kdebug()
                    atomic_read()
                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                        atomic_read()
                    BUG_ON()
                    validate_creds()
                    get_cred()
                    uid_eq()
                    gid_eq()
                    cred_cap_issubset() <bool cred_cap_issubset (const struct cred *set, const struct cred *subset) at cred.c:383>:
                        cap_issubset()
                        uid_eq()
                    set_dumpable()
                    smp_wmb()
                    key_fsuid_changed()
                    key_fsgid_changed()
                    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                        atomic_add()
                    atomic_inc()
                    rcu_assign_pointer()
                    atomic_dec()
                    proc_id_connector()
                    put_cred()
                do_execve()
                getname_kernel()
                umh_complete() <void umh_complete (struct subprocess_info *sub_info) at kmod.c:198>:
                    xchg()
                    complete()
                    call_usermodehelper_freeinfo() <void call_usermodehelper_freeinfo (struct subprocess_info *info) at kmod.c:191>:
                        kfree()
                do_exit() <void do_exit (long code) at exit.c:651>:
                    TASKS_RCU()
                    profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
                        blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
                    WARN_ON()
                    blk_needs_flush_plug()
                    unlikely()
                    in_interrupt()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    set_fs()
                    ptrace_event()
                    validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                    pr_alert()
                    set_current_state()
                    schedule()
                    exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
                        threadgroup_change_begin()
                        thread_group_empty()
                        signal_group_exit()
                        threadgroup_change_end()
                        spin_lock_irq()
                        signal_pending()
                        signotset()
                        retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                            sigandsets()
                            sigisemptyset()
                            while_each_thread()
                            has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                            signal_pending()
                            signal_wake_up()
                        unlikely()
                        task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                            WARN_ON_ONCE()
                            task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                                BUG_ON()
                                task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                                    unlikely()
                                    smp_mb()
                                    wake_up_bit()
                        spin_unlock_irq()
                        read_lock()
                        do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                            rcu_read_lock()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            task_cred_xxx()
                            task_uid()
                            rcu_read_unlock()
                            task_cputime()
                            cputime_to_clock_t()
                            BUG()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                        read_unlock()
                    smp_mb()
                    raw_spin_unlock_wait()
                    in_atomic()
                    pr_info()
                    task_pid_nr()
                    preempt_count()
                    preempt_count_set()
                    sync_mm_rss()
                    acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
                        task_cputime()
                    atomic_dec_and_test()
                    hrtimer_cancel()
                    exit_itimers()
                    setmax_mm_hiwater_rss()
                    acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
                        down_read()
                        up_read()
                        spin_lock_irq()
                        thread_group_leader()
                        task_cputime()
                        spin_unlock_irq()
                    tty_audit_exit()
                    audit_free()
                    taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
                        taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                            nla_total_size()
                        taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                            thread_group_empty()
                            kmem_cache_zalloc()
                            spin_lock_irq()
                            spin_unlock_irq()
                            kmem_cache_free()
                        fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                            spin_lock_irqsave()
                            delayacct_add_tsk()
                            spin_unlock_irqrestore()
                        raw_cpu_ptr()
                        list_empty()
                        prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                            genlmsg_new()
                            this_cpu_inc_return()
                            genlmsg_put()
                            genlmsg_put_reply()
                            nlmsg_free()
                        mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                            nla_put()
                            nla_nest_start()
                            nla_nest_cancel()
                            nla_reserve()
                            nla_nest_end()
                            nla_data()
                        task_pid_nr_ns()
                        fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                            delayacct_add_tsk()
                            bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                                BUILD_BUG_ON()
                                ktime_get_ns()
                                do_div()
                                get_seconds()
                                thread_group_leader()
                                task_nice()
                                task_pid_nr_ns()
                                rcu_read_lock()
                                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                            smp_rmb()
                                from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                                    from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                            smp_rmb()
                                pid_alive()
                                task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                    pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                    task_tgid()
                                rcu_dereference()
                                rcu_read_unlock()
                                task_cputime()
                                cputime_to_usecs()
                                task_cputime_scaled()
                            xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                    task_lock()
                                    atomic_inc()
                                    task_unlock()
                                get_mm_hiwater_rss()
                                get_mm_hiwater_vm()
                                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                    might_sleep()
                                    atomic_dec_and_test()
                                    uprobe_clear_state()
                                    exit_aio()
                                    ksm_exit()
                                    khugepaged_exit()
                                    exit_mmap()
                                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                        rcu_dereference_raw()
                                        get_file()
                                        rcu_assign_pointer()
                                        fput()
                                    list_empty()
                                    spin_lock()
                                    list_del()
                                    spin_unlock()
                                    module_put() <void module_put (struct module *module) at module.c:1098>:
                                        preempt_disable()
                                        atomic_dec_if_positive()
                                        WARN_ON()
                                        trace_module_put()
                                        preempt_enable()
                                    mmdrop()
                        task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                            pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                            task_tgid()
                        send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                            nlmsg_data()
                            nlmsg_hdr()
                            genlmsg_data()
                            genlmsg_end()
                            down_read()
                            list_for_each_entry()
                            list_is_last()
                            skb_clone()
                            genlmsg_unicast()
                            up_read()
                            nlmsg_free()
                            down_write()
                            list_for_each_entry_safe()
                            list_del()
                            kfree()
                            up_write()
                        nlmsg_free()
                    exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
                        mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                            unlikely()
                            exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                                uninitialized_var()
                                fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                                    get_user()
                                get_user()
                                handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                                    uninitialized_var()
                                    get_user()
                                    task_pid_vnr()
                                    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                        pagefault_disable()
                                        futex_atomic_cmpxchg_inatomic()
                                        pagefault_enable()
                                    fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                        down_read()
                                        fixup_user_fault()
                                        up_read()
                                    futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                        WAKE_Q()
                                        get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                            unlikely()
                                            access_ok()
                                            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                                should_fail()
                                            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                                ihold()
                                                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                                    atomic_inc()
                                                    smp_mb__after_atomic()
                                                smp_mb()
                                            get_user_pages_fast()
                                            lock_page()
                                            compound_head()
                                            PageSwapCache()
                                            unlock_page()
                                            put_page()
                                            PageAnon()
                                            basepage_index()
                                        unlikely()
                                        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                            jhash2()
                                        hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                            atomic_read()
                                        spin_lock()
                                        plist_for_each_entry_safe()
                                        match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                        mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                            WARN()
                                            wake_q_add()
                                            smp_wmb()
                                        spin_unlock()
                                        wake_up_q()
                                        put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                                WARN_ON_ONCE()
                                                iput()
                                                mmdrop()
                                cond_resched()
                            compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                                uninitialized_var()
                                fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                                    get_user()
                                    compat_ptr()
                                get_user()
                                futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                                    ptr_to_compat()
                                    compat_ptr()
                                handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                                    uninitialized_var()
                                    get_user()
                                    task_pid_vnr()
                                    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                        pagefault_disable()
                                        futex_atomic_cmpxchg_inatomic()
                                        pagefault_enable()
                                    fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                        down_read()
                                        fixup_user_fault()
                                        up_read()
                                    futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                        WAKE_Q()
                                        get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                            unlikely()
                                            access_ok()
                                            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                                should_fail()
                                            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                                ihold()
                                                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                                    atomic_inc()
                                                    smp_mb__after_atomic()
                                                smp_mb()
                                            get_user_pages_fast()
                                            lock_page()
                                            compound_head()
                                            PageSwapCache()
                                            unlock_page()
                                            put_page()
                                            PageAnon()
                                            basepage_index()
                                        unlikely()
                                        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                            jhash2()
                                        hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                            atomic_read()
                                        spin_lock()
                                        plist_for_each_entry_safe()
                                        match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                        mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                            WARN()
                                            wake_q_add()
                                            smp_wmb()
                                        spin_unlock()
                                        wake_up_q()
                                        put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                                WARN_ON_ONCE()
                                                iput()
                                                mmdrop()
                                cond_resched()
                            list_empty()
                            exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                                raw_spin_lock_irq()
                                list_empty()
                                list_entry()
                                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                    jhash2()
                                raw_spin_unlock_irq()
                                spin_lock()
                                spin_unlock()
                                WARN_ON()
                                list_del_init()
                                rt_mutex_unlock()
                            uprobe_free_utask()
                            deactivate_mm()
                            atomic_read()
                            put_user()
                            sys_futex()
                            complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                                task_lock()
                                likely()
                                complete()
                                task_unlock()
                        sync_mm_rss()
                        down_read()
                        up_read()
                        xchg()
                        atomic_dec_and_test()
                        complete()
                        set_task_state()
                        freezable_schedule()
                        atomic_inc()
                        BUG_ON()
                        task_lock()
                        enter_lazy_tlb()
                        task_unlock()
                        mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                            atomic_read()
                            read_lock()
                            list_for_each_entry()
                            for_each_process()
                            for_each_thread()
                            read_unlock()
                            BUG_ON()
                            get_task_struct()
                            task_lock()
                            task_unlock()
                            put_task_struct()
                        mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                            might_sleep()
                            atomic_dec_and_test()
                            uprobe_clear_state()
                            exit_aio()
                            ksm_exit()
                            khugepaged_exit()
                            exit_mmap()
                            set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                rcu_dereference_raw()
                                get_file()
                                rcu_assign_pointer()
                                fput()
                            list_empty()
                            spin_lock()
                            list_del()
                            spin_unlock()
                            module_put() <void module_put (struct module *module) at module.c:1098>:
                                preempt_disable()
                                atomic_dec_if_positive()
                                WARN_ON()
                                trace_module_put()
                                preempt_enable()
                            mmdrop()
                        test_thread_flag()
                        exit_oom_victim()
                    acct_process() <void acct_process (void) at acct.c:587>:
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        unlikely()
                        slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                            acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                                smp_rmb()
                                rcu_read_lock()
                                to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                                    container_of()
                                ACCESS_ONCE()
                                rcu_read_unlock()
                                atomic_long_inc_not_zero()
                                cpu_relax()
                                mutex_lock()
                                mutex_unlock()
                                acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                                    atomic_long_dec_and_test()
                                    kfree_rcu()
                            do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                                override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                                    kdebug()
                                    atomic_read()
                                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                        atomic_read()
                                    validate_creds()
                                    get_cred()
                                    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                        atomic_add()
                                    rcu_assign_pointer()
                                check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                                    time_is_before_jiffies()
                                    vfs_statfs()
                                    do_div()
                                    pr_info()
                                fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                                    strlcpy()
                                    ktime_get_ns()
                                    nsec_to_AHZ()
                                    encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                                    encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                                    encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                                    do_div()
                                    get_seconds()
                                    spin_lock_irq()
                                    old_encode_dev()
                                    tty_devnum()
                                    jiffies_to_AHZ()
                                    cputime_to_jiffies()
                                    spin_unlock_irq()
                                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                            smp_rmb()
                                from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                                    from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                            smp_rmb()
                                task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                    pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                    task_tgid()
                                rcu_read_lock()
                                rcu_dereference()
                                rcu_read_unlock()
                                file_start_write_trylock()
                                file_end_write()
                                revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                                    kdebug()
                                    atomic_read()
                                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                        atomic_read()
                                    validate_creds()
                                    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                        atomic_add()
                                    rcu_assign_pointer()
                                    put_cred()
                            mutex_unlock()
                            acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                                atomic_long_dec_and_test()
                                kfree_rcu()
                    trace_sched_process_exit()
                    exit_sem()
                    exit_shm()
                    exit_files()
                    exit_fs()
                    disassociate_ctty()
                    exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
                        switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                            might_sleep()
                            task_lock()
                            task_unlock()
                            atomic_dec_and_test()
                            free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                                put_mnt_ns()
                                put_uts_ns()
                                put_ipc_ns()
                                put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                                    kref_put()
                                    free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                        container_of()
                                        destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                            ns_free_inum()
                                            kfree()
                                            put_user_ns()
                                            call_rcu()
                                            delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                                kmem_cache_free()
                                                container_of()
                                put_net()
                                kmem_cache_free()
                    exit_task_work()
                    exit_thread()
                    perf_event_exit_task()
                    cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
                        task_css_set()
                        list_empty()
                        spin_lock_bh()
                        css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                            lockdep_assert_held()
                            WARN_ON_ONCE()
                            list_empty()
                            list_for_each_entry_safe()
                            css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                                lockdep_assert_held()
                                WARN_ON_ONCE()
                                css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                                    lockdep_assert_held()
                                    container_of()
                                    list_entry()
                                    css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                        lockdep_assert_held()
                                        list_empty()
                                    list_empty()
                                    list_del()
                                    put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                                        lockdep_assert_held()
                                        atomic_dec_and_test()
                                        for_each_subsys()
                                        list_del()
                                        css_put()
                                        hash_del()
                                        list_for_each_entry_safe()
                                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                            container_of()
                                        cgroup_put()
                                        kfree()
                                        kfree_rcu()
                                    get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                        atomic_inc()
                                    list_add()
                            list_del_init()
                            css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                lockdep_assert_held()
                                list_empty()
                            css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                                lockdep_assert_held()
                                list_for_each_entry()
                                cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                                    lockdep_assert_held()
                                    check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                                        notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                            test_bit()
                                        cgroup_is_populated()
                                        css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                            rcu_read_lock()
                                            css_for_each_child()
                                            rcu_read_unlock()
                                        cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                                        schedule_work()
                                    cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                                        spin_lock_irqsave()
                                        kernfs_notify()
                                        spin_unlock_irqrestore()
                                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                        container_of()
                            rcu_assign_pointer()
                            list_add_tail()
                        spin_unlock_bh()
                        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                            atomic_inc()
                        for_each_subsys_which()
                    flush_ptrace_hw_breakpoint()
                    preempt_disable()
                    preempt_enable()
                    exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
                        LIST_HEAD()
                        write_lock_irq()
                        forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                            unlikely()
                            list_empty()
                            exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                                list_for_each_entry_safe()
                                unlikely()
                                send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                                    valid_signal()
                                    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                        lock_task_sighand()
                                        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                                SI_FROMUSER()
                                            task_pid_nr_ns()
                                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                ns_of_pid()
                                                task_pid()
                                        unlock_task_sighand()
                                list_add()
                            find_child_reaper()
                            find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                                find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                                    for_each_thread()
                                same_thread_group()
                            list_for_each_entry()
                            for_each_thread()
                            BUG_ON()
                            likely()
                            group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                                rcu_read_lock()
                                check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                                    valid_signal()
                                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                        SI_FROMUSER()
                                    audit_signal_info()
                                    same_thread_group()
                                    kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                                        current_cred()
                                        uid_eq()
                                        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                            unlikely()
                                            cap_valid()
                                            pr_crit()
                                            BUG()
                                            security_capable()
                                            current_cred()
                                    task_session()
                                    security_task_kill()
                                rcu_read_unlock()
                                do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                    lock_task_sighand()
                                    send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                            SI_FROMUSER()
                                        task_pid_nr_ns()
                                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                            ns_of_pid()
                                            task_pid()
                                    unlock_task_sighand()
                            same_thread_group()
                            reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                                unlikely()
                                thread_group_empty()
                                do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                                    BUG_ON()
                                    task_is_stopped_or_traced()
                                    thread_group_empty()
                                    rcu_read_lock()
                                    task_pid_nr_ns()
                                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                        ns_of_pid()
                                        task_pid()
                                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                smp_rmb()
                                    task_cred_xxx()
                                    task_uid()
                                    rcu_read_unlock()
                                    task_cputime()
                                    cputime_to_clock_t()
                                    spin_lock_irqsave()
                                    valid_signal()
                                    spin_unlock_irqrestore()
                                list_add()
                                kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                                    task_pgrp()
                                    task_session()
                                    will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                                        do_each_pid_task()
                                        thread_group_empty()
                                        is_global_init()
                                        task_pgrp()
                                        task_session()
                                        while_each_pid_task()
                                    has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                                        do_each_pid_task()
                                        while_each_pid_task()
                            list_splice_tail_init()
                        kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                            task_pgrp()
                            task_session()
                            will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                                do_each_pid_task()
                                thread_group_empty()
                                is_global_init()
                                task_pgrp()
                                task_session()
                                while_each_pid_task()
                            has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                                do_each_pid_task()
                                while_each_pid_task()
                        unlikely()
                        thread_group_leader()
                        thread_group_empty()
                        ptrace_reparented()
                        do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                            BUG_ON()
                            task_is_stopped_or_traced()
                            thread_group_empty()
                            rcu_read_lock()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            task_cred_xxx()
                            task_uid()
                            rcu_read_unlock()
                            task_cputime()
                            cputime_to_clock_t()
                            spin_lock_irqsave()
                            valid_signal()
                            spin_unlock_irqrestore()
                        list_add()
                        wake_up_process()
                        write_unlock_irq()
                        list_for_each_entry_safe()
                        list_del_init()
                        release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                            rcu_read_lock()
                            atomic_dec()
                            rcu_read_unlock()
                            proc_flush_task()
                            write_lock_irq()
                            ptrace_release_task()
                            thread_group_empty()
                            do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                                BUG_ON()
                                task_is_stopped_or_traced()
                                thread_group_empty()
                                rcu_read_lock()
                                task_pid_nr_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                            smp_rmb()
                                task_cred_xxx()
                                task_uid()
                                rcu_read_unlock()
                                task_cputime()
                                cputime_to_clock_t()
                                spin_lock_irqsave()
                                valid_signal()
                                spin_unlock_irqrestore()
                            write_unlock_irq()
                            release_thread()
                            call_rcu()
                            delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                                container_of()
                                perf_event_delayed_put()
                                trace_sched_process_free()
                                put_task_struct()
                            unlikely()
                    proc_exit_connector()
                    task_lock()
                    mpol_put()
                    task_unlock()
                    kfree()
                    debug_check_no_locks_held()
                    exit_io_context()
                    free_pipe_info()
                    put_page()
                    check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
                        stack_not_used()
                        spin_lock()
                        pr_warn()
                        task_pid_nr()
                        spin_unlock()
                    exit_rcu()
                    BUG()
                    cpu_relax()
            sys_wait4()
            umh_complete() <void umh_complete (struct subprocess_info *sub_info) at kmod.c:198>:
                xchg()
                complete()
                call_usermodehelper_freeinfo() <void call_usermodehelper_freeinfo (struct subprocess_info *info) at kmod.c:191>:
                    kfree()
        kernel_thread() <pid_t kernel_thread (int (*fn) (void *), void *arg, unsigned long flags) at fork.c:1779>:
        call_usermodehelper_exec_async() <int call_usermodehelper_exec_async (void *data) at kmod.c:215>:
            spin_lock_irq()
            flush_signal_handlers() <void flush_signal_handlers (struct task_struct *t, int force_default) at signal.c:479>:
            spin_unlock_irq()
            set_user_nice()
            prepare_kernel_cred() <struct cred *prepare_kernel_cred (struct task_struct *daemon) at cred.c:594>:
                kmem_cache_alloc()
                kdebug()
                get_task_cred() <const struct cred *get_task_cred (struct task_struct *task) at cred.c:187>:
                    rcu_read_lock()
                    BUG_ON()
                    atomic_inc_not_zero()
                    rcu_read_unlock()
                get_cred()
                validate_creds()
                atomic_set()
                set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
                    atomic_set()
                get_uid()
                get_user_ns()
                get_group_info()
                security_prepare_creds()
                put_cred()
            spin_lock()
            cap_intersect()
            spin_unlock()
            abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
                kdebug()
                atomic_read()
                read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                    atomic_read()
                BUG_ON()
                put_cred()
            commit_creds() <int commit_creds (struct cred *new) at cred.c:422>:
                kdebug()
                atomic_read()
                read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                    atomic_read()
                BUG_ON()
                validate_creds()
                get_cred()
                uid_eq()
                gid_eq()
                cred_cap_issubset() <bool cred_cap_issubset (const struct cred *set, const struct cred *subset) at cred.c:383>:
                    cap_issubset()
                    uid_eq()
                set_dumpable()
                smp_wmb()
                key_fsuid_changed()
                key_fsgid_changed()
                alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                    atomic_add()
                atomic_inc()
                rcu_assign_pointer()
                atomic_dec()
                proc_id_connector()
                put_cred()
            do_execve()
            getname_kernel()
            umh_complete() <void umh_complete (struct subprocess_info *sub_info) at kmod.c:198>:
                xchg()
                complete()
                call_usermodehelper_freeinfo() <void call_usermodehelper_freeinfo (struct subprocess_info *info) at kmod.c:191>:
                    kfree()
            do_exit() <void do_exit (long code) at exit.c:651>:
                TASKS_RCU()
                profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
                    blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
                WARN_ON()
                blk_needs_flush_plug()
                unlikely()
                in_interrupt()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
                set_fs()
                ptrace_event()
                validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
                    kdebug()
                    atomic_read()
                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                        atomic_read()
                pr_alert()
                set_current_state()
                schedule()
                exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
                    threadgroup_change_begin()
                    thread_group_empty()
                    signal_group_exit()
                    threadgroup_change_end()
                    spin_lock_irq()
                    signal_pending()
                    signotset()
                    retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                        sigandsets()
                        sigisemptyset()
                        while_each_thread()
                        has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                        signal_pending()
                        signal_wake_up()
                    unlikely()
                    task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                        WARN_ON_ONCE()
                        task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                            BUG_ON()
                            task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                                unlikely()
                                smp_mb()
                                wake_up_bit()
                    spin_unlock_irq()
                    read_lock()
                    do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        BUG()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                    read_unlock()
                smp_mb()
                raw_spin_unlock_wait()
                in_atomic()
                pr_info()
                task_pid_nr()
                preempt_count()
                preempt_count_set()
                sync_mm_rss()
                acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
                    task_cputime()
                atomic_dec_and_test()
                hrtimer_cancel()
                exit_itimers()
                setmax_mm_hiwater_rss()
                acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
                    down_read()
                    up_read()
                    spin_lock_irq()
                    thread_group_leader()
                    task_cputime()
                    spin_unlock_irq()
                tty_audit_exit()
                audit_free()
                taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
                    taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                        nla_total_size()
                    taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                        thread_group_empty()
                        kmem_cache_zalloc()
                        spin_lock_irq()
                        spin_unlock_irq()
                        kmem_cache_free()
                    fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                        spin_lock_irqsave()
                        delayacct_add_tsk()
                        spin_unlock_irqrestore()
                    raw_cpu_ptr()
                    list_empty()
                    prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                        genlmsg_new()
                        this_cpu_inc_return()
                        genlmsg_put()
                        genlmsg_put_reply()
                        nlmsg_free()
                    mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                        nla_put()
                        nla_nest_start()
                        nla_nest_cancel()
                        nla_reserve()
                        nla_nest_end()
                        nla_data()
                    task_pid_nr_ns()
                    fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                        delayacct_add_tsk()
                        bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                            BUILD_BUG_ON()
                            ktime_get_ns()
                            do_div()
                            get_seconds()
                            thread_group_leader()
                            task_nice()
                            task_pid_nr_ns()
                            rcu_read_lock()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                                from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            pid_alive()
                            task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                task_tgid()
                            rcu_dereference()
                            rcu_read_unlock()
                            task_cputime()
                            cputime_to_usecs()
                            task_cputime_scaled()
                        xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                            get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                task_lock()
                                atomic_inc()
                                task_unlock()
                            get_mm_hiwater_rss()
                            get_mm_hiwater_vm()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                        task_tgid()
                    send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                        nlmsg_data()
                        nlmsg_hdr()
                        genlmsg_data()
                        genlmsg_end()
                        down_read()
                        list_for_each_entry()
                        list_is_last()
                        skb_clone()
                        genlmsg_unicast()
                        up_read()
                        nlmsg_free()
                        down_write()
                        list_for_each_entry_safe()
                        list_del()
                        kfree()
                        up_write()
                    nlmsg_free()
                exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
                    mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                        unlikely()
                        exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                            uninitialized_var()
                            fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                                get_user()
                            get_user()
                            handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                                uninitialized_var()
                                get_user()
                                task_pid_vnr()
                                cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                    pagefault_disable()
                                    futex_atomic_cmpxchg_inatomic()
                                    pagefault_enable()
                                fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                    down_read()
                                    fixup_user_fault()
                                    up_read()
                                futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                    WAKE_Q()
                                    get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                        unlikely()
                                        access_ok()
                                        should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                            should_fail()
                                        get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                            ihold()
                                            futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                                atomic_inc()
                                                smp_mb__after_atomic()
                                            smp_mb()
                                        get_user_pages_fast()
                                        lock_page()
                                        compound_head()
                                        PageSwapCache()
                                        unlock_page()
                                        put_page()
                                        PageAnon()
                                        basepage_index()
                                    unlikely()
                                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                        jhash2()
                                    hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                        atomic_read()
                                    spin_lock()
                                    plist_for_each_entry_safe()
                                    match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                    mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                        WARN()
                                        wake_q_add()
                                        smp_wmb()
                                    spin_unlock()
                                    wake_up_q()
                                    put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                        drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                            WARN_ON_ONCE()
                                            iput()
                                            mmdrop()
                            cond_resched()
                        compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                            uninitialized_var()
                            fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                                get_user()
                                compat_ptr()
                            get_user()
                            futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                                ptr_to_compat()
                                compat_ptr()
                            handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                                uninitialized_var()
                                get_user()
                                task_pid_vnr()
                                cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                    pagefault_disable()
                                    futex_atomic_cmpxchg_inatomic()
                                    pagefault_enable()
                                fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                    down_read()
                                    fixup_user_fault()
                                    up_read()
                                futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                    WAKE_Q()
                                    get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                        unlikely()
                                        access_ok()
                                        should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                            should_fail()
                                        get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                            ihold()
                                            futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                                atomic_inc()
                                                smp_mb__after_atomic()
                                            smp_mb()
                                        get_user_pages_fast()
                                        lock_page()
                                        compound_head()
                                        PageSwapCache()
                                        unlock_page()
                                        put_page()
                                        PageAnon()
                                        basepage_index()
                                    unlikely()
                                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                        jhash2()
                                    hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                        atomic_read()
                                    spin_lock()
                                    plist_for_each_entry_safe()
                                    match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                    mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                        WARN()
                                        wake_q_add()
                                        smp_wmb()
                                    spin_unlock()
                                    wake_up_q()
                                    put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                        drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                            WARN_ON_ONCE()
                                            iput()
                                            mmdrop()
                            cond_resched()
                        list_empty()
                        exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                            raw_spin_lock_irq()
                            list_empty()
                            list_entry()
                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                jhash2()
                            raw_spin_unlock_irq()
                            spin_lock()
                            spin_unlock()
                            WARN_ON()
                            list_del_init()
                            rt_mutex_unlock()
                        uprobe_free_utask()
                        deactivate_mm()
                        atomic_read()
                        put_user()
                        sys_futex()
                        complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                            task_lock()
                            likely()
                            complete()
                            task_unlock()
                    sync_mm_rss()
                    down_read()
                    up_read()
                    xchg()
                    atomic_dec_and_test()
                    complete()
                    set_task_state()
                    freezable_schedule()
                    atomic_inc()
                    BUG_ON()
                    task_lock()
                    enter_lazy_tlb()
                    task_unlock()
                    mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                        atomic_read()
                        read_lock()
                        list_for_each_entry()
                        for_each_process()
                        for_each_thread()
                        read_unlock()
                        BUG_ON()
                        get_task_struct()
                        task_lock()
                        task_unlock()
                        put_task_struct()
                    mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                        might_sleep()
                        atomic_dec_and_test()
                        uprobe_clear_state()
                        exit_aio()
                        ksm_exit()
                        khugepaged_exit()
                        exit_mmap()
                        set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                            rcu_dereference_raw()
                            get_file()
                            rcu_assign_pointer()
                            fput()
                        list_empty()
                        spin_lock()
                        list_del()
                        spin_unlock()
                        module_put() <void module_put (struct module *module) at module.c:1098>:
                            preempt_disable()
                            atomic_dec_if_positive()
                            WARN_ON()
                            trace_module_put()
                            preempt_enable()
                        mmdrop()
                    test_thread_flag()
                    exit_oom_victim()
                acct_process() <void acct_process (void) at acct.c:587>:
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    unlikely()
                    slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                        acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                            smp_rmb()
                            rcu_read_lock()
                            to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                                container_of()
                            ACCESS_ONCE()
                            rcu_read_unlock()
                            atomic_long_inc_not_zero()
                            cpu_relax()
                            mutex_lock()
                            mutex_unlock()
                            acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                                atomic_long_dec_and_test()
                                kfree_rcu()
                        do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                            override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                                kdebug()
                                atomic_read()
                                read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                    atomic_read()
                                validate_creds()
                                get_cred()
                                alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                    atomic_add()
                                rcu_assign_pointer()
                            check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                                time_is_before_jiffies()
                                vfs_statfs()
                                do_div()
                                pr_info()
                            fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                                strlcpy()
                                ktime_get_ns()
                                nsec_to_AHZ()
                                encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                                encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                                encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                                do_div()
                                get_seconds()
                                spin_lock_irq()
                                old_encode_dev()
                                tty_devnum()
                                jiffies_to_AHZ()
                                cputime_to_jiffies()
                                spin_unlock_irq()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                                from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                task_tgid()
                            rcu_read_lock()
                            rcu_dereference()
                            rcu_read_unlock()
                            file_start_write_trylock()
                            file_end_write()
                            revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                                kdebug()
                                atomic_read()
                                read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                    atomic_read()
                                validate_creds()
                                alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                    atomic_add()
                                rcu_assign_pointer()
                                put_cred()
                        mutex_unlock()
                        acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                            atomic_long_dec_and_test()
                            kfree_rcu()
                trace_sched_process_exit()
                exit_sem()
                exit_shm()
                exit_files()
                exit_fs()
                disassociate_ctty()
                exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
                    switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                        might_sleep()
                        task_lock()
                        task_unlock()
                        atomic_dec_and_test()
                        free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                            put_mnt_ns()
                            put_uts_ns()
                            put_ipc_ns()
                            put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                                kref_put()
                                free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                    container_of()
                                    destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                        ns_free_inum()
                                        kfree()
                                        put_user_ns()
                                        call_rcu()
                                        delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                            kmem_cache_free()
                                            container_of()
                            put_net()
                            kmem_cache_free()
                exit_task_work()
                exit_thread()
                perf_event_exit_task()
                cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
                    task_css_set()
                    list_empty()
                    spin_lock_bh()
                    css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                        lockdep_assert_held()
                        WARN_ON_ONCE()
                        list_empty()
                        list_for_each_entry_safe()
                        css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                            lockdep_assert_held()
                            WARN_ON_ONCE()
                            css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                                lockdep_assert_held()
                                container_of()
                                list_entry()
                                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                    lockdep_assert_held()
                                    list_empty()
                                list_empty()
                                list_del()
                                put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                                    lockdep_assert_held()
                                    atomic_dec_and_test()
                                    for_each_subsys()
                                    list_del()
                                    css_put()
                                    hash_del()
                                    list_for_each_entry_safe()
                                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                        container_of()
                                    cgroup_put()
                                    kfree()
                                    kfree_rcu()
                                get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                    atomic_inc()
                                list_add()
                        list_del_init()
                        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                            lockdep_assert_held()
                            list_empty()
                        css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                            lockdep_assert_held()
                            list_for_each_entry()
                            cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                                lockdep_assert_held()
                                check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                                    notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                        test_bit()
                                    cgroup_is_populated()
                                    css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                        rcu_read_lock()
                                        css_for_each_child()
                                        rcu_read_unlock()
                                    cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                                    schedule_work()
                                cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                                    spin_lock_irqsave()
                                    kernfs_notify()
                                    spin_unlock_irqrestore()
                                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                    container_of()
                        rcu_assign_pointer()
                        list_add_tail()
                    spin_unlock_bh()
                    get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                        atomic_inc()
                    for_each_subsys_which()
                flush_ptrace_hw_breakpoint()
                preempt_disable()
                preempt_enable()
                exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
                    LIST_HEAD()
                    write_lock_irq()
                    forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                        unlikely()
                        list_empty()
                        exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                            list_for_each_entry_safe()
                            unlikely()
                            send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                                valid_signal()
                                do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                    lock_task_sighand()
                                    send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                            SI_FROMUSER()
                                        task_pid_nr_ns()
                                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                            ns_of_pid()
                                            task_pid()
                                    unlock_task_sighand()
                            list_add()
                        find_child_reaper()
                        find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                            find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                                for_each_thread()
                            same_thread_group()
                        list_for_each_entry()
                        for_each_thread()
                        BUG_ON()
                        likely()
                        group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                            rcu_read_lock()
                            check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                                valid_signal()
                                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                    SI_FROMUSER()
                                audit_signal_info()
                                same_thread_group()
                                kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                                    current_cred()
                                    uid_eq()
                                    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                        unlikely()
                                        cap_valid()
                                        pr_crit()
                                        BUG()
                                        security_capable()
                                        current_cred()
                                task_session()
                                security_task_kill()
                            rcu_read_unlock()
                            do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                lock_task_sighand()
                                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                        SI_FROMUSER()
                                    task_pid_nr_ns()
                                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                        ns_of_pid()
                                        task_pid()
                                unlock_task_sighand()
                        same_thread_group()
                        reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                            unlikely()
                            thread_group_empty()
                            do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                                BUG_ON()
                                task_is_stopped_or_traced()
                                thread_group_empty()
                                rcu_read_lock()
                                task_pid_nr_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                            smp_rmb()
                                task_cred_xxx()
                                task_uid()
                                rcu_read_unlock()
                                task_cputime()
                                cputime_to_clock_t()
                                spin_lock_irqsave()
                                valid_signal()
                                spin_unlock_irqrestore()
                            list_add()
                            kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                                task_pgrp()
                                task_session()
                                will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                                    do_each_pid_task()
                                    thread_group_empty()
                                    is_global_init()
                                    task_pgrp()
                                    task_session()
                                    while_each_pid_task()
                                has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                                    do_each_pid_task()
                                    while_each_pid_task()
                        list_splice_tail_init()
                    kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                        task_pgrp()
                        task_session()
                        will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                            do_each_pid_task()
                            thread_group_empty()
                            is_global_init()
                            task_pgrp()
                            task_session()
                            while_each_pid_task()
                        has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                            do_each_pid_task()
                            while_each_pid_task()
                    unlikely()
                    thread_group_leader()
                    thread_group_empty()
                    ptrace_reparented()
                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                        BUG_ON()
                        task_is_stopped_or_traced()
                        thread_group_empty()
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        spin_lock_irqsave()
                        valid_signal()
                        spin_unlock_irqrestore()
                    list_add()
                    wake_up_process()
                    write_unlock_irq()
                    list_for_each_entry_safe()
                    list_del_init()
                    release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                        rcu_read_lock()
                        atomic_dec()
                        rcu_read_unlock()
                        proc_flush_task()
                        write_lock_irq()
                        ptrace_release_task()
                        thread_group_empty()
                        do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                            BUG_ON()
                            task_is_stopped_or_traced()
                            thread_group_empty()
                            rcu_read_lock()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            task_cred_xxx()
                            task_uid()
                            rcu_read_unlock()
                            task_cputime()
                            cputime_to_clock_t()
                            spin_lock_irqsave()
                            valid_signal()
                            spin_unlock_irqrestore()
                        write_unlock_irq()
                        release_thread()
                        call_rcu()
                        delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                            container_of()
                            perf_event_delayed_put()
                            trace_sched_process_free()
                            put_task_struct()
                        unlikely()
                proc_exit_connector()
                task_lock()
                mpol_put()
                task_unlock()
                kfree()
                debug_check_no_locks_held()
                exit_io_context()
                free_pipe_info()
                put_page()
                check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
                    stack_not_used()
                    spin_lock()
                    pr_warn()
                    task_pid_nr()
                    spin_unlock()
                exit_rcu()
                BUG()
                cpu_relax()
        umh_complete() <void umh_complete (struct subprocess_info *sub_info) at kmod.c:198>:
            xchg()
            complete()
            call_usermodehelper_freeinfo() <void call_usermodehelper_freeinfo (struct subprocess_info *info) at kmod.c:191>:
                kfree()
cancel_delayed_work() <bool cancel_delayed_work (struct delayed_work *dwork) at workqueue.c:2992>:
    try_to_grab_pending() <int try_to_grab_pending (struct work_struct *work, bool is_dwork, unsigned long *flags) at workqueue.c:1203>:
        local_irq_save()
        to_delayed_work()
        likely()
        del_timer()
        test_and_set_bit()
        work_data_bits()
        get_work_pool() <struct worker_pool *get_work_pool (struct work_struct *work) at workqueue.c:703>:
            atomic_long_read()
            assert_rcu_or_pool_mutex()
            idr_find()
        spin_lock()
        get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
            atomic_long_read()
        debug_work_deactivate() <inline void debug_work_deactivate (struct work_struct *work) at workqueue.c:548>:
            debug_object_deactivate()
        pwq_activate_delayed_work() <void pwq_activate_delayed_work (struct work_struct *work) at workqueue.c:1109>:
            get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                atomic_long_read()
            trace_workqueue_activate_work()
            list_empty()
            move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                list_for_each_entry_safe_from()
                list_move_tail()
                work_data_bits()
            work_data_bits()
        list_del_init()
        pwq_dec_nr_in_flight() <void pwq_dec_nr_in_flight (struct pool_workqueue *pwq, int color) at workqueue.c:1140>:
            list_empty()
            pwq_activate_first_delayed() <void pwq_activate_first_delayed (struct pool_workqueue *pwq) at workqueue.c:1121>:
                list_first_entry()
                pwq_activate_delayed_work() <void pwq_activate_delayed_work (struct work_struct *work) at workqueue.c:1109>:
                    get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                        atomic_long_read()
                    trace_workqueue_activate_work()
                    list_empty()
                    move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                        list_for_each_entry_safe_from()
                        list_move_tail()
                        work_data_bits()
                    work_data_bits()
            likely()
            atomic_dec_and_test()
            complete()
            put_pwq() <void put_pwq (struct pool_workqueue *pwq) at workqueue.c:1072>:
                lockdep_assert_held()
                likely()
                WARN_ON_ONCE()
                schedule_work()
        get_work_color() <int get_work_color (struct work_struct *work) at workqueue.c:607>:
            work_data_bits()
        set_work_pool_and_keep_pending() <void set_work_pool_and_keep_pending (struct work_struct *work, int pool_id) at workqueue.c:652>:
            set_work_data() <inline void set_work_data (struct work_struct *work, unsigned long data, unsigned long flags) at workqueue.c:638>:
                WARN_ON_ONCE()
                work_pending()
                atomic_long_set()
                work_static()
        spin_unlock()
        local_irq_restore()
        work_is_canceling() <bool work_is_canceling (struct work_struct *work) at workqueue.c:747>:
            atomic_long_read()
        cpu_relax()
    unlikely()
    set_work_pool_and_clear_pending() <void set_work_pool_and_clear_pending (struct work_struct *work, int pool_id) at workqueue.c:659>:
        smp_wmb()
        set_work_data() <inline void set_work_data (struct work_struct *work, unsigned long data, unsigned long flags) at workqueue.c:638>:
            WARN_ON_ONCE()
            work_pending()
            atomic_long_set()
            work_static()
    get_work_pool_id() <int get_work_pool_id (struct work_struct *work) at workqueue.c:728>:
        atomic_long_read()
    local_irq_restore()
cancel_delayed_work_sync() <bool cancel_delayed_work_sync (struct delayed_work *dwork) at workqueue.c:3020>:
cancel_work_sync() <bool cancel_work_sync (struct work_struct *work) at workqueue.c:2948>:
capable() <bool capable (int cap) at capability.c:401>:
    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
        unlikely()
        cap_valid()
        pr_crit()
        BUG()
        security_capable()
        current_cred()
capable_wrt_inode_uidgid() <bool capable_wrt_inode_uidgid (const struct inode *inode, int cap) at capability.c:442>:
    current_user_ns()
    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
        unlikely()
        cap_valid()
        pr_crit()
        BUG()
        security_capable()
        current_cred()
    kuid_has_mapping()
    kgid_has_mapping()
cgroup_add_dfl_cftypes() <int cgroup_add_dfl_cftypes (struct cgroup_subsys *ss, struct cftype *cfts) at cgroup.c:3552>:
    cgroup_add_cftypes() <int cgroup_add_cftypes (struct cgroup_subsys *ss, struct cftype *cfts) at cgroup.c:3519>:
        cgroup_ssid_enabled() <bool cgroup_ssid_enabled (int ssid) at cgroup.c:239>:
            static_key_enabled()
        cgroup_init_cftypes() <int cgroup_init_cftypes (struct cgroup_subsys *ss, struct cftype *cfts) at cgroup.c:3437>:
            WARN_ON()
            kmemdup()
            cgroup_exit_cftypes() <void cgroup_exit_cftypes (struct cftype *cfts) at cgroup.c:3421>:
                kfree()
        mutex_lock()
        list_add_tail()
        cgroup_apply_cftypes() <int cgroup_apply_cftypes (struct cftype *cfts, bool is_add) at cgroup.c:3394>:
            LIST_HEAD()
            lockdep_assert_held()
            css_for_each_descendant_pre()
            cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                rcu_dereference_check()
                lockdep_is_held()
            cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
            cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                lockdep_assert_held()
                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
                cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                    cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                    IS_ERR()
                    PTR_ERR()
                    cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                        current_fsuid()
                        current_fsgid()
                        uid_eq()
                        gid_eq()
                        kernfs_setattr()
                    kernfs_remove()
                    spin_lock_irq()
                    spin_unlock_irq()
                pr_warn()
                cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                    lockdep_assert_held()
                    cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                        rcu_dereference_check()
                        lockdep_is_held()
                    spin_lock_irq()
                    spin_unlock_irq()
                    kernfs_remove_by_name()
                    cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
            kernfs_activate()
        cgroup_rm_cftypes_locked() <int cgroup_rm_cftypes_locked (struct cftype *cfts) at cgroup.c:3471>:
            lockdep_assert_held()
            list_del()
            cgroup_apply_cftypes() <int cgroup_apply_cftypes (struct cftype *cfts, bool is_add) at cgroup.c:3394>:
                LIST_HEAD()
                lockdep_assert_held()
                css_for_each_descendant_pre()
                cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                    rcu_dereference_check()
                    lockdep_is_held()
                cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                    lockdep_assert_held()
                    cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                        cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                        cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                        IS_ERR()
                        PTR_ERR()
                        cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                            current_fsuid()
                            current_fsgid()
                            uid_eq()
                            gid_eq()
                            kernfs_setattr()
                        kernfs_remove()
                        spin_lock_irq()
                        spin_unlock_irq()
                    pr_warn()
                    cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                        lockdep_assert_held()
                        cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                            rcu_dereference_check()
                            lockdep_is_held()
                        spin_lock_irq()
                        spin_unlock_irq()
                        kernfs_remove_by_name()
                        cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                kernfs_activate()
            cgroup_exit_cftypes() <void cgroup_exit_cftypes (struct cftype *cfts) at cgroup.c:3421>:
                kfree()
        mutex_unlock()
cgroup_add_legacy_cftypes() <int cgroup_add_legacy_cftypes (struct cgroup_subsys *ss, struct cftype *cfts) at cgroup.c:3569>:
    cgroup_add_cftypes() <int cgroup_add_cftypes (struct cgroup_subsys *ss, struct cftype *cfts) at cgroup.c:3519>:
        cgroup_ssid_enabled() <bool cgroup_ssid_enabled (int ssid) at cgroup.c:239>:
            static_key_enabled()
        cgroup_init_cftypes() <int cgroup_init_cftypes (struct cgroup_subsys *ss, struct cftype *cfts) at cgroup.c:3437>:
            WARN_ON()
            kmemdup()
            cgroup_exit_cftypes() <void cgroup_exit_cftypes (struct cftype *cfts) at cgroup.c:3421>:
                kfree()
        mutex_lock()
        list_add_tail()
        cgroup_apply_cftypes() <int cgroup_apply_cftypes (struct cftype *cfts, bool is_add) at cgroup.c:3394>:
            LIST_HEAD()
            lockdep_assert_held()
            css_for_each_descendant_pre()
            cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                rcu_dereference_check()
                lockdep_is_held()
            cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
            cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                lockdep_assert_held()
                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
                cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                    cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                    IS_ERR()
                    PTR_ERR()
                    cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                        current_fsuid()
                        current_fsgid()
                        uid_eq()
                        gid_eq()
                        kernfs_setattr()
                    kernfs_remove()
                    spin_lock_irq()
                    spin_unlock_irq()
                pr_warn()
                cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                    lockdep_assert_held()
                    cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                        rcu_dereference_check()
                        lockdep_is_held()
                    spin_lock_irq()
                    spin_unlock_irq()
                    kernfs_remove_by_name()
                    cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
            kernfs_activate()
        cgroup_rm_cftypes_locked() <int cgroup_rm_cftypes_locked (struct cftype *cfts) at cgroup.c:3471>:
            lockdep_assert_held()
            list_del()
            cgroup_apply_cftypes() <int cgroup_apply_cftypes (struct cftype *cfts, bool is_add) at cgroup.c:3394>:
                LIST_HEAD()
                lockdep_assert_held()
                css_for_each_descendant_pre()
                cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                    rcu_dereference_check()
                    lockdep_is_held()
                cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                    lockdep_assert_held()
                    cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                        cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                        cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                        IS_ERR()
                        PTR_ERR()
                        cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                            current_fsuid()
                            current_fsgid()
                            uid_eq()
                            gid_eq()
                            kernfs_setattr()
                        kernfs_remove()
                        spin_lock_irq()
                        spin_unlock_irq()
                    pr_warn()
                    cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                        lockdep_assert_held()
                        cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                            rcu_dereference_check()
                            lockdep_is_held()
                        spin_lock_irq()
                        spin_unlock_irq()
                        kernfs_remove_by_name()
                        cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                kernfs_activate()
            cgroup_exit_cftypes() <void cgroup_exit_cftypes (struct cftype *cfts) at cgroup.c:3421>:
                kfree()
        mutex_unlock()
cgroup_attach_task_all() <int cgroup_attach_task_all (struct task_struct *from, struct task_struct *tsk) at cgroup.c:2752>:
    mutex_lock()
    for_each_root()
    spin_lock_bh()
    task_cgroup_from_root() <struct cgroup *task_cgroup_from_root (struct task_struct *task, struct cgroup_root *root) at cgroup.c:1172>:
        cset_cgroup_from_root() <struct cgroup *cset_cgroup_from_root (struct css_set *cset, struct cgroup_root *root) at cgroup.c:1141>:
            lockdep_assert_held()
            list_for_each_entry()
            BUG_ON()
        task_css_set()
    spin_unlock_bh()
    cgroup_attach_task() <int cgroup_attach_task (struct cgroup *dst_cgrp, struct task_struct *leader, bool threadgroup) at cgroup.c:2613>:
        LIST_HEAD()
        spin_lock_bh()
        rcu_read_lock()
        cgroup_migrate_add_src() <void cgroup_migrate_add_src (struct css_set *src_cset, struct cgroup *dst_cgrp, struct list_head *preloaded_csets) at cgroup.c:2468>:
            lockdep_assert_held()
            cset_cgroup_from_root() <struct cgroup *cset_cgroup_from_root (struct css_set *cset, struct cgroup_root *root) at cgroup.c:1141>:
                lockdep_assert_held()
                list_for_each_entry()
                BUG_ON()
            list_empty()
            WARN_ON()
            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                atomic_inc()
            list_add()
        task_css_set()
        while_each_thread()
        rcu_read_unlock()
        spin_unlock_bh()
        cgroup_migrate_prepare_dst() <int cgroup_migrate_prepare_dst (struct cgroup *dst_cgrp, struct list_head *preloaded_csets) at cgroup.c:2507>:
            LIST_HEAD()
            lockdep_assert_held()
            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                container_of()
            list_for_each_entry_safe()
            find_css_set() <struct css_set *find_css_set (struct css_set *old_cset, struct cgroup *cgrp) at cgroup.c:980>:
                lockdep_assert_held()
                spin_lock_bh()
                find_existing_css_set() <struct css_set *find_existing_css_set (struct css_set *old_cset, struct cgroup *cgrp, struct cgroup_subsys_state *template[]) at cgroup.c:861>:
                    for_each_subsys()
                    cgroup_e_css() <struct cgroup_subsys_state *cgroup_e_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:373>:
                        lockdep_assert_held()
                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                            container_of()
                        cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                            rcu_dereference_check()
                            lockdep_is_held()
                    css_set_hash() <unsigned long css_set_hash (struct cgroup_subsys_state *css[]) at cgroup.c:717>:
                        for_each_subsys()
                    hash_for_each_possible()
                    compare_css_sets() <bool compare_css_sets (struct css_set *cset, struct css_set *old_cset, struct cgroup *new_cgrp, struct cgroup_subsys_state *template[]) at cgroup.c:793>:
                        BUG_ON()
                        list_entry()
                get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                    atomic_inc()
                spin_unlock_bh()
                kzalloc()
                allocate_cgrp_cset_links() <int allocate_cgrp_cset_links (int count, struct list_head *tmp_links) at cgroup.c:923>:
                    INIT_LIST_HEAD()
                    kzalloc()
                    free_cgrp_cset_links() <void free_cgrp_cset_links (struct list_head *links_to_free) at cgroup.c:905>:
                        list_for_each_entry_safe()
                        list_del()
                        kfree()
                    list_add()
                kfree()
                atomic_set()
                INIT_LIST_HEAD()
                INIT_HLIST_NODE()
                list_for_each_entry()
                link_css_set() <void link_css_set (struct list_head *tmp_links, struct css_set *cset, struct cgroup *cgrp) at cgroup.c:947>:
                    BUG_ON()
                    list_empty()
                    cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    list_first_entry()
                    list_move_tail()
                    list_add_tail()
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_get() <void cgroup_get (struct cgroup *cgrp) at cgroup.c:434>:
                        WARN_ON_ONCE()
                        cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                        css_get()
                BUG_ON()
                list_empty()
                css_set_hash() <unsigned long css_set_hash (struct cgroup_subsys_state *css[]) at cgroup.c:717>:
                    for_each_subsys()
                hash_add()
                for_each_subsys()
                list_add_tail()
                css_get()
            WARN_ON_ONCE()
            list_del_init()
            put_css_set() <void put_css_set (struct css_set *cset) at cgroup.c:760>:
                atomic_add_unless()
                spin_lock_bh()
                put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                    lockdep_assert_held()
                    atomic_dec_and_test()
                    for_each_subsys()
                    list_del()
                    css_put()
                    hash_del()
                    list_for_each_entry_safe()
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_put()
                    kfree()
                    kfree_rcu()
                spin_unlock_bh()
            list_empty()
            list_add()
            list_splice_tail()
            cgroup_migrate_finish() <void cgroup_migrate_finish (struct list_head *preloaded_csets) at cgroup.c:2436>:
                lockdep_assert_held()
                spin_lock_bh()
                list_for_each_entry_safe()
                list_del_init()
                put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                    lockdep_assert_held()
                    atomic_dec_and_test()
                    for_each_subsys()
                    list_del()
                    css_put()
                    hash_del()
                    list_for_each_entry_safe()
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_put()
                    kfree()
                    kfree_rcu()
                spin_unlock_bh()
        cgroup_migrate() <int cgroup_migrate (struct task_struct *leader, bool threadgroup, struct cgroup *cgrp) at cgroup.c:2580>:
            CGROUP_TASKSET_INIT()
            spin_lock_bh()
            rcu_read_lock()
            cgroup_taskset_add() <void cgroup_taskset_add (struct task_struct *task, struct cgroup_taskset *tset) at cgroup.c:2251>:
                lockdep_assert_held()
                list_empty()
                task_css_set()
                list_move_tail()
                list_add_tail()
            while_each_thread()
            rcu_read_unlock()
            spin_unlock_bh()
            cgroup_taskset_migrate() <int cgroup_taskset_migrate (struct cgroup_taskset *tset, struct cgroup *dst_cgrp) at cgroup.c:2350>:
                list_empty()
                for_each_e_css()
                can_attach()
                spin_lock_bh()
                list_for_each_entry()
                list_for_each_entry_safe()
                task_css_set()
                get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                    atomic_inc()
                css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                    lockdep_assert_held()
                    WARN_ON_ONCE()
                    list_empty()
                    list_for_each_entry_safe()
                    css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                        lockdep_assert_held()
                        WARN_ON_ONCE()
                        css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                            lockdep_assert_held()
                            container_of()
                            list_entry()
                            css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                lockdep_assert_held()
                                list_empty()
                            list_empty()
                            list_del()
                            put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                                lockdep_assert_held()
                                atomic_dec_and_test()
                                for_each_subsys()
                                list_del()
                                css_put()
                                hash_del()
                                list_for_each_entry_safe()
                                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                    container_of()
                                cgroup_put()
                                kfree()
                                kfree_rcu()
                            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                atomic_inc()
                            list_add()
                    list_del_init()
                    css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                        lockdep_assert_held()
                        list_empty()
                    css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                        lockdep_assert_held()
                        list_for_each_entry()
                        cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                            lockdep_assert_held()
                            check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                                notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                    test_bit()
                                cgroup_is_populated()
                                css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                    rcu_read_lock()
                                    css_for_each_child()
                                    rcu_read_unlock()
                                cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                                schedule_work()
                            cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                                spin_lock_irqsave()
                                kernfs_notify()
                                spin_unlock_irqrestore()
                            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                container_of()
                    rcu_assign_pointer()
                    list_add_tail()
                put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                    lockdep_assert_held()
                    atomic_dec_and_test()
                    for_each_subsys()
                    list_del()
                    css_put()
                    hash_del()
                    list_for_each_entry_safe()
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_put()
                    kfree()
                    kfree_rcu()
                spin_unlock_bh()
                attach()
                cancel_attach()
                list_splice_init()
                list_splice_tail_init()
                list_del_init()
        cgroup_migrate_finish() <void cgroup_migrate_finish (struct list_head *preloaded_csets) at cgroup.c:2436>:
            lockdep_assert_held()
            spin_lock_bh()
            list_for_each_entry_safe()
            list_del_init()
            put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                lockdep_assert_held()
                atomic_dec_and_test()
                for_each_subsys()
                list_del()
                css_put()
                hash_del()
                list_for_each_entry_safe()
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
                cgroup_put()
                kfree()
                kfree_rcu()
            spin_unlock_bh()
    mutex_unlock()
cgroup_can_fork() <int cgroup_can_fork (struct task_struct *child) at cgroup.c:5511>:
    for_each_subsys_which()
    for_each_subsys()
cgroup_cancel_fork() <void cgroup_cancel_fork (struct task_struct *child) at cgroup.c:5542>:
    for_each_subsys()
cgroup_destroy_locked():
    lockdep_assert_held()
    cgroup_is_populated()
    css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
        rcu_read_lock()
        css_for_each_child()
        rcu_read_unlock()
    for_each_css()
    kill_css() <void kill_css (struct cgroup_subsys_state *css) at cgroup.c:5060>:
        lockdep_assert_held()
        css_clear_dir() <void css_clear_dir (struct cgroup_subsys_state *css, struct cgroup *cgrp_override) at cgroup.c:1404>:
            list_for_each_entry()
            cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                lockdep_assert_held()
                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
                cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                    cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                    IS_ERR()
                    PTR_ERR()
                    cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                        current_fsuid()
                        current_fsgid()
                        uid_eq()
                        gid_eq()
                        kernfs_setattr()
                    kernfs_remove()
                    spin_lock_irq()
                    spin_unlock_irq()
                pr_warn()
                cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                    lockdep_assert_held()
                    cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                        rcu_dereference_check()
                        lockdep_is_held()
                    spin_lock_irq()
                    spin_unlock_irq()
                    kernfs_remove_by_name()
                    cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
        css_get()
        percpu_ref_kill_and_confirm()
        css_killed_ref_fn() <void css_killed_ref_fn (struct percpu_ref *ref) at cgroup.c:5040>:
            container_of()
            atomic_dec_and_test()
            INIT_WORK()
            css_killed_work_fn() <void css_killed_work_fn (struct work_struct *work) at cgroup.c:5022>:
                container_of()
                mutex_lock()
                offline_css() <void offline_css (struct cgroup_subsys_state *css) at cgroup.c:4796>:
                    lockdep_assert_held()
                    RCU_INIT_POINTER()
                    wake_up_all()
                css_put()
                atomic_dec_and_test()
                mutex_unlock()
            queue_work()
    kernfs_remove()
    check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
        notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
            test_bit()
        cgroup_is_populated()
        css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
            rcu_read_lock()
            css_for_each_child()
            rcu_read_unlock()
        cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
        schedule_work()
    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
        container_of()
    percpu_ref_kill()
cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
    task_css_set()
    list_empty()
    spin_lock_bh()
    css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
        lockdep_assert_held()
        WARN_ON_ONCE()
        list_empty()
        list_for_each_entry_safe()
        css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
            lockdep_assert_held()
            WARN_ON_ONCE()
            css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                lockdep_assert_held()
                container_of()
                list_entry()
                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                    lockdep_assert_held()
                    list_empty()
                list_empty()
                list_del()
                put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                    lockdep_assert_held()
                    atomic_dec_and_test()
                    for_each_subsys()
                    list_del()
                    css_put()
                    hash_del()
                    list_for_each_entry_safe()
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_put()
                    kfree()
                    kfree_rcu()
                get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                    atomic_inc()
                list_add()
        list_del_init()
        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
            lockdep_assert_held()
            list_empty()
        css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
            lockdep_assert_held()
            list_for_each_entry()
            cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                lockdep_assert_held()
                check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                    notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                        test_bit()
                    cgroup_is_populated()
                    css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                        rcu_read_lock()
                        css_for_each_child()
                        rcu_read_unlock()
                    cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                    schedule_work()
                cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                    spin_lock_irqsave()
                    kernfs_notify()
                    spin_unlock_irqrestore()
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
        rcu_assign_pointer()
        list_add_tail()
    spin_unlock_bh()
    get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
        atomic_inc()
    for_each_subsys_which()
cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
    spin_lock_irqsave()
    kernfs_notify()
    spin_unlock_irqrestore()
cgroup_fork() <void cgroup_fork (struct task_struct *child) at cgroup.c:5497>:
    RCU_INIT_POINTER()
    INIT_LIST_HEAD()
cgroup_free() <void cgroup_free (struct task_struct *task) at cgroup.c:5653>:
    task_css_set()
    for_each_subsys_which()
    put_css_set() <void put_css_set (struct css_set *cset) at cgroup.c:760>:
        atomic_add_unless()
        spin_lock_bh()
        put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
            lockdep_assert_held()
            atomic_dec_and_test()
            for_each_subsys()
            list_del()
            css_put()
            hash_del()
            list_for_each_entry_safe()
            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                container_of()
            cgroup_put()
            kfree()
            kfree_rcu()
        spin_unlock_bh()
cgroup_freezing() <bool cgroup_freezing (struct task_struct *task) at cgroup_freezer.c:65>:
    rcu_read_lock()
    task_freezer() <inline struct freezer *task_freezer (struct task_struct *task) at cgroup_freezer.c:55>:
        css_freezer() <inline struct freezer *css_freezer (struct cgroup_subsys_state *css) at cgroup_freezer.c:50>:
            container_of()
        task_css()
    rcu_read_unlock()
cgroup_get_e_css() <struct cgroup_subsys_state *cgroup_get_e_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:406>:
    rcu_read_lock()
    cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
        rcu_dereference_check()
        lockdep_is_held()
    css_tryget_online()
    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
        container_of()
    css_get()
    rcu_read_unlock()
cgroup_get_from_path() <struct cgroup *cgroup_get_from_path (const char *path) at cgroup.c:5815>:
    mutex_lock()
    kernfs_walk_and_get()
    kernfs_type()
    cgroup_get() <void cgroup_get (struct cgroup *cgrp) at cgroup.c:434>:
        WARN_ON_ONCE()
        cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
        css_get()
    ERR_PTR()
    kernfs_put()
    mutex_unlock()
cgroup_init() <int __init cgroup_init (void) at cgroup.c:5280>:
    BUG_ON()
    percpu_init_rwsem()
    cgroup_init_cftypes() <int cgroup_init_cftypes (struct cgroup_subsys *ss, struct cftype *cfts) at cgroup.c:3437>:
        WARN_ON()
        kmemdup()
        cgroup_exit_cftypes() <void cgroup_exit_cftypes (struct cftype *cfts) at cgroup.c:3421>:
            kfree()
    mutex_lock()
    css_set_hash() <unsigned long css_set_hash (struct cgroup_subsys_state *css[]) at cgroup.c:717>:
        for_each_subsys()
    hash_add()
    cgroup_setup_root() <int cgroup_setup_root (struct cgroup_root *root, unsigned long ss_mask) at cgroup.c:1879>:
        LIST_HEAD()
        lockdep_assert_held()
        cgroup_idr_alloc() <int cgroup_idr_alloc (struct idr *idr, void *ptr, int start, int end, gfp_t gfp_mask) at cgroup.c:303>:
            idr_preload()
            spin_lock_bh()
            idr_alloc()
            spin_unlock_bh()
            idr_preload_end()
        percpu_ref_init()
        css_release() <void css_release (struct percpu_ref *ref) at cgroup.c:4742>:
            container_of()
            INIT_WORK()
            css_release_work_fn() <void css_release_work_fn (struct work_struct *work) at cgroup.c:4705>:
                container_of()
                mutex_lock()
                list_del_rcu()
                cgroup_idr_replace() <void *cgroup_idr_replace (struct idr *idr, void *ptr, int id) at cgroup.c:316>:
                    spin_lock_bh()
                    idr_replace()
                    spin_unlock_bh()
                cgroup_idr_remove() <void cgroup_idr_remove (struct idr *idr, int id) at cgroup.c:326>:
                    spin_lock_bh()
                    idr_remove()
                    spin_unlock_bh()
                RCU_INIT_POINTER()
                mutex_unlock()
                call_rcu()
                css_free_rcu_fn() <void css_free_rcu_fn (struct rcu_head *rcu_head) at cgroup.c:4696>:
                    container_of()
                    INIT_WORK()
                    css_free_work_fn() <void css_free_work_fn (struct work_struct *work) at cgroup.c:4649>:
                        container_of()
                        percpu_ref_exit()
                        cgroup_idr_remove() <void cgroup_idr_remove (struct idr *idr, int id) at cgroup.c:326>:
                            spin_lock_bh()
                            idr_remove()
                            spin_unlock_bh()
                        cgroup_put()
                        css_put()
                        atomic_dec()
                        cgroup_pidlist_destroy_all() <void cgroup_pidlist_destroy_all (struct cgroup *cgrp) at cgroup.c:4126>:
                            mutex_lock()
                            list_for_each_entry_safe()
                            mod_delayed_work()
                            mutex_unlock()
                            flush_workqueue() <void flush_workqueue (struct workqueue_struct *wq) at workqueue.c:2576>:
                                LIST_HEAD_INIT()
                                COMPLETION_INITIALIZER_ONSTACK()
                                lock_map_acquire()
                                lock_map_release()
                                mutex_lock()
                                work_next_color() <int work_next_color (int color) at workqueue.c:613>:
                                WARN_ON_ONCE()
                                list_empty()
                                flush_workqueue_prep_pwqs() <bool flush_workqueue_prep_pwqs (struct workqueue_struct *wq, int flush_color, int work_color) at workqueue.c:2529>:
                                    WARN_ON_ONCE()
                                    atomic_read()
                                    atomic_set()
                                    for_each_pwq()
                                    spin_lock_irq()
                                    atomic_inc()
                                    work_next_color() <int work_next_color (int color) at workqueue.c:613>:
                                    spin_unlock_irq()
                                    atomic_dec_and_test()
                                    complete()
                                list_add_tail()
                                check_flush_dependency() <void check_flush_dependency (struct workqueue_struct *target_wq, struct work_struct *target_work) at workqueue.c:2403>:
                                    current_wq_worker()
                                    WARN_ONCE()
                                mutex_unlock()
                                wait_for_completion()
                                list_for_each_entry_safe()
                                list_del_init()
                                complete()
                                list_for_each_entry()
                                list_splice_tail_init()
                            BUG_ON()
                            list_empty()
                        cancel_work_sync() <bool cancel_work_sync (struct work_struct *work) at workqueue.c:2948>:
                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                            container_of()
                        kernfs_put()
                        kfree()
                        cgroup_destroy_root() <void cgroup_destroy_root (struct cgroup_root *root) at cgroup.c:1100>:
                            mutex_lock()
                            BUG_ON()
                            atomic_read()
                            list_empty()
                            rebind_subsystems() <int rebind_subsystems (struct cgroup_root *dst_root, unsigned long ss_mask) at cgroup.c:1454>:
                                lockdep_assert_held()
                                for_each_subsys_which()
                                css_next_child() <struct cgroup_subsys_state *css_next_child (struct cgroup_subsys_state *pos, struct cgroup_subsys_state *parent) at cgroup.c:3629>:
                                    cgroup_assert_mutex_or_rcu_locked()
                                    list_entry_rcu()
                                    likely()
                                    list_for_each_entry_rcu()
                                cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                                    rcu_dereference_check()
                                    lockdep_is_held()
                                css_populate_dir() <int css_populate_dir (struct cgroup_subsys_state *css, struct cgroup *cgrp_override) at cgroup.c:1421>:
                                    cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                                    cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                                        lockdep_assert_held()
                                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                            container_of()
                                        cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                                            cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                                                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                                            cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                                            IS_ERR()
                                            PTR_ERR()
                                            cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                                                current_fsuid()
                                                current_fsgid()
                                                uid_eq()
                                                gid_eq()
                                                kernfs_setattr()
                                            kernfs_remove()
                                            spin_lock_irq()
                                            spin_unlock_irq()
                                        pr_warn()
                                        cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                                            lockdep_assert_held()
                                            cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                                                rcu_dereference_check()
                                                lockdep_is_held()
                                            spin_lock_irq()
                                            spin_unlock_irq()
                                            kernfs_remove_by_name()
                                            cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                                                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                                    list_for_each_entry()
                                pr_warn()
                                css_clear_dir() <void css_clear_dir (struct cgroup_subsys_state *css, struct cgroup *cgrp_override) at cgroup.c:1404>:
                                    list_for_each_entry()
                                    cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                                        lockdep_assert_held()
                                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                            container_of()
                                        cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                                            cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                                                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                                            cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                                            IS_ERR()
                                            PTR_ERR()
                                            cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                                                current_fsuid()
                                                current_fsgid()
                                                uid_eq()
                                                gid_eq()
                                                kernfs_setattr()
                                            kernfs_remove()
                                            spin_lock_irq()
                                            spin_unlock_irq()
                                        pr_warn()
                                        cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                                            lockdep_assert_held()
                                            cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                                                rcu_dereference_check()
                                                lockdep_is_held()
                                            spin_lock_irq()
                                            spin_unlock_irq()
                                            kernfs_remove_by_name()
                                            cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                                                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                                WARN_ON()
                                RCU_INIT_POINTER()
                                rcu_assign_pointer()
                                spin_lock_bh()
                                hash_for_each()
                                list_move_tail()
                                spin_unlock_bh()
                                cgroup_refresh_child_subsys_mask() <void cgroup_refresh_child_subsys_mask (struct cgroup *cgrp) at cgroup.c:1307>:
                                    cgroup_calc_child_subsys_mask() <unsigned long cgroup_calc_child_subsys_mask (struct cgroup *cgrp, unsigned long subtree_control) at cgroup.c:1263>:
                                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                            container_of()
                                        lockdep_assert_held()
                                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                                        for_each_subsys_which()
                                static_branch_enable()
                                static_branch_disable()
                                kernfs_activate()
                            spin_lock_bh()
                            list_for_each_entry_safe()
                            list_del()
                            kfree()
                            spin_unlock_bh()
                            cgroup_exit_root_id() <void cgroup_exit_root_id (struct cgroup_root *root) at cgroup.c:1079>:
                                lockdep_assert_held()
                                idr_remove()
                            mutex_unlock()
                            kernfs_destroy_root()
                            cgroup_free_root() <void cgroup_free_root (struct cgroup_root *root) at cgroup.c:1089>:
                                WARN_ON_ONCE()
                                idr_destroy()
                                kfree()
                    queue_work()
            queue_work()
        allocate_cgrp_cset_links() <int allocate_cgrp_cset_links (int count, struct list_head *tmp_links) at cgroup.c:923>:
            INIT_LIST_HEAD()
            kzalloc()
            free_cgrp_cset_links() <void free_cgrp_cset_links (struct list_head *links_to_free) at cgroup.c:905>:
                list_for_each_entry_safe()
                list_del()
                kfree()
            list_add()
        cgroup_init_root_id() <int cgroup_init_root_id (struct cgroup_root *root) at cgroup.c:1065>:
            lockdep_assert_held()
            idr_alloc_cyclic()
        kernfs_create_root()
        IS_ERR()
        PTR_ERR()
        css_populate_dir() <int css_populate_dir (struct cgroup_subsys_state *css, struct cgroup *cgrp_override) at cgroup.c:1421>:
            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
            cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                lockdep_assert_held()
                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
                cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                    cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                    IS_ERR()
                    PTR_ERR()
                    cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                        current_fsuid()
                        current_fsgid()
                        uid_eq()
                        gid_eq()
                        kernfs_setattr()
                    kernfs_remove()
                    spin_lock_irq()
                    spin_unlock_irq()
                pr_warn()
                cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                    lockdep_assert_held()
                    cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                        rcu_dereference_check()
                        lockdep_is_held()
                    spin_lock_irq()
                    spin_unlock_irq()
                    kernfs_remove_by_name()
                    cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
            list_for_each_entry()
        rebind_subsystems() <int rebind_subsystems (struct cgroup_root *dst_root, unsigned long ss_mask) at cgroup.c:1454>:
            lockdep_assert_held()
            for_each_subsys_which()
            css_next_child() <struct cgroup_subsys_state *css_next_child (struct cgroup_subsys_state *pos, struct cgroup_subsys_state *parent) at cgroup.c:3629>:
                cgroup_assert_mutex_or_rcu_locked()
                list_entry_rcu()
                likely()
                list_for_each_entry_rcu()
            cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                rcu_dereference_check()
                lockdep_is_held()
            css_populate_dir() <int css_populate_dir (struct cgroup_subsys_state *css, struct cgroup *cgrp_override) at cgroup.c:1421>:
                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                    lockdep_assert_held()
                    cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                        cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                        cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                        IS_ERR()
                        PTR_ERR()
                        cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                            current_fsuid()
                            current_fsgid()
                            uid_eq()
                            gid_eq()
                            kernfs_setattr()
                        kernfs_remove()
                        spin_lock_irq()
                        spin_unlock_irq()
                    pr_warn()
                    cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                        lockdep_assert_held()
                        cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                            rcu_dereference_check()
                            lockdep_is_held()
                        spin_lock_irq()
                        spin_unlock_irq()
                        kernfs_remove_by_name()
                        cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                list_for_each_entry()
            pr_warn()
            css_clear_dir() <void css_clear_dir (struct cgroup_subsys_state *css, struct cgroup *cgrp_override) at cgroup.c:1404>:
                list_for_each_entry()
                cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                    lockdep_assert_held()
                    cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                        cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                        cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                        IS_ERR()
                        PTR_ERR()
                        cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                            current_fsuid()
                            current_fsgid()
                            uid_eq()
                            gid_eq()
                            kernfs_setattr()
                        kernfs_remove()
                        spin_lock_irq()
                        spin_unlock_irq()
                    pr_warn()
                    cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                        lockdep_assert_held()
                        cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                            rcu_dereference_check()
                            lockdep_is_held()
                        spin_lock_irq()
                        spin_unlock_irq()
                        kernfs_remove_by_name()
                        cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
            WARN_ON()
            RCU_INIT_POINTER()
            rcu_assign_pointer()
            spin_lock_bh()
            hash_for_each()
            list_move_tail()
            spin_unlock_bh()
            cgroup_refresh_child_subsys_mask() <void cgroup_refresh_child_subsys_mask (struct cgroup *cgrp) at cgroup.c:1307>:
                cgroup_calc_child_subsys_mask() <unsigned long cgroup_calc_child_subsys_mask (struct cgroup *cgrp, unsigned long subtree_control) at cgroup.c:1263>:
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    lockdep_assert_held()
                    cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    for_each_subsys_which()
            static_branch_enable()
            static_branch_disable()
            kernfs_activate()
        list_add()
        spin_lock_bh()
        hash_for_each()
        link_css_set() <void link_css_set (struct list_head *tmp_links, struct css_set *cset, struct cgroup *cgrp) at cgroup.c:947>:
            BUG_ON()
            list_empty()
            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
            list_first_entry()
            list_move_tail()
            list_add_tail()
            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                container_of()
            cgroup_get() <void cgroup_get (struct cgroup *cgrp) at cgroup.c:434>:
                WARN_ON_ONCE()
                cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                css_get()
        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
            lockdep_assert_held()
            list_empty()
        cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
            lockdep_assert_held()
            check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                    test_bit()
                cgroup_is_populated()
                css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                    rcu_read_lock()
                    css_for_each_child()
                    rcu_read_unlock()
                cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                schedule_work()
            cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                spin_lock_irqsave()
                kernfs_notify()
                spin_unlock_irqrestore()
            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                container_of()
        spin_unlock_bh()
        BUG_ON()
        list_empty()
        atomic_read()
        kernfs_activate()
        kernfs_destroy_root()
        cgroup_exit_root_id() <void cgroup_exit_root_id (struct cgroup_root *root) at cgroup.c:1079>:
            lockdep_assert_held()
            idr_remove()
        percpu_ref_exit()
        free_cgrp_cset_links() <void free_cgrp_cset_links (struct list_head *links_to_free) at cgroup.c:905>:
            list_for_each_entry_safe()
            list_del()
            kfree()
    mutex_unlock()
    for_each_subsys()
    cgroup_idr_alloc() <int cgroup_idr_alloc (struct idr *idr, void *ptr, int start, int end, gfp_t gfp_mask) at cgroup.c:303>:
        idr_preload()
        spin_lock_bh()
        idr_alloc()
        spin_unlock_bh()
        idr_preload_end()
    cgroup_init_subsys() <void __init cgroup_init_subsys (struct cgroup_subsys *ss, bool early) at cgroup.c:5183>:
        pr_debug()
        mutex_lock()
        idr_init()
        INIT_LIST_HEAD()
        cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
            rcu_dereference_check()
            lockdep_is_held()
        BUG_ON()
        IS_ERR()
        init_and_link_css() <void init_and_link_css (struct cgroup_subsys_state *css, struct cgroup_subsys *ss, struct cgroup *cgrp) at cgroup.c:4751>:
            lockdep_assert_held()
            cgroup_get() <void cgroup_get (struct cgroup *cgrp) at cgroup.c:434>:
                WARN_ON_ONCE()
                cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                css_get()
            INIT_LIST_HEAD()
            atomic_set()
            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                container_of()
            cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                rcu_dereference_check()
                lockdep_is_held()
            css_get()
            BUG_ON()
        cgroup_idr_alloc() <int cgroup_idr_alloc (struct idr *idr, void *ptr, int start, int end, gfp_t gfp_mask) at cgroup.c:303>:
            idr_preload()
            spin_lock_bh()
            idr_alloc()
            spin_unlock_bh()
            idr_preload_end()
        list_empty()
        online_css() <int online_css (struct cgroup_subsys_state *css) at cgroup.c:4775>:
            lockdep_assert_held()
            rcu_assign_pointer()
            atomic_inc()
        mutex_unlock()
    list_add_tail()
    static_branch_disable()
    printk()
    WARN_ON()
    cgroup_add_cftypes() <int cgroup_add_cftypes (struct cgroup_subsys *ss, struct cftype *cfts) at cgroup.c:3519>:
        cgroup_ssid_enabled() <bool cgroup_ssid_enabled (int ssid) at cgroup.c:239>:
            static_key_enabled()
        cgroup_init_cftypes() <int cgroup_init_cftypes (struct cgroup_subsys *ss, struct cftype *cfts) at cgroup.c:3437>:
            WARN_ON()
            kmemdup()
            cgroup_exit_cftypes() <void cgroup_exit_cftypes (struct cftype *cfts) at cgroup.c:3421>:
                kfree()
        mutex_lock()
        list_add_tail()
        cgroup_apply_cftypes() <int cgroup_apply_cftypes (struct cftype *cfts, bool is_add) at cgroup.c:3394>:
            LIST_HEAD()
            lockdep_assert_held()
            css_for_each_descendant_pre()
            cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                rcu_dereference_check()
                lockdep_is_held()
            cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
            cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                lockdep_assert_held()
                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
                cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                    cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                    IS_ERR()
                    PTR_ERR()
                    cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                        current_fsuid()
                        current_fsgid()
                        uid_eq()
                        gid_eq()
                        kernfs_setattr()
                    kernfs_remove()
                    spin_lock_irq()
                    spin_unlock_irq()
                pr_warn()
                cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                    lockdep_assert_held()
                    cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                        rcu_dereference_check()
                        lockdep_is_held()
                    spin_lock_irq()
                    spin_unlock_irq()
                    kernfs_remove_by_name()
                    cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
            kernfs_activate()
        cgroup_rm_cftypes_locked() <int cgroup_rm_cftypes_locked (struct cftype *cfts) at cgroup.c:3471>:
            lockdep_assert_held()
            list_del()
            cgroup_apply_cftypes() <int cgroup_apply_cftypes (struct cftype *cfts, bool is_add) at cgroup.c:3394>:
                LIST_HEAD()
                lockdep_assert_held()
                css_for_each_descendant_pre()
                cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                    rcu_dereference_check()
                    lockdep_is_held()
                cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                    lockdep_assert_held()
                    cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                        cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                        cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                        IS_ERR()
                        PTR_ERR()
                        cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                            current_fsuid()
                            current_fsgid()
                            uid_eq()
                            gid_eq()
                            kernfs_setattr()
                        kernfs_remove()
                        spin_lock_irq()
                        spin_unlock_irq()
                    pr_warn()
                    cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                        lockdep_assert_held()
                        cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                            rcu_dereference_check()
                            lockdep_is_held()
                        spin_lock_irq()
                        spin_unlock_irq()
                        kernfs_remove_by_name()
                        cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                kernfs_activate()
            cgroup_exit_cftypes() <void cgroup_exit_cftypes (struct cftype *cfts) at cgroup.c:3421>:
                kfree()
        mutex_unlock()
    cgroup_add_dfl_cftypes() <int cgroup_add_dfl_cftypes (struct cgroup_subsys *ss, struct cftype *cfts) at cgroup.c:3552>:
        cgroup_add_cftypes() <int cgroup_add_cftypes (struct cgroup_subsys *ss, struct cftype *cfts) at cgroup.c:3519>:
            cgroup_ssid_enabled() <bool cgroup_ssid_enabled (int ssid) at cgroup.c:239>:
                static_key_enabled()
            cgroup_init_cftypes() <int cgroup_init_cftypes (struct cgroup_subsys *ss, struct cftype *cfts) at cgroup.c:3437>:
                WARN_ON()
                kmemdup()
                cgroup_exit_cftypes() <void cgroup_exit_cftypes (struct cftype *cfts) at cgroup.c:3421>:
                    kfree()
            mutex_lock()
            list_add_tail()
            cgroup_apply_cftypes() <int cgroup_apply_cftypes (struct cftype *cfts, bool is_add) at cgroup.c:3394>:
                LIST_HEAD()
                lockdep_assert_held()
                css_for_each_descendant_pre()
                cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                    rcu_dereference_check()
                    lockdep_is_held()
                cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                    lockdep_assert_held()
                    cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                        cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                        cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                        IS_ERR()
                        PTR_ERR()
                        cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                            current_fsuid()
                            current_fsgid()
                            uid_eq()
                            gid_eq()
                            kernfs_setattr()
                        kernfs_remove()
                        spin_lock_irq()
                        spin_unlock_irq()
                    pr_warn()
                    cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                        lockdep_assert_held()
                        cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                            rcu_dereference_check()
                            lockdep_is_held()
                        spin_lock_irq()
                        spin_unlock_irq()
                        kernfs_remove_by_name()
                        cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                kernfs_activate()
            cgroup_rm_cftypes_locked() <int cgroup_rm_cftypes_locked (struct cftype *cfts) at cgroup.c:3471>:
                lockdep_assert_held()
                list_del()
                cgroup_apply_cftypes() <int cgroup_apply_cftypes (struct cftype *cfts, bool is_add) at cgroup.c:3394>:
                    LIST_HEAD()
                    lockdep_assert_held()
                    css_for_each_descendant_pre()
                    cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                        rcu_dereference_check()
                        lockdep_is_held()
                    cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                    cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                        lockdep_assert_held()
                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                            container_of()
                        cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                            cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                            cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                            IS_ERR()
                            PTR_ERR()
                            cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                                current_fsuid()
                                current_fsgid()
                                uid_eq()
                                gid_eq()
                                kernfs_setattr()
                            kernfs_remove()
                            spin_lock_irq()
                            spin_unlock_irq()
                        pr_warn()
                        cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                            lockdep_assert_held()
                            cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                                rcu_dereference_check()
                                lockdep_is_held()
                            spin_lock_irq()
                            spin_unlock_irq()
                            kernfs_remove_by_name()
                            cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    kernfs_activate()
                cgroup_exit_cftypes() <void cgroup_exit_cftypes (struct cftype *cfts) at cgroup.c:3421>:
                    kfree()
            mutex_unlock()
    cgroup_add_legacy_cftypes() <int cgroup_add_legacy_cftypes (struct cgroup_subsys *ss, struct cftype *cfts) at cgroup.c:3569>:
        cgroup_add_cftypes() <int cgroup_add_cftypes (struct cgroup_subsys *ss, struct cftype *cfts) at cgroup.c:3519>:
            cgroup_ssid_enabled() <bool cgroup_ssid_enabled (int ssid) at cgroup.c:239>:
                static_key_enabled()
            cgroup_init_cftypes() <int cgroup_init_cftypes (struct cgroup_subsys *ss, struct cftype *cfts) at cgroup.c:3437>:
                WARN_ON()
                kmemdup()
                cgroup_exit_cftypes() <void cgroup_exit_cftypes (struct cftype *cfts) at cgroup.c:3421>:
                    kfree()
            mutex_lock()
            list_add_tail()
            cgroup_apply_cftypes() <int cgroup_apply_cftypes (struct cftype *cfts, bool is_add) at cgroup.c:3394>:
                LIST_HEAD()
                lockdep_assert_held()
                css_for_each_descendant_pre()
                cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                    rcu_dereference_check()
                    lockdep_is_held()
                cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                    lockdep_assert_held()
                    cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                        cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                        cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                        IS_ERR()
                        PTR_ERR()
                        cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                            current_fsuid()
                            current_fsgid()
                            uid_eq()
                            gid_eq()
                            kernfs_setattr()
                        kernfs_remove()
                        spin_lock_irq()
                        spin_unlock_irq()
                    pr_warn()
                    cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                        lockdep_assert_held()
                        cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                            rcu_dereference_check()
                            lockdep_is_held()
                        spin_lock_irq()
                        spin_unlock_irq()
                        kernfs_remove_by_name()
                        cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                            cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                kernfs_activate()
            cgroup_rm_cftypes_locked() <int cgroup_rm_cftypes_locked (struct cftype *cfts) at cgroup.c:3471>:
                lockdep_assert_held()
                list_del()
                cgroup_apply_cftypes() <int cgroup_apply_cftypes (struct cftype *cfts, bool is_add) at cgroup.c:3394>:
                    LIST_HEAD()
                    lockdep_assert_held()
                    css_for_each_descendant_pre()
                    cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                        rcu_dereference_check()
                        lockdep_is_held()
                    cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                    cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                        lockdep_assert_held()
                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                            container_of()
                        cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                            cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                            cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                            IS_ERR()
                            PTR_ERR()
                            cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                                current_fsuid()
                                current_fsgid()
                                uid_eq()
                                gid_eq()
                                kernfs_setattr()
                            kernfs_remove()
                            spin_lock_irq()
                            spin_unlock_irq()
                        pr_warn()
                        cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                            lockdep_assert_held()
                            cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                                rcu_dereference_check()
                                lockdep_is_held()
                            spin_lock_irq()
                            spin_unlock_irq()
                            kernfs_remove_by_name()
                            cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    kernfs_activate()
                cgroup_exit_cftypes() <void cgroup_exit_cftypes (struct cftype *cfts) at cgroup.c:3421>:
                    kfree()
            mutex_unlock()
    sysfs_create_mount_point()
    register_filesystem()
    proc_create()
cgroup_init_early() <int __init cgroup_init_early (void) at cgroup.c:5242>:
    init_cgroup_root() <void init_cgroup_root (struct cgroup_root *root, struct cgroup_sb_opts *opts) at cgroup.c:1859>:
        INIT_LIST_HEAD()
        atomic_set()
        init_cgroup_housekeeping() <void init_cgroup_housekeeping (struct cgroup *cgrp) at cgroup.c:1839>:
            INIT_LIST_HEAD()
            mutex_init()
            for_each_subsys()
            init_waitqueue_head()
            INIT_WORK()
            cgroup_release_agent() <void cgroup_release_agent (struct work_struct *work) at cgroup.c:5695>:
                container_of()
                mutex_lock()
                kmalloc()
                kstrdup()
                cgroup_path()
                mutex_unlock()
                call_usermodehelper() <int call_usermodehelper (char *path, char **argv, char **envp, int wait) at kmod.c:616>:
                    call_usermodehelper_setup() <struct subprocess_info *call_usermodehelper_setup (char *path, char **argv, char **envp, gfp_t gfp_mask, int (*init) (struct subprocess_info *info, struct cred *new), void (*cleanup) (struct subprocess_info *info), void *data) at kmod.c:519>:
                        kzalloc()
                        INIT_WORK()
                        call_usermodehelper_exec_work() <void call_usermodehelper_exec_work (struct work_struct *work) at kmod.c:321>:
                            container_of()
                            call_usermodehelper_exec_sync() <void call_usermodehelper_exec_sync (struct subprocess_info *sub_info) at kmod.c:269>:
                                kernel_sigaction() <void kernel_sigaction (int sig, __sighandler_t action) at signal.c:3029>:
                                    spin_lock_irq()
                                    flush_sigqueue_mask() <int flush_sigqueue_mask (sigset_t *mask, struct sigpending *s) at signal.c:659>:
                                        sigandsets()
                                        sigisemptyset()
                                        sigandnsets()
                                        list_for_each_entry_safe()
                                        list_del_init()
                                    recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
                                        recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                                            PENDING()
                                            set_tsk_thread_flag()
                                        freezing()
                                        clear_thread_flag()
                                    spin_unlock_irq()
                                kernel_thread() <pid_t kernel_thread (int (*fn) (void *), void *arg, unsigned long flags) at fork.c:1779>:
                                call_usermodehelper_exec_async() <int call_usermodehelper_exec_async (void *data) at kmod.c:215>:
                                    spin_lock_irq()
                                    flush_signal_handlers() <void flush_signal_handlers (struct task_struct *t, int force_default) at signal.c:479>:
                                    spin_unlock_irq()
                                    set_user_nice()
                                    prepare_kernel_cred() <struct cred *prepare_kernel_cred (struct task_struct *daemon) at cred.c:594>:
                                        kmem_cache_alloc()
                                        kdebug()
                                        get_task_cred() <const struct cred *get_task_cred (struct task_struct *task) at cred.c:187>:
                                            rcu_read_lock()
                                            BUG_ON()
                                            atomic_inc_not_zero()
                                            rcu_read_unlock()
                                        get_cred()
                                        validate_creds()
                                        atomic_set()
                                        set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
                                            atomic_set()
                                        get_uid()
                                        get_user_ns()
                                        get_group_info()
                                        security_prepare_creds()
                                        put_cred()
                                    spin_lock()
                                    cap_intersect()
                                    spin_unlock()
                                    abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
                                        kdebug()
                                        atomic_read()
                                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                            atomic_read()
                                        BUG_ON()
                                        put_cred()
                                    commit_creds() <int commit_creds (struct cred *new) at cred.c:422>:
                                        kdebug()
                                        atomic_read()
                                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                            atomic_read()
                                        BUG_ON()
                                        validate_creds()
                                        get_cred()
                                        uid_eq()
                                        gid_eq()
                                        cred_cap_issubset() <bool cred_cap_issubset (const struct cred *set, const struct cred *subset) at cred.c:383>:
                                            cap_issubset()
                                            uid_eq()
                                        set_dumpable()
                                        smp_wmb()
                                        key_fsuid_changed()
                                        key_fsgid_changed()
                                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                            atomic_add()
                                        atomic_inc()
                                        rcu_assign_pointer()
                                        atomic_dec()
                                        proc_id_connector()
                                        put_cred()
                                    do_execve()
                                    getname_kernel()
                                    umh_complete() <void umh_complete (struct subprocess_info *sub_info) at kmod.c:198>:
                                        xchg()
                                        complete()
                                        call_usermodehelper_freeinfo() <void call_usermodehelper_freeinfo (struct subprocess_info *info) at kmod.c:191>:
                                            kfree()
                                    do_exit() <void do_exit (long code) at exit.c:651>:
                                        TASKS_RCU()
                                        profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
                                            blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
                                        WARN_ON()
                                        blk_needs_flush_plug()
                                        unlikely()
                                        in_interrupt()
                                        panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                            local_irq_disable()
                                            raw_smp_processor_id()
                                            atomic_cmpxchg()
                                            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                                cpu_relax()
                                            console_verbose()
                                            bust_spinlocks()
                                            pr_emerg()
                                            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                                test_bit()
                                            dump_stack()
                                            smp_send_stop()
                                            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                            kmsg_dump()
                                            debug_locks_off()
                                            console_flush_on_panic()
                                            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                            no_blink() <long no_blink (int state) at panic.c:46>
                                            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                                raw_cpu_write()
                                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                        raw_cpu_write()
                                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                        per_cpu()
                                                    raw_smp_processor_id()
                                            mdelay()
                                            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                                kmsg_dump()
                                                machine_emergency_restart()
                                            disabled_wait()
                                            local_irq_enable()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        set_fs()
                                        ptrace_event()
                                        validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
                                            kdebug()
                                            atomic_read()
                                            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                                atomic_read()
                                        pr_alert()
                                        set_current_state()
                                        schedule()
                                        exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
                                            threadgroup_change_begin()
                                            thread_group_empty()
                                            signal_group_exit()
                                            threadgroup_change_end()
                                            spin_lock_irq()
                                            signal_pending()
                                            signotset()
                                            retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                                                sigandsets()
                                                sigisemptyset()
                                                while_each_thread()
                                                has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                                                signal_pending()
                                                signal_wake_up()
                                            unlikely()
                                            task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                                                WARN_ON_ONCE()
                                                task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                                                    BUG_ON()
                                                    task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                                                        unlikely()
                                                        smp_mb()
                                                        wake_up_bit()
                                            spin_unlock_irq()
                                            read_lock()
                                            do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                                                rcu_read_lock()
                                                task_pid_nr_ns()
                                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                    ns_of_pid()
                                                    task_pid()
                                                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                            smp_rmb()
                                                task_cred_xxx()
                                                task_uid()
                                                rcu_read_unlock()
                                                task_cputime()
                                                cputime_to_clock_t()
                                                BUG()
                                                spin_lock_irqsave()
                                                spin_unlock_irqrestore()
                                            read_unlock()
                                        smp_mb()
                                        raw_spin_unlock_wait()
                                        in_atomic()
                                        pr_info()
                                        task_pid_nr()
                                        preempt_count()
                                        preempt_count_set()
                                        sync_mm_rss()
                                        acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
                                            task_cputime()
                                        atomic_dec_and_test()
                                        hrtimer_cancel()
                                        exit_itimers()
                                        setmax_mm_hiwater_rss()
                                        acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
                                            down_read()
                                            up_read()
                                            spin_lock_irq()
                                            thread_group_leader()
                                            task_cputime()
                                            spin_unlock_irq()
                                        tty_audit_exit()
                                        audit_free()
                                        taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
                                            taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                                                nla_total_size()
                                            taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                                                thread_group_empty()
                                                kmem_cache_zalloc()
                                                spin_lock_irq()
                                                spin_unlock_irq()
                                                kmem_cache_free()
                                            fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                                                spin_lock_irqsave()
                                                delayacct_add_tsk()
                                                spin_unlock_irqrestore()
                                            raw_cpu_ptr()
                                            list_empty()
                                            prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                                                genlmsg_new()
                                                this_cpu_inc_return()
                                                genlmsg_put()
                                                genlmsg_put_reply()
                                                nlmsg_free()
                                            mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                                                nla_put()
                                                nla_nest_start()
                                                nla_nest_cancel()
                                                nla_reserve()
                                                nla_nest_end()
                                                nla_data()
                                            task_pid_nr_ns()
                                            fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                                                delayacct_add_tsk()
                                                bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                                                    BUILD_BUG_ON()
                                                    ktime_get_ns()
                                                    do_div()
                                                    get_seconds()
                                                    thread_group_leader()
                                                    task_nice()
                                                    task_pid_nr_ns()
                                                    rcu_read_lock()
                                                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                                smp_rmb()
                                                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                                                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                                smp_rmb()
                                                    pid_alive()
                                                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                                        task_tgid()
                                                    rcu_dereference()
                                                    rcu_read_unlock()
                                                    task_cputime()
                                                    cputime_to_usecs()
                                                    task_cputime_scaled()
                                                xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                                                    get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                                        task_lock()
                                                        atomic_inc()
                                                        task_unlock()
                                                    get_mm_hiwater_rss()
                                                    get_mm_hiwater_vm()
                                                    mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                                        might_sleep()
                                                        atomic_dec_and_test()
                                                        uprobe_clear_state()
                                                        exit_aio()
                                                        ksm_exit()
                                                        khugepaged_exit()
                                                        exit_mmap()
                                                        set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                                            rcu_dereference_raw()
                                                            get_file()
                                                            rcu_assign_pointer()
                                                            fput()
                                                        list_empty()
                                                        spin_lock()
                                                        list_del()
                                                        spin_unlock()
                                                        module_put() <void module_put (struct module *module) at module.c:1098>:
                                                            preempt_disable()
                                                            atomic_dec_if_positive()
                                                            WARN_ON()
                                                            trace_module_put()
                                                            preempt_enable()
                                                        mmdrop()
                                            task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                                pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                                task_tgid()
                                            send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                                                nlmsg_data()
                                                nlmsg_hdr()
                                                genlmsg_data()
                                                genlmsg_end()
                                                down_read()
                                                list_for_each_entry()
                                                list_is_last()
                                                skb_clone()
                                                genlmsg_unicast()
                                                up_read()
                                                nlmsg_free()
                                                down_write()
                                                list_for_each_entry_safe()
                                                list_del()
                                                kfree()
                                                up_write()
                                            nlmsg_free()
                                        exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
                                            mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                                                unlikely()
                                                exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                                                    uninitialized_var()
                                                    fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                                                        get_user()
                                                    get_user()
                                                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                                                        uninitialized_var()
                                                        get_user()
                                                        task_pid_vnr()
                                                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                                            pagefault_disable()
                                                            futex_atomic_cmpxchg_inatomic()
                                                            pagefault_enable()
                                                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                                            down_read()
                                                            fixup_user_fault()
                                                            up_read()
                                                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                                            WAKE_Q()
                                                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                                                unlikely()
                                                                access_ok()
                                                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                                                    should_fail()
                                                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                                                    ihold()
                                                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                                                        atomic_inc()
                                                                        smp_mb__after_atomic()
                                                                    smp_mb()
                                                                get_user_pages_fast()
                                                                lock_page()
                                                                compound_head()
                                                                PageSwapCache()
                                                                unlock_page()
                                                                put_page()
                                                                PageAnon()
                                                                basepage_index()
                                                            unlikely()
                                                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                                                jhash2()
                                                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                                                atomic_read()
                                                            spin_lock()
                                                            plist_for_each_entry_safe()
                                                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                                                WARN()
                                                                wake_q_add()
                                                                smp_wmb()
                                                            spin_unlock()
                                                            wake_up_q()
                                                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                                                    WARN_ON_ONCE()
                                                                    iput()
                                                                    mmdrop()
                                                    cond_resched()
                                                compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                                                    uninitialized_var()
                                                    fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                                                        get_user()
                                                        compat_ptr()
                                                    get_user()
                                                    futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                                                        ptr_to_compat()
                                                        compat_ptr()
                                                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                                                        uninitialized_var()
                                                        get_user()
                                                        task_pid_vnr()
                                                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                                            pagefault_disable()
                                                            futex_atomic_cmpxchg_inatomic()
                                                            pagefault_enable()
                                                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                                            down_read()
                                                            fixup_user_fault()
                                                            up_read()
                                                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                                            WAKE_Q()
                                                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                                                unlikely()
                                                                access_ok()
                                                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                                                    should_fail()
                                                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                                                    ihold()
                                                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                                                        atomic_inc()
                                                                        smp_mb__after_atomic()
                                                                    smp_mb()
                                                                get_user_pages_fast()
                                                                lock_page()
                                                                compound_head()
                                                                PageSwapCache()
                                                                unlock_page()
                                                                put_page()
                                                                PageAnon()
                                                                basepage_index()
                                                            unlikely()
                                                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                                                jhash2()
                                                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                                                atomic_read()
                                                            spin_lock()
                                                            plist_for_each_entry_safe()
                                                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                                                WARN()
                                                                wake_q_add()
                                                                smp_wmb()
                                                            spin_unlock()
                                                            wake_up_q()
                                                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                                                    WARN_ON_ONCE()
                                                                    iput()
                                                                    mmdrop()
                                                    cond_resched()
                                                list_empty()
                                                exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                                                    raw_spin_lock_irq()
                                                    list_empty()
                                                    list_entry()
                                                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                                        jhash2()
                                                    raw_spin_unlock_irq()
                                                    spin_lock()
                                                    spin_unlock()
                                                    WARN_ON()
                                                    list_del_init()
                                                    rt_mutex_unlock()
                                                uprobe_free_utask()
                                                deactivate_mm()
                                                atomic_read()
                                                put_user()
                                                sys_futex()
                                                complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                                                    task_lock()
                                                    likely()
                                                    complete()
                                                    task_unlock()
                                            sync_mm_rss()
                                            down_read()
                                            up_read()
                                            xchg()
                                            atomic_dec_and_test()
                                            complete()
                                            set_task_state()
                                            freezable_schedule()
                                            atomic_inc()
                                            BUG_ON()
                                            task_lock()
                                            enter_lazy_tlb()
                                            task_unlock()
                                            mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                                                atomic_read()
                                                read_lock()
                                                list_for_each_entry()
                                                for_each_process()
                                                for_each_thread()
                                                read_unlock()
                                                BUG_ON()
                                                get_task_struct()
                                                task_lock()
                                                task_unlock()
                                                put_task_struct()
                                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                                might_sleep()
                                                atomic_dec_and_test()
                                                uprobe_clear_state()
                                                exit_aio()
                                                ksm_exit()
                                                khugepaged_exit()
                                                exit_mmap()
                                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                                    rcu_dereference_raw()
                                                    get_file()
                                                    rcu_assign_pointer()
                                                    fput()
                                                list_empty()
                                                spin_lock()
                                                list_del()
                                                spin_unlock()
                                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                                    preempt_disable()
                                                    atomic_dec_if_positive()
                                                    WARN_ON()
                                                    trace_module_put()
                                                    preempt_enable()
                                                mmdrop()
                                            test_thread_flag()
                                            exit_oom_victim()
                                        acct_process() <void acct_process (void) at acct.c:587>:
                                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                ns_of_pid()
                                                task_pid()
                                            unlikely()
                                            slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                                                acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                                                    smp_rmb()
                                                    rcu_read_lock()
                                                    to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                                                        container_of()
                                                    ACCESS_ONCE()
                                                    rcu_read_unlock()
                                                    atomic_long_inc_not_zero()
                                                    cpu_relax()
                                                    mutex_lock()
                                                    mutex_unlock()
                                                    acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                                                        atomic_long_dec_and_test()
                                                        kfree_rcu()
                                                do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                                                    override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                                                        kdebug()
                                                        atomic_read()
                                                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                                            atomic_read()
                                                        validate_creds()
                                                        get_cred()
                                                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                                            atomic_add()
                                                        rcu_assign_pointer()
                                                    check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                                                        time_is_before_jiffies()
                                                        vfs_statfs()
                                                        do_div()
                                                        pr_info()
                                                    fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                                                        strlcpy()
                                                        ktime_get_ns()
                                                        nsec_to_AHZ()
                                                        encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                                                        encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                                                        encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                                                        do_div()
                                                        get_seconds()
                                                        spin_lock_irq()
                                                        old_encode_dev()
                                                        tty_devnum()
                                                        jiffies_to_AHZ()
                                                        cputime_to_jiffies()
                                                        spin_unlock_irq()
                                                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                                smp_rmb()
                                                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                                                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                                smp_rmb()
                                                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                                        task_tgid()
                                                    rcu_read_lock()
                                                    rcu_dereference()
                                                    rcu_read_unlock()
                                                    file_start_write_trylock()
                                                    file_end_write()
                                                    revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                                                        kdebug()
                                                        atomic_read()
                                                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                                            atomic_read()
                                                        validate_creds()
                                                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                                            atomic_add()
                                                        rcu_assign_pointer()
                                                        put_cred()
                                                mutex_unlock()
                                                acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                                                    atomic_long_dec_and_test()
                                                    kfree_rcu()
                                        trace_sched_process_exit()
                                        exit_sem()
                                        exit_shm()
                                        exit_files()
                                        exit_fs()
                                        disassociate_ctty()
                                        exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
                                            switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                                                might_sleep()
                                                task_lock()
                                                task_unlock()
                                                atomic_dec_and_test()
                                                free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                                                    put_mnt_ns()
                                                    put_uts_ns()
                                                    put_ipc_ns()
                                                    put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                                                        kref_put()
                                                        free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                                            container_of()
                                                            destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                                                ns_free_inum()
                                                                kfree()
                                                                put_user_ns()
                                                                call_rcu()
                                                                delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                                                    kmem_cache_free()
                                                                    container_of()
                                                    put_net()
                                                    kmem_cache_free()
                                        exit_task_work()
                                        exit_thread()
                                        perf_event_exit_task()
                                        cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
                                            task_css_set()
                                            list_empty()
                                            spin_lock_bh()
                                            css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                                                lockdep_assert_held()
                                                WARN_ON_ONCE()
                                                list_empty()
                                                list_for_each_entry_safe()
                                                css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                                                    lockdep_assert_held()
                                                    WARN_ON_ONCE()
                                                    css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                                                        lockdep_assert_held()
                                                        container_of()
                                                        list_entry()
                                                        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                                            lockdep_assert_held()
                                                            list_empty()
                                                        list_empty()
                                                        list_del()
                                                        put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                                                            lockdep_assert_held()
                                                            atomic_dec_and_test()
                                                            for_each_subsys()
                                                            list_del()
                                                            css_put()
                                                            hash_del()
                                                            list_for_each_entry_safe()
                                                            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                                                container_of()
                                                            cgroup_put()
                                                            kfree()
                                                            kfree_rcu()
                                                        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                                            atomic_inc()
                                                        list_add()
                                                list_del_init()
                                                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                                    lockdep_assert_held()
                                                    list_empty()
                                                css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                                                    lockdep_assert_held()
                                                    list_for_each_entry()
                                                    cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                                                        lockdep_assert_held()
                                                        check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                                                            notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                                                test_bit()
                                                            cgroup_is_populated()
                                                            css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                                                rcu_read_lock()
                                                                css_for_each_child()
                                                                rcu_read_unlock()
                                                            cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                                                            schedule_work()
                                                        cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                                                            spin_lock_irqsave()
                                                            kernfs_notify()
                                                            spin_unlock_irqrestore()
                                                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                                            container_of()
                                                rcu_assign_pointer()
                                                list_add_tail()
                                            spin_unlock_bh()
                                            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                                atomic_inc()
                                            for_each_subsys_which()
                                        flush_ptrace_hw_breakpoint()
                                        preempt_disable()
                                        preempt_enable()
                                        exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
                                            LIST_HEAD()
                                            write_lock_irq()
                                            forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                                                unlikely()
                                                list_empty()
                                                exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                                                    list_for_each_entry_safe()
                                                    unlikely()
                                                    send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                                                        valid_signal()
                                                        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                                            lock_task_sighand()
                                                            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                                                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                                                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                                                    SI_FROMUSER()
                                                                task_pid_nr_ns()
                                                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                                    ns_of_pid()
                                                                    task_pid()
                                                            unlock_task_sighand()
                                                    list_add()
                                                find_child_reaper()
                                                find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                                                    find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                                                        for_each_thread()
                                                    same_thread_group()
                                                list_for_each_entry()
                                                for_each_thread()
                                                BUG_ON()
                                                likely()
                                                group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                                                    rcu_read_lock()
                                                    check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                                                        valid_signal()
                                                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                                            SI_FROMUSER()
                                                        audit_signal_info()
                                                        same_thread_group()
                                                        kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                                                            current_cred()
                                                            uid_eq()
                                                            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                                                unlikely()
                                                                cap_valid()
                                                                pr_crit()
                                                                BUG()
                                                                security_capable()
                                                                current_cred()
                                                        task_session()
                                                        security_task_kill()
                                                    rcu_read_unlock()
                                                    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                                        lock_task_sighand()
                                                        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                                                SI_FROMUSER()
                                                            task_pid_nr_ns()
                                                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                                ns_of_pid()
                                                                task_pid()
                                                        unlock_task_sighand()
                                                same_thread_group()
                                                reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                                                    unlikely()
                                                    thread_group_empty()
                                                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                                                        BUG_ON()
                                                        task_is_stopped_or_traced()
                                                        thread_group_empty()
                                                        rcu_read_lock()
                                                        task_pid_nr_ns()
                                                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                            ns_of_pid()
                                                            task_pid()
                                                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                                    smp_rmb()
                                                        task_cred_xxx()
                                                        task_uid()
                                                        rcu_read_unlock()
                                                        task_cputime()
                                                        cputime_to_clock_t()
                                                        spin_lock_irqsave()
                                                        valid_signal()
                                                        spin_unlock_irqrestore()
                                                    list_add()
                                                    kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                                                        task_pgrp()
                                                        task_session()
                                                        will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                                                            do_each_pid_task()
                                                            thread_group_empty()
                                                            is_global_init()
                                                            task_pgrp()
                                                            task_session()
                                                            while_each_pid_task()
                                                        has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                                                            do_each_pid_task()
                                                            while_each_pid_task()
                                                list_splice_tail_init()
                                            kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                                                task_pgrp()
                                                task_session()
                                                will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                                                    do_each_pid_task()
                                                    thread_group_empty()
                                                    is_global_init()
                                                    task_pgrp()
                                                    task_session()
                                                    while_each_pid_task()
                                                has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                                                    do_each_pid_task()
                                                    while_each_pid_task()
                                            unlikely()
                                            thread_group_leader()
                                            thread_group_empty()
                                            ptrace_reparented()
                                            do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                                                BUG_ON()
                                                task_is_stopped_or_traced()
                                                thread_group_empty()
                                                rcu_read_lock()
                                                task_pid_nr_ns()
                                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                    ns_of_pid()
                                                    task_pid()
                                                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                            smp_rmb()
                                                task_cred_xxx()
                                                task_uid()
                                                rcu_read_unlock()
                                                task_cputime()
                                                cputime_to_clock_t()
                                                spin_lock_irqsave()
                                                valid_signal()
                                                spin_unlock_irqrestore()
                                            list_add()
                                            wake_up_process()
                                            write_unlock_irq()
                                            list_for_each_entry_safe()
                                            list_del_init()
                                            release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                                                rcu_read_lock()
                                                atomic_dec()
                                                rcu_read_unlock()
                                                proc_flush_task()
                                                write_lock_irq()
                                                ptrace_release_task()
                                                thread_group_empty()
                                                do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                                                    BUG_ON()
                                                    task_is_stopped_or_traced()
                                                    thread_group_empty()
                                                    rcu_read_lock()
                                                    task_pid_nr_ns()
                                                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                        ns_of_pid()
                                                        task_pid()
                                                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                                smp_rmb()
                                                    task_cred_xxx()
                                                    task_uid()
                                                    rcu_read_unlock()
                                                    task_cputime()
                                                    cputime_to_clock_t()
                                                    spin_lock_irqsave()
                                                    valid_signal()
                                                    spin_unlock_irqrestore()
                                                write_unlock_irq()
                                                release_thread()
                                                call_rcu()
                                                delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                                                    container_of()
                                                    perf_event_delayed_put()
                                                    trace_sched_process_free()
                                                    put_task_struct()
                                                unlikely()
                                        proc_exit_connector()
                                        task_lock()
                                        mpol_put()
                                        task_unlock()
                                        kfree()
                                        debug_check_no_locks_held()
                                        exit_io_context()
                                        free_pipe_info()
                                        put_page()
                                        check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
                                            stack_not_used()
                                            spin_lock()
                                            pr_warn()
                                            task_pid_nr()
                                            spin_unlock()
                                        exit_rcu()
                                        BUG()
                                        cpu_relax()
                                sys_wait4()
                                umh_complete() <void umh_complete (struct subprocess_info *sub_info) at kmod.c:198>:
                                    xchg()
                                    complete()
                                    call_usermodehelper_freeinfo() <void call_usermodehelper_freeinfo (struct subprocess_info *info) at kmod.c:191>:
                                        kfree()
                            kernel_thread() <pid_t kernel_thread (int (*fn) (void *), void *arg, unsigned long flags) at fork.c:1779>:
                            call_usermodehelper_exec_async() <int call_usermodehelper_exec_async (void *data) at kmod.c:215>:
                                spin_lock_irq()
                                flush_signal_handlers() <void flush_signal_handlers (struct task_struct *t, int force_default) at signal.c:479>:
                                spin_unlock_irq()
                                set_user_nice()
                                prepare_kernel_cred() <struct cred *prepare_kernel_cred (struct task_struct *daemon) at cred.c:594>:
                                    kmem_cache_alloc()
                                    kdebug()
                                    get_task_cred() <const struct cred *get_task_cred (struct task_struct *task) at cred.c:187>:
                                        rcu_read_lock()
                                        BUG_ON()
                                        atomic_inc_not_zero()
                                        rcu_read_unlock()
                                    get_cred()
                                    validate_creds()
                                    atomic_set()
                                    set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
                                        atomic_set()
                                    get_uid()
                                    get_user_ns()
                                    get_group_info()
                                    security_prepare_creds()
                                    put_cred()
                                spin_lock()
                                cap_intersect()
                                spin_unlock()
                                abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
                                    kdebug()
                                    atomic_read()
                                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                        atomic_read()
                                    BUG_ON()
                                    put_cred()
                                commit_creds() <int commit_creds (struct cred *new) at cred.c:422>:
                                    kdebug()
                                    atomic_read()
                                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                        atomic_read()
                                    BUG_ON()
                                    validate_creds()
                                    get_cred()
                                    uid_eq()
                                    gid_eq()
                                    cred_cap_issubset() <bool cred_cap_issubset (const struct cred *set, const struct cred *subset) at cred.c:383>:
                                        cap_issubset()
                                        uid_eq()
                                    set_dumpable()
                                    smp_wmb()
                                    key_fsuid_changed()
                                    key_fsgid_changed()
                                    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                        atomic_add()
                                    atomic_inc()
                                    rcu_assign_pointer()
                                    atomic_dec()
                                    proc_id_connector()
                                    put_cred()
                                do_execve()
                                getname_kernel()
                                umh_complete() <void umh_complete (struct subprocess_info *sub_info) at kmod.c:198>:
                                    xchg()
                                    complete()
                                    call_usermodehelper_freeinfo() <void call_usermodehelper_freeinfo (struct subprocess_info *info) at kmod.c:191>:
                                        kfree()
                                do_exit() <void do_exit (long code) at exit.c:651>:
                                    TASKS_RCU()
                                    profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
                                        blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
                                    WARN_ON()
                                    blk_needs_flush_plug()
                                    unlikely()
                                    in_interrupt()
                                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                        local_irq_disable()
                                        raw_smp_processor_id()
                                        atomic_cmpxchg()
                                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                            cpu_relax()
                                        console_verbose()
                                        bust_spinlocks()
                                        pr_emerg()
                                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                            test_bit()
                                        dump_stack()
                                        smp_send_stop()
                                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                        kmsg_dump()
                                        debug_locks_off()
                                        console_flush_on_panic()
                                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                        no_blink() <long no_blink (int state) at panic.c:46>
                                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                            raw_cpu_write()
                                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                    raw_cpu_write()
                                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                    per_cpu()
                                                raw_smp_processor_id()
                                        mdelay()
                                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                            kmsg_dump()
                                            machine_emergency_restart()
                                        disabled_wait()
                                        local_irq_enable()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    set_fs()
                                    ptrace_event()
                                    validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
                                        kdebug()
                                        atomic_read()
                                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                            atomic_read()
                                    pr_alert()
                                    set_current_state()
                                    schedule()
                                    exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
                                        threadgroup_change_begin()
                                        thread_group_empty()
                                        signal_group_exit()
                                        threadgroup_change_end()
                                        spin_lock_irq()
                                        signal_pending()
                                        signotset()
                                        retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                                            sigandsets()
                                            sigisemptyset()
                                            while_each_thread()
                                            has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                                            signal_pending()
                                            signal_wake_up()
                                        unlikely()
                                        task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                                            WARN_ON_ONCE()
                                            task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                                                BUG_ON()
                                                task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                                                    unlikely()
                                                    smp_mb()
                                                    wake_up_bit()
                                        spin_unlock_irq()
                                        read_lock()
                                        do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                                            rcu_read_lock()
                                            task_pid_nr_ns()
                                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                ns_of_pid()
                                                task_pid()
                                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                        smp_rmb()
                                            task_cred_xxx()
                                            task_uid()
                                            rcu_read_unlock()
                                            task_cputime()
                                            cputime_to_clock_t()
                                            BUG()
                                            spin_lock_irqsave()
                                            spin_unlock_irqrestore()
                                        read_unlock()
                                    smp_mb()
                                    raw_spin_unlock_wait()
                                    in_atomic()
                                    pr_info()
                                    task_pid_nr()
                                    preempt_count()
                                    preempt_count_set()
                                    sync_mm_rss()
                                    acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
                                        task_cputime()
                                    atomic_dec_and_test()
                                    hrtimer_cancel()
                                    exit_itimers()
                                    setmax_mm_hiwater_rss()
                                    acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
                                        down_read()
                                        up_read()
                                        spin_lock_irq()
                                        thread_group_leader()
                                        task_cputime()
                                        spin_unlock_irq()
                                    tty_audit_exit()
                                    audit_free()
                                    taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
                                        taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                                            nla_total_size()
                                        taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                                            thread_group_empty()
                                            kmem_cache_zalloc()
                                            spin_lock_irq()
                                            spin_unlock_irq()
                                            kmem_cache_free()
                                        fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                                            spin_lock_irqsave()
                                            delayacct_add_tsk()
                                            spin_unlock_irqrestore()
                                        raw_cpu_ptr()
                                        list_empty()
                                        prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                                            genlmsg_new()
                                            this_cpu_inc_return()
                                            genlmsg_put()
                                            genlmsg_put_reply()
                                            nlmsg_free()
                                        mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                                            nla_put()
                                            nla_nest_start()
                                            nla_nest_cancel()
                                            nla_reserve()
                                            nla_nest_end()
                                            nla_data()
                                        task_pid_nr_ns()
                                        fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                                            delayacct_add_tsk()
                                            bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                                                BUILD_BUG_ON()
                                                ktime_get_ns()
                                                do_div()
                                                get_seconds()
                                                thread_group_leader()
                                                task_nice()
                                                task_pid_nr_ns()
                                                rcu_read_lock()
                                                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                            smp_rmb()
                                                from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                                                    from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                            smp_rmb()
                                                pid_alive()
                                                task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                                    pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                                    task_tgid()
                                                rcu_dereference()
                                                rcu_read_unlock()
                                                task_cputime()
                                                cputime_to_usecs()
                                                task_cputime_scaled()
                                            xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                                                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                                    task_lock()
                                                    atomic_inc()
                                                    task_unlock()
                                                get_mm_hiwater_rss()
                                                get_mm_hiwater_vm()
                                                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                                    might_sleep()
                                                    atomic_dec_and_test()
                                                    uprobe_clear_state()
                                                    exit_aio()
                                                    ksm_exit()
                                                    khugepaged_exit()
                                                    exit_mmap()
                                                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                                        rcu_dereference_raw()
                                                        get_file()
                                                        rcu_assign_pointer()
                                                        fput()
                                                    list_empty()
                                                    spin_lock()
                                                    list_del()
                                                    spin_unlock()
                                                    module_put() <void module_put (struct module *module) at module.c:1098>:
                                                        preempt_disable()
                                                        atomic_dec_if_positive()
                                                        WARN_ON()
                                                        trace_module_put()
                                                        preempt_enable()
                                                    mmdrop()
                                        task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                            pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                            task_tgid()
                                        send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                                            nlmsg_data()
                                            nlmsg_hdr()
                                            genlmsg_data()
                                            genlmsg_end()
                                            down_read()
                                            list_for_each_entry()
                                            list_is_last()
                                            skb_clone()
                                            genlmsg_unicast()
                                            up_read()
                                            nlmsg_free()
                                            down_write()
                                            list_for_each_entry_safe()
                                            list_del()
                                            kfree()
                                            up_write()
                                        nlmsg_free()
                                    exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
                                        mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                                            unlikely()
                                            exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                                                uninitialized_var()
                                                fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                                                    get_user()
                                                get_user()
                                                handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                                                    uninitialized_var()
                                                    get_user()
                                                    task_pid_vnr()
                                                    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                                        pagefault_disable()
                                                        futex_atomic_cmpxchg_inatomic()
                                                        pagefault_enable()
                                                    fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                                        down_read()
                                                        fixup_user_fault()
                                                        up_read()
                                                    futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                                        WAKE_Q()
                                                        get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                                            unlikely()
                                                            access_ok()
                                                            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                                                should_fail()
                                                            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                                                ihold()
                                                                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                                                    atomic_inc()
                                                                    smp_mb__after_atomic()
                                                                smp_mb()
                                                            get_user_pages_fast()
                                                            lock_page()
                                                            compound_head()
                                                            PageSwapCache()
                                                            unlock_page()
                                                            put_page()
                                                            PageAnon()
                                                            basepage_index()
                                                        unlikely()
                                                        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                                            jhash2()
                                                        hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                                            atomic_read()
                                                        spin_lock()
                                                        plist_for_each_entry_safe()
                                                        match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                                        mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                                            WARN()
                                                            wake_q_add()
                                                            smp_wmb()
                                                        spin_unlock()
                                                        wake_up_q()
                                                        put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                                            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                                                WARN_ON_ONCE()
                                                                iput()
                                                                mmdrop()
                                                cond_resched()
                                            compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                                                uninitialized_var()
                                                fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                                                    get_user()
                                                    compat_ptr()
                                                get_user()
                                                futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                                                    ptr_to_compat()
                                                    compat_ptr()
                                                handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                                                    uninitialized_var()
                                                    get_user()
                                                    task_pid_vnr()
                                                    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                                        pagefault_disable()
                                                        futex_atomic_cmpxchg_inatomic()
                                                        pagefault_enable()
                                                    fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                                        down_read()
                                                        fixup_user_fault()
                                                        up_read()
                                                    futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                                        WAKE_Q()
                                                        get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                                            unlikely()
                                                            access_ok()
                                                            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                                                should_fail()
                                                            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                                                ihold()
                                                                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                                                    atomic_inc()
                                                                    smp_mb__after_atomic()
                                                                smp_mb()
                                                            get_user_pages_fast()
                                                            lock_page()
                                                            compound_head()
                                                            PageSwapCache()
                                                            unlock_page()
                                                            put_page()
                                                            PageAnon()
                                                            basepage_index()
                                                        unlikely()
                                                        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                                            jhash2()
                                                        hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                                            atomic_read()
                                                        spin_lock()
                                                        plist_for_each_entry_safe()
                                                        match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                                        mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                                            WARN()
                                                            wake_q_add()
                                                            smp_wmb()
                                                        spin_unlock()
                                                        wake_up_q()
                                                        put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                                            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                                                WARN_ON_ONCE()
                                                                iput()
                                                                mmdrop()
                                                cond_resched()
                                            list_empty()
                                            exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                                                raw_spin_lock_irq()
                                                list_empty()
                                                list_entry()
                                                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                                    jhash2()
                                                raw_spin_unlock_irq()
                                                spin_lock()
                                                spin_unlock()
                                                WARN_ON()
                                                list_del_init()
                                                rt_mutex_unlock()
                                            uprobe_free_utask()
                                            deactivate_mm()
                                            atomic_read()
                                            put_user()
                                            sys_futex()
                                            complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                                                task_lock()
                                                likely()
                                                complete()
                                                task_unlock()
                                        sync_mm_rss()
                                        down_read()
                                        up_read()
                                        xchg()
                                        atomic_dec_and_test()
                                        complete()
                                        set_task_state()
                                        freezable_schedule()
                                        atomic_inc()
                                        BUG_ON()
                                        task_lock()
                                        enter_lazy_tlb()
                                        task_unlock()
                                        mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                                            atomic_read()
                                            read_lock()
                                            list_for_each_entry()
                                            for_each_process()
                                            for_each_thread()
                                            read_unlock()
                                            BUG_ON()
                                            get_task_struct()
                                            task_lock()
                                            task_unlock()
                                            put_task_struct()
                                        mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                            might_sleep()
                                            atomic_dec_and_test()
                                            uprobe_clear_state()
                                            exit_aio()
                                            ksm_exit()
                                            khugepaged_exit()
                                            exit_mmap()
                                            set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                                rcu_dereference_raw()
                                                get_file()
                                                rcu_assign_pointer()
                                                fput()
                                            list_empty()
                                            spin_lock()
                                            list_del()
                                            spin_unlock()
                                            module_put() <void module_put (struct module *module) at module.c:1098>:
                                                preempt_disable()
                                                atomic_dec_if_positive()
                                                WARN_ON()
                                                trace_module_put()
                                                preempt_enable()
                                            mmdrop()
                                        test_thread_flag()
                                        exit_oom_victim()
                                    acct_process() <void acct_process (void) at acct.c:587>:
                                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                            ns_of_pid()
                                            task_pid()
                                        unlikely()
                                        slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                                            acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                                                smp_rmb()
                                                rcu_read_lock()
                                                to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                                                    container_of()
                                                ACCESS_ONCE()
                                                rcu_read_unlock()
                                                atomic_long_inc_not_zero()
                                                cpu_relax()
                                                mutex_lock()
                                                mutex_unlock()
                                                acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                                                    atomic_long_dec_and_test()
                                                    kfree_rcu()
                                            do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                                                override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                                                    kdebug()
                                                    atomic_read()
                                                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                                        atomic_read()
                                                    validate_creds()
                                                    get_cred()
                                                    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                                        atomic_add()
                                                    rcu_assign_pointer()
                                                check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                                                    time_is_before_jiffies()
                                                    vfs_statfs()
                                                    do_div()
                                                    pr_info()
                                                fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                                                    strlcpy()
                                                    ktime_get_ns()
                                                    nsec_to_AHZ()
                                                    encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                                                    encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                                                    encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                                                    do_div()
                                                    get_seconds()
                                                    spin_lock_irq()
                                                    old_encode_dev()
                                                    tty_devnum()
                                                    jiffies_to_AHZ()
                                                    cputime_to_jiffies()
                                                    spin_unlock_irq()
                                                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                            smp_rmb()
                                                from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                                                    from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                            smp_rmb()
                                                task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                                    pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                                    task_tgid()
                                                rcu_read_lock()
                                                rcu_dereference()
                                                rcu_read_unlock()
                                                file_start_write_trylock()
                                                file_end_write()
                                                revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                                                    kdebug()
                                                    atomic_read()
                                                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                                        atomic_read()
                                                    validate_creds()
                                                    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                                        atomic_add()
                                                    rcu_assign_pointer()
                                                    put_cred()
                                            mutex_unlock()
                                            acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                                                atomic_long_dec_and_test()
                                                kfree_rcu()
                                    trace_sched_process_exit()
                                    exit_sem()
                                    exit_shm()
                                    exit_files()
                                    exit_fs()
                                    disassociate_ctty()
                                    exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
                                        switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                                            might_sleep()
                                            task_lock()
                                            task_unlock()
                                            atomic_dec_and_test()
                                            free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                                                put_mnt_ns()
                                                put_uts_ns()
                                                put_ipc_ns()
                                                put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                                                    kref_put()
                                                    free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                                        container_of()
                                                        destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                                            ns_free_inum()
                                                            kfree()
                                                            put_user_ns()
                                                            call_rcu()
                                                            delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                                                kmem_cache_free()
                                                                container_of()
                                                put_net()
                                                kmem_cache_free()
                                    exit_task_work()
                                    exit_thread()
                                    perf_event_exit_task()
                                    cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
                                        task_css_set()
                                        list_empty()
                                        spin_lock_bh()
                                        css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                                            lockdep_assert_held()
                                            WARN_ON_ONCE()
                                            list_empty()
                                            list_for_each_entry_safe()
                                            css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                                                lockdep_assert_held()
                                                WARN_ON_ONCE()
                                                css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                                                    lockdep_assert_held()
                                                    container_of()
                                                    list_entry()
                                                    css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                                        lockdep_assert_held()
                                                        list_empty()
                                                    list_empty()
                                                    list_del()
                                                    put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                                                        lockdep_assert_held()
                                                        atomic_dec_and_test()
                                                        for_each_subsys()
                                                        list_del()
                                                        css_put()
                                                        hash_del()
                                                        list_for_each_entry_safe()
                                                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                                            container_of()
                                                        cgroup_put()
                                                        kfree()
                                                        kfree_rcu()
                                                    get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                                        atomic_inc()
                                                    list_add()
                                            list_del_init()
                                            css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                                lockdep_assert_held()
                                                list_empty()
                                            css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                                                lockdep_assert_held()
                                                list_for_each_entry()
                                                cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                                                    lockdep_assert_held()
                                                    check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                                                        notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                                            test_bit()
                                                        cgroup_is_populated()
                                                        css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                                            rcu_read_lock()
                                                            css_for_each_child()
                                                            rcu_read_unlock()
                                                        cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                                                        schedule_work()
                                                    cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                                                        spin_lock_irqsave()
                                                        kernfs_notify()
                                                        spin_unlock_irqrestore()
                                                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                                        container_of()
                                            rcu_assign_pointer()
                                            list_add_tail()
                                        spin_unlock_bh()
                                        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                            atomic_inc()
                                        for_each_subsys_which()
                                    flush_ptrace_hw_breakpoint()
                                    preempt_disable()
                                    preempt_enable()
                                    exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
                                        LIST_HEAD()
                                        write_lock_irq()
                                        forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                                            unlikely()
                                            list_empty()
                                            exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                                                list_for_each_entry_safe()
                                                unlikely()
                                                send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                                                    valid_signal()
                                                    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                                        lock_task_sighand()
                                                        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                                                SI_FROMUSER()
                                                            task_pid_nr_ns()
                                                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                                ns_of_pid()
                                                                task_pid()
                                                        unlock_task_sighand()
                                                list_add()
                                            find_child_reaper()
                                            find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                                                find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                                                    for_each_thread()
                                                same_thread_group()
                                            list_for_each_entry()
                                            for_each_thread()
                                            BUG_ON()
                                            likely()
                                            group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                                                rcu_read_lock()
                                                check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                                                    valid_signal()
                                                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                                        SI_FROMUSER()
                                                    audit_signal_info()
                                                    same_thread_group()
                                                    kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                                                        current_cred()
                                                        uid_eq()
                                                        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                                            unlikely()
                                                            cap_valid()
                                                            pr_crit()
                                                            BUG()
                                                            security_capable()
                                                            current_cred()
                                                    task_session()
                                                    security_task_kill()
                                                rcu_read_unlock()
                                                do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                                    lock_task_sighand()
                                                    send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                                            SI_FROMUSER()
                                                        task_pid_nr_ns()
                                                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                            ns_of_pid()
                                                            task_pid()
                                                    unlock_task_sighand()
                                            same_thread_group()
                                            reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                                                unlikely()
                                                thread_group_empty()
                                                do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                                                    BUG_ON()
                                                    task_is_stopped_or_traced()
                                                    thread_group_empty()
                                                    rcu_read_lock()
                                                    task_pid_nr_ns()
                                                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                        ns_of_pid()
                                                        task_pid()
                                                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                                smp_rmb()
                                                    task_cred_xxx()
                                                    task_uid()
                                                    rcu_read_unlock()
                                                    task_cputime()
                                                    cputime_to_clock_t()
                                                    spin_lock_irqsave()
                                                    valid_signal()
                                                    spin_unlock_irqrestore()
                                                list_add()
                                                kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                                                    task_pgrp()
                                                    task_session()
                                                    will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                                                        do_each_pid_task()
                                                        thread_group_empty()
                                                        is_global_init()
                                                        task_pgrp()
                                                        task_session()
                                                        while_each_pid_task()
                                                    has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                                                        do_each_pid_task()
                                                        while_each_pid_task()
                                            list_splice_tail_init()
                                        kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                                            task_pgrp()
                                            task_session()
                                            will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                                                do_each_pid_task()
                                                thread_group_empty()
                                                is_global_init()
                                                task_pgrp()
                                                task_session()
                                                while_each_pid_task()
                                            has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                                                do_each_pid_task()
                                                while_each_pid_task()
                                        unlikely()
                                        thread_group_leader()
                                        thread_group_empty()
                                        ptrace_reparented()
                                        do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                                            BUG_ON()
                                            task_is_stopped_or_traced()
                                            thread_group_empty()
                                            rcu_read_lock()
                                            task_pid_nr_ns()
                                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                ns_of_pid()
                                                task_pid()
                                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                        smp_rmb()
                                            task_cred_xxx()
                                            task_uid()
                                            rcu_read_unlock()
                                            task_cputime()
                                            cputime_to_clock_t()
                                            spin_lock_irqsave()
                                            valid_signal()
                                            spin_unlock_irqrestore()
                                        list_add()
                                        wake_up_process()
                                        write_unlock_irq()
                                        list_for_each_entry_safe()
                                        list_del_init()
                                        release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                                            rcu_read_lock()
                                            atomic_dec()
                                            rcu_read_unlock()
                                            proc_flush_task()
                                            write_lock_irq()
                                            ptrace_release_task()
                                            thread_group_empty()
                                            do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                                                BUG_ON()
                                                task_is_stopped_or_traced()
                                                thread_group_empty()
                                                rcu_read_lock()
                                                task_pid_nr_ns()
                                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                                    ns_of_pid()
                                                    task_pid()
                                                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                                            smp_rmb()
                                                task_cred_xxx()
                                                task_uid()
                                                rcu_read_unlock()
                                                task_cputime()
                                                cputime_to_clock_t()
                                                spin_lock_irqsave()
                                                valid_signal()
                                                spin_unlock_irqrestore()
                                            write_unlock_irq()
                                            release_thread()
                                            call_rcu()
                                            delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                                                container_of()
                                                perf_event_delayed_put()
                                                trace_sched_process_free()
                                                put_task_struct()
                                            unlikely()
                                    proc_exit_connector()
                                    task_lock()
                                    mpol_put()
                                    task_unlock()
                                    kfree()
                                    debug_check_no_locks_held()
                                    exit_io_context()
                                    free_pipe_info()
                                    put_page()
                                    check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
                                        stack_not_used()
                                        spin_lock()
                                        pr_warn()
                                        task_pid_nr()
                                        spin_unlock()
                                    exit_rcu()
                                    BUG()
                                    cpu_relax()
                            umh_complete() <void umh_complete (struct subprocess_info *sub_info) at kmod.c:198>:
                                xchg()
                                complete()
                                call_usermodehelper_freeinfo() <void call_usermodehelper_freeinfo (struct subprocess_info *info) at kmod.c:191>:
                                    kfree()
                    call_usermodehelper_exec() <int call_usermodehelper_exec (struct subprocess_info *sub_info, int wait) at kmod.c:555>:
                        DECLARE_COMPLETION_ONSTACK()
                        call_usermodehelper_freeinfo() <void call_usermodehelper_freeinfo (struct subprocess_info *info) at kmod.c:191>:
                            kfree()
                        helper_lock() <void helper_lock (void) at kmod.c:484>:
                            atomic_inc()
                            smp_mb__after_atomic()
                        queue_work()
                        wait_for_completion_killable()
                        xchg()
                        wait_for_completion()
                        helper_unlock() <void helper_unlock (void) at kmod.c:490>:
                            atomic_dec_and_test()
                            wake_up()
                kfree()
        idr_init()
        set_bit()
    RCU_INIT_POINTER()
    for_each_subsys()
    WARN()
    cgroup_init_subsys() <void __init cgroup_init_subsys (struct cgroup_subsys *ss, bool early) at cgroup.c:5183>:
        pr_debug()
        mutex_lock()
        idr_init()
        INIT_LIST_HEAD()
        cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
            rcu_dereference_check()
            lockdep_is_held()
        BUG_ON()
        IS_ERR()
        init_and_link_css() <void init_and_link_css (struct cgroup_subsys_state *css, struct cgroup_subsys *ss, struct cgroup *cgrp) at cgroup.c:4751>:
            lockdep_assert_held()
            cgroup_get() <void cgroup_get (struct cgroup *cgrp) at cgroup.c:434>:
                WARN_ON_ONCE()
                cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                css_get()
            INIT_LIST_HEAD()
            atomic_set()
            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                container_of()
            cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                rcu_dereference_check()
                lockdep_is_held()
            css_get()
            BUG_ON()
        cgroup_idr_alloc() <int cgroup_idr_alloc (struct idr *idr, void *ptr, int start, int end, gfp_t gfp_mask) at cgroup.c:303>:
            idr_preload()
            spin_lock_bh()
            idr_alloc()
            spin_unlock_bh()
            idr_preload_end()
        list_empty()
        online_css() <int online_css (struct cgroup_subsys_state *css) at cgroup.c:4775>:
            lockdep_assert_held()
            rcu_assign_pointer()
            atomic_inc()
        mutex_unlock()
cgroup_post_fork() <void cgroup_post_fork (struct task_struct *child) at cgroup.c:5562>:
    spin_lock_bh()
    task_css_set()
    list_empty()
    get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
        atomic_inc()
    css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
        lockdep_assert_held()
        WARN_ON_ONCE()
        list_empty()
        list_for_each_entry_safe()
        css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
            lockdep_assert_held()
            WARN_ON_ONCE()
            css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                lockdep_assert_held()
                container_of()
                list_entry()
                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                    lockdep_assert_held()
                    list_empty()
                list_empty()
                list_del()
                put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                    lockdep_assert_held()
                    atomic_dec_and_test()
                    for_each_subsys()
                    list_del()
                    css_put()
                    hash_del()
                    list_for_each_entry_safe()
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_put()
                    kfree()
                    kfree_rcu()
                get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                    atomic_inc()
                list_add()
        list_del_init()
        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
            lockdep_assert_held()
            list_empty()
        css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
            lockdep_assert_held()
            list_for_each_entry()
            cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                lockdep_assert_held()
                check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                    notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                        test_bit()
                    cgroup_is_populated()
                    css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                        rcu_read_lock()
                        css_for_each_child()
                        rcu_read_unlock()
                    cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                    schedule_work()
                cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                    spin_lock_irqsave()
                    kernfs_notify()
                    spin_unlock_irqrestore()
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
        rcu_assign_pointer()
        list_add_tail()
    spin_unlock_bh()
    for_each_subsys_which()
cgroup_rm_cftypes() <int cgroup_rm_cftypes (struct cftype *cfts) at cgroup.c:3495>:
    mutex_lock()
    cgroup_rm_cftypes_locked() <int cgroup_rm_cftypes_locked (struct cftype *cfts) at cgroup.c:3471>:
        lockdep_assert_held()
        list_del()
        cgroup_apply_cftypes() <int cgroup_apply_cftypes (struct cftype *cfts, bool is_add) at cgroup.c:3394>:
            LIST_HEAD()
            lockdep_assert_held()
            css_for_each_descendant_pre()
            cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                rcu_dereference_check()
                lockdep_is_held()
            cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
            cgroup_addrm_files() <int cgroup_addrm_files (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype cfts[], bool is_add) at cgroup.c:3357>:
                lockdep_assert_held()
                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
                cgroup_add_file() <int cgroup_add_file (struct cgroup_subsys_state *css, struct cgroup *cgrp, struct cftype *cft) at cgroup.c:3313>:
                    cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                    cgroup_file_mode() <umode_t cgroup_file_mode (const struct cftype *cft) at cgroup.c:1233>:
                    IS_ERR()
                    PTR_ERR()
                    cgroup_kn_set_ugid() <int cgroup_kn_set_ugid (struct kernfs_node *kn) at cgroup.c:3300>:
                        current_fsuid()
                        current_fsgid()
                        uid_eq()
                        gid_eq()
                        kernfs_setattr()
                    kernfs_remove()
                    spin_lock_irq()
                    spin_unlock_irq()
                pr_warn()
                cgroup_rm_file() <void cgroup_rm_file (struct cgroup *cgrp, const struct cftype *cft) at cgroup.c:1381>:
                    lockdep_assert_held()
                    cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                        rcu_dereference_check()
                        lockdep_is_held()
                    spin_lock_irq()
                    spin_unlock_irq()
                    kernfs_remove_by_name()
                    cgroup_file_name() <char *cgroup_file_name (struct cgroup *cgrp, const struct cftype *cft, char *buf) at cgroup.c:1212>:
                        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
            kernfs_activate()
        cgroup_exit_cftypes() <void cgroup_exit_cftypes (struct cftype *cfts) at cgroup.c:3421>:
            kfree()
    mutex_unlock()
cgroup_sk_alloc() <void cgroup_sk_alloc (struct sock_cgroup_data *skcd) at cgroup.c:5865>:
    rcu_read_lock()
    task_css_set()
    likely()
    cgroup_tryget() <bool cgroup_tryget (struct cgroup *cgrp) at cgroup.c:440>:
        css_tryget()
    cpu_relax()
    rcu_read_unlock()
cgroup_sk_alloc_disable() <void cgroup_sk_alloc_disable (void) at cgroup.c:5851>:
    pr_info()
cgroup_sk_free() <void cgroup_sk_free (struct sock_cgroup_data *skcd) at cgroup.c:5886>:
    cgroup_put()
    sock_cgroup_ptr()
cgroup_taskset_first() <struct task_struct *cgroup_taskset_first (struct cgroup_taskset *tset, struct cgroup_subsys_state **dst_cssp) at cgroup.c:2285>:
    list_first_entry()
    cgroup_taskset_next() <struct task_struct *cgroup_taskset_next (struct cgroup_taskset *tset, struct cgroup_subsys_state **dst_cssp) at cgroup.c:2302>:
        list_first_entry()
        list_next_entry()
cgroup_taskset_next() <struct task_struct *cgroup_taskset_next (struct cgroup_taskset *tset, struct cgroup_subsys_state **dst_cssp) at cgroup.c:2302>:
    list_first_entry()
    list_next_entry()
cgroup_transfer_tasks() <int cgroup_transfer_tasks (struct cgroup *to, struct cgroup *from) at cgroup.c:4021>:
    LIST_HEAD()
    mutex_lock()
    spin_lock_bh()
    list_for_each_entry()
    cgroup_migrate_add_src() <void cgroup_migrate_add_src (struct css_set *src_cset, struct cgroup *dst_cgrp, struct list_head *preloaded_csets) at cgroup.c:2468>:
        lockdep_assert_held()
        cset_cgroup_from_root() <struct cgroup *cset_cgroup_from_root (struct css_set *cset, struct cgroup_root *root) at cgroup.c:1141>:
            lockdep_assert_held()
            list_for_each_entry()
            BUG_ON()
        list_empty()
        WARN_ON()
        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
            atomic_inc()
        list_add()
    spin_unlock_bh()
    cgroup_migrate_prepare_dst() <int cgroup_migrate_prepare_dst (struct cgroup *dst_cgrp, struct list_head *preloaded_csets) at cgroup.c:2507>:
        LIST_HEAD()
        lockdep_assert_held()
        cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
            container_of()
        list_for_each_entry_safe()
        find_css_set() <struct css_set *find_css_set (struct css_set *old_cset, struct cgroup *cgrp) at cgroup.c:980>:
            lockdep_assert_held()
            spin_lock_bh()
            find_existing_css_set() <struct css_set *find_existing_css_set (struct css_set *old_cset, struct cgroup *cgrp, struct cgroup_subsys_state *template[]) at cgroup.c:861>:
                for_each_subsys()
                cgroup_e_css() <struct cgroup_subsys_state *cgroup_e_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:373>:
                    lockdep_assert_held()
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
                        rcu_dereference_check()
                        lockdep_is_held()
                css_set_hash() <unsigned long css_set_hash (struct cgroup_subsys_state *css[]) at cgroup.c:717>:
                    for_each_subsys()
                hash_for_each_possible()
                compare_css_sets() <bool compare_css_sets (struct css_set *cset, struct css_set *old_cset, struct cgroup *new_cgrp, struct cgroup_subsys_state *template[]) at cgroup.c:793>:
                    BUG_ON()
                    list_entry()
            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                atomic_inc()
            spin_unlock_bh()
            kzalloc()
            allocate_cgrp_cset_links() <int allocate_cgrp_cset_links (int count, struct list_head *tmp_links) at cgroup.c:923>:
                INIT_LIST_HEAD()
                kzalloc()
                free_cgrp_cset_links() <void free_cgrp_cset_links (struct list_head *links_to_free) at cgroup.c:905>:
                    list_for_each_entry_safe()
                    list_del()
                    kfree()
                list_add()
            kfree()
            atomic_set()
            INIT_LIST_HEAD()
            INIT_HLIST_NODE()
            list_for_each_entry()
            link_css_set() <void link_css_set (struct list_head *tmp_links, struct css_set *cset, struct cgroup *cgrp) at cgroup.c:947>:
                BUG_ON()
                list_empty()
                cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
                list_first_entry()
                list_move_tail()
                list_add_tail()
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
                cgroup_get() <void cgroup_get (struct cgroup *cgrp) at cgroup.c:434>:
                    WARN_ON_ONCE()
                    cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                    css_get()
            BUG_ON()
            list_empty()
            css_set_hash() <unsigned long css_set_hash (struct cgroup_subsys_state *css[]) at cgroup.c:717>:
                for_each_subsys()
            hash_add()
            for_each_subsys()
            list_add_tail()
            css_get()
        WARN_ON_ONCE()
        list_del_init()
        put_css_set() <void put_css_set (struct css_set *cset) at cgroup.c:760>:
            atomic_add_unless()
            spin_lock_bh()
            put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                lockdep_assert_held()
                atomic_dec_and_test()
                for_each_subsys()
                list_del()
                css_put()
                hash_del()
                list_for_each_entry_safe()
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
                cgroup_put()
                kfree()
                kfree_rcu()
            spin_unlock_bh()
        list_empty()
        list_add()
        list_splice_tail()
        cgroup_migrate_finish() <void cgroup_migrate_finish (struct list_head *preloaded_csets) at cgroup.c:2436>:
            lockdep_assert_held()
            spin_lock_bh()
            list_for_each_entry_safe()
            list_del_init()
            put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                lockdep_assert_held()
                atomic_dec_and_test()
                for_each_subsys()
                list_del()
                css_put()
                hash_del()
                list_for_each_entry_safe()
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
                cgroup_put()
                kfree()
                kfree_rcu()
            spin_unlock_bh()
    css_task_iter_start() <void css_task_iter_start (struct cgroup_subsys_state *css, struct css_task_iter *it) at cgroup.c:3938>:
        WARN_ON_ONCE()
        spin_lock_bh()
        css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
            lockdep_assert_held()
            container_of()
            list_entry()
            css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                lockdep_assert_held()
                list_empty()
            list_empty()
            list_del()
            put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                lockdep_assert_held()
                atomic_dec_and_test()
                for_each_subsys()
                list_del()
                css_put()
                hash_del()
                list_for_each_entry_safe()
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
                cgroup_put()
                kfree()
                kfree_rcu()
            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                atomic_inc()
            list_add()
        spin_unlock_bh()
    css_task_iter_next() <struct task_struct *css_task_iter_next (struct css_task_iter *it) at cgroup.c:3970>:
        put_task_struct()
        spin_lock_bh()
        list_entry()
        get_task_struct()
        css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
            lockdep_assert_held()
            WARN_ON_ONCE()
            css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                lockdep_assert_held()
                container_of()
                list_entry()
                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                    lockdep_assert_held()
                    list_empty()
                list_empty()
                list_del()
                put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                    lockdep_assert_held()
                    atomic_dec_and_test()
                    for_each_subsys()
                    list_del()
                    css_put()
                    hash_del()
                    list_for_each_entry_safe()
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_put()
                    kfree()
                    kfree_rcu()
                get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                    atomic_inc()
                list_add()
        spin_unlock_bh()
    get_task_struct()
    css_task_iter_end() <void css_task_iter_end (struct css_task_iter *it) at cgroup.c:3997>:
        spin_lock_bh()
        list_del()
        put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
            lockdep_assert_held()
            atomic_dec_and_test()
            for_each_subsys()
            list_del()
            css_put()
            hash_del()
            list_for_each_entry_safe()
            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                container_of()
            cgroup_put()
            kfree()
            kfree_rcu()
        spin_unlock_bh()
        put_task_struct()
    cgroup_migrate() <int cgroup_migrate (struct task_struct *leader, bool threadgroup, struct cgroup *cgrp) at cgroup.c:2580>:
        CGROUP_TASKSET_INIT()
        spin_lock_bh()
        rcu_read_lock()
        cgroup_taskset_add() <void cgroup_taskset_add (struct task_struct *task, struct cgroup_taskset *tset) at cgroup.c:2251>:
            lockdep_assert_held()
            list_empty()
            task_css_set()
            list_move_tail()
            list_add_tail()
        while_each_thread()
        rcu_read_unlock()
        spin_unlock_bh()
        cgroup_taskset_migrate() <int cgroup_taskset_migrate (struct cgroup_taskset *tset, struct cgroup *dst_cgrp) at cgroup.c:2350>:
            list_empty()
            for_each_e_css()
            can_attach()
            spin_lock_bh()
            list_for_each_entry()
            list_for_each_entry_safe()
            task_css_set()
            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                atomic_inc()
            css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                lockdep_assert_held()
                WARN_ON_ONCE()
                list_empty()
                list_for_each_entry_safe()
                css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                    lockdep_assert_held()
                    WARN_ON_ONCE()
                    css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                        lockdep_assert_held()
                        container_of()
                        list_entry()
                        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                            lockdep_assert_held()
                            list_empty()
                        list_empty()
                        list_del()
                        put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                            lockdep_assert_held()
                            atomic_dec_and_test()
                            for_each_subsys()
                            list_del()
                            css_put()
                            hash_del()
                            list_for_each_entry_safe()
                            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                container_of()
                            cgroup_put()
                            kfree()
                            kfree_rcu()
                        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                            atomic_inc()
                        list_add()
                list_del_init()
                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                    lockdep_assert_held()
                    list_empty()
                css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                    lockdep_assert_held()
                    list_for_each_entry()
                    cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                        lockdep_assert_held()
                        check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                            notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                test_bit()
                            cgroup_is_populated()
                            css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                rcu_read_lock()
                                css_for_each_child()
                                rcu_read_unlock()
                            cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                            schedule_work()
                        cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                            spin_lock_irqsave()
                            kernfs_notify()
                            spin_unlock_irqrestore()
                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                            container_of()
                rcu_assign_pointer()
                list_add_tail()
            put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                lockdep_assert_held()
                atomic_dec_and_test()
                for_each_subsys()
                list_del()
                css_put()
                hash_del()
                list_for_each_entry_safe()
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
                cgroup_put()
                kfree()
                kfree_rcu()
            spin_unlock_bh()
            attach()
            cancel_attach()
            list_splice_init()
            list_splice_tail_init()
            list_del_init()
    put_task_struct()
    cgroup_migrate_finish() <void cgroup_migrate_finish (struct list_head *preloaded_csets) at cgroup.c:2436>:
        lockdep_assert_held()
        spin_lock_bh()
        list_for_each_entry_safe()
        list_del_init()
        put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
            lockdep_assert_held()
            atomic_dec_and_test()
            for_each_subsys()
            list_del()
            css_put()
            hash_del()
            list_for_each_entry_safe()
            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                container_of()
            cgroup_put()
            kfree()
            kfree_rcu()
        spin_unlock_bh()
    mutex_unlock()
cgroupstats_build() <int cgroupstats_build (struct cgroupstats *stats, struct dentry *dentry) at cgroup.c:4354>:
    kernfs_node_from_dentry()
    kernfs_type()
    mutex_lock()
    rcu_read_lock()
    rcu_dereference()
    cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
    rcu_read_unlock()
    mutex_unlock()
    css_task_iter_start() <void css_task_iter_start (struct cgroup_subsys_state *css, struct css_task_iter *it) at cgroup.c:3938>:
        WARN_ON_ONCE()
        spin_lock_bh()
        css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
            lockdep_assert_held()
            container_of()
            list_entry()
            css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                lockdep_assert_held()
                list_empty()
            list_empty()
            list_del()
            put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                lockdep_assert_held()
                atomic_dec_and_test()
                for_each_subsys()
                list_del()
                css_put()
                hash_del()
                list_for_each_entry_safe()
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
                cgroup_put()
                kfree()
                kfree_rcu()
            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                atomic_inc()
            list_add()
        spin_unlock_bh()
    css_task_iter_next() <struct task_struct *css_task_iter_next (struct css_task_iter *it) at cgroup.c:3970>:
        put_task_struct()
        spin_lock_bh()
        list_entry()
        get_task_struct()
        css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
            lockdep_assert_held()
            WARN_ON_ONCE()
            css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                lockdep_assert_held()
                container_of()
                list_entry()
                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                    lockdep_assert_held()
                    list_empty()
                list_empty()
                list_del()
                put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                    lockdep_assert_held()
                    atomic_dec_and_test()
                    for_each_subsys()
                    list_del()
                    css_put()
                    hash_del()
                    list_for_each_entry_safe()
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
                    cgroup_put()
                    kfree()
                    kfree_rcu()
                get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                    atomic_inc()
                list_add()
        spin_unlock_bh()
    delayacct_is_task_waiting_on_io()
    css_task_iter_end() <void css_task_iter_end (struct css_task_iter *it) at cgroup.c:3997>:
        spin_lock_bh()
        list_del()
        put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
            lockdep_assert_held()
            atomic_dec_and_test()
            for_each_subsys()
            list_del()
            css_put()
            hash_del()
            list_for_each_entry_safe()
            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                container_of()
            cgroup_put()
            kfree()
            kfree_rcu()
        spin_unlock_bh()
        put_task_struct()
change_pid() <void change_pid (struct task_struct *task, enum pid_type type, struct pid *pid) at pid.c:420>:
    attach_pid() <void attach_pid (struct task_struct *task, enum pid_type type) at pid.c:389>:
        hlist_add_head_rcu()
clean_sort_range() <int clean_sort_range (struct range *range, int az) at range.c:124>:
    start()
    sort()
    cmp_range() <int cmp_range (const void *x1, const void *x2) at range.c:112>:
clear_all_latency_tracing() <void clear_all_latency_tracing (struct task_struct *p) at latencytop.c:68>:
    raw_spin_lock_irqsave()
    raw_spin_unlock_irqrestore()
clear_tasks_mm_cpumask() <void clear_tasks_mm_cpumask (int cpu) at cpu.c:261>:
    WARN_ON()
    cpu_online()
    rcu_read_lock()
    for_each_process()
    find_lock_task_mm()
    cpumask_clear_cpu()
    mm_cpumask()
    task_unlock()
    rcu_read_unlock()
commit_creds() <int commit_creds (struct cred *new) at cred.c:422>:
    kdebug()
    atomic_read()
    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
        atomic_read()
    BUG_ON()
    validate_creds()
    get_cred()
    uid_eq()
    gid_eq()
    cred_cap_issubset() <bool cred_cap_issubset (const struct cred *set, const struct cred *subset) at cred.c:383>:
        cap_issubset()
        uid_eq()
    set_dumpable()
    smp_wmb()
    key_fsuid_changed()
    key_fsgid_changed()
    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
        atomic_add()
    atomic_inc()
    rcu_assign_pointer()
    atomic_dec()
    proc_id_connector()
    put_cred()
compat_alloc_user_space() <void __user *compat_alloc_user_space (unsigned long len) at compat.c:1161>:
    unlikely()
    arch_compat_alloc_user_space()
    access_ok()
compat_convert_timespec() <int compat_convert_timespec (struct timespec __user **kts, const void __user *cts) at compat.c:193>:
    compat_alloc_user_space() <void __user *compat_alloc_user_space (unsigned long len) at compat.c:1161>:
        unlikely()
        arch_compat_alloc_user_space()
        access_ok()
    compat_get_timespec() <int compat_get_timespec (struct timespec *ts, const void __user *uts) at compat.c:175>:
        copy_from_user()
    copy_to_user()
compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
    uninitialized_var()
    fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
        get_user()
        compat_ptr()
    get_user()
    futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
        ptr_to_compat()
        compat_ptr()
    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
        uninitialized_var()
        get_user()
        task_pid_vnr()
        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
            pagefault_disable()
            futex_atomic_cmpxchg_inatomic()
            pagefault_enable()
        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
            down_read()
            fixup_user_fault()
            up_read()
        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
            WAKE_Q()
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            unlikely()
            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                jhash2()
            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                atomic_read()
            spin_lock()
            plist_for_each_entry_safe()
            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                WARN()
                wake_q_add()
                smp_wmb()
            spin_unlock()
            wake_up_q()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
    cond_resched()
compat_get_bitmap() <long compat_get_bitmap (unsigned long *mask, const compat_ulong_t __user *umask, unsigned long bitmap_size) at compat.c:890>:
    ALIGN()
    access_ok()
    BITS_TO_COMPAT_LONGS()
    BITS_TO_LONGS()
compat_get_timespec() <int compat_get_timespec (struct timespec *ts, const void __user *uts) at compat.c:175>:
    copy_from_user()
compat_get_timeval() <int compat_get_timeval (struct timeval *tv, const void __user *utv) at compat.c:157>:
    copy_from_user()
compat_ptrace_request() <int compat_ptrace_request (struct task_struct *child, compat_long_t request, compat_ulong_t addr, compat_ulong_t data) at ptrace.c:1147>:
    compat_ptr()
    access_process_vm()
    put_user()
    ptrace_getsiginfo() <int ptrace_getsiginfo (struct task_struct *child, siginfo_t *info) at ptrace.c:610>:
        lock_task_sighand()
        likely()
        unlock_task_sighand()
    copy_siginfo_to_user32()
    copy_siginfo_from_user32()
    ptrace_setsiginfo() <int ptrace_setsiginfo (struct task_struct *child, const siginfo_t *info) at ptrace.c:626>:
        lock_task_sighand()
        likely()
        unlock_task_sighand()
    access_ok()
    ptrace_regset() <int ptrace_regset (struct task_struct *task, int req, unsigned int type, struct iovec *kiov) at ptrace.c:811>:
        task_user_regset_view()
        find_regset() <const struct user_regset *find_regset (const struct user_regset_view *view, unsigned int type) at ptrace.c:797>:
        min()
        copy_regset_to_user()
        copy_regset_from_user()
    ptrace_request() <int ptrace_request (struct task_struct *child, long request, unsigned long addr, unsigned long data) at ptrace.c:841>:
        generic_ptrace_peekdata() <int generic_ptrace_peekdata (struct task_struct *tsk, unsigned long addr, unsigned long data) at ptrace.c:1124>:
            access_process_vm()
            put_user()
        generic_ptrace_pokedata() <int generic_ptrace_pokedata (struct task_struct *tsk, unsigned long addr, unsigned long data) at ptrace.c:1136>:
            access_process_vm()
        ptrace_setoptions() <int ptrace_setoptions (struct task_struct *child, unsigned long data) at ptrace.c:581>:
            unlikely()
            config_enabled()
            capable() <bool capable (int cap) at capability.c:401>:
                ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                    unlikely()
                    cap_valid()
                    pr_crit()
                    BUG()
                    security_capable()
                    current_cred()
            seccomp_mode()
        put_user()
        ptrace_peek_siginfo() <int ptrace_peek_siginfo (struct task_struct *child, unsigned long addr, unsigned long data) at ptrace.c:642>:
            copy_from_user()
            spin_lock_irq()
            list_for_each_entry()
            copy_siginfo()
            spin_unlock_irq()
            unlikely()
            is_compat_task()
            compat_ptr()
            copy_siginfo_to_user32()
            copy_siginfo_to_user() <int copy_siginfo_to_user (siginfo_t __user *to, const siginfo_t *from) at signal.c:2657>:
                access_ok()
            signal_pending()
            cond_resched()
        ptrace_getsiginfo() <int ptrace_getsiginfo (struct task_struct *child, siginfo_t *info) at ptrace.c:610>:
            lock_task_sighand()
            likely()
            unlock_task_sighand()
        copy_siginfo_to_user() <int copy_siginfo_to_user (siginfo_t __user *to, const siginfo_t *from) at signal.c:2657>:
            access_ok()
        copy_from_user()
        ptrace_setsiginfo() <int ptrace_setsiginfo (struct task_struct *child, const siginfo_t *info) at ptrace.c:626>:
            lock_task_sighand()
            likely()
            unlock_task_sighand()
        copy_to_user()
        sigdelsetmask()
        spin_lock_irq()
        spin_unlock_irq()
        unlikely()
        lock_task_sighand()
        likely()
        task_set_jobctl_pending() <bool task_set_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:248>:
            BUG_ON()
            unlikely()
            fatal_signal_pending()
        ptrace_signal_wake_up()
        unlock_task_sighand()
        ptrace_detach() <int ptrace_detach (struct task_struct *child, unsigned int data) at ptrace.c:486>:
            valid_signal()
            ptrace_disable()
            clear_tsk_thread_flag()
            write_lock_irq()
            WARN_ON()
            write_unlock_irq()
            proc_ptrace_connector()
        get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
            task_lock()
            atomic_inc()
            task_unlock()
        mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
            might_sleep()
            atomic_dec_and_test()
            uprobe_clear_state()
            exit_aio()
            ksm_exit()
            khugepaged_exit()
            exit_mmap()
            set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                rcu_dereference_raw()
                get_file()
                rcu_assign_pointer()
                fput()
            list_empty()
            spin_lock()
            list_del()
            spin_unlock()
            module_put() <void module_put (struct module *module) at module.c:1098>:
                preempt_disable()
                atomic_dec_if_positive()
                WARN_ON()
                trace_module_put()
                preempt_enable()
            mmdrop()
        ptrace_resume() <int ptrace_resume (struct task_struct *child, long request, unsigned long data) at ptrace.c:738>:
            valid_signal()
            set_tsk_thread_flag()
            clear_tsk_thread_flag()
            is_singleblock()
            unlikely()
            arch_has_block_step()
            user_enable_block_step()
            is_singlestep()
            is_sysemu_singlestep()
            arch_has_single_step()
            user_enable_single_step()
            user_disable_single_step()
            thread_group_empty()
            spin_lock_irq()
            wake_up_state()
            spin_unlock_irq()
        access_ok()
        ptrace_regset() <int ptrace_regset (struct task_struct *task, int req, unsigned int type, struct iovec *kiov) at ptrace.c:811>:
            task_user_regset_view()
            find_regset() <const struct user_regset *find_regset (const struct user_regset_view *view, unsigned int type) at ptrace.c:797>:
            min()
            copy_regset_to_user()
            copy_regset_from_user()
        seccomp_get_filter() <long seccomp_get_filter (struct task_struct *task, unsigned long filter_off, void __user *data) at seccomp.c:873>:
            capable() <bool capable (int cap) at capability.c:401>:
                ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                    unlikely()
                    cap_valid()
                    pr_crit()
                    BUG()
                    security_capable()
                    current_cred()
            spin_lock_irq()
            WARN_ON()
            get_seccomp_filter() <void get_seccomp_filter (struct task_struct *tsk) at seccomp.c:461>:
                atomic_inc()
            spin_unlock_irq()
            copy_to_user()
            bpf_classic_proglen()
            put_seccomp_filter() <void put_seccomp_filter (struct task_struct *tsk) at seccomp.c:479>:
                atomic_dec_and_test()
                seccomp_filter_free() <inline void seccomp_filter_free (struct seccomp_filter *filter) at seccomp.c:470>:
                    bpf_prog_destroy()
                    kfree()
compat_put_bitmap() <long compat_put_bitmap (compat_ulong_t __user *umask, unsigned long *mask, unsigned long bitmap_size) at compat.c:932>:
    ALIGN()
    access_ok()
    BITS_TO_COMPAT_LONGS()
    BITS_TO_LONGS()
compat_put_timespec() <int compat_put_timespec (const struct timespec *ts, void __user *uts) at compat.c:184>:
    copy_to_user()
compat_put_timeval() <int compat_put_timeval (const struct timeval *tv, void __user *utv) at compat.c:166>:
    copy_to_user()
compat_restore_altstack() <int compat_restore_altstack (const compat_stack_t __user *uss) at signal.c:3210>:
    compat_sys_sigaltstack()
complete_and_exit() <void complete_and_exit (struct completion *comp, long code) at exit.c:834>:
    complete()
    do_exit() <void do_exit (long code) at exit.c:651>:
        TASKS_RCU()
        profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
            blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
        WARN_ON()
        blk_needs_flush_plug()
        unlikely()
        in_interrupt()
        panic() <void panic (const char *fmt, ...) at panic.c:83>:
            local_irq_disable()
            raw_smp_processor_id()
            atomic_cmpxchg()
            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                cpu_relax()
            console_verbose()
            bust_spinlocks()
            pr_emerg()
            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                test_bit()
            dump_stack()
            smp_send_stop()
            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
            kmsg_dump()
            debug_locks_off()
            console_flush_on_panic()
            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
            no_blink() <long no_blink (int state) at panic.c:46>
            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                raw_cpu_write()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            mdelay()
            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                kmsg_dump()
                machine_emergency_restart()
            disabled_wait()
            local_irq_enable()
            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                    raw_cpu_write()
                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                    per_cpu()
                raw_smp_processor_id()
        set_fs()
        ptrace_event()
        validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
        pr_alert()
        set_current_state()
        schedule()
        exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
            threadgroup_change_begin()
            thread_group_empty()
            signal_group_exit()
            threadgroup_change_end()
            spin_lock_irq()
            signal_pending()
            signotset()
            retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                sigandsets()
                sigisemptyset()
                while_each_thread()
                has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                signal_pending()
                signal_wake_up()
            unlikely()
            task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                WARN_ON_ONCE()
                task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                    BUG_ON()
                    task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                        unlikely()
                        smp_mb()
                        wake_up_bit()
            spin_unlock_irq()
            read_lock()
            do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                BUG()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
            read_unlock()
        smp_mb()
        raw_spin_unlock_wait()
        in_atomic()
        pr_info()
        task_pid_nr()
        preempt_count()
        preempt_count_set()
        sync_mm_rss()
        acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
            task_cputime()
        atomic_dec_and_test()
        hrtimer_cancel()
        exit_itimers()
        setmax_mm_hiwater_rss()
        acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
            down_read()
            up_read()
            spin_lock_irq()
            thread_group_leader()
            task_cputime()
            spin_unlock_irq()
        tty_audit_exit()
        audit_free()
        taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
            taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                nla_total_size()
            taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                thread_group_empty()
                kmem_cache_zalloc()
                spin_lock_irq()
                spin_unlock_irq()
                kmem_cache_free()
            fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                spin_lock_irqsave()
                delayacct_add_tsk()
                spin_unlock_irqrestore()
            raw_cpu_ptr()
            list_empty()
            prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                genlmsg_new()
                this_cpu_inc_return()
                genlmsg_put()
                genlmsg_put_reply()
                nlmsg_free()
            mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                nla_put()
                nla_nest_start()
                nla_nest_cancel()
                nla_reserve()
                nla_nest_end()
                nla_data()
            task_pid_nr_ns()
            fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                delayacct_add_tsk()
                bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                    BUILD_BUG_ON()
                    ktime_get_ns()
                    do_div()
                    get_seconds()
                    thread_group_leader()
                    task_nice()
                    task_pid_nr_ns()
                    rcu_read_lock()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    pid_alive()
                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                        task_tgid()
                    rcu_dereference()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_usecs()
                    task_cputime_scaled()
                xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                    get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                        task_lock()
                        atomic_inc()
                        task_unlock()
                    get_mm_hiwater_rss()
                    get_mm_hiwater_vm()
                    mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                        might_sleep()
                        atomic_dec_and_test()
                        uprobe_clear_state()
                        exit_aio()
                        ksm_exit()
                        khugepaged_exit()
                        exit_mmap()
                        set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                            rcu_dereference_raw()
                            get_file()
                            rcu_assign_pointer()
                            fput()
                        list_empty()
                        spin_lock()
                        list_del()
                        spin_unlock()
                        module_put() <void module_put (struct module *module) at module.c:1098>:
                            preempt_disable()
                            atomic_dec_if_positive()
                            WARN_ON()
                            trace_module_put()
                            preempt_enable()
                        mmdrop()
            task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                task_tgid()
            send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                nlmsg_data()
                nlmsg_hdr()
                genlmsg_data()
                genlmsg_end()
                down_read()
                list_for_each_entry()
                list_is_last()
                skb_clone()
                genlmsg_unicast()
                up_read()
                nlmsg_free()
                down_write()
                list_for_each_entry_safe()
                list_del()
                kfree()
                up_write()
            nlmsg_free()
        exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
            mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                unlikely()
                exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                    uninitialized_var()
                    fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                        get_user()
                    get_user()
                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                        uninitialized_var()
                        get_user()
                        task_pid_vnr()
                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                            pagefault_disable()
                            futex_atomic_cmpxchg_inatomic()
                            pagefault_enable()
                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                            down_read()
                            fixup_user_fault()
                            up_read()
                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                            WAKE_Q()
                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                unlikely()
                                access_ok()
                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                    should_fail()
                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                    ihold()
                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                        atomic_inc()
                                        smp_mb__after_atomic()
                                    smp_mb()
                                get_user_pages_fast()
                                lock_page()
                                compound_head()
                                PageSwapCache()
                                unlock_page()
                                put_page()
                                PageAnon()
                                basepage_index()
                            unlikely()
                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                jhash2()
                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                atomic_read()
                            spin_lock()
                            plist_for_each_entry_safe()
                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                WARN()
                                wake_q_add()
                                smp_wmb()
                            spin_unlock()
                            wake_up_q()
                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                    WARN_ON_ONCE()
                                    iput()
                                    mmdrop()
                    cond_resched()
                compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                    uninitialized_var()
                    fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                        get_user()
                        compat_ptr()
                    get_user()
                    futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                        ptr_to_compat()
                        compat_ptr()
                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                        uninitialized_var()
                        get_user()
                        task_pid_vnr()
                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                            pagefault_disable()
                            futex_atomic_cmpxchg_inatomic()
                            pagefault_enable()
                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                            down_read()
                            fixup_user_fault()
                            up_read()
                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                            WAKE_Q()
                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                unlikely()
                                access_ok()
                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                    should_fail()
                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                    ihold()
                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                        atomic_inc()
                                        smp_mb__after_atomic()
                                    smp_mb()
                                get_user_pages_fast()
                                lock_page()
                                compound_head()
                                PageSwapCache()
                                unlock_page()
                                put_page()
                                PageAnon()
                                basepage_index()
                            unlikely()
                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                jhash2()
                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                atomic_read()
                            spin_lock()
                            plist_for_each_entry_safe()
                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                WARN()
                                wake_q_add()
                                smp_wmb()
                            spin_unlock()
                            wake_up_q()
                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                    WARN_ON_ONCE()
                                    iput()
                                    mmdrop()
                    cond_resched()
                list_empty()
                exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                    raw_spin_lock_irq()
                    list_empty()
                    list_entry()
                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                        jhash2()
                    raw_spin_unlock_irq()
                    spin_lock()
                    spin_unlock()
                    WARN_ON()
                    list_del_init()
                    rt_mutex_unlock()
                uprobe_free_utask()
                deactivate_mm()
                atomic_read()
                put_user()
                sys_futex()
                complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                    task_lock()
                    likely()
                    complete()
                    task_unlock()
            sync_mm_rss()
            down_read()
            up_read()
            xchg()
            atomic_dec_and_test()
            complete()
            set_task_state()
            freezable_schedule()
            atomic_inc()
            BUG_ON()
            task_lock()
            enter_lazy_tlb()
            task_unlock()
            mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                atomic_read()
                read_lock()
                list_for_each_entry()
                for_each_process()
                for_each_thread()
                read_unlock()
                BUG_ON()
                get_task_struct()
                task_lock()
                task_unlock()
                put_task_struct()
            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                might_sleep()
                atomic_dec_and_test()
                uprobe_clear_state()
                exit_aio()
                ksm_exit()
                khugepaged_exit()
                exit_mmap()
                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                    rcu_dereference_raw()
                    get_file()
                    rcu_assign_pointer()
                    fput()
                list_empty()
                spin_lock()
                list_del()
                spin_unlock()
                module_put() <void module_put (struct module *module) at module.c:1098>:
                    preempt_disable()
                    atomic_dec_if_positive()
                    WARN_ON()
                    trace_module_put()
                    preempt_enable()
                mmdrop()
            test_thread_flag()
            exit_oom_victim()
        acct_process() <void acct_process (void) at acct.c:587>:
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
            unlikely()
            slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                    smp_rmb()
                    rcu_read_lock()
                    to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                        container_of()
                    ACCESS_ONCE()
                    rcu_read_unlock()
                    atomic_long_inc_not_zero()
                    cpu_relax()
                    mutex_lock()
                    mutex_unlock()
                    acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                        atomic_long_dec_and_test()
                        kfree_rcu()
                do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                    override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        validate_creds()
                        get_cred()
                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                            atomic_add()
                        rcu_assign_pointer()
                    check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                        time_is_before_jiffies()
                        vfs_statfs()
                        do_div()
                        pr_info()
                    fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                        strlcpy()
                        ktime_get_ns()
                        nsec_to_AHZ()
                        encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                        encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                        encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                        do_div()
                        get_seconds()
                        spin_lock_irq()
                        old_encode_dev()
                        tty_devnum()
                        jiffies_to_AHZ()
                        cputime_to_jiffies()
                        spin_unlock_irq()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                        task_tgid()
                    rcu_read_lock()
                    rcu_dereference()
                    rcu_read_unlock()
                    file_start_write_trylock()
                    file_end_write()
                    revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        validate_creds()
                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                            atomic_add()
                        rcu_assign_pointer()
                        put_cred()
                mutex_unlock()
                acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                    atomic_long_dec_and_test()
                    kfree_rcu()
        trace_sched_process_exit()
        exit_sem()
        exit_shm()
        exit_files()
        exit_fs()
        disassociate_ctty()
        exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
            switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                might_sleep()
                task_lock()
                task_unlock()
                atomic_dec_and_test()
                free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                    put_mnt_ns()
                    put_uts_ns()
                    put_ipc_ns()
                    put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                        kref_put()
                        free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                            container_of()
                            destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                ns_free_inum()
                                kfree()
                                put_user_ns()
                                call_rcu()
                                delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                    kmem_cache_free()
                                    container_of()
                    put_net()
                    kmem_cache_free()
        exit_task_work()
        exit_thread()
        perf_event_exit_task()
        cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
            task_css_set()
            list_empty()
            spin_lock_bh()
            css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                lockdep_assert_held()
                WARN_ON_ONCE()
                list_empty()
                list_for_each_entry_safe()
                css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                    lockdep_assert_held()
                    WARN_ON_ONCE()
                    css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                        lockdep_assert_held()
                        container_of()
                        list_entry()
                        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                            lockdep_assert_held()
                            list_empty()
                        list_empty()
                        list_del()
                        put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                            lockdep_assert_held()
                            atomic_dec_and_test()
                            for_each_subsys()
                            list_del()
                            css_put()
                            hash_del()
                            list_for_each_entry_safe()
                            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                container_of()
                            cgroup_put()
                            kfree()
                            kfree_rcu()
                        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                            atomic_inc()
                        list_add()
                list_del_init()
                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                    lockdep_assert_held()
                    list_empty()
                css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                    lockdep_assert_held()
                    list_for_each_entry()
                    cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                        lockdep_assert_held()
                        check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                            notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                test_bit()
                            cgroup_is_populated()
                            css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                rcu_read_lock()
                                css_for_each_child()
                                rcu_read_unlock()
                            cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                            schedule_work()
                        cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                            spin_lock_irqsave()
                            kernfs_notify()
                            spin_unlock_irqrestore()
                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                            container_of()
                rcu_assign_pointer()
                list_add_tail()
            spin_unlock_bh()
            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                atomic_inc()
            for_each_subsys_which()
        flush_ptrace_hw_breakpoint()
        preempt_disable()
        preempt_enable()
        exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
            LIST_HEAD()
            write_lock_irq()
            forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                unlikely()
                list_empty()
                exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                    list_for_each_entry_safe()
                    unlikely()
                    send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                        valid_signal()
                        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                            lock_task_sighand()
                            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                    SI_FROMUSER()
                                task_pid_nr_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                            unlock_task_sighand()
                    list_add()
                find_child_reaper()
                find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                    find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                        for_each_thread()
                    same_thread_group()
                list_for_each_entry()
                for_each_thread()
                BUG_ON()
                likely()
                group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                    rcu_read_lock()
                    check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                        valid_signal()
                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                            SI_FROMUSER()
                        audit_signal_info()
                        same_thread_group()
                        kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                            current_cred()
                            uid_eq()
                            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                unlikely()
                                cap_valid()
                                pr_crit()
                                BUG()
                                security_capable()
                                current_cred()
                        task_session()
                        security_task_kill()
                    rcu_read_unlock()
                    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                        lock_task_sighand()
                        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                SI_FROMUSER()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                        unlock_task_sighand()
                same_thread_group()
                reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                    unlikely()
                    thread_group_empty()
                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                        BUG_ON()
                        task_is_stopped_or_traced()
                        thread_group_empty()
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        spin_lock_irqsave()
                        valid_signal()
                        spin_unlock_irqrestore()
                    list_add()
                    kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                        task_pgrp()
                        task_session()
                        will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                            do_each_pid_task()
                            thread_group_empty()
                            is_global_init()
                            task_pgrp()
                            task_session()
                            while_each_pid_task()
                        has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                            do_each_pid_task()
                            while_each_pid_task()
                list_splice_tail_init()
            kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                task_pgrp()
                task_session()
                will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                    do_each_pid_task()
                    thread_group_empty()
                    is_global_init()
                    task_pgrp()
                    task_session()
                    while_each_pid_task()
                has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                    do_each_pid_task()
                    while_each_pid_task()
            unlikely()
            thread_group_leader()
            thread_group_empty()
            ptrace_reparented()
            do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                BUG_ON()
                task_is_stopped_or_traced()
                thread_group_empty()
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                spin_lock_irqsave()
                valid_signal()
                spin_unlock_irqrestore()
            list_add()
            wake_up_process()
            write_unlock_irq()
            list_for_each_entry_safe()
            list_del_init()
            release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                rcu_read_lock()
                atomic_dec()
                rcu_read_unlock()
                proc_flush_task()
                write_lock_irq()
                ptrace_release_task()
                thread_group_empty()
                do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                    BUG_ON()
                    task_is_stopped_or_traced()
                    thread_group_empty()
                    rcu_read_lock()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_cred_xxx()
                    task_uid()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_clock_t()
                    spin_lock_irqsave()
                    valid_signal()
                    spin_unlock_irqrestore()
                write_unlock_irq()
                release_thread()
                call_rcu()
                delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                    container_of()
                    perf_event_delayed_put()
                    trace_sched_process_free()
                    put_task_struct()
                unlikely()
        proc_exit_connector()
        task_lock()
        mpol_put()
        task_unlock()
        kfree()
        debug_check_no_locks_held()
        exit_io_context()
        free_pipe_info()
        put_page()
        check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
            stack_not_used()
            spin_lock()
            pr_warn()
            task_pid_nr()
            spin_unlock()
        exit_rcu()
        BUG()
        cpu_relax()
context_tracking_cpu_set() <void __init context_tracking_cpu_set (int cpu) at context_tracking.c:188>:
    per_cpu()
    static_branch_inc()
    set_tsk_thread_flag()
    WARN_ON_ONCE()
    tasklist_empty()
context_tracking_enter() <void context_tracking_enter (enum ctx_state state) at context_tracking.c:104>:
    in_interrupt()
    local_irq_save()
    local_irq_restore()
context_tracking_exit() <void context_tracking_exit (enum ctx_state state) at context_tracking.c:168>:
    in_interrupt()
    local_irq_save()
    local_irq_restore()
context_tracking_init() <void __init context_tracking_init (void) at context_tracking.c:211>:
    for_each_possible_cpu()
    context_tracking_cpu_set() <void __init context_tracking_cpu_set (int cpu) at context_tracking.c:188>:
        per_cpu()
        static_branch_inc()
        set_tsk_thread_flag()
        WARN_ON_ONCE()
        tasklist_empty()
context_tracking_user_enter() <void context_tracking_user_enter (void) at context_tracking.c:126>:
    user_enter()
context_tracking_user_exit() <void context_tracking_user_exit (void) at context_tracking.c:182>:
    user_exit()
copy_creds() <int copy_creds (struct task_struct *p, unsigned long clone_flags) at cred.c:322>:
    get_cred()
    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
        atomic_add()
    kdebug()
    atomic_read()
    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
        atomic_read()
    atomic_inc()
    prepare_creds() <struct cred *prepare_creds (void) at cred.c:243>:
        validate_process_creds()
        kmem_cache_alloc()
        kdebug()
        atomic_set()
        set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
            atomic_set()
        get_group_info()
        get_uid()
        get_user_ns()
        key_get()
        security_prepare_creds()
        validate_creds()
        abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
            BUG_ON()
            put_cred()
    create_user_ns() <int create_user_ns (struct cred *new) at user_namespace.c:60>:
        current_chrooted()
        kuid_has_mapping()
        kgid_has_mapping()
        kmem_cache_zalloc()
        ns_alloc_inum()
        kmem_cache_free()
        atomic_set()
        mutex_lock()
        mutex_unlock()
        set_cred_user_ns() <void set_cred_user_ns (struct cred *cred, struct user_namespace *user_ns) at user_namespace.c:33>:
            key_put()
        init_rwsem()
    key_put()
    install_thread_keyring_to_cred()
    validate_creds()
    put_cred()
copy_namespaces() <int copy_namespaces (unsigned long flags, struct task_struct *tsk) at nsproxy.c:124>:
    task_cred_xxx()
    likely()
    get_nsproxy()
    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
        unlikely()
        cap_valid()
        pr_crit()
        BUG()
        security_capable()
        current_cred()
    create_new_namespaces() <struct nsproxy *create_new_namespaces (unsigned long flags, struct task_struct *tsk, struct user_namespace *user_ns, struct fs_struct *new_fs) at nsproxy.c:59>:
        create_nsproxy() <inline struct nsproxy *create_nsproxy (void) at nsproxy.c:44>:
            kmem_cache_alloc()
            atomic_set()
        ERR_PTR()
        copy_mnt_ns()
        IS_ERR()
        PTR_ERR()
        copy_utsname() <struct uts_namespace *copy_utsname (unsigned long flags, struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:66>:
            BUG_ON()
            get_uts_ns()
            clone_uts_ns() <struct uts_namespace *clone_uts_ns (struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:35>:
                create_uts_ns() <struct uts_namespace *create_uts_ns (void) at utsname.c:20>:
                    kmalloc()
                    kref_init()
                ERR_PTR()
                ns_alloc_inum()
                kfree()
                down_read()
                get_user_ns()
                up_read()
            put_uts_ns()
        copy_ipcs()
        copy_pid_ns() <struct pid_namespace *copy_pid_ns (unsigned long flags, struct user_namespace *user_ns, struct pid_namespace *old_ns) at pid_namespace.c:153>:
            get_pid_ns()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
            ERR_PTR()
            create_pid_namespace() <struct pid_namespace *create_pid_namespace (struct user_namespace *user_ns, struct pid_namespace *parent_pid_ns) at pid_namespace.c:82>:
                kmem_cache_zalloc()
                kzalloc()
                create_pid_cachep() <struct kmem_cache *create_pid_cachep (int nr_ids) at pid_namespace.c:38>:
                    mutex_lock()
                    list_for_each_entry()
                    kmalloc()
                    kmem_cache_create()
                    list_add()
                    mutex_unlock()
                    kfree()
                ns_alloc_inum()
                kref_init()
                get_pid_ns()
                get_user_ns()
                INIT_WORK()
                proc_cleanup_work() <void proc_cleanup_work (struct work_struct *work) at pid_namespace.c:73>:
                    container_of()
                    pid_ns_release_proc()
                set_bit()
                atomic_set()
                kfree()
                kmem_cache_free()
                ERR_PTR()
        copy_net_ns()
        put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
            kref_put()
            free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                container_of()
                destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                    ns_free_inum()
                    kfree()
                    put_user_ns()
                    call_rcu()
                    delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                        kmem_cache_free()
                        container_of()
        put_ipc_ns()
        put_uts_ns()
        put_mnt_ns()
        kmem_cache_free()
    IS_ERR()
    PTR_ERR()
copy_pid_ns() <struct pid_namespace *copy_pid_ns (unsigned long flags, struct user_namespace *user_ns, struct pid_namespace *old_ns) at pid_namespace.c:153>:
    get_pid_ns()
    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
        ns_of_pid()
        task_pid()
    ERR_PTR()
    create_pid_namespace() <struct pid_namespace *create_pid_namespace (struct user_namespace *user_ns, struct pid_namespace *parent_pid_ns) at pid_namespace.c:82>:
        kmem_cache_zalloc()
        kzalloc()
        create_pid_cachep() <struct kmem_cache *create_pid_cachep (int nr_ids) at pid_namespace.c:38>:
            mutex_lock()
            list_for_each_entry()
            kmalloc()
            kmem_cache_create()
            list_add()
            mutex_unlock()
            kfree()
        ns_alloc_inum()
        kref_init()
        get_pid_ns()
        get_user_ns()
        INIT_WORK()
        proc_cleanup_work() <void proc_cleanup_work (struct work_struct *work) at pid_namespace.c:73>:
            container_of()
            pid_ns_release_proc()
        set_bit()
        atomic_set()
        kfree()
        kmem_cache_free()
        ERR_PTR()
copy_siginfo_to_user() <int copy_siginfo_to_user (siginfo_t __user *to, const siginfo_t *from) at signal.c:2657>:
    access_ok()
copy_utsname() <struct uts_namespace *copy_utsname (unsigned long flags, struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:66>:
    BUG_ON()
    get_uts_ns()
    clone_uts_ns() <struct uts_namespace *clone_uts_ns (struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:35>:
        create_uts_ns() <struct uts_namespace *create_uts_ns (void) at utsname.c:20>:
            kmalloc()
            kref_init()
        ERR_PTR()
        ns_alloc_inum()
        kfree()
        down_read()
        get_user_ns()
        up_read()
    put_uts_ns()
core_kernel_data() <int core_kernel_data (unsigned long addr) at extable.c:91>:
core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
    init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
cpu_check_up_prepare() <int cpu_check_up_prepare (int cpu) at smpboot.c:396>:
    IS_ENABLED()
    atomic_set()
    per_cpu()
    atomic_read()
cpu_cluster_pm_enter() <int cpu_cluster_pm_enter (void) at cpu_pm.c:157>:
    read_lock()
    cpu_pm_notify() <int cpu_pm_notify (enum cpu_pm_event event, int nr_to_call, int *nr_calls) at cpu_pm.c:28>:
        notifier_to_errno()
    read_unlock()
cpu_cluster_pm_exit() <int cpu_cluster_pm_exit (void) at cpu_pm.c:191>:
    read_lock()
    cpu_pm_notify() <int cpu_pm_notify (enum cpu_pm_event event, int nr_to_call, int *nr_calls) at cpu_pm.c:28>:
        notifier_to_errno()
    read_unlock()
cpu_down() <int cpu_down (unsigned int cpu) at cpu.c:433>:
    cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
        mutex_lock()
    cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
        mutex_unlock()
cpu_hotplug_begin() <void cpu_hotplug_begin (void) at cpu.c:146>:
    DEFINE_WAIT()
    cpuhp_lock_acquire()
    mutex_lock()
    prepare_to_wait()
    likely()
    atomic_read()
    mutex_unlock()
    schedule()
    finish_wait()
cpu_hotplug_disable() <void cpu_hotplug_disable (void) at cpu.c:178>:
    cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
        mutex_lock()
    cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
        mutex_unlock()
cpu_hotplug_done() <void cpu_hotplug_done (void) at cpu.c:164>:
    mutex_unlock()
    cpuhp_lock_release()
cpu_hotplug_enable() <void cpu_hotplug_enable (void) at cpu.c:186>:
    cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
        mutex_lock()
    WARN_ON()
    cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
        mutex_unlock()
cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
    mutex_lock()
cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
    mutex_unlock()
cpu_pm_enter() <int cpu_pm_enter (void) at cpu_pm.c:98>:
    read_lock()
    cpu_pm_notify() <int cpu_pm_notify (enum cpu_pm_event event, int nr_to_call, int *nr_calls) at cpu_pm.c:28>:
        notifier_to_errno()
    read_unlock()
cpu_pm_exit() <int cpu_pm_exit (void) at cpu_pm.c:129>:
    read_lock()
    cpu_pm_notify() <int cpu_pm_notify (enum cpu_pm_event event, int nr_to_call, int *nr_calls) at cpu_pm.c:28>:
        notifier_to_errno()
    read_unlock()
cpu_pm_register_notifier() <int cpu_pm_register_notifier (struct notifier_block *nb) at cpu_pm.c:48>:
    write_lock_irqsave()
    raw_notifier_chain_register() <int raw_notifier_chain_register (struct raw_notifier_head *nh, struct notifier_block *n) at notifier.c:347>:
        notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
            rcu_assign_pointer()
    write_unlock_irqrestore()
cpu_pm_unregister_notifier() <int cpu_pm_unregister_notifier (struct notifier_block *nb) at cpu_pm.c:70>:
    write_lock_irqsave()
    raw_notifier_chain_unregister() <int raw_notifier_chain_unregister (struct raw_notifier_head *nh, struct notifier_block *n) at notifier.c:364>:
        notifier_chain_unregister() <int notifier_chain_unregister (struct notifier_block **nl, struct notifier_block *n) at notifier.c:49>:
            rcu_assign_pointer()
    write_unlock_irqrestore()
cpu_report_death() <bool cpu_report_death (void) at smpboot.c:509>:
    smp_processor_id()
    atomic_read()
    per_cpu()
    atomic_cmpxchg()
cpu_report_state() <int cpu_report_state (int cpu) at smpboot.c:379>:
    atomic_read()
    per_cpu()
cpu_set_state_online() <void cpu_set_state_online (int cpu) at smpboot.c:452>:
    atomic_xchg()
    per_cpu()
cpu_up() <int cpu_up (unsigned int cpu) at cpu.c:537>:
    cpu_possible()
    pr_err()
    try_online_node()
    cpu_to_node()
    cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
        mutex_lock()
    cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
        mutex_unlock()
cpu_wait_death() <bool cpu_wait_death (unsigned int cpu, int seconds) at smpboot.c:462>:
    might_sleep()
    atomic_read()
    per_cpu()
    udelay()
    schedule_timeout_uninterruptible()
    DIV_ROUND_UP()
    smp_mb()
    atomic_set()
    atomic_cmpxchg()
cpuset_cpus_allowed() <void cpuset_cpus_allowed (struct task_struct *tsk, struct cpumask *pmask) at cpuset.c:2402>:
    spin_lock_irqsave()
    rcu_read_lock()
    guarantee_online_cpus() <void guarantee_online_cpus (struct cpuset *cs, struct cpumask *pmask) at cpuset.c:337>:
        cpumask_intersects()
        parent_cs() <inline struct cpuset *parent_cs (struct cpuset *cs) at cpuset.c:147>:
            css_cs() <inline struct cpuset *css_cs (struct cgroup_subsys_state *css) at cpuset.c:136>:
                container_of()
        cpumask_and()
    task_cs() <inline struct cpuset *task_cs (struct task_struct *task) at cpuset.c:142>:
        css_cs() <inline struct cpuset *css_cs (struct cgroup_subsys_state *css) at cpuset.c:136>:
            container_of()
        task_css()
    rcu_read_unlock()
    spin_unlock_irqrestore()
cpuset_cpus_allowed_fallback() <void cpuset_cpus_allowed_fallback (struct task_struct *tsk) at cpuset.c:2413>:
    rcu_read_lock()
    do_set_cpus_allowed()
    task_cs() <inline struct cpuset *task_cs (struct task_struct *task) at cpuset.c:142>:
        css_cs() <inline struct cpuset *css_cs (struct cgroup_subsys_state *css) at cpuset.c:136>:
            container_of()
        task_css()
    rcu_read_unlock()
cpuset_init() <int __init cpuset_init (void) at cpuset.c:2101>:
    alloc_cpumask_var()
    BUG()
    cpumask_setall()
    nodes_setall()
    fmeter_init() <void fmeter_init (struct fmeter *fmp) at cpuset.c:1406>:
        spin_lock_init()
    set_bit()
    register_filesystem()
cpuset_init_current_mems_allowed() <void __init cpuset_init_current_mems_allowed (void) at cpuset.c:2438>:
    nodes_setall()
cpuset_init_smp() <void __init cpuset_init_smp (void) at cpuset.c:2376>:
    cpumask_copy()
    register_hotmemory_notifier()
    alloc_ordered_workqueue()
    BUG_ON()
cpuset_mem_spread_node() <int cpuset_mem_spread_node (void) at cpuset.c:2603>:
    node_random()
    cpuset_spread_node() <int cpuset_spread_node (int *rotor) at cpuset.c:2592>:
        next_node()
        first_node()
cpuset_mems_allowed() <nodemask_t cpuset_mems_allowed (struct task_struct *tsk) at cpuset.c:2453>:
    spin_lock_irqsave()
    rcu_read_lock()
    guarantee_online_mems() <void guarantee_online_mems (struct cpuset *cs, nodemask_t *pmask) at cpuset.c:355>:
        nodes_intersects()
        parent_cs() <inline struct cpuset *parent_cs (struct cpuset *cs) at cpuset.c:147>:
            css_cs() <inline struct cpuset *css_cs (struct cgroup_subsys_state *css) at cpuset.c:136>:
                container_of()
        nodes_and()
    task_cs() <inline struct cpuset *task_cs (struct task_struct *task) at cpuset.c:142>:
        css_cs() <inline struct cpuset *css_cs (struct cgroup_subsys_state *css) at cpuset.c:136>:
            container_of()
        task_css()
    rcu_read_unlock()
    spin_unlock_irqrestore()
cpuset_mems_allowed_intersects() <int cpuset_mems_allowed_intersects (const struct task_struct *tsk1, const struct task_struct *tsk2) at cpuset.c:2634>:
    nodes_intersects()
cpuset_nodemask_valid_mems_allowed() <int cpuset_nodemask_valid_mems_allowed (nodemask_t *nodemask) at cpuset.c:2473>:
    nodes_intersects()
cpuset_post_attach_flush() <void cpuset_post_attach_flush (void) at cpuset.c:1019>:
    flush_workqueue() <void flush_workqueue (struct workqueue_struct *wq) at workqueue.c:2576>:
        LIST_HEAD_INIT()
        COMPLETION_INITIALIZER_ONSTACK()
        lock_map_acquire()
        lock_map_release()
        mutex_lock()
        work_next_color() <int work_next_color (int color) at workqueue.c:613>:
        WARN_ON_ONCE()
        list_empty()
        flush_workqueue_prep_pwqs() <bool flush_workqueue_prep_pwqs (struct workqueue_struct *wq, int flush_color, int work_color) at workqueue.c:2529>:
            WARN_ON_ONCE()
            atomic_read()
            atomic_set()
            for_each_pwq()
            spin_lock_irq()
            atomic_inc()
            work_next_color() <int work_next_color (int color) at workqueue.c:613>:
            spin_unlock_irq()
            atomic_dec_and_test()
            complete()
        list_add_tail()
        check_flush_dependency() <void check_flush_dependency (struct workqueue_struct *target_wq, struct work_struct *target_work) at workqueue.c:2403>:
            current_wq_worker()
            WARN_ONCE()
        mutex_unlock()
        wait_for_completion()
        list_for_each_entry_safe()
        list_del_init()
        complete()
        list_for_each_entry()
        list_splice_tail_init()
cpuset_print_current_mems_allowed() <void cpuset_print_current_mems_allowed (void) at cpuset.c:2646>:
    rcu_read_lock()
    task_cs() <inline struct cpuset *task_cs (struct task_struct *task) at cpuset.c:142>:
        css_cs() <inline struct cpuset *css_cs (struct cgroup_subsys_state *css) at cpuset.c:136>:
            container_of()
        task_css()
    pr_info()
    pr_cont_cgroup_name()
    pr_cont()
    nodemask_pr_args()
    rcu_read_unlock()
cpuset_slab_spread_node() <int cpuset_slab_spread_node (void) at cpuset.c:2612>:
    node_random()
    cpuset_spread_node() <int cpuset_spread_node (int *rotor) at cpuset.c:2592>:
        next_node()
        first_node()
cpuset_task_status_allowed() <void cpuset_task_status_allowed (struct seq_file *m, struct task_struct *task) at cpuset.c:2734>:
    seq_printf()
    nodemask_pr_args()
cpuset_update_active_cpus() <void cpuset_update_active_cpus (bool cpu_online) at cpuset.c:2338>:
    partition_sched_domains()
    schedule_work()
crash_free_reserved_phys_range() <void __weak crash_free_reserved_phys_range (unsigned long begin, unsigned long end) at kexec_core.c:915>:
    free_reserved_page()
    pfn_to_page()
crash_get_memory_size() <size_t crash_get_memory_size (void) at kexec_core.c:904>:
    mutex_lock()
    resource_size()
    mutex_unlock()
crash_kexec() <void crash_kexec (struct pt_regs *regs) at kexec_core.c:881>:
    raw_smp_processor_id()
    atomic_cmpxchg()
    atomic_set()
crash_save_cpu() <void crash_save_cpu (struct pt_regs *regs, int cpu) at kexec_core.c:1003>:
    per_cpu_ptr()
    elf_core_copy_kernel_regs()
    append_elf_note() <u32 *append_elf_note (u32 *buf, char *name, unsigned type, void *data, size_t data_len) at kexec_core.c:975>:
    final_note() <void final_note (u32 *buf) at kexec_core.c:993>:
crash_save_vmcoreinfo() <void crash_save_vmcoreinfo (void) at kexec_core.c:1346>:
    vmcoreinfo_append_str() <void vmcoreinfo_append_str (const char *fmt, ...) at kexec_core.c:1352>:
        vscnprintf()
        min()
    get_seconds()
    update_vmcoreinfo_note() <void update_vmcoreinfo_note (void) at kexec_core.c:1335>:
        append_elf_note() <u32 *append_elf_note (u32 *buf, char *name, unsigned type, void *data, size_t data_len) at kexec_core.c:975>:
        final_note() <void final_note (u32 *buf) at kexec_core.c:993>:
crash_shrink_memory() <int crash_shrink_memory (unsigned long new_size) at kexec_core.c:924>:
    start()
    mutex_lock()
    kzalloc()
    roundup()
    crash_map_reserved_pages() <void __weak crash_map_reserved_pages (void) at kexec_core.c:1555>
    crash_free_reserved_phys_range() <void __weak crash_free_reserved_phys_range (unsigned long begin, unsigned long end) at kexec_core.c:915>:
        free_reserved_page()
        pfn_to_page()
    release_resource() <int release_resource (struct resource *old) at resource.c:323>:
        write_lock()
        write_unlock()
    insert_resource() <int insert_resource (struct resource *parent, struct resource *new) at resource.c:834>:
        insert_resource_conflict() <struct resource *insert_resource_conflict (struct resource *parent, struct resource *new) at resource.c:817>:
            write_lock()
            write_unlock()
    crash_unmap_reserved_pages() <void __weak crash_unmap_reserved_pages (void) at kexec_core.c:1558>
    mutex_unlock()
create_proc_profile() <int __ref create_proc_profile (void) at profile.c:586>:
    cpu_notifier_register_begin()
    create_hash_tables() <int create_hash_tables (void) at profile.c:538>:
        for_each_online_cpu()
        cpu_to_mem()
        per_cpu()
        profile_hit()
        page_address()
        smp_mb()
        on_each_cpu() <int on_each_cpu (smp_call_func_t func, void *info, int wait) at up.c:36>:
            preempt_disable()
            smp_call_function() <int smp_call_function (smp_call_func_t func, void *info, int wait) at smp.c:488>:
                preempt_disable()
                smp_call_function_many() <void smp_call_function_many (const struct cpumask *mask, smp_call_func_t func, void *info, bool wait) at smp.c:404>:
                    smp_processor_id()
                    WARN_ON_ONCE()
                    cpu_online()
                    irqs_disabled()
                    cpumask_first_and()
                    cpumask_next_and()
                    smp_call_function_single() <int smp_call_function_single (int cpu, void (*func) (void *info), void *info, int wait) at up.c:10>:
                        get_cpu()
                        WARN_ON_ONCE()
                        cpu_online()
                        irqs_disabled()
                        this_cpu_ptr()
                        csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
                            csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                                smp_load_acquire()
                                cpu_relax()
                            smp_wmb()
                        generic_exec_single() <int generic_exec_single (int cpu, struct call_single_data *csd, smp_call_func_t func, void *info) at smp.c:144>:
                            smp_processor_id()
                            csd_unlock() <void csd_unlock (struct call_single_data *csd) at smp.c:127>:
                                WARN_ON()
                                smp_store_release()
                            local_irq_save()
                            local_irq_restore()
                            cpu_online()
                            llist_add()
                            per_cpu()
                            arch_send_call_function_single_ipi()
                        csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                            smp_load_acquire()
                            cpu_relax()
                        put_cpu()
                        WARN_ON()
                        local_irq_save()
                        local_irq_restore()
                    this_cpu_ptr()
                    cpumask_and()
                    cpumask_clear_cpu()
                    unlikely()
                    cpumask_weight()
                    for_each_cpu()
                    per_cpu_ptr()
                    csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
                        csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                            smp_load_acquire()
                            cpu_relax()
                        smp_wmb()
                    llist_add()
                    per_cpu()
                    arch_send_call_function_ipi_mask()
                    csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                        smp_load_acquire()
                        cpu_relax()
                preempt_enable()
            local_irq_save()
            local_irq_restore()
            preempt_enable()
        profile_nop() <void profile_nop (void *unused) at profile.c:534>
        virt_to_page()
    proc_create()
    proc_set_size()
    profile_cpu_callback() <int profile_cpu_callback (struct notifier_block *info, unsigned long action, void *__cpu) at profile.c:330>:
        cpu_to_mem()
        per_cpu()
        notifier_from_errno()
        page_address()
        virt_to_page()
        cpumask_set_cpu()
        cpumask_clear_cpu()
    cpu_notifier_register_done()
create_prof_cpu_mask() <void create_prof_cpu_mask (void) at profile.c:460>:
    proc_create()
create_user_ns() <int create_user_ns (struct cred *new) at user_namespace.c:60>:
    current_chrooted()
    kuid_has_mapping()
    kgid_has_mapping()
    kmem_cache_zalloc()
    ns_alloc_inum()
    kmem_cache_free()
    atomic_set()
    mutex_lock()
    mutex_unlock()
    set_cred_user_ns() <void set_cred_user_ns (struct cred *cred, struct user_namespace *user_ns) at user_namespace.c:33>:
        key_put()
    init_rwsem()
cred_alloc_blank() <struct cred *cred_alloc_blank (void) at cred.c:206>:
    kmem_cache_zalloc()
    atomic_set()
    security_cred_alloc_blank()
    abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
        kdebug()
        atomic_read()
        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
            atomic_read()
        BUG_ON()
        put_cred()
cred_init() <void __init cred_init (void) at cred.c:569>:
    kmem_cache_create()
creds_are_invalid() <bool creds_are_invalid (const struct cred *cred) at cred.c:700>:
    selinux_is_enabled()
css_from_id() <struct cgroup_subsys_state *css_from_id (int id, struct cgroup_subsys *ss) at cgroup.c:5800>:
    WARN_ON_ONCE()
    rcu_read_lock_held()
    idr_find()
css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
    rcu_read_lock()
    css_for_each_child()
    rcu_read_unlock()
css_next_child() <struct cgroup_subsys_state *css_next_child (struct cgroup_subsys_state *pos, struct cgroup_subsys_state *parent) at cgroup.c:3629>:
    cgroup_assert_mutex_or_rcu_locked()
    list_entry_rcu()
    likely()
    list_for_each_entry_rcu()
css_next_descendant_post() <struct cgroup_subsys_state *css_next_descendant_post (struct cgroup_subsys_state *pos, struct cgroup_subsys_state *root) at cgroup.c:3791>:
    cgroup_assert_mutex_or_rcu_locked()
    css_leftmost_descendant() <struct cgroup_subsys_state *css_leftmost_descendant (struct cgroup_subsys_state *pos) at cgroup.c:3756>:
        css_next_child() <struct cgroup_subsys_state *css_next_child (struct cgroup_subsys_state *pos, struct cgroup_subsys_state *parent) at cgroup.c:3629>:
            cgroup_assert_mutex_or_rcu_locked()
            list_entry_rcu()
            likely()
            list_for_each_entry_rcu()
    css_next_child() <struct cgroup_subsys_state *css_next_child (struct cgroup_subsys_state *pos, struct cgroup_subsys_state *parent) at cgroup.c:3629>:
        cgroup_assert_mutex_or_rcu_locked()
        list_entry_rcu()
        likely()
        list_for_each_entry_rcu()
css_next_descendant_pre() <struct cgroup_subsys_state *css_next_descendant_pre (struct cgroup_subsys_state *pos, struct cgroup_subsys_state *root) at cgroup.c:3697>:
    cgroup_assert_mutex_or_rcu_locked()
    css_next_child() <struct cgroup_subsys_state *css_next_child (struct cgroup_subsys_state *pos, struct cgroup_subsys_state *parent) at cgroup.c:3629>:
        cgroup_assert_mutex_or_rcu_locked()
        list_entry_rcu()
        likely()
        list_for_each_entry_rcu()
css_rightmost_descendant() <struct cgroup_subsys_state *css_rightmost_descendant (struct cgroup_subsys_state *pos) at cgroup.c:3738>:
    cgroup_assert_mutex_or_rcu_locked()
    css_for_each_child()
css_task_iter_end() <void css_task_iter_end (struct css_task_iter *it) at cgroup.c:3997>:
    spin_lock_bh()
    list_del()
    put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
        lockdep_assert_held()
        atomic_dec_and_test()
        for_each_subsys()
        list_del()
        css_put()
        hash_del()
        list_for_each_entry_safe()
        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
            container_of()
        cgroup_put()
        kfree()
        kfree_rcu()
    spin_unlock_bh()
    put_task_struct()
css_task_iter_next() <struct task_struct *css_task_iter_next (struct css_task_iter *it) at cgroup.c:3970>:
    put_task_struct()
    spin_lock_bh()
    list_entry()
    get_task_struct()
    css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
        lockdep_assert_held()
        WARN_ON_ONCE()
        css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
            lockdep_assert_held()
            container_of()
            list_entry()
            css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                lockdep_assert_held()
                list_empty()
            list_empty()
            list_del()
            put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                lockdep_assert_held()
                atomic_dec_and_test()
                for_each_subsys()
                list_del()
                css_put()
                hash_del()
                list_for_each_entry_safe()
                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                    container_of()
                cgroup_put()
                kfree()
                kfree_rcu()
            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                atomic_inc()
            list_add()
    spin_unlock_bh()
css_task_iter_start() <void css_task_iter_start (struct cgroup_subsys_state *css, struct css_task_iter *it) at cgroup.c:3938>:
    WARN_ON_ONCE()
    spin_lock_bh()
    css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
        lockdep_assert_held()
        container_of()
        list_entry()
        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
            lockdep_assert_held()
            list_empty()
        list_empty()
        list_del()
        put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
            lockdep_assert_held()
            atomic_dec_and_test()
            for_each_subsys()
            list_del()
            css_put()
            hash_del()
            list_for_each_entry_safe()
            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                container_of()
            cgroup_put()
            kfree()
            kfree_rcu()
        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
            atomic_inc()
        list_add()
    spin_unlock_bh()
css_tryget_online_from_dir() <struct cgroup_subsys_state *css_tryget_online_from_dir (struct dentry *dentry, struct cgroup_subsys *ss) at cgroup.c:5762>:
    kernfs_node_from_dentry()
    kernfs_type()
    ERR_PTR()
    rcu_read_lock()
    rcu_dereference()
    cgroup_css() <struct cgroup_subsys_state *cgroup_css (struct cgroup *cgrp, struct cgroup_subsys *ss) at cgroup.c:353>:
        rcu_dereference_check()
        lockdep_is_held()
    css_tryget_online()
    rcu_read_unlock()
ctrl_alt_del() <void ctrl_alt_del (void) at reboot.c:379>:
    schedule_work()
    kill_cad_pid()
current_cpuset_is_being_rebound() <int current_cpuset_is_being_rebound (void) at cpuset.c:1258>:
    rcu_read_lock()
    task_cs() <inline struct cpuset *task_cs (struct task_struct *task) at cpuset.c:142>:
        css_cs() <inline struct cpuset *css_cs (struct cgroup_subsys_state *css) at cpuset.c:136>:
            container_of()
        task_css()
    rcu_read_unlock()
current_is_async() <bool current_is_async (void) at async.c:323>:
    current_wq_worker()
    async_run_entry_fn() <void async_run_entry_fn (struct work_struct *work) at async.c:109>:
        container_of()
        uninitialized_var()
        pr_debug()
        task_pid_nr()
        ktime_get()
        ktime_sub()
        ktime_to_ns()
        spin_lock_irqsave()
        list_del_init()
        kfree()
        atomic_dec()
        spin_unlock_irqrestore()
        wake_up()
current_is_workqueue_rescuer() <bool current_is_workqueue_rescuer (void) at workqueue.c:4117>:
    current_wq_worker()
delayacct_init() <void delayacct_init (void) at delayacct.c:35>:
    KMEM_CACHE()
    delayacct_tsk_init()
delayed_work_timer_fn() <void delayed_work_timer_fn (unsigned long __data) at workqueue.c:1492>:
dequeue_signal() <int dequeue_signal (struct task_struct *tsk, sigset_t *mask, siginfo_t *info) at signal.c:559>:
    unlikely()
    hrtimer_is_queued()
    hrtimer_forward()
    get_time()
    hrtimer_restart()
    recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
        recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
            PENDING()
            set_tsk_thread_flag()
        freezing()
        clear_thread_flag()
    sig_kernel_stop()
    spin_unlock()
    do_schedule_next_timer()
    spin_lock()
destroy_delayed_work_on_stack() <void destroy_delayed_work_on_stack (struct delayed_work *work) at workqueue.c:539>:
    destroy_timer_on_stack()
    debug_object_free()
destroy_params() <void destroy_params (const struct kernel_param *params, unsigned num) at params.c:789>:
destroy_work_on_stack() <void destroy_work_on_stack (struct work_struct *work) at workqueue.c:533>:
    debug_object_free()
destroy_workqueue() <void destroy_workqueue (struct workqueue_struct *wq) at workqueue.c:4007>:
    drain_workqueue() <void drain_workqueue (struct workqueue_struct *wq) at workqueue.c:2735>:
        mutex_lock()
        mutex_unlock()
        flush_workqueue() <void flush_workqueue (struct workqueue_struct *wq) at workqueue.c:2576>:
            LIST_HEAD_INIT()
            COMPLETION_INITIALIZER_ONSTACK()
            lock_map_acquire()
            lock_map_release()
            mutex_lock()
            work_next_color() <int work_next_color (int color) at workqueue.c:613>:
            WARN_ON_ONCE()
            list_empty()
            flush_workqueue_prep_pwqs() <bool flush_workqueue_prep_pwqs (struct workqueue_struct *wq, int flush_color, int work_color) at workqueue.c:2529>:
                WARN_ON_ONCE()
                atomic_read()
                atomic_set()
                for_each_pwq()
                spin_lock_irq()
                atomic_inc()
                work_next_color() <int work_next_color (int color) at workqueue.c:613>:
                spin_unlock_irq()
                atomic_dec_and_test()
                complete()
            list_add_tail()
            check_flush_dependency() <void check_flush_dependency (struct workqueue_struct *target_wq, struct work_struct *target_work) at workqueue.c:2403>:
                current_wq_worker()
                WARN_ONCE()
            mutex_unlock()
            wait_for_completion()
            list_for_each_entry_safe()
            list_del_init()
            complete()
            list_for_each_entry()
            list_splice_tail_init()
        for_each_pwq()
        spin_lock_irq()
        list_empty()
        spin_unlock_irq()
        pr_warn()
    mutex_lock()
    for_each_pwq()
    WARN_ON()
    mutex_unlock()
    list_empty()
    list_del_rcu()
    workqueue_sysfs_unregister() <void workqueue_sysfs_unregister (struct workqueue_struct *wq) at workqueue.c:5276>:
        device_unregister()
    kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
        trace_sched_kthread_stop()
        get_task_struct()
        to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
            ACCESS_ONCE()
            likely()
        set_bit()
        wake_up_process()
        wait_for_completion()
        put_task_struct()
        trace_sched_kthread_stop_ret()
    call_rcu_sched()
    rcu_free_wq() <void rcu_free_wq (struct rcu_head *rcu) at workqueue.c:3208>:
        container_of()
        free_percpu()
        free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
            free_cpumask_var()
            kfree()
        kfree()
    for_each_node()
    rcu_access_pointer()
    RCU_INIT_POINTER()
    put_pwq_unlocked() <void put_pwq_unlocked (struct pool_workqueue *pwq) at workqueue.c:1096>:
        spin_lock_irq()
        put_pwq() <void put_pwq (struct pool_workqueue *pwq) at workqueue.c:1072>:
            lockdep_assert_held()
            likely()
            WARN_ON_ONCE()
            schedule_work()
        spin_unlock_irq()
detach_pid() <void detach_pid (struct task_struct *task, enum pid_type type) at pid.c:415>:
devm_memremap() <void *devm_memremap (struct device *dev, resource_size_t offset, size_t size, unsigned long flags) at memremap.c:125>:
    devres_alloc_node()
    devm_memremap_release() <void devm_memremap_release (struct device *dev, void *res) at memremap.c:115>:
        memunmap() <void memunmap (void *addr) at memremap.c:108>:
            is_vmalloc_addr()
            iounmap()
    dev_to_node()
    ERR_PTR()
    memremap() <void *memremap (resource_size_t offset, size_t size, unsigned long flags) at memremap.c:61>:
        region_intersects() <int region_intersects (resource_size_t start, size_t size, const char *name) at resource.c:513>:
            read_lock()
            read_unlock()
        WARN_ONCE()
        try_ram_remap() <void *try_ram_remap (resource_size_t offset, size_t size) at memremap.c:30>:
            PHYS_PFN()
            pfn_valid()
            PageHighMem()
            pfn_to_page()
        ioremap_cache() <__weak void __iomem *ioremap_cache (resource_size_t offset, unsigned long size) at memremap.c:24>:
            ioremap()
        ioremap_wt()
    devres_add()
    devres_free()
devm_memremap_pages() <void *devm_memremap_pages (struct device *dev, struct resource *res, struct percpu_ref *ref, struct vmem_altmap *altmap) at memremap.c:270>:
    ALIGN()
    resource_size()
    region_intersects() <int region_intersects (resource_size_t start, size_t size, const char *name) at resource.c:513>:
        read_lock()
        read_unlock()
    WARN_ONCE()
    ERR_PTR()
    IS_ENABLED()
    dev_err()
    devres_alloc_node()
    devm_memremap_pages_release() <void devm_memremap_pages_release (struct device *dev, void *data) at memremap.c:223>:
        percpu_ref_tryget_live()
        dev_WARN()
        percpu_ref_put()
        ALIGN()
        resource_size()
        arch_remove_memory()
        pgmap_radix_release() <void pgmap_radix_release (struct resource *res) at memremap.c:186>:
            ALIGN()
            resource_size()
            mutex_lock()
            radix_tree_delete()
            mutex_unlock()
        dev_WARN_ONCE()
    dev_to_node()
    mutex_lock()
    rcu_read_lock()
    find_dev_pagemap() <struct dev_pagemap *find_dev_pagemap (resource_size_t phys) at memremap.c:245>:
        WARN_ON_ONCE()
        rcu_read_lock_held()
        radix_tree_lookup()
    rcu_read_unlock()
    dev_name()
    radix_tree_insert()
    mutex_unlock()
    numa_mem_id()
    arch_add_memory()
    for_each_device_pfn()
    pfn_to_page()
    list_del()
    devres_add()
    pgmap_radix_release() <void pgmap_radix_release (struct resource *res) at memremap.c:186>:
        ALIGN()
        resource_size()
        mutex_lock()
        radix_tree_delete()
        mutex_unlock()
    devres_free()
devm_memunmap() <void devm_memunmap (struct device *dev, void *addr) at memremap.c:148>:
    WARN_ON()
    devres_release()
    devm_memremap_release() <void devm_memremap_release (struct device *dev, void *res) at memremap.c:115>:
        memunmap() <void memunmap (void *addr) at memremap.c:108>:
            is_vmalloc_addr()
            iounmap()
    devm_memremap_match() <int devm_memremap_match (struct device *dev, void *res, void *match_data) at memremap.c:120>
devm_release_resource() <void devm_release_resource (struct device *dev, struct resource *new) at resource.c:1328>:
    WARN_ON()
    devres_release()
    devm_resource_release() <void devm_resource_release (struct device *dev, void *ptr) at resource.c:1265>:
        release_resource() <int release_resource (struct resource *old) at resource.c:323>:
            write_lock()
            write_unlock()
    devm_resource_match() <int devm_resource_match (struct device *dev, void *res, void *data) at resource.c:1314>
devm_request_resource() <int devm_request_resource (struct device *dev, struct resource *root, struct resource *new) at resource.c:1290>:
    devres_alloc()
    devm_resource_release() <void devm_resource_release (struct device *dev, void *ptr) at resource.c:1265>:
        release_resource() <int release_resource (struct resource *old) at resource.c:323>:
            write_lock()
            write_unlock()
    request_resource_conflict() <struct resource *request_resource_conflict (struct resource *root, struct resource *new) at resource.c:292>:
        write_lock()
        write_unlock()
    dev_err()
    devres_free()
    devres_add()
disable_kprobe() <int disable_kprobe (struct kprobe *kp) at kprobes.c:1992>:
    mutex_lock()
    mutex_unlock()
disable_nonboot_cpus() <int disable_nonboot_cpus (void) at cpu.c:572>:
    cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
        mutex_lock()
    cpumask_first()
    cpumask_clear()
    pr_info()
    for_each_online_cpu()
    trace_suspend_resume()
    TPS()
    cpumask_set_cpu()
    pr_err()
    BUG_ON()
    num_online_cpus()
    cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
        mutex_unlock()
disable_pid_allocation() <void disable_pid_allocation (struct pid_namespace *ns) at pid.c:359>:
    spin_lock_irq()
    spin_unlock_irq()
do_exit() <void do_exit (long code) at exit.c:651>:
    TASKS_RCU()
    profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
        blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
    WARN_ON()
    blk_needs_flush_plug()
    unlikely()
    in_interrupt()
    panic() <void panic (const char *fmt, ...) at panic.c:83>:
        local_irq_disable()
        raw_smp_processor_id()
        atomic_cmpxchg()
        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
            cpu_relax()
        console_verbose()
        bust_spinlocks()
        pr_emerg()
        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
            test_bit()
        dump_stack()
        smp_send_stop()
        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
        kmsg_dump()
        debug_locks_off()
        console_flush_on_panic()
        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
        no_blink() <long no_blink (int state) at panic.c:46>
        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
            raw_cpu_write()
            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                    raw_cpu_write()
                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                    per_cpu()
                raw_smp_processor_id()
        mdelay()
        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
            kmsg_dump()
            machine_emergency_restart()
        disabled_wait()
        local_irq_enable()
        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                raw_cpu_write()
            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                per_cpu()
            raw_smp_processor_id()
    set_fs()
    ptrace_event()
    validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
        kdebug()
        atomic_read()
        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
            atomic_read()
    pr_alert()
    set_current_state()
    schedule()
    exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
        threadgroup_change_begin()
        thread_group_empty()
        signal_group_exit()
        threadgroup_change_end()
        spin_lock_irq()
        signal_pending()
        signotset()
        retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
            sigandsets()
            sigisemptyset()
            while_each_thread()
            has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
            signal_pending()
            signal_wake_up()
        unlikely()
        task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
            WARN_ON_ONCE()
            task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                BUG_ON()
                task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                    unlikely()
                    smp_mb()
                    wake_up_bit()
        spin_unlock_irq()
        read_lock()
        do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
            rcu_read_lock()
            task_pid_nr_ns()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                        smp_rmb()
            task_cred_xxx()
            task_uid()
            rcu_read_unlock()
            task_cputime()
            cputime_to_clock_t()
            BUG()
            spin_lock_irqsave()
            spin_unlock_irqrestore()
        read_unlock()
    smp_mb()
    raw_spin_unlock_wait()
    in_atomic()
    pr_info()
    task_pid_nr()
    preempt_count()
    preempt_count_set()
    sync_mm_rss()
    acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
        task_cputime()
    atomic_dec_and_test()
    hrtimer_cancel()
    exit_itimers()
    setmax_mm_hiwater_rss()
    acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
        down_read()
        up_read()
        spin_lock_irq()
        thread_group_leader()
        task_cputime()
        spin_unlock_irq()
    tty_audit_exit()
    audit_free()
    taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
        taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
            nla_total_size()
        taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
            thread_group_empty()
            kmem_cache_zalloc()
            spin_lock_irq()
            spin_unlock_irq()
            kmem_cache_free()
        fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
            spin_lock_irqsave()
            delayacct_add_tsk()
            spin_unlock_irqrestore()
        raw_cpu_ptr()
        list_empty()
        prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
            genlmsg_new()
            this_cpu_inc_return()
            genlmsg_put()
            genlmsg_put_reply()
            nlmsg_free()
        mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
            nla_put()
            nla_nest_start()
            nla_nest_cancel()
            nla_reserve()
            nla_nest_end()
            nla_data()
        task_pid_nr_ns()
        fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
            delayacct_add_tsk()
            bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                BUILD_BUG_ON()
                ktime_get_ns()
                do_div()
                get_seconds()
                thread_group_leader()
                task_nice()
                task_pid_nr_ns()
                rcu_read_lock()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                    from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                pid_alive()
                task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                    pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                    task_tgid()
                rcu_dereference()
                rcu_read_unlock()
                task_cputime()
                cputime_to_usecs()
                task_cputime_scaled()
            xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                    task_lock()
                    atomic_inc()
                    task_unlock()
                get_mm_hiwater_rss()
                get_mm_hiwater_vm()
                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                    might_sleep()
                    atomic_dec_and_test()
                    uprobe_clear_state()
                    exit_aio()
                    ksm_exit()
                    khugepaged_exit()
                    exit_mmap()
                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                        rcu_dereference_raw()
                        get_file()
                        rcu_assign_pointer()
                        fput()
                    list_empty()
                    spin_lock()
                    list_del()
                    spin_unlock()
                    module_put() <void module_put (struct module *module) at module.c:1098>:
                        preempt_disable()
                        atomic_dec_if_positive()
                        WARN_ON()
                        trace_module_put()
                        preempt_enable()
                    mmdrop()
        task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
            pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
            task_tgid()
        send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
            nlmsg_data()
            nlmsg_hdr()
            genlmsg_data()
            genlmsg_end()
            down_read()
            list_for_each_entry()
            list_is_last()
            skb_clone()
            genlmsg_unicast()
            up_read()
            nlmsg_free()
            down_write()
            list_for_each_entry_safe()
            list_del()
            kfree()
            up_write()
        nlmsg_free()
    exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
        mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
            unlikely()
            exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                uninitialized_var()
                fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                    get_user()
                get_user()
                handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                    uninitialized_var()
                    get_user()
                    task_pid_vnr()
                    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                        pagefault_disable()
                        futex_atomic_cmpxchg_inatomic()
                        pagefault_enable()
                    fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                        down_read()
                        fixup_user_fault()
                        up_read()
                    futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                        WAKE_Q()
                        get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                            unlikely()
                            access_ok()
                            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                should_fail()
                            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                ihold()
                                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                    atomic_inc()
                                    smp_mb__after_atomic()
                                smp_mb()
                            get_user_pages_fast()
                            lock_page()
                            compound_head()
                            PageSwapCache()
                            unlock_page()
                            put_page()
                            PageAnon()
                            basepage_index()
                        unlikely()
                        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                            jhash2()
                        hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                            atomic_read()
                        spin_lock()
                        plist_for_each_entry_safe()
                        match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                        mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                            WARN()
                            wake_q_add()
                            smp_wmb()
                        spin_unlock()
                        wake_up_q()
                        put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                WARN_ON_ONCE()
                                iput()
                                mmdrop()
                cond_resched()
            compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                uninitialized_var()
                fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                    get_user()
                    compat_ptr()
                get_user()
                futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                    ptr_to_compat()
                    compat_ptr()
                handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                    uninitialized_var()
                    get_user()
                    task_pid_vnr()
                    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                        pagefault_disable()
                        futex_atomic_cmpxchg_inatomic()
                        pagefault_enable()
                    fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                        down_read()
                        fixup_user_fault()
                        up_read()
                    futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                        WAKE_Q()
                        get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                            unlikely()
                            access_ok()
                            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                should_fail()
                            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                ihold()
                                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                    atomic_inc()
                                    smp_mb__after_atomic()
                                smp_mb()
                            get_user_pages_fast()
                            lock_page()
                            compound_head()
                            PageSwapCache()
                            unlock_page()
                            put_page()
                            PageAnon()
                            basepage_index()
                        unlikely()
                        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                            jhash2()
                        hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                            atomic_read()
                        spin_lock()
                        plist_for_each_entry_safe()
                        match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                        mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                            WARN()
                            wake_q_add()
                            smp_wmb()
                        spin_unlock()
                        wake_up_q()
                        put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                WARN_ON_ONCE()
                                iput()
                                mmdrop()
                cond_resched()
            list_empty()
            exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                raw_spin_lock_irq()
                list_empty()
                list_entry()
                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                    jhash2()
                raw_spin_unlock_irq()
                spin_lock()
                spin_unlock()
                WARN_ON()
                list_del_init()
                rt_mutex_unlock()
            uprobe_free_utask()
            deactivate_mm()
            atomic_read()
            put_user()
            sys_futex()
            complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                task_lock()
                likely()
                complete()
                task_unlock()
        sync_mm_rss()
        down_read()
        up_read()
        xchg()
        atomic_dec_and_test()
        complete()
        set_task_state()
        freezable_schedule()
        atomic_inc()
        BUG_ON()
        task_lock()
        enter_lazy_tlb()
        task_unlock()
        mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
            atomic_read()
            read_lock()
            list_for_each_entry()
            for_each_process()
            for_each_thread()
            read_unlock()
            BUG_ON()
            get_task_struct()
            task_lock()
            task_unlock()
            put_task_struct()
        mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
            might_sleep()
            atomic_dec_and_test()
            uprobe_clear_state()
            exit_aio()
            ksm_exit()
            khugepaged_exit()
            exit_mmap()
            set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                rcu_dereference_raw()
                get_file()
                rcu_assign_pointer()
                fput()
            list_empty()
            spin_lock()
            list_del()
            spin_unlock()
            module_put() <void module_put (struct module *module) at module.c:1098>:
                preempt_disable()
                atomic_dec_if_positive()
                WARN_ON()
                trace_module_put()
                preempt_enable()
            mmdrop()
        test_thread_flag()
        exit_oom_victim()
    acct_process() <void acct_process (void) at acct.c:587>:
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
        unlikely()
        slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
            acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                smp_rmb()
                rcu_read_lock()
                to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                    container_of()
                ACCESS_ONCE()
                rcu_read_unlock()
                atomic_long_inc_not_zero()
                cpu_relax()
                mutex_lock()
                mutex_unlock()
                acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                    atomic_long_dec_and_test()
                    kfree_rcu()
            do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                    kdebug()
                    atomic_read()
                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                        atomic_read()
                    validate_creds()
                    get_cred()
                    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                        atomic_add()
                    rcu_assign_pointer()
                check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                    time_is_before_jiffies()
                    vfs_statfs()
                    do_div()
                    pr_info()
                fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                    strlcpy()
                    ktime_get_ns()
                    nsec_to_AHZ()
                    encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                    encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                    encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                    do_div()
                    get_seconds()
                    spin_lock_irq()
                    old_encode_dev()
                    tty_devnum()
                    jiffies_to_AHZ()
                    cputime_to_jiffies()
                    spin_unlock_irq()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                    from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                    pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                    task_tgid()
                rcu_read_lock()
                rcu_dereference()
                rcu_read_unlock()
                file_start_write_trylock()
                file_end_write()
                revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                    kdebug()
                    atomic_read()
                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                        atomic_read()
                    validate_creds()
                    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                        atomic_add()
                    rcu_assign_pointer()
                    put_cred()
            mutex_unlock()
            acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                atomic_long_dec_and_test()
                kfree_rcu()
    trace_sched_process_exit()
    exit_sem()
    exit_shm()
    exit_files()
    exit_fs()
    disassociate_ctty()
    exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
        switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
            might_sleep()
            task_lock()
            task_unlock()
            atomic_dec_and_test()
            free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                put_mnt_ns()
                put_uts_ns()
                put_ipc_ns()
                put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                    kref_put()
                    free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                        container_of()
                        destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                            ns_free_inum()
                            kfree()
                            put_user_ns()
                            call_rcu()
                            delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                kmem_cache_free()
                                container_of()
                put_net()
                kmem_cache_free()
    exit_task_work()
    exit_thread()
    perf_event_exit_task()
    cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
        task_css_set()
        list_empty()
        spin_lock_bh()
        css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
            lockdep_assert_held()
            WARN_ON_ONCE()
            list_empty()
            list_for_each_entry_safe()
            css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                lockdep_assert_held()
                WARN_ON_ONCE()
                css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                    lockdep_assert_held()
                    container_of()
                    list_entry()
                    css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                        lockdep_assert_held()
                        list_empty()
                    list_empty()
                    list_del()
                    put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                        lockdep_assert_held()
                        atomic_dec_and_test()
                        for_each_subsys()
                        list_del()
                        css_put()
                        hash_del()
                        list_for_each_entry_safe()
                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                            container_of()
                        cgroup_put()
                        kfree()
                        kfree_rcu()
                    get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                        atomic_inc()
                    list_add()
            list_del_init()
            css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                lockdep_assert_held()
                list_empty()
            css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                lockdep_assert_held()
                list_for_each_entry()
                cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                    lockdep_assert_held()
                    check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                        notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                            test_bit()
                        cgroup_is_populated()
                        css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                            rcu_read_lock()
                            css_for_each_child()
                            rcu_read_unlock()
                        cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                        schedule_work()
                    cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                        spin_lock_irqsave()
                        kernfs_notify()
                        spin_unlock_irqrestore()
                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                        container_of()
            rcu_assign_pointer()
            list_add_tail()
        spin_unlock_bh()
        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
            atomic_inc()
        for_each_subsys_which()
    flush_ptrace_hw_breakpoint()
    preempt_disable()
    preempt_enable()
    exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
        LIST_HEAD()
        write_lock_irq()
        forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
            unlikely()
            list_empty()
            exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                list_for_each_entry_safe()
                unlikely()
                send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                    valid_signal()
                    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                        lock_task_sighand()
                        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                SI_FROMUSER()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                        unlock_task_sighand()
                list_add()
            find_child_reaper()
            find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                    for_each_thread()
                same_thread_group()
            list_for_each_entry()
            for_each_thread()
            BUG_ON()
            likely()
            group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                rcu_read_lock()
                check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                    valid_signal()
                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                        SI_FROMUSER()
                    audit_signal_info()
                    same_thread_group()
                    kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                        current_cred()
                        uid_eq()
                        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                            unlikely()
                            cap_valid()
                            pr_crit()
                            BUG()
                            security_capable()
                            current_cred()
                    task_session()
                    security_task_kill()
                rcu_read_unlock()
                do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                    lock_task_sighand()
                    send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                            SI_FROMUSER()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                    unlock_task_sighand()
            same_thread_group()
            reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                unlikely()
                thread_group_empty()
                do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                    BUG_ON()
                    task_is_stopped_or_traced()
                    thread_group_empty()
                    rcu_read_lock()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_cred_xxx()
                    task_uid()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_clock_t()
                    spin_lock_irqsave()
                    valid_signal()
                    spin_unlock_irqrestore()
                list_add()
                kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                    task_pgrp()
                    task_session()
                    will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                        do_each_pid_task()
                        thread_group_empty()
                        is_global_init()
                        task_pgrp()
                        task_session()
                        while_each_pid_task()
                    has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                        do_each_pid_task()
                        while_each_pid_task()
            list_splice_tail_init()
        kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
            task_pgrp()
            task_session()
            will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                do_each_pid_task()
                thread_group_empty()
                is_global_init()
                task_pgrp()
                task_session()
                while_each_pid_task()
            has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                do_each_pid_task()
                while_each_pid_task()
        unlikely()
        thread_group_leader()
        thread_group_empty()
        ptrace_reparented()
        do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
            BUG_ON()
            task_is_stopped_or_traced()
            thread_group_empty()
            rcu_read_lock()
            task_pid_nr_ns()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                        smp_rmb()
            task_cred_xxx()
            task_uid()
            rcu_read_unlock()
            task_cputime()
            cputime_to_clock_t()
            spin_lock_irqsave()
            valid_signal()
            spin_unlock_irqrestore()
        list_add()
        wake_up_process()
        write_unlock_irq()
        list_for_each_entry_safe()
        list_del_init()
        release_task() <void release_task (struct task_struct *p) at exit.c:167>:
            rcu_read_lock()
            atomic_dec()
            rcu_read_unlock()
            proc_flush_task()
            write_lock_irq()
            ptrace_release_task()
            thread_group_empty()
            do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                BUG_ON()
                task_is_stopped_or_traced()
                thread_group_empty()
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                spin_lock_irqsave()
                valid_signal()
                spin_unlock_irqrestore()
            write_unlock_irq()
            release_thread()
            call_rcu()
            delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                container_of()
                perf_event_delayed_put()
                trace_sched_process_free()
                put_task_struct()
            unlikely()
    proc_exit_connector()
    task_lock()
    mpol_put()
    task_unlock()
    kfree()
    debug_check_no_locks_held()
    exit_io_context()
    free_pipe_info()
    put_page()
    check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
        stack_not_used()
        spin_lock()
        pr_warn()
        task_pid_nr()
        spin_unlock()
    exit_rcu()
    BUG()
    cpu_relax()
do_fork() <long do_fork (unsigned long clone_flags, unsigned long stack_start, unsigned long stack_size, int __user *parent_tidptr, int __user *child_tidptr) at fork.c:1765>:
do_futex() <long do_futex (u32 __user *uaddr, int op, u32 val, ktime_t *timeout, u32 __user *uaddr2, u32 val2, u32 val3) at futex.c:3041>:
    futex_wait() <int futex_wait (u32 __user *uaddr, unsigned int flags, u32 val, ktime_t *abs_time, u32 bitset) at futex.c:2267> (R):
        hrtimer_init_on_stack()
        hrtimer_init_sleeper()
        hrtimer_set_expires_range_ns()
        futex_wait_setup() <int futex_wait_setup (u32 __user *uaddr, u32 val, unsigned int flags, struct futex_q *q, struct futex_hash_bucket **hb) at futex.c:2208>:
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            unlikely()
            queue_lock() <inline struct futex_hash_bucket *queue_lock (struct futex_q *q) at futex.c:1848>:
                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                    jhash2()
                hb_waiters_inc() <inline void hb_waiters_inc (struct futex_hash_bucket *hb) at futex.c:345>:
                    atomic_inc()
                    smp_mb__after_atomic()
                spin_lock()
            get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                pagefault_disable()
                pagefault_enable()
            queue_unlock() <inline void queue_unlock (struct futex_hash_bucket *hb) at futex.c:1872>:
                spin_unlock()
                hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                    atomic_dec()
            get_user()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
        futex_wait_queue_me() <void futex_wait_queue_me (struct futex_hash_bucket *hb, struct futex_q *q, struct hrtimer_sleeper *timeout) at futex.c:2159>:
            set_current_state()
            queue_me() <inline void queue_me (struct futex_q *q, struct futex_hash_bucket *hb) at futex.c:1891>:
                min()
                plist_node_init()
                plist_add()
                spin_unlock()
            hrtimer_start_expires()
            likely()
            plist_node_empty()
            freezable_schedule()
        unqueue_me() <int unqueue_me (struct futex_q *q) at futex.c:1923>:
            barrier()
            spin_lock()
            unlikely()
            spin_unlock()
            BUG_ON()
            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                WARN_ON_ONCE()
                iput()
                mmdrop()
        signal_pending()
        futex_wait_restart() <long futex_wait_restart (struct restart_block *restart) at futex.c:2342> (R):
            do_no_restart_syscall() <long do_no_restart_syscall (struct restart_block *param) at signal.c:2454>:
            futex_wait() <int futex_wait (u32 __user *uaddr, unsigned int flags, u32 val, ktime_t *abs_time, u32 bitset) at futex.c:2267> (recursive: see 35646)
        hrtimer_cancel()
        destroy_hrtimer_on_stack()
    futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
        WAKE_Q()
        get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
            unlikely()
            access_ok()
            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                should_fail()
            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                ihold()
                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                    atomic_inc()
                    smp_mb__after_atomic()
                smp_mb()
            get_user_pages_fast()
            lock_page()
            compound_head()
            PageSwapCache()
            unlock_page()
            put_page()
            PageAnon()
            basepage_index()
        unlikely()
        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
            jhash2()
        hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
            atomic_read()
        spin_lock()
        plist_for_each_entry_safe()
        match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
        mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
            WARN()
            wake_q_add()
            smp_wmb()
        spin_unlock()
        wake_up_q()
        put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                WARN_ON_ONCE()
                iput()
                mmdrop()
    futex_requeue() <int futex_requeue (u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2, int nr_wake, int nr_requeue, u32 *cmpval, int requeue_pi) at futex.c:1571>:
        WAKE_Q()
        refill_pi_state_cache() <int refill_pi_state_cache (void) at futex.c:659>:
            likely()
            kzalloc()
            INIT_LIST_HEAD()
            atomic_set()
        get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
            unlikely()
            access_ok()
            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                should_fail()
            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                ihold()
                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                    atomic_inc()
                    smp_mb__after_atomic()
                smp_mb()
            get_user_pages_fast()
            lock_page()
            compound_head()
            PageSwapCache()
            unlock_page()
            put_page()
            PageAnon()
            basepage_index()
        unlikely()
        match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
            jhash2()
        hb_waiters_inc() <inline void hb_waiters_inc (struct futex_hash_bucket *hb) at futex.c:345>:
            atomic_inc()
            smp_mb__after_atomic()
        double_lock_hb() <inline void double_lock_hb (struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2) at futex.c:1257>:
            spin_lock()
            spin_lock_nested()
        likely()
        get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
            pagefault_disable()
            pagefault_enable()
        double_unlock_hb() <inline void double_unlock_hb (struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2) at futex.c:1270>:
            spin_unlock()
        hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
            atomic_dec()
        get_user()
        put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                WARN_ON_ONCE()
                iput()
                mmdrop()
        futex_proxy_trylock_atomic() <int futex_proxy_trylock_atomic (u32 __user *pifutex, struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2, union futex_key *key1, union futex_key *key2, struct futex_pi_state **ps, int set_waiters) at futex.c:1504>:
            get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                pagefault_disable()
                pagefault_enable()
            unlikely()
            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                should_fail()
            futex_top_waiter() <struct futex_q *futex_top_waiter (struct futex_hash_bucket *hb, union futex_key *key) at futex.c:620>:
                plist_for_each_entry()
                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            task_pid_vnr()
            futex_lock_pi_atomic() <int futex_lock_pi_atomic (u32 __user *uaddr, struct futex_hash_bucket *hb, union futex_key *key, struct futex_pi_state **ps, struct task_struct *task, int set_waiters) at futex.c:1050>:
                task_pid_vnr()
                get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                    pagefault_disable()
                    pagefault_enable()
                unlikely()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                futex_top_waiter() <struct futex_q *futex_top_waiter (struct futex_hash_bucket *hb, union futex_key *key) at futex.c:620>:
                    plist_for_each_entry()
                    match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                attach_to_pi_state() <int attach_to_pi_state (u32 uval, struct futex_pi_state *pi_state, struct futex_pi_state **ps) at futex.c:860>:
                    unlikely()
                    WARN_ON()
                    atomic_read()
                    task_pid_vnr()
                    atomic_inc()
                lock_pi_update_atomic() <int lock_pi_update_atomic (u32 __user *uaddr, u32 uval, u32 newval) at futex.c:1018>:
                    uninitialized_var()
                    unlikely()
                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                        should_fail()
                    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                        pagefault_disable()
                        futex_atomic_cmpxchg_inatomic()
                        pagefault_enable()
                attach_to_pi_owner() <int attach_to_pi_owner (u32 uval, union futex_key *key, struct futex_pi_state **ps) at futex.c:931>:
                    futex_find_get_task() <struct task_struct *futex_find_get_task (pid_t pid) at futex.c:736>:
                        rcu_read_lock()
                        find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
                            find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                                RCU_LOCKDEP_WARN()
                                rcu_read_lock_held()
                                pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                                    rcu_dereference_check()
                                    hlist_first_rcu()
                                    lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                                        lockdep_is_held()
                                    hlist_entry()
                                find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                                    hlist_for_each_entry_rcu()
                                    pid_hashfn()
                                    container_of()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                        get_task_struct()
                        rcu_read_unlock()
                    unlikely()
                    put_task_struct()
                    raw_spin_lock_irq()
                    raw_spin_unlock_irq()
                    alloc_pi_state() <struct futex_pi_state *alloc_pi_state (void) at futex.c:682>:
                        WARN_ON()
                    rt_mutex_init_proxy_locked()
                    WARN_ON()
                    list_empty()
                    list_add()
            requeue_pi_wake_futex() <inline void requeue_pi_wake_futex (struct futex_q *q, union futex_key *key, struct futex_hash_bucket *hb) at futex.c:1468>:
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                WARN_ON()
                wake_up_state()
        WARN_ON()
        lookup_pi_state() <int lookup_pi_state (u32 uval, struct futex_hash_bucket *hb, union futex_key *key, struct futex_pi_state **ps) at futex.c:999>:
            futex_top_waiter() <struct futex_q *futex_top_waiter (struct futex_hash_bucket *hb, union futex_key *key) at futex.c:620>:
                plist_for_each_entry()
                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            attach_to_pi_state() <int attach_to_pi_state (u32 uval, struct futex_pi_state *pi_state, struct futex_pi_state **ps) at futex.c:860>:
                unlikely()
                WARN_ON()
                atomic_read()
                task_pid_vnr()
                atomic_inc()
            attach_to_pi_owner() <int attach_to_pi_owner (u32 uval, union futex_key *key, struct futex_pi_state **ps) at futex.c:931>:
                futex_find_get_task() <struct task_struct *futex_find_get_task (pid_t pid) at futex.c:736>:
                    rcu_read_lock()
                    find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
                        find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                            RCU_LOCKDEP_WARN()
                            rcu_read_lock_held()
                            pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                                rcu_dereference_check()
                                hlist_first_rcu()
                                lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                                    lockdep_is_held()
                                hlist_entry()
                            find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                                hlist_for_each_entry_rcu()
                                pid_hashfn()
                                container_of()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                    get_task_struct()
                    rcu_read_unlock()
                unlikely()
                put_task_struct()
                raw_spin_lock_irq()
                raw_spin_unlock_irq()
                alloc_pi_state() <struct futex_pi_state *alloc_pi_state (void) at futex.c:682>:
                    WARN_ON()
                rt_mutex_init_proxy_locked()
                WARN_ON()
                list_empty()
                list_add()
        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
            down_read()
            fixup_user_fault()
            up_read()
        cond_resched()
        plist_for_each_entry_safe()
        mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
            WARN()
            wake_q_add()
            smp_wmb()
        atomic_inc()
        rt_mutex_start_proxy_lock()
        requeue_pi_wake_futex() <inline void requeue_pi_wake_futex (struct futex_q *q, union futex_key *key, struct futex_hash_bucket *hb) at futex.c:1468>:
            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                ihold()
                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                    atomic_inc()
                    smp_mb__after_atomic()
                smp_mb()
            WARN_ON()
            wake_up_state()
        put_pi_state() <void put_pi_state (struct futex_pi_state *pi_state) at futex.c:698>:
            atomic_dec_and_test()
            raw_spin_lock_irq()
            list_del_init()
            raw_spin_unlock_irq()
            rt_mutex_proxy_unlock()
            kfree()
            atomic_set()
        requeue_futex() <inline void requeue_futex (struct futex_q *q, struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2, union futex_key *key2) at futex.c:1434>:
            likely()
            plist_del()
            hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                atomic_dec()
            plist_add()
            hb_waiters_inc() <inline void hb_waiters_inc (struct futex_hash_bucket *hb) at futex.c:345>:
                atomic_inc()
                smp_mb__after_atomic()
            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                ihold()
                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                    atomic_inc()
                    smp_mb__after_atomic()
                smp_mb()
        wake_up_q()
        drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
            WARN_ON_ONCE()
            iput()
            mmdrop()
    futex_wake_op() <int futex_wake_op (u32 __user *uaddr1, unsigned int flags, u32 __user *uaddr2, int nr_wake, int nr_wake2, int op) at futex.c:1334>:
        WAKE_Q()
        get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
            unlikely()
            access_ok()
            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                should_fail()
            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                ihold()
                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                    atomic_inc()
                    smp_mb__after_atomic()
                smp_mb()
            get_user_pages_fast()
            lock_page()
            compound_head()
            PageSwapCache()
            unlock_page()
            put_page()
            PageAnon()
            basepage_index()
        unlikely()
        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
            jhash2()
        double_lock_hb() <inline void double_lock_hb (struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2) at futex.c:1257>:
            spin_lock()
            spin_lock_nested()
        futex_atomic_op_inuser()
        double_unlock_hb() <inline void double_unlock_hb (struct futex_hash_bucket *hb1, struct futex_hash_bucket *hb2) at futex.c:1270>:
            spin_unlock()
        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
            down_read()
            fixup_user_fault()
            up_read()
        put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                WARN_ON_ONCE()
                iput()
                mmdrop()
        plist_for_each_entry_safe()
        match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
        mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
            WARN()
            wake_q_add()
            smp_wmb()
        wake_up_q()
    futex_lock_pi() <int futex_lock_pi (u32 __user *uaddr, unsigned int flags, ktime_t *time, int trylock) at futex.c:2367>:
        refill_pi_state_cache() <int refill_pi_state_cache (void) at futex.c:659>:
            likely()
            kzalloc()
            INIT_LIST_HEAD()
            atomic_set()
        hrtimer_init_on_stack()
        hrtimer_init_sleeper()
        hrtimer_set_expires()
        get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
            unlikely()
            access_ok()
            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                should_fail()
            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                ihold()
                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                    atomic_inc()
                    smp_mb__after_atomic()
                smp_mb()
            get_user_pages_fast()
            lock_page()
            compound_head()
            PageSwapCache()
            unlock_page()
            put_page()
            PageAnon()
            basepage_index()
        unlikely()
        queue_lock() <inline struct futex_hash_bucket *queue_lock (struct futex_q *q) at futex.c:1848>:
            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                jhash2()
            hb_waiters_inc() <inline void hb_waiters_inc (struct futex_hash_bucket *hb) at futex.c:345>:
                atomic_inc()
                smp_mb__after_atomic()
            spin_lock()
        futex_lock_pi_atomic() <int futex_lock_pi_atomic (u32 __user *uaddr, struct futex_hash_bucket *hb, union futex_key *key, struct futex_pi_state **ps, struct task_struct *task, int set_waiters) at futex.c:1050>:
            task_pid_vnr()
            get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                pagefault_disable()
                pagefault_enable()
            unlikely()
            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                should_fail()
            futex_top_waiter() <struct futex_q *futex_top_waiter (struct futex_hash_bucket *hb, union futex_key *key) at futex.c:620>:
                plist_for_each_entry()
                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            attach_to_pi_state() <int attach_to_pi_state (u32 uval, struct futex_pi_state *pi_state, struct futex_pi_state **ps) at futex.c:860>:
                unlikely()
                WARN_ON()
                atomic_read()
                task_pid_vnr()
                atomic_inc()
            lock_pi_update_atomic() <int lock_pi_update_atomic (u32 __user *uaddr, u32 uval, u32 newval) at futex.c:1018>:
                uninitialized_var()
                unlikely()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                    pagefault_disable()
                    futex_atomic_cmpxchg_inatomic()
                    pagefault_enable()
            attach_to_pi_owner() <int attach_to_pi_owner (u32 uval, union futex_key *key, struct futex_pi_state **ps) at futex.c:931>:
                futex_find_get_task() <struct task_struct *futex_find_get_task (pid_t pid) at futex.c:736>:
                    rcu_read_lock()
                    find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
                        find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
                            RCU_LOCKDEP_WARN()
                            rcu_read_lock_held()
                            pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
                                rcu_dereference_check()
                                hlist_first_rcu()
                                lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                                    lockdep_is_held()
                                hlist_entry()
                            find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
                                hlist_for_each_entry_rcu()
                                pid_hashfn()
                                container_of()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                    get_task_struct()
                    rcu_read_unlock()
                unlikely()
                put_task_struct()
                raw_spin_lock_irq()
                raw_spin_unlock_irq()
                alloc_pi_state() <struct futex_pi_state *alloc_pi_state (void) at futex.c:682>:
                    WARN_ON()
                rt_mutex_init_proxy_locked()
                WARN_ON()
                list_empty()
                list_add()
        queue_unlock() <inline void queue_unlock (struct futex_hash_bucket *hb) at futex.c:1872>:
            spin_unlock()
            hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                atomic_dec()
        put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                WARN_ON_ONCE()
                iput()
                mmdrop()
        cond_resched()
        queue_me() <inline void queue_me (struct futex_q *q, struct futex_hash_bucket *hb) at futex.c:1891>:
            min()
            plist_node_init()
            plist_add()
            spin_unlock()
        WARN_ON()
        rt_mutex_timed_futex_lock()
        rt_mutex_trylock()
        spin_lock()
        fixup_owner() <int fixup_owner (u32 __user *uaddr, struct futex_q *q, int locked) at futex.c:2095>:
            fixup_pi_state_owner() <int fixup_pi_state_owner (u32 __user *uaddr, struct futex_q *q, struct task_struct *newowner) at futex.c:1986>:
                task_pid_vnr()
                uninitialized_var()
                get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                    pagefault_disable()
                    pagefault_enable()
                cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                    pagefault_disable()
                    futex_atomic_cmpxchg_inatomic()
                    pagefault_enable()
                raw_spin_lock_irq()
                WARN_ON()
                list_empty()
                list_del_init()
                raw_spin_unlock_irq()
                list_add()
                spin_unlock()
                fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                    down_read()
                    fixup_user_fault()
                    up_read()
                spin_lock()
            rt_mutex_trylock()
            raw_spin_lock_irq()
            rt_mutex_owner()
            rt_mutex_next_owner()
            raw_spin_unlock_irq()
            printk()
        rt_mutex_owner()
        rt_mutex_unlock()
        unqueue_me_pi() < at futex.c:1968>:
            BUG_ON()
            put_pi_state() <void put_pi_state (struct futex_pi_state *pi_state) at futex.c:698>:
                atomic_dec_and_test()
                raw_spin_lock_irq()
                list_del_init()
                raw_spin_unlock_irq()
                rt_mutex_proxy_unlock()
                kfree()
                atomic_set()
            spin_unlock()
        destroy_hrtimer_on_stack()
        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
            down_read()
            fixup_user_fault()
            up_read()
    futex_unlock_pi() <int futex_unlock_pi (u32 __user *uaddr, unsigned int flags) at futex.c:2494>:
        uninitialized_var()
        task_pid_vnr()
        get_user()
        get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
            unlikely()
            access_ok()
            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                should_fail()
            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                ihold()
                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                    atomic_inc()
                    smp_mb__after_atomic()
                smp_mb()
            get_user_pages_fast()
            lock_page()
            compound_head()
            PageSwapCache()
            unlock_page()
            put_page()
            PageAnon()
            basepage_index()
        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
            jhash2()
        spin_lock()
        futex_top_waiter() <struct futex_q *futex_top_waiter (struct futex_hash_bucket *hb, union futex_key *key) at futex.c:620>:
            plist_for_each_entry()
            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
        wake_futex_pi() <int wake_futex_pi (u32 __user *uaddr, u32 uval, struct futex_q *this, struct futex_hash_bucket *hb) at futex.c:1174>:
            uninitialized_var()
            WAKE_Q()
            raw_spin_lock_irq()
            rt_mutex_next_owner()
            task_pid_vnr()
            unlikely()
            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                should_fail()
            cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                pagefault_disable()
                futex_atomic_cmpxchg_inatomic()
                pagefault_enable()
            raw_spin_unlock_irq()
            raw_spin_lock()
            WARN_ON()
            list_empty()
            list_del_init()
            raw_spin_unlock()
            list_add()
            rt_mutex_futex_unlock()
            spin_unlock()
            wake_up_q()
            rt_mutex_adjust_prio()
        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
            pagefault_disable()
            futex_atomic_cmpxchg_inatomic()
            pagefault_enable()
        spin_unlock()
        put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                WARN_ON_ONCE()
                iput()
                mmdrop()
        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
            down_read()
            fixup_user_fault()
            up_read()
    futex_wait_requeue_pi() <int futex_wait_requeue_pi (u32 __user *uaddr, unsigned int flags, u32 val, ktime_t *abs_time, u32 bitset, u32 __user *uaddr2) at futex.c:2666>:
        hrtimer_init_on_stack()
        hrtimer_init_sleeper()
        hrtimer_set_expires_range_ns()
        debug_rt_mutex_init_waiter()
        RB_CLEAR_NODE()
        get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
            unlikely()
            access_ok()
            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                should_fail()
            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                ihold()
                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                    atomic_inc()
                    smp_mb__after_atomic()
                smp_mb()
            get_user_pages_fast()
            lock_page()
            compound_head()
            PageSwapCache()
            unlock_page()
            put_page()
            PageAnon()
            basepage_index()
        unlikely()
        futex_wait_setup() <int futex_wait_setup (u32 __user *uaddr, u32 val, unsigned int flags, struct futex_q *q, struct futex_hash_bucket **hb) at futex.c:2208>:
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            unlikely()
            queue_lock() <inline struct futex_hash_bucket *queue_lock (struct futex_q *q) at futex.c:1848>:
                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                    jhash2()
                hb_waiters_inc() <inline void hb_waiters_inc (struct futex_hash_bucket *hb) at futex.c:345>:
                    atomic_inc()
                    smp_mb__after_atomic()
                spin_lock()
            get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                pagefault_disable()
                pagefault_enable()
            queue_unlock() <inline void queue_unlock (struct futex_hash_bucket *hb) at futex.c:1872>:
                spin_unlock()
                hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                    atomic_dec()
            get_user()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
        match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
        queue_unlock() <inline void queue_unlock (struct futex_hash_bucket *hb) at futex.c:1872>:
            spin_unlock()
            hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                atomic_dec()
        futex_wait_queue_me() <void futex_wait_queue_me (struct futex_hash_bucket *hb, struct futex_q *q, struct hrtimer_sleeper *timeout) at futex.c:2159>:
            set_current_state()
            queue_me() <inline void queue_me (struct futex_q *q, struct futex_hash_bucket *hb) at futex.c:1891>:
                min()
                plist_node_init()
                plist_add()
                spin_unlock()
            hrtimer_start_expires()
            likely()
            plist_node_empty()
            freezable_schedule()
        spin_lock()
        handle_early_requeue_pi_wakeup() <inline int handle_early_requeue_pi_wakeup (struct futex_hash_bucket *hb, struct futex_q *q, union futex_key *key2, struct hrtimer_sleeper *timeout) at futex.c:2594>:
            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            WARN_ON()
            plist_del()
            hb_waiters_dec() <inline void hb_waiters_dec (struct futex_hash_bucket *hb) at futex.c:360>:
                atomic_dec()
            signal_pending()
        spin_unlock()
        fixup_pi_state_owner() <int fixup_pi_state_owner (u32 __user *uaddr, struct futex_q *q, struct task_struct *newowner) at futex.c:1986>:
            task_pid_vnr()
            uninitialized_var()
            get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                pagefault_disable()
                pagefault_enable()
            cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                pagefault_disable()
                futex_atomic_cmpxchg_inatomic()
                pagefault_enable()
            raw_spin_lock_irq()
            WARN_ON()
            list_empty()
            list_del_init()
            raw_spin_unlock_irq()
            list_add()
            spin_unlock()
            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                down_read()
                fixup_user_fault()
                up_read()
            spin_lock()
        put_pi_state() <void put_pi_state (struct futex_pi_state *pi_state) at futex.c:698>:
            atomic_dec_and_test()
            raw_spin_lock_irq()
            list_del_init()
            raw_spin_unlock_irq()
            rt_mutex_proxy_unlock()
            kfree()
            atomic_set()
        WARN_ON()
        rt_mutex_finish_proxy_lock()
        debug_rt_mutex_free_waiter()
        fixup_owner() <int fixup_owner (u32 __user *uaddr, struct futex_q *q, int locked) at futex.c:2095>:
            fixup_pi_state_owner() <int fixup_pi_state_owner (u32 __user *uaddr, struct futex_q *q, struct task_struct *newowner) at futex.c:1986>:
                task_pid_vnr()
                uninitialized_var()
                get_futex_value_locked() <int get_futex_value_locked (u32 *dest, u32 __user *from) at futex.c:644>:
                    pagefault_disable()
                    pagefault_enable()
                cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                    pagefault_disable()
                    futex_atomic_cmpxchg_inatomic()
                    pagefault_enable()
                raw_spin_lock_irq()
                WARN_ON()
                list_empty()
                list_del_init()
                raw_spin_unlock_irq()
                list_add()
                spin_unlock()
                fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                    down_read()
                    fixup_user_fault()
                    up_read()
                spin_lock()
            rt_mutex_trylock()
            raw_spin_lock_irq()
            rt_mutex_owner()
            rt_mutex_next_owner()
            raw_spin_unlock_irq()
            printk()
        unqueue_me_pi() < at futex.c:1968>:
            BUG_ON()
            put_pi_state() <void put_pi_state (struct futex_pi_state *pi_state) at futex.c:698>:
                atomic_dec_and_test()
                raw_spin_lock_irq()
                list_del_init()
                raw_spin_unlock_irq()
                rt_mutex_proxy_unlock()
                kfree()
                atomic_set()
            spin_unlock()
        rt_mutex_owner()
        rt_mutex_unlock()
        put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                WARN_ON_ONCE()
                iput()
                mmdrop()
        hrtimer_cancel()
        destroy_hrtimer_on_stack()
do_group_exit() <void do_group_exit (int exit_code) at exit.c:853>:
    BUG_ON()
    signal_group_exit()
    thread_group_empty()
    spin_lock_irq()
    zap_other_threads() <int zap_other_threads (struct task_struct *p) at signal.c:1188>:
        while_each_thread()
        task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
            BUG_ON()
            task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                unlikely()
                smp_mb()
                wake_up_bit()
        signal_wake_up()
    spin_unlock_irq()
    do_exit() <void do_exit (long code) at exit.c:651>:
        TASKS_RCU()
        profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
            blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
        WARN_ON()
        blk_needs_flush_plug()
        unlikely()
        in_interrupt()
        panic() <void panic (const char *fmt, ...) at panic.c:83>:
            local_irq_disable()
            raw_smp_processor_id()
            atomic_cmpxchg()
            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                cpu_relax()
            console_verbose()
            bust_spinlocks()
            pr_emerg()
            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                test_bit()
            dump_stack()
            smp_send_stop()
            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
            kmsg_dump()
            debug_locks_off()
            console_flush_on_panic()
            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
            no_blink() <long no_blink (int state) at panic.c:46>
            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                raw_cpu_write()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            mdelay()
            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                kmsg_dump()
                machine_emergency_restart()
            disabled_wait()
            local_irq_enable()
            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                    raw_cpu_write()
                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                    per_cpu()
                raw_smp_processor_id()
        set_fs()
        ptrace_event()
        validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
        pr_alert()
        set_current_state()
        schedule()
        exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
            threadgroup_change_begin()
            thread_group_empty()
            signal_group_exit()
            threadgroup_change_end()
            spin_lock_irq()
            signal_pending()
            signotset()
            retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                sigandsets()
                sigisemptyset()
                while_each_thread()
                has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                signal_pending()
                signal_wake_up()
            unlikely()
            task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                WARN_ON_ONCE()
                task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                    BUG_ON()
                    task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                        unlikely()
                        smp_mb()
                        wake_up_bit()
            spin_unlock_irq()
            read_lock()
            do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                BUG()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
            read_unlock()
        smp_mb()
        raw_spin_unlock_wait()
        in_atomic()
        pr_info()
        task_pid_nr()
        preempt_count()
        preempt_count_set()
        sync_mm_rss()
        acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
            task_cputime()
        atomic_dec_and_test()
        hrtimer_cancel()
        exit_itimers()
        setmax_mm_hiwater_rss()
        acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
            down_read()
            up_read()
            spin_lock_irq()
            thread_group_leader()
            task_cputime()
            spin_unlock_irq()
        tty_audit_exit()
        audit_free()
        taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
            taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                nla_total_size()
            taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                thread_group_empty()
                kmem_cache_zalloc()
                spin_lock_irq()
                spin_unlock_irq()
                kmem_cache_free()
            fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                spin_lock_irqsave()
                delayacct_add_tsk()
                spin_unlock_irqrestore()
            raw_cpu_ptr()
            list_empty()
            prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                genlmsg_new()
                this_cpu_inc_return()
                genlmsg_put()
                genlmsg_put_reply()
                nlmsg_free()
            mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                nla_put()
                nla_nest_start()
                nla_nest_cancel()
                nla_reserve()
                nla_nest_end()
                nla_data()
            task_pid_nr_ns()
            fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                delayacct_add_tsk()
                bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                    BUILD_BUG_ON()
                    ktime_get_ns()
                    do_div()
                    get_seconds()
                    thread_group_leader()
                    task_nice()
                    task_pid_nr_ns()
                    rcu_read_lock()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    pid_alive()
                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                        task_tgid()
                    rcu_dereference()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_usecs()
                    task_cputime_scaled()
                xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                    get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                        task_lock()
                        atomic_inc()
                        task_unlock()
                    get_mm_hiwater_rss()
                    get_mm_hiwater_vm()
                    mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                        might_sleep()
                        atomic_dec_and_test()
                        uprobe_clear_state()
                        exit_aio()
                        ksm_exit()
                        khugepaged_exit()
                        exit_mmap()
                        set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                            rcu_dereference_raw()
                            get_file()
                            rcu_assign_pointer()
                            fput()
                        list_empty()
                        spin_lock()
                        list_del()
                        spin_unlock()
                        module_put() <void module_put (struct module *module) at module.c:1098>:
                            preempt_disable()
                            atomic_dec_if_positive()
                            WARN_ON()
                            trace_module_put()
                            preempt_enable()
                        mmdrop()
            task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                task_tgid()
            send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                nlmsg_data()
                nlmsg_hdr()
                genlmsg_data()
                genlmsg_end()
                down_read()
                list_for_each_entry()
                list_is_last()
                skb_clone()
                genlmsg_unicast()
                up_read()
                nlmsg_free()
                down_write()
                list_for_each_entry_safe()
                list_del()
                kfree()
                up_write()
            nlmsg_free()
        exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
            mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                unlikely()
                exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                    uninitialized_var()
                    fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                        get_user()
                    get_user()
                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                        uninitialized_var()
                        get_user()
                        task_pid_vnr()
                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                            pagefault_disable()
                            futex_atomic_cmpxchg_inatomic()
                            pagefault_enable()
                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                            down_read()
                            fixup_user_fault()
                            up_read()
                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                            WAKE_Q()
                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                unlikely()
                                access_ok()
                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                    should_fail()
                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                    ihold()
                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                        atomic_inc()
                                        smp_mb__after_atomic()
                                    smp_mb()
                                get_user_pages_fast()
                                lock_page()
                                compound_head()
                                PageSwapCache()
                                unlock_page()
                                put_page()
                                PageAnon()
                                basepage_index()
                            unlikely()
                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                jhash2()
                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                atomic_read()
                            spin_lock()
                            plist_for_each_entry_safe()
                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                WARN()
                                wake_q_add()
                                smp_wmb()
                            spin_unlock()
                            wake_up_q()
                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                    WARN_ON_ONCE()
                                    iput()
                                    mmdrop()
                    cond_resched()
                compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                    uninitialized_var()
                    fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                        get_user()
                        compat_ptr()
                    get_user()
                    futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                        ptr_to_compat()
                        compat_ptr()
                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                        uninitialized_var()
                        get_user()
                        task_pid_vnr()
                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                            pagefault_disable()
                            futex_atomic_cmpxchg_inatomic()
                            pagefault_enable()
                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                            down_read()
                            fixup_user_fault()
                            up_read()
                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                            WAKE_Q()
                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                unlikely()
                                access_ok()
                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                    should_fail()
                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                    ihold()
                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                        atomic_inc()
                                        smp_mb__after_atomic()
                                    smp_mb()
                                get_user_pages_fast()
                                lock_page()
                                compound_head()
                                PageSwapCache()
                                unlock_page()
                                put_page()
                                PageAnon()
                                basepage_index()
                            unlikely()
                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                jhash2()
                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                atomic_read()
                            spin_lock()
                            plist_for_each_entry_safe()
                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                WARN()
                                wake_q_add()
                                smp_wmb()
                            spin_unlock()
                            wake_up_q()
                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                    WARN_ON_ONCE()
                                    iput()
                                    mmdrop()
                    cond_resched()
                list_empty()
                exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                    raw_spin_lock_irq()
                    list_empty()
                    list_entry()
                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                        jhash2()
                    raw_spin_unlock_irq()
                    spin_lock()
                    spin_unlock()
                    WARN_ON()
                    list_del_init()
                    rt_mutex_unlock()
                uprobe_free_utask()
                deactivate_mm()
                atomic_read()
                put_user()
                sys_futex()
                complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                    task_lock()
                    likely()
                    complete()
                    task_unlock()
            sync_mm_rss()
            down_read()
            up_read()
            xchg()
            atomic_dec_and_test()
            complete()
            set_task_state()
            freezable_schedule()
            atomic_inc()
            BUG_ON()
            task_lock()
            enter_lazy_tlb()
            task_unlock()
            mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                atomic_read()
                read_lock()
                list_for_each_entry()
                for_each_process()
                for_each_thread()
                read_unlock()
                BUG_ON()
                get_task_struct()
                task_lock()
                task_unlock()
                put_task_struct()
            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                might_sleep()
                atomic_dec_and_test()
                uprobe_clear_state()
                exit_aio()
                ksm_exit()
                khugepaged_exit()
                exit_mmap()
                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                    rcu_dereference_raw()
                    get_file()
                    rcu_assign_pointer()
                    fput()
                list_empty()
                spin_lock()
                list_del()
                spin_unlock()
                module_put() <void module_put (struct module *module) at module.c:1098>:
                    preempt_disable()
                    atomic_dec_if_positive()
                    WARN_ON()
                    trace_module_put()
                    preempt_enable()
                mmdrop()
            test_thread_flag()
            exit_oom_victim()
        acct_process() <void acct_process (void) at acct.c:587>:
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
            unlikely()
            slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                    smp_rmb()
                    rcu_read_lock()
                    to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                        container_of()
                    ACCESS_ONCE()
                    rcu_read_unlock()
                    atomic_long_inc_not_zero()
                    cpu_relax()
                    mutex_lock()
                    mutex_unlock()
                    acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                        atomic_long_dec_and_test()
                        kfree_rcu()
                do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                    override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        validate_creds()
                        get_cred()
                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                            atomic_add()
                        rcu_assign_pointer()
                    check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                        time_is_before_jiffies()
                        vfs_statfs()
                        do_div()
                        pr_info()
                    fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                        strlcpy()
                        ktime_get_ns()
                        nsec_to_AHZ()
                        encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                        encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                        encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                        do_div()
                        get_seconds()
                        spin_lock_irq()
                        old_encode_dev()
                        tty_devnum()
                        jiffies_to_AHZ()
                        cputime_to_jiffies()
                        spin_unlock_irq()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                        task_tgid()
                    rcu_read_lock()
                    rcu_dereference()
                    rcu_read_unlock()
                    file_start_write_trylock()
                    file_end_write()
                    revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        validate_creds()
                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                            atomic_add()
                        rcu_assign_pointer()
                        put_cred()
                mutex_unlock()
                acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                    atomic_long_dec_and_test()
                    kfree_rcu()
        trace_sched_process_exit()
        exit_sem()
        exit_shm()
        exit_files()
        exit_fs()
        disassociate_ctty()
        exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
            switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                might_sleep()
                task_lock()
                task_unlock()
                atomic_dec_and_test()
                free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                    put_mnt_ns()
                    put_uts_ns()
                    put_ipc_ns()
                    put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                        kref_put()
                        free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                            container_of()
                            destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                ns_free_inum()
                                kfree()
                                put_user_ns()
                                call_rcu()
                                delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                    kmem_cache_free()
                                    container_of()
                    put_net()
                    kmem_cache_free()
        exit_task_work()
        exit_thread()
        perf_event_exit_task()
        cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
            task_css_set()
            list_empty()
            spin_lock_bh()
            css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                lockdep_assert_held()
                WARN_ON_ONCE()
                list_empty()
                list_for_each_entry_safe()
                css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                    lockdep_assert_held()
                    WARN_ON_ONCE()
                    css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                        lockdep_assert_held()
                        container_of()
                        list_entry()
                        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                            lockdep_assert_held()
                            list_empty()
                        list_empty()
                        list_del()
                        put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                            lockdep_assert_held()
                            atomic_dec_and_test()
                            for_each_subsys()
                            list_del()
                            css_put()
                            hash_del()
                            list_for_each_entry_safe()
                            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                container_of()
                            cgroup_put()
                            kfree()
                            kfree_rcu()
                        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                            atomic_inc()
                        list_add()
                list_del_init()
                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                    lockdep_assert_held()
                    list_empty()
                css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                    lockdep_assert_held()
                    list_for_each_entry()
                    cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                        lockdep_assert_held()
                        check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                            notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                test_bit()
                            cgroup_is_populated()
                            css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                rcu_read_lock()
                                css_for_each_child()
                                rcu_read_unlock()
                            cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                            schedule_work()
                        cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                            spin_lock_irqsave()
                            kernfs_notify()
                            spin_unlock_irqrestore()
                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                            container_of()
                rcu_assign_pointer()
                list_add_tail()
            spin_unlock_bh()
            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                atomic_inc()
            for_each_subsys_which()
        flush_ptrace_hw_breakpoint()
        preempt_disable()
        preempt_enable()
        exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
            LIST_HEAD()
            write_lock_irq()
            forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                unlikely()
                list_empty()
                exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                    list_for_each_entry_safe()
                    unlikely()
                    send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                        valid_signal()
                        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                            lock_task_sighand()
                            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                    SI_FROMUSER()
                                task_pid_nr_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                            unlock_task_sighand()
                    list_add()
                find_child_reaper()
                find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                    find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                        for_each_thread()
                    same_thread_group()
                list_for_each_entry()
                for_each_thread()
                BUG_ON()
                likely()
                group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                    rcu_read_lock()
                    check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                        valid_signal()
                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                            SI_FROMUSER()
                        audit_signal_info()
                        same_thread_group()
                        kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                            current_cred()
                            uid_eq()
                            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                unlikely()
                                cap_valid()
                                pr_crit()
                                BUG()
                                security_capable()
                                current_cred()
                        task_session()
                        security_task_kill()
                    rcu_read_unlock()
                    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                        lock_task_sighand()
                        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                SI_FROMUSER()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                        unlock_task_sighand()
                same_thread_group()
                reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                    unlikely()
                    thread_group_empty()
                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                        BUG_ON()
                        task_is_stopped_or_traced()
                        thread_group_empty()
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        spin_lock_irqsave()
                        valid_signal()
                        spin_unlock_irqrestore()
                    list_add()
                    kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                        task_pgrp()
                        task_session()
                        will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                            do_each_pid_task()
                            thread_group_empty()
                            is_global_init()
                            task_pgrp()
                            task_session()
                            while_each_pid_task()
                        has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                            do_each_pid_task()
                            while_each_pid_task()
                list_splice_tail_init()
            kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                task_pgrp()
                task_session()
                will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                    do_each_pid_task()
                    thread_group_empty()
                    is_global_init()
                    task_pgrp()
                    task_session()
                    while_each_pid_task()
                has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                    do_each_pid_task()
                    while_each_pid_task()
            unlikely()
            thread_group_leader()
            thread_group_empty()
            ptrace_reparented()
            do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                BUG_ON()
                task_is_stopped_or_traced()
                thread_group_empty()
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                spin_lock_irqsave()
                valid_signal()
                spin_unlock_irqrestore()
            list_add()
            wake_up_process()
            write_unlock_irq()
            list_for_each_entry_safe()
            list_del_init()
            release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                rcu_read_lock()
                atomic_dec()
                rcu_read_unlock()
                proc_flush_task()
                write_lock_irq()
                ptrace_release_task()
                thread_group_empty()
                do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                    BUG_ON()
                    task_is_stopped_or_traced()
                    thread_group_empty()
                    rcu_read_lock()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_cred_xxx()
                    task_uid()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_clock_t()
                    spin_lock_irqsave()
                    valid_signal()
                    spin_unlock_irqrestore()
                write_unlock_irq()
                release_thread()
                call_rcu()
                delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                    container_of()
                    perf_event_delayed_put()
                    trace_sched_process_free()
                    put_task_struct()
                unlikely()
        proc_exit_connector()
        task_lock()
        mpol_put()
        task_unlock()
        kfree()
        debug_check_no_locks_held()
        exit_io_context()
        free_pipe_info()
        put_page()
        check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
            stack_not_used()
            spin_lock()
            pr_warn()
            task_pid_nr()
            spin_unlock()
        exit_rcu()
        BUG()
        cpu_relax()
do_kernel_restart() <void do_kernel_restart (char *cmd) at reboot.c:183>:
    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
do_kimage_alloc_init() <struct kimage *do_kimage_alloc_init (void) at kexec_core.c:237>:
    kzalloc()
    INIT_LIST_HEAD()
do_no_restart_syscall() <long do_no_restart_syscall (struct restart_block *param) at signal.c:2454>:
do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
    BUG_ON()
    task_is_stopped_or_traced()
    thread_group_empty()
    rcu_read_lock()
    task_pid_nr_ns()
    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
        ns_of_pid()
        task_pid()
    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                smp_rmb()
    task_cred_xxx()
    task_uid()
    rcu_read_unlock()
    task_cputime()
    cputime_to_clock_t()
    spin_lock_irqsave()
    valid_signal()
    spin_unlock_irqrestore()
do_prlimit() <int do_prlimit (struct task_struct *tsk, unsigned int resource, struct rlimit *new_rlim, struct rlimit *old_rlim) at sys.c:1360>:
    read_lock()
    task_lock()
    capable() <bool capable (int cap) at capability.c:401>:
        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
            unlikely()
            cap_valid()
            pr_crit()
            BUG()
            security_capable()
            current_cred()
    security_task_setrlimit()
    task_unlock()
    update_rlimit_cpu()
    read_unlock()
do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
    lock_task_sighand()
    send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
            SI_FROMUSER()
        task_pid_nr_ns()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
    unlock_task_sighand()
do_sigaction() <int do_sigaction (int sig, struct k_sigaction *act, struct k_sigaction *oact) at signal.c:3047>:
    valid_signal()
    sig_kernel_only()
    spin_lock_irq()
    sigdelsetmask()
    sig_handler_ignored() <int sig_handler_ignored (void __user *handler, int sig) at signal.c:61>:
        sig_kernel_ignore()
    sig_handler() <void __user *sig_handler (struct task_struct *t, int sig) at signal.c:56>:
    flush_sigqueue_mask() <int flush_sigqueue_mask (sigset_t *mask, struct sigpending *s) at signal.c:659>:
        sigandsets()
        sigisemptyset()
        sigandnsets()
        list_for_each_entry_safe()
        list_del_init()
    for_each_thread()
    spin_unlock_irq()
do_sigtimedwait() <int do_sigtimedwait (const sigset_t *which, siginfo_t *info, const struct timespec *ts) at signal.c:2749>:
    timespec_valid()
    timespec_to_jiffies()
    sigdelsetmask()
    signotset()
    spin_lock_irq()
    dequeue_signal() <int dequeue_signal (struct task_struct *tsk, sigset_t *mask, siginfo_t *info) at signal.c:559>:
        unlikely()
        hrtimer_is_queued()
        hrtimer_forward()
        get_time()
        hrtimer_restart()
        recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
            recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                PENDING()
                set_tsk_thread_flag()
            freezing()
            clear_thread_flag()
        sig_kernel_stop()
        spin_unlock()
        do_schedule_next_timer()
        spin_lock()
    sigandsets()
    recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
        recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
            PENDING()
            set_tsk_thread_flag()
        freezing()
        clear_thread_flag()
    spin_unlock_irq()
    freezable_schedule_timeout_interruptible()
do_softirq() <asmlinkage __visible void do_softirq (void) at softirq.c:304>:
    in_interrupt()
    local_irq_save()
    local_softirq_pending()
    do_softirq_own_stack()
    local_irq_restore()
do_sys_times() <void do_sys_times (struct tms *tms) at sys.c:882>:
    thread_group_cputime_adjusted()
    cputime_to_clock_t()
drain_workqueue() <void drain_workqueue (struct workqueue_struct *wq) at workqueue.c:2735>:
    mutex_lock()
    mutex_unlock()
    flush_workqueue() <void flush_workqueue (struct workqueue_struct *wq) at workqueue.c:2576>:
        LIST_HEAD_INIT()
        COMPLETION_INITIALIZER_ONSTACK()
        lock_map_acquire()
        lock_map_release()
        mutex_lock()
        work_next_color() <int work_next_color (int color) at workqueue.c:613>:
        WARN_ON_ONCE()
        list_empty()
        flush_workqueue_prep_pwqs() <bool flush_workqueue_prep_pwqs (struct workqueue_struct *wq, int flush_color, int work_color) at workqueue.c:2529>:
            WARN_ON_ONCE()
            atomic_read()
            atomic_set()
            for_each_pwq()
            spin_lock_irq()
            atomic_inc()
            work_next_color() <int work_next_color (int color) at workqueue.c:613>:
            spin_unlock_irq()
            atomic_dec_and_test()
            complete()
        list_add_tail()
        check_flush_dependency() <void check_flush_dependency (struct workqueue_struct *target_wq, struct work_struct *target_work) at workqueue.c:2403>:
            current_wq_worker()
            WARN_ONCE()
        mutex_unlock()
        wait_for_completion()
        list_for_each_entry_safe()
        list_del_init()
        complete()
        list_for_each_entry()
        list_splice_tail_init()
    for_each_pwq()
    spin_lock_irq()
    list_empty()
    spin_unlock_irq()
    pr_warn()
dump_kprobe() <void dump_kprobe (struct kprobe *kp) at kprobes.c:2041>:
    printk()
each_symbol_section() <bool each_symbol_section (bool (*fn) (const struct symsearch *arr, struct module *owner, void *data), void *data) at module.c:424>:
    module_assert_mutex_or_preempt() <void module_assert_mutex_or_preempt (void) at module.c:260>:
        unlikely()
        WARN_ON()
        rcu_read_lock_sched_held()
        lockdep_is_held()
    each_symbol_in_section() <bool each_symbol_in_section (const struct symsearch *arr, unsigned int arrsize, struct module *owner, bool (*fn) (const struct symsearch *syms, struct module *owner, void *data), void *data) at module.c:405>:
        fn()
    ARRAY_SIZE()
    fn()
    list_for_each_entry_rcu()
emergency_restart() <void emergency_restart (void) at reboot.c:61>:
    kmsg_dump()
    machine_emergency_restart()
enable_kprobe() <int enable_kprobe (struct kprobe *kp) at kprobes.c:2008>:
    mutex_lock()
    unlikely()
    kprobe_gone()
    kprobe_disabled()
    arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
        unlikely()
        kprobe_ftrace()
        arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
            ftrace_set_filter_ip()
            WARN()
            register_ftrace_function()
        mutex_lock()
        mutex_unlock()
    mutex_unlock()
enable_nonboot_cpus() <void enable_nonboot_cpus (void) at cpu.c:623>:
    cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
        mutex_lock()
    WARN_ON()
    cpumask_empty()
    pr_info()
    arch_enable_nonboot_cpus_begin() <void __weak arch_enable_nonboot_cpus_begin (void) at cpu.c:615>
    for_each_cpu()
    trace_suspend_resume()
    TPS()
    pr_warn()
    arch_enable_nonboot_cpus_end() <void __weak arch_enable_nonboot_cpus_end (void) at cpu.c:619>
    cpumask_clear()
    cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
        mutex_unlock()
execute_in_process_context() <int execute_in_process_context (work_func_t fn, struct execute_work *ew) at workqueue.c:3075>:
    in_interrupt()
    INIT_WORK()
    schedule_work()
exit_creds() <void exit_creds (struct task_struct *tsk) at cred.c:156>:
    kdebug()
    atomic_read()
    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
        atomic_read()
    validate_creds()
    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
        atomic_add()
    put_cred()
exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
    raw_spin_lock_irq()
    list_empty()
    list_entry()
    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
        jhash2()
    raw_spin_unlock_irq()
    spin_lock()
    spin_unlock()
    WARN_ON()
    list_del_init()
    rt_mutex_unlock()
exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
    list_for_each_entry_safe()
    unlikely()
    send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
        valid_signal()
        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
            lock_task_sighand()
            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                    SI_FROMUSER()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
            unlock_task_sighand()
    list_add()
exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
    uninitialized_var()
    fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
        get_user()
    get_user()
    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
        uninitialized_var()
        get_user()
        task_pid_vnr()
        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
            pagefault_disable()
            futex_atomic_cmpxchg_inatomic()
            pagefault_enable()
        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
            down_read()
            fixup_user_fault()
            up_read()
        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
            WAKE_Q()
            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                unlikely()
                access_ok()
                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                    should_fail()
                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                    ihold()
                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                        atomic_inc()
                        smp_mb__after_atomic()
                    smp_mb()
                get_user_pages_fast()
                lock_page()
                compound_head()
                PageSwapCache()
                unlock_page()
                put_page()
                PageAnon()
                basepage_index()
            unlikely()
            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                jhash2()
            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                atomic_read()
            spin_lock()
            plist_for_each_entry_safe()
            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                WARN()
                wake_q_add()
                smp_wmb()
            spin_unlock()
            wake_up_q()
            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                    WARN_ON_ONCE()
                    iput()
                    mmdrop()
    cond_resched()
exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
    threadgroup_change_begin()
    thread_group_empty()
    signal_group_exit()
    threadgroup_change_end()
    spin_lock_irq()
    signal_pending()
    signotset()
    retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
        sigandsets()
        sigisemptyset()
        while_each_thread()
        has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
        signal_pending()
        signal_wake_up()
    unlikely()
    task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
        WARN_ON_ONCE()
        task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
            BUG_ON()
            task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                unlikely()
                smp_mb()
                wake_up_bit()
    spin_unlock_irq()
    read_lock()
    do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
        rcu_read_lock()
        task_pid_nr_ns()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                    smp_rmb()
        task_cred_xxx()
        task_uid()
        rcu_read_unlock()
        task_cputime()
        cputime_to_clock_t()
        BUG()
        spin_lock_irqsave()
        spin_unlock_irqrestore()
    read_unlock()
exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
    switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
        might_sleep()
        task_lock()
        task_unlock()
        atomic_dec_and_test()
        free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
            put_mnt_ns()
            put_uts_ns()
            put_ipc_ns()
            put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                kref_put()
                free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                    container_of()
                    destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                        ns_free_inum()
                        kfree()
                        put_user_ns()
                        call_rcu()
                        delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                            kmem_cache_free()
                            container_of()
            put_net()
            kmem_cache_free()
file_ns_capable() <bool file_ns_capable (const struct file *file, struct user_namespace *ns, int cap) at capability.c:420>:
    WARN_ON_ONCE()
    cap_valid()
    security_capable()
find_dev_pagemap() <struct dev_pagemap *find_dev_pagemap (resource_size_t phys) at memremap.c:245>:
    WARN_ON_ONCE()
    rcu_read_lock_held()
    radix_tree_lookup()
find_ge_pid() <struct pid *find_ge_pid (int nr, struct pid_namespace *ns) at pid.c:556>:
    find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
        hlist_for_each_entry_rcu()
        pid_hashfn()
        container_of()
    next_pidmap() <int next_pidmap (struct pid_namespace *pid_ns, unsigned int last) at pid.c:216>:
        unlikely()
        find_next_bit()
        mk_pid() <inline int mk_pid (struct pid_namespace *pid_ns, struct pidmap *map, int off) at pid.c:55>:
find_get_pid() <struct pid *find_get_pid (pid_t nr) at pid.c:488>:
    rcu_read_lock()
    get_pid()
    find_vpid() <struct pid *find_vpid (int nr) at pid.c:380>:
        find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
            hlist_for_each_entry_rcu()
            pid_hashfn()
            container_of()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
    rcu_read_unlock()
find_module() <struct module *find_module (const char *name) at module.c:604>:
    module_assert_mutex() <void module_assert_mutex (void) at module.c:255>:
        lockdep_assert_held()
    find_module_all() <struct module *find_module_all (const char *name, size_t len, bool even_unformed) at module.c:588>:
        module_assert_mutex_or_preempt() <void module_assert_mutex_or_preempt (void) at module.c:260>:
            unlikely()
            WARN_ON()
            rcu_read_lock_sched_held()
            lockdep_is_held()
        list_for_each_entry()
find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
    hlist_for_each_entry_rcu()
    pid_hashfn()
    container_of()
find_symbol() <const struct kernel_symbol *find_symbol (const char *name, struct module **owner, const unsigned long **crc, bool gplok, bool warn) at module.c:559>:
    each_symbol_section() <bool each_symbol_section (bool (*fn) (const struct symsearch *arr, struct module *owner, void *data), void *data) at module.c:424>:
        module_assert_mutex_or_preempt() <void module_assert_mutex_or_preempt (void) at module.c:260>:
            unlikely()
            WARN_ON()
            rcu_read_lock_sched_held()
            lockdep_is_held()
        each_symbol_in_section() <bool each_symbol_in_section (const struct symsearch *arr, unsigned int arrsize, struct module *owner, bool (*fn) (const struct symsearch *syms, struct module *owner, void *data), void *data) at module.c:405>:
            fn()
        ARRAY_SIZE()
        fn()
        list_for_each_entry_rcu()
    find_symbol_in_section() <bool find_symbol_in_section (const struct symsearch *syms, struct module *owner, void *data) at module.c:541>:
        cmp_name() <int cmp_name (const void *va, const void *vb) at module.c:533>:
        check_symbol() <bool check_symbol (const struct symsearch *syms, struct module *owner, unsigned int symnum, void *data) at module.c:499>:
            pr_warn()
            symversion()
    pr_debug()
find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
    RCU_LOCKDEP_WARN()
    rcu_read_lock_held()
    pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
        rcu_dereference_check()
        hlist_first_rcu()
        lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
            lockdep_is_held()
        hlist_entry()
    find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
        hlist_for_each_entry_rcu()
        pid_hashfn()
        container_of()
find_task_by_vpid() <struct task_struct *find_task_by_vpid (pid_t vnr) at pid.c:459>:
    find_task_by_pid_ns() <struct task_struct *find_task_by_pid_ns (pid_t nr, struct pid_namespace *ns) at pid.c:452>:
        RCU_LOCKDEP_WARN()
        rcu_read_lock_held()
        pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
            rcu_dereference_check()
            hlist_first_rcu()
            lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                lockdep_is_held()
            hlist_entry()
        find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
            hlist_for_each_entry_rcu()
            pid_hashfn()
            container_of()
    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
        ns_of_pid()
        task_pid()
find_user() <struct user_struct *find_user (kuid_t uid) at user.c:146>:
    spin_lock_irqsave()
    uid_hash_find() <struct user_struct *uid_hash_find (kuid_t uid, struct hlist_head *hashent) at user.c:112>:
        hlist_for_each_entry()
        uid_eq()
        atomic_inc()
    uidhashentry()
    spin_unlock_irqrestore()
find_vpid() <struct pid *find_vpid (int nr) at pid.c:380>:
    find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
        hlist_for_each_entry_rcu()
        pid_hashfn()
        container_of()
    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
        ns_of_pid()
        task_pid()
fire_user_return_notifiers() <void fire_user_return_notifiers (void) at user-return-notifier.c:34>:
    get_cpu_var()
    hlist_for_each_entry_safe()
    put_cpu_var()
flush_delayed_work() <bool flush_delayed_work (struct delayed_work *dwork) at workqueue.c:2966>:
    local_irq_disable()
    del_timer_sync()
    local_irq_enable()
    flush_work() <bool flush_work (struct work_struct *work) at workqueue.c:2841>:
        lock_map_acquire()
        lock_map_release()
        start_flush_work() <bool start_flush_work (struct work_struct *work, struct wq_barrier *barr) at workqueue.c:2779>:
            might_sleep()
            local_irq_disable()
            get_work_pool() <struct worker_pool *get_work_pool (struct work_struct *work) at workqueue.c:703>:
                atomic_long_read()
                assert_rcu_or_pool_mutex()
                idr_find()
            local_irq_enable()
            spin_lock()
            get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                atomic_long_read()
            unlikely()
            find_worker_executing_work() <struct worker *find_worker_executing_work (struct worker_pool *pool, struct work_struct *work) at workqueue.c:996>:
                hash_for_each_possible()
            check_flush_dependency() <void check_flush_dependency (struct workqueue_struct *target_wq, struct work_struct *target_work) at workqueue.c:2403>:
                current_wq_worker()
                WARN_ONCE()
            insert_wq_barrier() <void insert_wq_barrier (struct pool_workqueue *pwq, struct wq_barrier *barr, struct work_struct *target, struct worker *worker) at workqueue.c:2460>:
                INIT_WORK_ONSTACK()
                wq_barrier_func() <void wq_barrier_func (struct work_struct *work) at workqueue.c:2430>:
                    container_of()
                    complete()
                work_data_bits()
                init_completion()
                debug_work_activate() <inline void debug_work_activate (struct work_struct *work) at workqueue.c:547>:
                    debug_object_activate()
                insert_work() <void insert_work (struct pool_workqueue *pwq, struct work_struct *work, struct list_head *head, unsigned int extra_flags) at workqueue.c:1290>:
                    set_work_pwq() <void set_work_pwq (struct work_struct *work, struct pool_workqueue *pwq, unsigned long extra_flags) at workqueue.c:645>:
                        set_work_data() <inline void set_work_data (struct work_struct *work, unsigned long data, unsigned long flags) at workqueue.c:638>:
                            WARN_ON_ONCE()
                            work_pending()
                            atomic_long_set()
                            work_static()
                    list_add_tail()
                    get_pwq() <void get_pwq (struct pool_workqueue *pwq) at workqueue.c:1058>:
                        lockdep_assert_held()
                        WARN_ON_ONCE()
                    smp_mb()
                    wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
                        first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                            unlikely()
                            list_empty()
                            list_first_entry()
                        likely()
                        wake_up_process()
                work_color_to_flags() <unsigned int work_color_to_flags (int color) at workqueue.c:602>:
            spin_unlock_irq()
            lock_map_acquire()
            lock_map_acquire_read()
            lock_map_release()
        wait_for_completion()
        destroy_work_on_stack() <void destroy_work_on_stack (struct work_struct *work) at workqueue.c:533>:
            debug_object_free()
flush_itimer_signals() <void flush_itimer_signals (void) at signal.c:453>:
    spin_lock_irqsave()
    spin_unlock_irqrestore()
flush_kthread_work() <void flush_kthread_work (struct kthread_work *work) at kthread.c:660>:
    KTHREAD_WORK_INIT()
    kthread_flush_work_fn() <void kthread_flush_work_fn (struct kthread_work *work) at kthread.c:647>:
        container_of()
        complete()
    COMPLETION_INITIALIZER_ONSTACK()
    spin_lock_irq()
    spin_unlock_irq()
    list_empty()
    insert_kthread_work() <void insert_kthread_work (struct kthread_worker *worker, struct kthread_work *work, struct list_head *pos) at kthread.c:605>:
        lockdep_assert_held()
        list_add_tail()
        likely()
        wake_up_process()
    wait_for_completion()
flush_kthread_worker() <void flush_kthread_worker (struct kthread_worker *worker) at kthread.c:701>:
    KTHREAD_WORK_INIT()
    kthread_flush_work_fn() <void kthread_flush_work_fn (struct kthread_work *work) at kthread.c:647>:
        container_of()
        complete()
    COMPLETION_INITIALIZER_ONSTACK()
    queue_kthread_work() <bool queue_kthread_work (struct kthread_worker *worker, struct kthread_work *work) at kthread.c:626>:
        spin_lock_irqsave()
        list_empty()
        insert_kthread_work() <void insert_kthread_work (struct kthread_worker *worker, struct kthread_work *work, struct list_head *pos) at kthread.c:605>:
            lockdep_assert_held()
            list_add_tail()
            likely()
            wake_up_process()
        spin_unlock_irqrestore()
    wait_for_completion()
flush_signal_handlers() <void flush_signal_handlers (struct task_struct *t, int force_default) at signal.c:479>:
flush_signals() <void flush_signals (struct task_struct *t) at signal.c:419>:
    spin_lock_irqsave()
    clear_tsk_thread_flag()
    flush_sigqueue() <void flush_sigqueue (struct sigpending *queue) at signal.c:404>:
        list_empty()
        list_entry()
        list_del_init()
    spin_unlock_irqrestore()
flush_sigqueue() <void flush_sigqueue (struct sigpending *queue) at signal.c:404>:
    list_empty()
    list_entry()
    list_del_init()
flush_work() <bool flush_work (struct work_struct *work) at workqueue.c:2841>:
    lock_map_acquire()
    lock_map_release()
    start_flush_work() <bool start_flush_work (struct work_struct *work, struct wq_barrier *barr) at workqueue.c:2779>:
        might_sleep()
        local_irq_disable()
        get_work_pool() <struct worker_pool *get_work_pool (struct work_struct *work) at workqueue.c:703>:
            atomic_long_read()
            assert_rcu_or_pool_mutex()
            idr_find()
        local_irq_enable()
        spin_lock()
        get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
            atomic_long_read()
        unlikely()
        find_worker_executing_work() <struct worker *find_worker_executing_work (struct worker_pool *pool, struct work_struct *work) at workqueue.c:996>:
            hash_for_each_possible()
        check_flush_dependency() <void check_flush_dependency (struct workqueue_struct *target_wq, struct work_struct *target_work) at workqueue.c:2403>:
            current_wq_worker()
            WARN_ONCE()
        insert_wq_barrier() <void insert_wq_barrier (struct pool_workqueue *pwq, struct wq_barrier *barr, struct work_struct *target, struct worker *worker) at workqueue.c:2460>:
            INIT_WORK_ONSTACK()
            wq_barrier_func() <void wq_barrier_func (struct work_struct *work) at workqueue.c:2430>:
                container_of()
                complete()
            work_data_bits()
            init_completion()
            debug_work_activate() <inline void debug_work_activate (struct work_struct *work) at workqueue.c:547>:
                debug_object_activate()
            insert_work() <void insert_work (struct pool_workqueue *pwq, struct work_struct *work, struct list_head *head, unsigned int extra_flags) at workqueue.c:1290>:
                set_work_pwq() <void set_work_pwq (struct work_struct *work, struct pool_workqueue *pwq, unsigned long extra_flags) at workqueue.c:645>:
                    set_work_data() <inline void set_work_data (struct work_struct *work, unsigned long data, unsigned long flags) at workqueue.c:638>:
                        WARN_ON_ONCE()
                        work_pending()
                        atomic_long_set()
                        work_static()
                list_add_tail()
                get_pwq() <void get_pwq (struct pool_workqueue *pwq) at workqueue.c:1058>:
                    lockdep_assert_held()
                    WARN_ON_ONCE()
                smp_mb()
                wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
                    first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                        unlikely()
                        list_empty()
                        list_first_entry()
                    likely()
                    wake_up_process()
            work_color_to_flags() <unsigned int work_color_to_flags (int color) at workqueue.c:602>:
        spin_unlock_irq()
        lock_map_acquire()
        lock_map_acquire_read()
        lock_map_release()
    wait_for_completion()
    destroy_work_on_stack() <void destroy_work_on_stack (struct work_struct *work) at workqueue.c:533>:
        debug_object_free()
flush_workqueue() <void flush_workqueue (struct workqueue_struct *wq) at workqueue.c:2576>:
    LIST_HEAD_INIT()
    COMPLETION_INITIALIZER_ONSTACK()
    lock_map_acquire()
    lock_map_release()
    mutex_lock()
    work_next_color() <int work_next_color (int color) at workqueue.c:613>:
    WARN_ON_ONCE()
    list_empty()
    flush_workqueue_prep_pwqs() <bool flush_workqueue_prep_pwqs (struct workqueue_struct *wq, int flush_color, int work_color) at workqueue.c:2529>:
        WARN_ON_ONCE()
        atomic_read()
        atomic_set()
        for_each_pwq()
        spin_lock_irq()
        atomic_inc()
        work_next_color() <int work_next_color (int color) at workqueue.c:613>:
        spin_unlock_irq()
        atomic_dec_and_test()
        complete()
    list_add_tail()
    check_flush_dependency() <void check_flush_dependency (struct workqueue_struct *target_wq, struct work_struct *target_work) at workqueue.c:2403>:
        current_wq_worker()
        WARN_ONCE()
    mutex_unlock()
    wait_for_completion()
    list_for_each_entry_safe()
    list_del_init()
    complete()
    list_for_each_entry()
    list_splice_tail_init()
foo() <void foo (void) at bounds.c:15>:
    DEFINE()
    ilog2()
for_each_kernel_tracepoint() <void for_each_kernel_tracepoint (void (*fct) (struct tracepoint *tp, void *priv), void *priv) at tracepoint.c:519>:
    for_each_tracepoint_range() <void for_each_tracepoint_range (struct tracepoint *const *begin, struct tracepoint *const *end, void (*fct) (struct tracepoint *tp, void *priv), void *priv) at tracepoint.c:501>
force_sig() <void force_sig (int sig, struct task_struct *p) at signal.c:1435>:
    force_sig_info() <int force_sig_info (int sig, struct siginfo *info, struct task_struct *t) at signal.c:1160>:
        spin_lock_irqsave()
        recalc_sigpending_and_wake() <void recalc_sigpending_and_wake (struct task_struct *t) at signal.c:152>:
            recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                PENDING()
                set_tsk_thread_flag()
            signal_wake_up()
        specific_send_sig_info() <int specific_send_sig_info (int sig, struct siginfo *info, struct task_struct *t) at signal.c:1129>:
            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                    SI_FROMUSER()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
        spin_unlock_irqrestore()
force_sig_info() <int force_sig_info (int sig, struct siginfo *info, struct task_struct *t) at signal.c:1160>:
    spin_lock_irqsave()
    recalc_sigpending_and_wake() <void recalc_sigpending_and_wake (struct task_struct *t) at signal.c:152>:
        recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
            PENDING()
            set_tsk_thread_flag()
        signal_wake_up()
    specific_send_sig_info() <int specific_send_sig_info (int sig, struct siginfo *info, struct task_struct *t) at signal.c:1129>:
        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                SI_FROMUSER()
            task_pid_nr_ns()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
    spin_unlock_irqrestore()
force_sigsegv() <int force_sigsegv (int sig, struct task_struct *p) at signal.c:1447>:
    spin_lock_irqsave()
    spin_unlock_irqrestore()
    force_sig() <void force_sig (int sig, struct task_struct *p) at signal.c:1435>:
        force_sig_info() <int force_sig_info (int sig, struct siginfo *info, struct task_struct *t) at signal.c:1160>:
            spin_lock_irqsave()
            recalc_sigpending_and_wake() <void recalc_sigpending_and_wake (struct task_struct *t) at signal.c:152>:
                recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                    PENDING()
                    set_tsk_thread_flag()
                signal_wake_up()
            specific_send_sig_info() <int specific_send_sig_info (int sig, struct siginfo *info, struct task_struct *t) at signal.c:1129>:
                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                        SI_FROMUSER()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
            spin_unlock_irqrestore()
fork_idle() <struct task_struct *fork_idle (int cpu) at fork.c:1673>:
    copy_process() <struct task_struct *copy_process (unsigned long clone_flags, unsigned long stack_start, unsigned long stack_size, int __user *child_tidptr, struct pid *pid, int trace, unsigned long tls) at fork.c:1242>:
        ERR_PTR()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
        security_task_create()
        dup_task_struct() <struct task_struct *dup_task_struct (struct task_struct *orig) at fork.c:334>:
            tsk_fork_get_node() <int tsk_fork_get_node (struct task_struct *tsk) at kthread.c:216>:
            alloc_task_struct_node() <inline struct task_struct *alloc_task_struct_node (int node) at fork.c:139>:
                kmem_cache_alloc_node()
            alloc_thread_info_node() <struct thread_info *alloc_thread_info_node (struct task_struct *tsk, int node) at fork.c:177>:
                alloc_kmem_pages_node()
                page_address()
                kmem_cache_alloc_node()
            arch_dup_task_struct() <int __weak arch_dup_task_struct (struct task_struct *dst, struct task_struct *src) at fork.c:319>
            setup_thread_stack()
            clear_user_return_notifier()
            clear_tsk_need_resched()
            set_task_stack_end_magic() <void set_task_stack_end_magic (struct task_struct *tsk) at fork.c:326>:
                end_of_stack()
            get_random_int()
            atomic_set()
            account_kernel_stack() <void account_kernel_stack (struct thread_info *ti, int account) at fork.c:215>:
                page_zone()
                virt_to_page()
                mod_zone_page_state()
            free_thread_info() <void free_thread_info (struct thread_info *ti) at fork.c:183>:
                free_kmem_pages()
                kmem_cache_free()
            free_task_struct() <inline void free_task_struct (struct task_struct *tsk) at fork.c:144>:
                kmem_cache_free()
        ftrace_graph_init_task()
        rt_mutex_init_task() <void rt_mutex_init_task (struct task_struct *p) at fork.c:1205>:
            raw_spin_lock_init()
        DEBUG_LOCKS_WARN_ON()
        atomic_read()
        task_rlimit()
        capable() <bool capable (int cap) at capability.c:401>:
            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                unlikely()
                cap_valid()
                pr_crit()
                BUG()
                security_capable()
                current_cred()
        copy_creds() <int copy_creds (struct task_struct *p, unsigned long clone_flags) at cred.c:322>:
            get_cred()
            alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                atomic_add()
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
            atomic_inc()
            prepare_creds() <struct cred *prepare_creds (void) at cred.c:243>:
                validate_process_creds()
                kmem_cache_alloc()
                kdebug()
                atomic_set()
                set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
                    atomic_set()
                get_group_info()
                get_uid()
                get_user_ns()
                key_get()
                security_prepare_creds()
                validate_creds()
                abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
                    kdebug()
                    atomic_read()
                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                        atomic_read()
                    BUG_ON()
                    put_cred()
            create_user_ns() <int create_user_ns (struct cred *new) at user_namespace.c:60>:
                current_chrooted()
                kuid_has_mapping()
                kgid_has_mapping()
                kmem_cache_zalloc()
                ns_alloc_inum()
                kmem_cache_free()
                atomic_set()
                mutex_lock()
                mutex_unlock()
                set_cred_user_ns() <void set_cred_user_ns (struct cred *cred, struct user_namespace *user_ns) at user_namespace.c:33>:
                    key_put()
                init_rwsem()
            key_put()
            install_thread_keyring_to_cred()
            validate_creds()
            put_cred()
        delayacct_tsk_init()
        INIT_LIST_HEAD()
        rcu_copy_process()
        spin_lock_init()
        init_sigpending()
        prev_cputime_init()
        seqcount_init()
        task_io_accounting_init()
        acct_clear_integrals() <void acct_clear_integrals (struct task_struct *tsk) at tsacct.c:174>
        posix_cpu_timers_init() <void posix_cpu_timers_init (struct task_struct *tsk) at fork.c:1218>:
            INIT_LIST_HEAD()
        ktime_get_ns()
        ktime_get_boot_ns()
        threadgroup_change_begin()
        cgroup_fork() <void cgroup_fork (struct task_struct *child) at cgroup.c:5497>:
            RCU_INIT_POINTER()
            INIT_LIST_HEAD()
        mpol_dup()
        IS_ERR()
        PTR_ERR()
        sched_fork()
        perf_event_init_task()
        audit_alloc() <int audit_alloc (struct task_struct *tsk) at auditsc.c:920>:
            likely()
            audit_filter_task() <enum audit_state audit_filter_task (struct task_struct *tsk, char **key) at auditsc.c:708>:
                rcu_read_lock()
                list_for_each_entry_rcu()
                audit_filter_rules() <int audit_filter_rules (struct task_struct *tsk, struct audit_krule *rule, struct audit_context *ctx, struct audit_names *name, enum audit_state *state, bool task_creation) at auditsc.c:438>:
                    rcu_dereference_check()
                    task_pid_nr()
                    audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                        BUG()
                    task_ppid_nr()
                    audit_exe_compare() <int audit_exe_compare (struct task_struct *tsk, struct audit_fsnotify_mark *mark) at audit_watch.c:541>:
                        rcu_read_lock()
                        rcu_dereference()
                        rcu_read_unlock()
                        audit_mark_compare() <int audit_mark_compare (struct audit_fsnotify_mark *mark, unsigned long ino, dev_t dev) at audit_fsnotify.c:69>:
                    audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
                        uid_eq()
                        uid_lt()
                        uid_lte()
                        uid_gt()
                        uid_gte()
                        BUG()
                    audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
                        gid_eq()
                        gid_lt()
                        gid_lte()
                        gid_gt()
                        gid_gte()
                        BUG()
                    in_group_p() <int in_group_p (kgid_t grp) at groups.c:255>:
                        current_cred()
                        gid_eq()
                        groups_search() <int groups_search (const struct group_info *group_info, kgid_t grp) at groups.c:133>:
                            gid_gt()
                            GROUP_AT()
                            gid_lt()
                    in_egroup_p() <int in_egroup_p (kgid_t grp) at groups.c:267>:
                        current_cred()
                        gid_eq()
                        groups_search() <int groups_search (const struct group_info *group_info, kgid_t grp) at groups.c:133>:
                            gid_gt()
                            GROUP_AT()
                            gid_lt()
                    MAJOR()
                    list_for_each_entry()
                    MINOR()
                    audit_watch_compare() <int audit_watch_compare (struct audit_watch *watch, unsigned long ino, dev_t dev) at audit_watch.c:139>:
                    match_tree_refs() <int match_tree_refs (struct audit_context *ctx, struct audit_tree *tree) at auditsc.c:287>:
                        audit_tree_match() <bool audit_tree_match (struct audit_chunk *chunk, struct audit_tree *tree) at audit_tree.c:200>:
                    audit_loginuid_set()
                    security_task_getsecid()
                    security_audit_rule_match()
                    audit_match_perm() <int audit_match_perm (struct audit_context *ctx, int mask) at auditsc.c:131>:
                        unlikely()
                        audit_classify_syscall()
                        audit_match_class() <int audit_match_class (int class, unsigned syscall) at auditfilter.c:197>:
                            unlikely()
                            AUDIT_WORD()
                            AUDIT_BIT()
                        ACC_MODE()
                    audit_match_filetype() <int audit_match_filetype (struct audit_context *ctx, int val) at auditsc.c:174>:
                        unlikely()
                        list_for_each_entry()
                    audit_field_compare() <int audit_field_compare (struct task_struct *tsk, const struct cred *cred, struct audit_field *f, struct audit_context *ctx, struct audit_names *name) at auditsc.c:358>:
                        audit_compare_uid() <int audit_compare_uid (kuid_t uid, struct audit_names *name, struct audit_field *f, struct audit_context *ctx) at auditsc.c:310>:
                            audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
                                uid_eq()
                                uid_lt()
                                uid_lte()
                                uid_gt()
                                uid_gte()
                                BUG()
                            list_for_each_entry()
                        audit_compare_gid() <int audit_compare_gid (kgid_t gid, struct audit_names *name, struct audit_field *f, struct audit_context *ctx) at auditsc.c:334>:
                            audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
                                gid_eq()
                                gid_lt()
                                gid_lte()
                                gid_gt()
                                gid_gte()
                                BUG()
                            list_for_each_entry()
                        audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
                            uid_eq()
                            uid_lt()
                            uid_lte()
                            uid_gt()
                            uid_gte()
                            BUG()
                        audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
                            gid_eq()
                            gid_lt()
                            gid_lte()
                            gid_gt()
                            gid_gte()
                            BUG()
                        WARN()
                    kfree()
                    kstrdup()
                kstrdup()
                rcu_read_unlock()
            clear_tsk_thread_flag()
            audit_alloc_context() <inline struct audit_context *audit_alloc_context (enum audit_state state) at auditsc.c:897>:
                kzalloc()
                INIT_LIST_HEAD()
            kfree()
            audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                atomic_inc()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
                printk_ratelimit()
                pr_warn()
                atomic_read()
                audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                    printk_ratelimit()
                    pr_err()
                    panic() <void panic (const char *fmt, ...) at panic.c:83>:
                        local_irq_disable()
                        raw_smp_processor_id()
                        atomic_cmpxchg()
                        panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                            cpu_relax()
                        console_verbose()
                        bust_spinlocks()
                        pr_emerg()
                        test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                            test_bit()
                        dump_stack()
                        smp_send_stop()
                        atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                        kmsg_dump()
                        debug_locks_off()
                        console_flush_on_panic()
                        panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                        no_blink() <long no_blink (int state) at panic.c:46>
                        touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                            raw_cpu_write()
                            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                    raw_cpu_write()
                                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                    per_cpu()
                                raw_smp_processor_id()
                        mdelay()
                        emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                            kmsg_dump()
                            machine_emergency_restart()
                        disabled_wait()
                        local_irq_enable()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
            set_tsk_thread_flag()
        shm_init_task()
        copy_semundo()
        copy_files() <int copy_files (unsigned long clone_flags, struct task_struct *tsk) at fork.c:1013>:
            atomic_inc()
            dup_fd()
        copy_fs() <int copy_fs (unsigned long clone_flags, struct task_struct *tsk) at fork.c:993>:
            spin_lock()
            spin_unlock()
            copy_fs_struct()
        copy_sighand() <int copy_sighand (unsigned long clone_flags, struct task_struct *tsk) at fork.c:1066>:
            atomic_inc()
            kmem_cache_alloc()
            rcu_assign_pointer()
            atomic_set()
        copy_signal() <int copy_signal (unsigned long clone_flags, struct task_struct *tsk) at fork.c:1115>:
            kmem_cache_zalloc()
            atomic_set()
            LIST_HEAD_INIT()
            init_waitqueue_head()
            init_sigpending()
            INIT_LIST_HEAD()
            seqlock_init()
            prev_cputime_init()
            hrtimer_init()
            task_lock()
            task_unlock()
            posix_cpu_timers_init_group() <void posix_cpu_timers_init_group (struct signal_struct *sig) at fork.c:1099>:
                READ_ONCE()
                secs_to_cputime()
                INIT_LIST_HEAD()
            tty_audit_fork()
            sched_autogroup_fork()
            mutex_init()
        copy_mm() <int copy_mm (unsigned long clone_flags, struct task_struct *tsk) at fork.c:947>:
            vmacache_flush()
            atomic_inc()
            dup_mm() <struct mm_struct *dup_mm (struct task_struct *tsk) at fork.c:912>:
                allocate_mm()
                mm_init() <struct mm_struct *mm_init (struct mm_struct *mm, struct task_struct *p) at fork.c:587>:
                    atomic_set()
                    init_rwsem()
                    INIT_LIST_HEAD()
                    atomic_long_set()
                    mm_nr_pmds_init()
                    spin_lock_init()
                    mm_init_cpumask()
                    mm_init_aio() <void mm_init_aio (struct mm_struct *mm) at fork.c:572>:
                        spin_lock_init()
                    mm_init_owner() <void mm_init_owner (struct mm_struct *mm, struct task_struct *p) at fork.c:580>
                    mmu_notifier_mm_init()
                    clear_tlb_flush_pending()
                    mm_alloc_pgd() <inline int mm_alloc_pgd (struct mm_struct *mm) at fork.c:529>:
                        pgd_alloc()
                        unlikely()
                    init_new_context()
                    mm_free_pgd() <inline void mm_free_pgd (struct mm_struct *mm) at fork.c:537>:
                        pgd_free()
                    free_mm()
                dup_mmap() <int dup_mmap (struct mm_struct *mm, struct mm_struct *oldmm) at fork.c:542>:
                    uprobe_start_dup_mmap()
                    down_write()
                    flush_cache_dup_mm()
                    uprobe_dup_mmap()
                    down_write_nested()
                    RCU_INIT_POINTER()
                    get_mm_exe_file() <struct file *get_mm_exe_file (struct mm_struct *mm) at fork.c:752>:
                        rcu_read_lock()
                        rcu_dereference()
                        get_file_rcu()
                        rcu_read_unlock()
                    ksm_fork()
                    khugepaged_fork()
                    vm_stat_account()
                    vma_pages()
                    security_vm_enough_memory_mm()
                    kmem_cache_alloc()
                    INIT_LIST_HEAD()
                    vma_dup_policy()
                    anon_vma_fork()
                    file_inode()
                    get_file()
                    atomic_dec()
                    i_mmap_lock_write()
                    atomic_inc()
                    flush_dcache_mmap_lock()
                    vma_interval_tree_insert_after()
                    flush_dcache_mmap_unlock()
                    i_mmap_unlock_write()
                    is_vm_hugetlb_page()
                    reset_vma_resv_huge_pages()
                    copy_page_range()
                    arch_dup_mmap()
                    up_write()
                    flush_tlb_mm()
                    uprobe_end_dup_mmap()
                    mpol_put()
                    vma_policy()
                    kmem_cache_free()
                    vm_unacct_memory()
                get_mm_rss()
                try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
                    preempt_disable()
                    likely()
                    module_is_live()
                    atomic_inc_not_zero()
                    trace_module_get()
                    preempt_enable()
                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                    might_sleep()
                    atomic_dec_and_test()
                    uprobe_clear_state()
                    exit_aio()
                    ksm_exit()
                    khugepaged_exit()
                    exit_mmap()
                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                        rcu_dereference_raw()
                        get_file()
                        rcu_assign_pointer()
                        fput()
                    list_empty()
                    spin_lock()
                    list_del()
                    spin_unlock()
                    module_put() <void module_put (struct module *module) at module.c:1098>:
                        preempt_disable()
                        atomic_dec_if_positive()
                        WARN_ON()
                        trace_module_put()
                        preempt_enable()
                    mmdrop()
        copy_namespaces() <int copy_namespaces (unsigned long flags, struct task_struct *tsk) at nsproxy.c:124>:
            task_cred_xxx()
            likely()
            get_nsproxy()
            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                unlikely()
                cap_valid()
                pr_crit()
                BUG()
                security_capable()
                current_cred()
            create_new_namespaces() <struct nsproxy *create_new_namespaces (unsigned long flags, struct task_struct *tsk, struct user_namespace *user_ns, struct fs_struct *new_fs) at nsproxy.c:59>:
                create_nsproxy() <inline struct nsproxy *create_nsproxy (void) at nsproxy.c:44>:
                    kmem_cache_alloc()
                    atomic_set()
                ERR_PTR()
                copy_mnt_ns()
                IS_ERR()
                PTR_ERR()
                copy_utsname() <struct uts_namespace *copy_utsname (unsigned long flags, struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:66>:
                    BUG_ON()
                    get_uts_ns()
                    clone_uts_ns() <struct uts_namespace *clone_uts_ns (struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:35>:
                        create_uts_ns() <struct uts_namespace *create_uts_ns (void) at utsname.c:20>:
                            kmalloc()
                            kref_init()
                        ERR_PTR()
                        ns_alloc_inum()
                        kfree()
                        down_read()
                        get_user_ns()
                        up_read()
                    put_uts_ns()
                copy_ipcs()
                copy_pid_ns() <struct pid_namespace *copy_pid_ns (unsigned long flags, struct user_namespace *user_ns, struct pid_namespace *old_ns) at pid_namespace.c:153>:
                    get_pid_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    ERR_PTR()
                    create_pid_namespace() <struct pid_namespace *create_pid_namespace (struct user_namespace *user_ns, struct pid_namespace *parent_pid_ns) at pid_namespace.c:82>:
                        kmem_cache_zalloc()
                        kzalloc()
                        create_pid_cachep() <struct kmem_cache *create_pid_cachep (int nr_ids) at pid_namespace.c:38>:
                            mutex_lock()
                            list_for_each_entry()
                            kmalloc()
                            kmem_cache_create()
                            list_add()
                            mutex_unlock()
                            kfree()
                        ns_alloc_inum()
                        kref_init()
                        get_pid_ns()
                        get_user_ns()
                        INIT_WORK()
                        proc_cleanup_work() <void proc_cleanup_work (struct work_struct *work) at pid_namespace.c:73>:
                            container_of()
                            pid_ns_release_proc()
                        set_bit()
                        atomic_set()
                        kfree()
                        kmem_cache_free()
                        ERR_PTR()
                copy_net_ns()
                put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                    kref_put()
                    free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                        container_of()
                        destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                            ns_free_inum()
                            kfree()
                            put_user_ns()
                            call_rcu()
                            delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                kmem_cache_free()
                                container_of()
                put_ipc_ns()
                put_uts_ns()
                put_mnt_ns()
                kmem_cache_free()
            IS_ERR()
            PTR_ERR()
        copy_io() <int copy_io (unsigned long clone_flags, struct task_struct *tsk) at fork.c:1040>:
            ioc_task_link()
            ioprio_valid()
            get_task_io_context()
            unlikely()
            put_io_context()
        copy_thread_tls()
        alloc_pid() <struct pid *alloc_pid (struct pid_namespace *ns) at pid.c:297>:
            kmem_cache_alloc()
            ERR_PTR()
            alloc_pidmap() <int alloc_pidmap (struct pid_namespace *pid_ns) at pid.c:154>:
                DIV_ROUND_UP()
                unlikely()
                kzalloc()
                spin_lock_irq()
                spin_unlock_irq()
                kfree()
                likely()
                atomic_read()
                test_and_set_bit()
                atomic_dec()
                set_last_pid() <void set_last_pid (struct pid_namespace *pid_ns, int base, int pid) at pid.c:144>:
                    cmpxchg()
                    pid_before() <int pid_before (int base, int a, int b) at pid.c:118>
                find_next_offset()
                mk_pid() <inline int mk_pid (struct pid_namespace *pid_ns, struct pidmap *map, int off) at pid.c:55>:
            IS_ERR_VALUE()
            unlikely()
            is_child_reaper()
            pid_ns_prepare_proc()
            get_pid_ns()
            atomic_set()
            INIT_HLIST_HEAD()
            spin_lock_irq()
            hlist_add_head_rcu()
            pid_hashfn()
            spin_unlock_irq()
            put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                kref_put()
                free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                    container_of()
                    destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                        ns_free_inum()
                        kfree()
                        put_user_ns()
                        call_rcu()
                        delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                            kmem_cache_free()
                            container_of()
            free_pidmap() <void free_pidmap (struct upid *upid) at pid.c:105>:
                clear_bit()
                atomic_inc()
            kmem_cache_free()
        user_disable_single_step()
        clear_tsk_thread_flag()
        clear_all_latency_tracing() <void clear_all_latency_tracing (struct task_struct *p) at latencytop.c:68>:
            raw_spin_lock_irqsave()
            raw_spin_unlock_irqrestore()
        pid_nr()
        cgroup_can_fork() <int cgroup_can_fork (struct task_struct *child) at cgroup.c:5511>:
            for_each_subsys_which()
            for_each_subsys()
        write_lock_irq()
        spin_lock()
        copy_seccomp() <void copy_seccomp (struct task_struct *p) at fork.c:1165>:
            assert_spin_locked()
            get_seccomp_filter() <void get_seccomp_filter (struct task_struct *tsk) at seccomp.c:461>:
                atomic_inc()
            task_no_new_privs()
            task_set_no_new_privs()
            set_tsk_thread_flag()
        recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
            recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                PENDING()
                set_tsk_thread_flag()
            freezing()
            clear_thread_flag()
        signal_pending()
        spin_unlock()
        write_unlock_irq()
        likely()
        ptrace_init_task()
        init_task_pid() <inline void init_task_pid (struct task_struct *task, enum pid_type type, struct pid *pid) at fork.c:1229>
        thread_group_leader()
        task_pgrp()
        task_session()
        is_child_reaper()
        ns_of_pid()
        tty_kref_get()
        list_add_tail()
        list_add_tail_rcu()
        attach_pid() <void attach_pid (struct task_struct *task, enum pid_type type) at pid.c:389>:
            hlist_add_head_rcu()
        atomic_inc()
        syscall_tracepoint_update()
        proc_fork_connector()
        cgroup_post_fork() <void cgroup_post_fork (struct task_struct *child) at cgroup.c:5562>:
            spin_lock_bh()
            task_css_set()
            list_empty()
            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                atomic_inc()
            css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                lockdep_assert_held()
                WARN_ON_ONCE()
                list_empty()
                list_for_each_entry_safe()
                css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                    lockdep_assert_held()
                    WARN_ON_ONCE()
                    css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                        lockdep_assert_held()
                        container_of()
                        list_entry()
                        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                            lockdep_assert_held()
                            list_empty()
                        list_empty()
                        list_del()
                        put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                            lockdep_assert_held()
                            atomic_dec_and_test()
                            for_each_subsys()
                            list_del()
                            css_put()
                            hash_del()
                            list_for_each_entry_safe()
                            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                container_of()
                            cgroup_put()
                            kfree()
                            kfree_rcu()
                        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                            atomic_inc()
                        list_add()
                list_del_init()
                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                    lockdep_assert_held()
                    list_empty()
                css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                    lockdep_assert_held()
                    list_for_each_entry()
                    cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                        lockdep_assert_held()
                        check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                            notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                test_bit()
                            cgroup_is_populated()
                            css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                rcu_read_lock()
                                css_for_each_child()
                                rcu_read_unlock()
                            cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                            schedule_work()
                        cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                            spin_lock_irqsave()
                            kernfs_notify()
                            spin_unlock_irqrestore()
                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                            container_of()
                rcu_assign_pointer()
                list_add_tail()
            spin_unlock_bh()
            for_each_subsys_which()
        threadgroup_change_end()
        perf_event_fork()
        trace_task_newtask()
        uprobe_copy_process()
        cgroup_cancel_fork() <void cgroup_cancel_fork (struct task_struct *child) at cgroup.c:5542>:
            for_each_subsys()
        free_pid() <void free_pid (struct pid *pid) at pid.c:259>:
            spin_lock_irqsave()
            hlist_del_rcu()
            wake_up_process()
            WARN_ON()
            schedule_work()
            spin_unlock_irqrestore()
            free_pidmap() <void free_pidmap (struct upid *upid) at pid.c:105>:
                clear_bit()
                atomic_inc()
            call_rcu()
            delayed_put_pid() <void delayed_put_pid (struct rcu_head *rhp) at pid.c:253>:
                container_of()
                put_pid() <void put_pid (struct pid *pid) at pid.c:237>:
                    atomic_read()
                    atomic_dec_and_test()
                    kmem_cache_free()
                    put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                        kref_put()
                        free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                            container_of()
                            destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                ns_free_inum()
                                kfree()
                                put_user_ns()
                                call_rcu()
                                delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                    kmem_cache_free()
                                    container_of()
        exit_io_context()
        exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
            switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                might_sleep()
                task_lock()
                task_unlock()
                atomic_dec_and_test()
                free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                    put_mnt_ns()
                    put_uts_ns()
                    put_ipc_ns()
                    put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                        kref_put()
                        free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                            container_of()
                            destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                ns_free_inum()
                                kfree()
                                put_user_ns()
                                call_rcu()
                                delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                    kmem_cache_free()
                                    container_of()
                    put_net()
                    kmem_cache_free()
        mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
            might_sleep()
            atomic_dec_and_test()
            uprobe_clear_state()
            exit_aio()
            ksm_exit()
            khugepaged_exit()
            exit_mmap()
            set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                rcu_dereference_raw()
                get_file()
                rcu_assign_pointer()
                fput()
            list_empty()
            spin_lock()
            list_del()
            spin_unlock()
            module_put() <void module_put (struct module *module) at module.c:1098>:
                preempt_disable()
                atomic_dec_if_positive()
                WARN_ON()
                trace_module_put()
                preempt_enable()
            mmdrop()
        free_signal_struct() <inline void free_signal_struct (struct signal_struct *sig) at fork.c:235>:
            taskstats_tgid_free()
            sched_autogroup_exit()
            kmem_cache_free()
        exit_fs()
        exit_files()
        exit_sem()
        audit_free()
        perf_event_free_task()
        mpol_put()
        delayacct_tsk_free()
        atomic_dec()
        exit_creds() <void exit_creds (struct task_struct *tsk) at cred.c:156>:
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
            validate_creds()
            alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                atomic_add()
            put_cred()
        free_task() <void free_task (struct task_struct *tsk) at fork.c:222>:
            account_kernel_stack() <void account_kernel_stack (struct thread_info *ti, int account) at fork.c:215>:
                page_zone()
                virt_to_page()
                mod_zone_page_state()
            arch_release_thread_info() <void __weak arch_release_thread_info (struct thread_info *ti) at fork.c:150>
            free_thread_info() <void free_thread_info (struct thread_info *ti) at fork.c:183>:
                free_kmem_pages()
                kmem_cache_free()
            rt_mutex_debug_task_free()
            ftrace_graph_exit_task()
            put_seccomp_filter() <void put_seccomp_filter (struct task_struct *tsk) at seccomp.c:479>:
                atomic_dec_and_test()
                seccomp_filter_free() <inline void seccomp_filter_free (struct seccomp_filter *filter) at seccomp.c:470>:
                    bpf_prog_destroy()
                    kfree()
            arch_release_task_struct() <void __weak arch_release_task_struct (struct task_struct *tsk) at fork.c:132>
            free_task_struct() <inline void free_task_struct (struct task_struct *tsk) at fork.c:144>:
                kmem_cache_free()
    IS_ERR()
    init_idle_pids() <inline void init_idle_pids (struct pid_link *links) at fork.c:1663>:
        INIT_HLIST_NODE()
    init_idle()
fork_init() <void __init fork_init (void) at fork.c:296>:
    kmem_cache_create()
    arch_task_cache_init() <void __init __weak arch_task_cache_init (void) at fork.c:266>
    set_max_threads() <void set_max_threads (unsigned int max_threads_suggested) at fork.c:271>:
        fls64()
        div64_u64()
        clamp_t()
free_dma() <void free_dma (unsigned int dmanr) at dma.c:108>:
    printk()
    xchg()
free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
    put_mnt_ns()
    put_uts_ns()
    put_ipc_ns()
    put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
        kref_put()
        free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
            container_of()
            destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                ns_free_inum()
                kfree()
                put_user_ns()
                call_rcu()
                delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                    kmem_cache_free()
                    container_of()
    put_net()
    kmem_cache_free()
free_pid() <void free_pid (struct pid *pid) at pid.c:259>:
    spin_lock_irqsave()
    hlist_del_rcu()
    wake_up_process()
    WARN_ON()
    schedule_work()
    spin_unlock_irqrestore()
    free_pidmap() <void free_pidmap (struct upid *upid) at pid.c:105>:
        clear_bit()
        atomic_inc()
    call_rcu()
    delayed_put_pid() <void delayed_put_pid (struct rcu_head *rhp) at pid.c:253>:
        container_of()
        put_pid() <void put_pid (struct pid *pid) at pid.c:237>:
            atomic_read()
            atomic_dec_and_test()
            kmem_cache_free()
            put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                kref_put()
                free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                    container_of()
                    destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                        ns_free_inum()
                        kfree()
                        put_user_ns()
                        call_rcu()
                        delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                            kmem_cache_free()
                            container_of()
free_task() <void free_task (struct task_struct *tsk) at fork.c:222>:
    account_kernel_stack() <void account_kernel_stack (struct thread_info *ti, int account) at fork.c:215>:
        page_zone()
        virt_to_page()
        mod_zone_page_state()
    arch_release_thread_info() <void __weak arch_release_thread_info (struct thread_info *ti) at fork.c:150>
    free_thread_info() <void free_thread_info (struct thread_info *ti) at fork.c:183>:
        free_kmem_pages()
        kmem_cache_free()
    rt_mutex_debug_task_free()
    ftrace_graph_exit_task()
    put_seccomp_filter() <void put_seccomp_filter (struct task_struct *tsk) at seccomp.c:479>:
        atomic_dec_and_test()
        seccomp_filter_free() <inline void seccomp_filter_free (struct seccomp_filter *filter) at seccomp.c:470>:
            bpf_prog_destroy()
            kfree()
    arch_release_task_struct() <void __weak arch_release_task_struct (struct task_struct *tsk) at fork.c:132>
    free_task_struct() <inline void free_task_struct (struct task_struct *tsk) at fork.c:144>:
        kmem_cache_free()
free_uid() <void free_uid (struct user_struct *up) at user.c:157>:
    local_irq_save()
    atomic_dec_and_lock()
    free_user() <void free_user (struct user_struct *up, unsigned long flags) at user.c:130>:
        uid_hash_remove() <void uid_hash_remove (struct user_struct *up) at user.c:107>:
            hlist_del_init()
        spin_unlock_irqrestore()
        key_put()
        kmem_cache_free()
    local_irq_restore()
free_user_ns() <void free_user_ns (struct user_namespace *ns) at user_namespace.c:138>:
    key_put()
    ns_free_inum()
    kmem_cache_free()
    atomic_dec_and_test()
free_uts_ns() <void free_uts_ns (struct kref *kref) at utsname.c:83>:
    container_of()
    put_user_ns()
    ns_free_inum()
    kfree()
free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
    free_cpumask_var()
    kfree()
freeze_task() <bool freeze_task (struct task_struct *p) at freezer.c:118>:
    freezer_should_skip()
    spin_lock_irqsave()
    freezing()
    frozen()
    spin_unlock_irqrestore()
    fake_signal_wake_up() <void fake_signal_wake_up (struct task_struct *p) at freezer.c:97>:
        lock_task_sighand()
        signal_wake_up()
        unlock_task_sighand()
    wake_up_state()
freeze_workqueues_begin() <void freeze_workqueues_begin (void) at workqueue.c:4734>:
    mutex_lock()
    WARN_ON_ONCE()
    list_for_each_entry()
    for_each_pwq()
    pwq_adjust_max_active() <void pwq_adjust_max_active (struct pool_workqueue *pwq) at workqueue.c:3415>:
        lockdep_assert_held()
        spin_lock_irq()
        list_empty()
        pwq_activate_first_delayed() <void pwq_activate_first_delayed (struct pool_workqueue *pwq) at workqueue.c:1121>:
            list_first_entry()
            pwq_activate_delayed_work() <void pwq_activate_delayed_work (struct work_struct *work) at workqueue.c:1109>:
                get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                    atomic_long_read()
                trace_workqueue_activate_work()
                list_empty()
                move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                    list_for_each_entry_safe_from()
                    list_move_tail()
                    work_data_bits()
                work_data_bits()
        wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
            first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                unlikely()
                list_empty()
                list_first_entry()
            likely()
            wake_up_process()
        spin_unlock_irq()
    mutex_unlock()
freeze_workqueues_busy() <bool freeze_workqueues_busy (void) at workqueue.c:4767>:
    mutex_lock()
    WARN_ON_ONCE()
    list_for_each_entry()
    rcu_read_lock_sched()
    for_each_pwq()
    rcu_read_unlock_sched()
    mutex_unlock()
freezing_slow_path() <bool freezing_slow_path (struct task_struct *p) at freezer.c:40>:
    test_thread_flag()
    cgroup_freezing() <bool cgroup_freezing (struct task_struct *task) at cgroup_freezer.c:65>:
        rcu_read_lock()
        task_freezer() <inline struct freezer *task_freezer (struct task_struct *task) at cgroup_freezer.c:55>:
            css_freezer() <inline struct freezer *css_freezer (struct cgroup_subsys_state *css) at cgroup_freezer.c:50>:
                container_of()
            task_css()
        rcu_read_unlock()
from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
        smp_rmb()
from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
    from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
            smp_rmb()
from_kprojid() <projid_t from_kprojid (struct user_namespace *targ, kprojid_t kprojid) at user_namespace.c:393>:
    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
        smp_rmb()
from_kprojid_munged() <projid_t from_kprojid_munged (struct user_namespace *targ, kprojid_t kprojid) at user_namespace.c:418>:
    from_kprojid() <projid_t from_kprojid (struct user_namespace *targ, kprojid_t kprojid) at user_namespace.c:393>:
        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
            smp_rmb()
from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
        smp_rmb()
from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
            smp_rmb()
func_ptr_is_kernel_text() <int func_ptr_is_kernel_text (void *ptr) at extable.c:136>:
    dereference_function_descriptor()
    core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
        init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
    is_module_text_address() <bool is_module_text_address (unsigned long addr) at module.c:4052>:
        preempt_disable()
        preempt_enable()
generic_ptrace_peekdata() <int generic_ptrace_peekdata (struct task_struct *tsk, unsigned long addr, unsigned long data) at ptrace.c:1124>:
    access_process_vm()
    put_user()
generic_ptrace_pokedata() <int generic_ptrace_pokedata (struct task_struct *tsk, unsigned long addr, unsigned long data) at ptrace.c:1136>:
    access_process_vm()
generic_smp_call_function_single_interrupt() <void generic_smp_call_function_single_interrupt (void) at smp.c:193>:
    flush_smp_call_function_queue() <void flush_smp_call_function_queue (bool warn_cpu_offline) at smp.c:212>:
        WARN_ON()
        irqs_disabled()
        this_cpu_ptr()
        llist_del_all()
        llist_reverse_order()
        unlikely()
        cpu_online()
        smp_processor_id()
        llist_empty()
        WARN()
        llist_for_each_entry()
        pr_warn()
        llist_for_each_entry_safe()
        func()
        csd_unlock() <void csd_unlock (struct call_single_data *csd) at smp.c:127>:
            WARN_ON()
            smp_store_release()
        irq_work_run() <void irq_work_run (void) at irq_work.c:169>:
            irq_work_run_list() <void irq_work_run_list (struct llist_head *list) at irq_work.c:129>:
                BUG_ON()
                irqs_disabled()
                llist_empty()
                llist_del_all()
                llist_entry()
                llist_next()
                xchg()
                cmpxchg()
            this_cpu_ptr()
get_compat_itimerspec() <int get_compat_itimerspec (struct itimerspec *dst, const struct compat_itimerspec __user *src) at compat.c:664>:
get_compat_sigevent() <int get_compat_sigevent (struct sigevent *event, const struct compat_sigevent __user *u_event) at compat.c:876>:
    access_ok()
get_kprobe() <struct kprobe *get_kprobe (void *addr) at kprobes.c:304>:
    hash_ptr()
    hlist_for_each_entry_rcu()
get_mm_exe_file() <struct file *get_mm_exe_file (struct mm_struct *mm) at fork.c:752>:
    rcu_read_lock()
    rcu_dereference()
    get_file_rcu()
    rcu_read_unlock()
get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
    might_sleep()
    cpuhp_lock_acquire_read()
    mutex_lock()
    atomic_inc()
    mutex_unlock()
get_pid_task() <struct task_struct *get_pid_task (struct pid *pid, enum pid_type type) at pid.c:476>:
    rcu_read_lock()
    pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
        rcu_dereference_check()
        hlist_first_rcu()
        lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
            lockdep_is_held()
        hlist_entry()
    get_task_struct()
    rcu_read_unlock()
get_seccomp_filter() <void get_seccomp_filter (struct task_struct *tsk) at seccomp.c:461>:
    atomic_inc()
get_signal() <int get_signal (struct ksignal *ksig) at signal.c:2130>:
    unlikely()
    task_work_run() <void task_work_run (void) at task_work.c:87>:
        ACCESS_ONCE()
        cmpxchg()
        raw_spin_unlock_wait()
        smp_mb()
        cond_resched()
    uprobe_deny_signal()
    try_to_freeze()
    spin_lock_irq()
    spin_unlock_irq()
    read_lock()
    do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
        rcu_read_lock()
        task_pid_nr_ns()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                    smp_rmb()
        task_cred_xxx()
        task_uid()
        rcu_read_unlock()
        task_cputime()
        cputime_to_clock_t()
        BUG()
        spin_lock_irqsave()
        spin_unlock_irqrestore()
    ptrace_reparented()
    read_unlock()
    do_signal_stop() <bool do_signal_stop (int signr) at signal.c:1946>:
        WARN_ON_ONCE()
        likely()
        unlikely()
        signal_group_exit()
        task_set_jobctl_pending() <bool task_set_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:248>:
            BUG_ON()
            unlikely()
            fatal_signal_pending()
        while_each_thread()
        task_is_stopped()
        signal_wake_up()
        ptrace_trap_notify() <void ptrace_trap_notify (struct task_struct *t) at signal.c:765>:
            WARN_ON_ONCE()
            assert_spin_locked()
            task_set_jobctl_pending() <bool task_set_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:248>:
                BUG_ON()
                unlikely()
                fatal_signal_pending()
            ptrace_signal_wake_up()
        task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
            WARN_ON_ONCE()
            task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                BUG_ON()
                task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                    unlikely()
                    smp_mb()
                    wake_up_bit()
        spin_unlock_irq()
        read_lock()
        do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
            rcu_read_lock()
            task_pid_nr_ns()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                        smp_rmb()
            task_cred_xxx()
            task_uid()
            rcu_read_unlock()
            task_cputime()
            cputime_to_clock_t()
            BUG()
            spin_lock_irqsave()
            spin_unlock_irqrestore()
        read_unlock()
        freezable_schedule()
    do_jobctl_trap() <void do_jobctl_trap (void) at signal.c:2063>:
        WARN_ON_ONCE()
        ptrace_do_notify() <void ptrace_do_notify (int signr, int exit_code, int why) at signal.c:1899>:
            task_pid_vnr()
            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                        smp_rmb()
            current_user_ns()
            current_uid()
            ptrace_stop() <void ptrace_stop (int exit_code, int why, int clear_code, siginfo_t *info) at signal.c:1777>:
                arch_ptrace_stop_needed()
                spin_unlock_irq()
                arch_ptrace_stop()
                spin_lock_irq()
                sigkill_pending() <int sigkill_pending (struct task_struct *tsk) at signal.c:1760>:
                set_current_state()
                task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                    WARN_ON_ONCE()
                    task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                        BUG_ON()
                        task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                            unlikely()
                            smp_mb()
                            wake_up_bit()
                task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                    BUG_ON()
                    task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                        unlikely()
                        smp_mb()
                        wake_up_bit()
                task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                    unlikely()
                    smp_mb()
                    wake_up_bit()
                read_lock()
                may_ptrace_stop() <inline int may_ptrace_stop (void) at signal.c:1732>:
                    likely()
                    unlikely()
                do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                    rcu_read_lock()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_cred_xxx()
                    task_uid()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_clock_t()
                    BUG()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                ptrace_reparented()
                preempt_disable()
                read_unlock()
                preempt_enable_no_resched()
                freezable_schedule()
                recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                    PENDING()
                    set_tsk_thread_flag()
        ptrace_stop() <void ptrace_stop (int exit_code, int why, int clear_code, siginfo_t *info) at signal.c:1777>:
            arch_ptrace_stop_needed()
            spin_unlock_irq()
            arch_ptrace_stop()
            spin_lock_irq()
            sigkill_pending() <int sigkill_pending (struct task_struct *tsk) at signal.c:1760>:
            set_current_state()
            task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                WARN_ON_ONCE()
                task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                    BUG_ON()
                    task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                        unlikely()
                        smp_mb()
                        wake_up_bit()
            task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                BUG_ON()
                task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                    unlikely()
                    smp_mb()
                    wake_up_bit()
            task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                unlikely()
                smp_mb()
                wake_up_bit()
            read_lock()
            may_ptrace_stop() <inline int may_ptrace_stop (void) at signal.c:1732>:
                likely()
                unlikely()
            do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                BUG()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
            ptrace_reparented()
            preempt_disable()
            read_unlock()
            preempt_enable_no_resched()
            freezable_schedule()
            recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                PENDING()
                set_tsk_thread_flag()
    dequeue_signal() <int dequeue_signal (struct task_struct *tsk, sigset_t *mask, siginfo_t *info) at signal.c:559>:
        unlikely()
        hrtimer_is_queued()
        hrtimer_forward()
        get_time()
        hrtimer_restart()
        recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
            recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                PENDING()
                set_tsk_thread_flag()
            freezing()
            clear_thread_flag()
        sig_kernel_stop()
        spin_unlock()
        do_schedule_next_timer()
        spin_lock()
    ptrace_signal() <int ptrace_signal (int signr, siginfo_t *info) at signal.c:2082>:
        ptrace_signal_deliver()
        ptrace_stop() <void ptrace_stop (int exit_code, int why, int clear_code, siginfo_t *info) at signal.c:1777>:
            arch_ptrace_stop_needed()
            spin_unlock_irq()
            arch_ptrace_stop()
            spin_lock_irq()
            sigkill_pending() <int sigkill_pending (struct task_struct *tsk) at signal.c:1760>:
            set_current_state()
            task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                WARN_ON_ONCE()
                task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                    BUG_ON()
                    task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                        unlikely()
                        smp_mb()
                        wake_up_bit()
            task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                BUG_ON()
                task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                    unlikely()
                    smp_mb()
                    wake_up_bit()
            task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                unlikely()
                smp_mb()
                wake_up_bit()
            read_lock()
            may_ptrace_stop() <inline int may_ptrace_stop (void) at signal.c:1732>:
                likely()
                unlikely()
            do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                BUG()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
            ptrace_reparented()
            preempt_disable()
            read_unlock()
            preempt_enable_no_resched()
            freezable_schedule()
            recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                PENDING()
                set_tsk_thread_flag()
        rcu_read_lock()
        task_pid_vnr()
        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                    smp_rmb()
        current_user_ns()
        task_uid()
        rcu_read_unlock()
        specific_send_sig_info() <int specific_send_sig_info (int sig, struct siginfo *info, struct task_struct *t) at signal.c:1129>:
            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                    SI_FROMUSER()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
    trace_signal_deliver()
    sig_kernel_ignore()
    sig_kernel_only()
    sig_kernel_stop()
    is_current_pgrp_orphaned() <int is_current_pgrp_orphaned (void) at exit.c:239>:
        read_lock()
        will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
            do_each_pid_task()
            thread_group_empty()
            is_global_init()
            task_pgrp()
            task_session()
            while_each_pid_task()
        task_pgrp()
        read_unlock()
    likely()
    sig_kernel_coredump()
    print_fatal_signal() <void print_fatal_signal (int signr) at signal.c:1089>:
        signal_pt_regs()
        printk()
        get_user()
        preempt_disable()
        show_regs()
        preempt_enable()
    proc_coredump_connector()
    do_coredump()
    do_group_exit() <void do_group_exit (int exit_code) at exit.c:853>:
        BUG_ON()
        signal_group_exit()
        thread_group_empty()
        spin_lock_irq()
        zap_other_threads() <int zap_other_threads (struct task_struct *p) at signal.c:1188>:
            while_each_thread()
            task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                BUG_ON()
                task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                    unlikely()
                    smp_mb()
                    wake_up_bit()
            signal_wake_up()
        spin_unlock_irq()
        do_exit() <void do_exit (long code) at exit.c:651>:
            TASKS_RCU()
            profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
                blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
            WARN_ON()
            blk_needs_flush_plug()
            unlikely()
            in_interrupt()
            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                local_irq_disable()
                raw_smp_processor_id()
                atomic_cmpxchg()
                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                    cpu_relax()
                console_verbose()
                bust_spinlocks()
                pr_emerg()
                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                    test_bit()
                dump_stack()
                smp_send_stop()
                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                kmsg_dump()
                debug_locks_off()
                console_flush_on_panic()
                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                no_blink() <long no_blink (int state) at panic.c:46>
                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                    raw_cpu_write()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
                mdelay()
                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                    kmsg_dump()
                    machine_emergency_restart()
                disabled_wait()
                local_irq_enable()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            set_fs()
            ptrace_event()
            validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
                kdebug()
                atomic_read()
                read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                    atomic_read()
            pr_alert()
            set_current_state()
            schedule()
            exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
                threadgroup_change_begin()
                thread_group_empty()
                signal_group_exit()
                threadgroup_change_end()
                spin_lock_irq()
                signal_pending()
                signotset()
                retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                    sigandsets()
                    sigisemptyset()
                    while_each_thread()
                    has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                    signal_pending()
                    signal_wake_up()
                unlikely()
                task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                    WARN_ON_ONCE()
                    task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                        BUG_ON()
                        task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                            unlikely()
                            smp_mb()
                            wake_up_bit()
                spin_unlock_irq()
                read_lock()
                do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                    rcu_read_lock()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_cred_xxx()
                    task_uid()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_clock_t()
                    BUG()
                    spin_lock_irqsave()
                    spin_unlock_irqrestore()
                read_unlock()
            smp_mb()
            raw_spin_unlock_wait()
            in_atomic()
            pr_info()
            task_pid_nr()
            preempt_count()
            preempt_count_set()
            sync_mm_rss()
            acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
                task_cputime()
            atomic_dec_and_test()
            hrtimer_cancel()
            exit_itimers()
            setmax_mm_hiwater_rss()
            acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
                down_read()
                up_read()
                spin_lock_irq()
                thread_group_leader()
                task_cputime()
                spin_unlock_irq()
            tty_audit_exit()
            audit_free()
            taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
                taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                    nla_total_size()
                taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                    thread_group_empty()
                    kmem_cache_zalloc()
                    spin_lock_irq()
                    spin_unlock_irq()
                    kmem_cache_free()
                fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                    spin_lock_irqsave()
                    delayacct_add_tsk()
                    spin_unlock_irqrestore()
                raw_cpu_ptr()
                list_empty()
                prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                    genlmsg_new()
                    this_cpu_inc_return()
                    genlmsg_put()
                    genlmsg_put_reply()
                    nlmsg_free()
                mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                    nla_put()
                    nla_nest_start()
                    nla_nest_cancel()
                    nla_reserve()
                    nla_nest_end()
                    nla_data()
                task_pid_nr_ns()
                fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                    delayacct_add_tsk()
                    bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                        BUILD_BUG_ON()
                        ktime_get_ns()
                        do_div()
                        get_seconds()
                        thread_group_leader()
                        task_nice()
                        task_pid_nr_ns()
                        rcu_read_lock()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                            from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        pid_alive()
                        task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                            pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                            task_tgid()
                        rcu_dereference()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_usecs()
                        task_cputime_scaled()
                    xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                        get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                            task_lock()
                            atomic_inc()
                            task_unlock()
                        get_mm_hiwater_rss()
                        get_mm_hiwater_vm()
                        mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                            might_sleep()
                            atomic_dec_and_test()
                            uprobe_clear_state()
                            exit_aio()
                            ksm_exit()
                            khugepaged_exit()
                            exit_mmap()
                            set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                rcu_dereference_raw()
                                get_file()
                                rcu_assign_pointer()
                                fput()
                            list_empty()
                            spin_lock()
                            list_del()
                            spin_unlock()
                            module_put() <void module_put (struct module *module) at module.c:1098>:
                                preempt_disable()
                                atomic_dec_if_positive()
                                WARN_ON()
                                trace_module_put()
                                preempt_enable()
                            mmdrop()
                task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                    pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                    task_tgid()
                send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                    nlmsg_data()
                    nlmsg_hdr()
                    genlmsg_data()
                    genlmsg_end()
                    down_read()
                    list_for_each_entry()
                    list_is_last()
                    skb_clone()
                    genlmsg_unicast()
                    up_read()
                    nlmsg_free()
                    down_write()
                    list_for_each_entry_safe()
                    list_del()
                    kfree()
                    up_write()
                nlmsg_free()
            exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
                mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                    unlikely()
                    exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                        uninitialized_var()
                        fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                            get_user()
                        get_user()
                        handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                            uninitialized_var()
                            get_user()
                            task_pid_vnr()
                            cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                pagefault_disable()
                                futex_atomic_cmpxchg_inatomic()
                                pagefault_enable()
                            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                down_read()
                                fixup_user_fault()
                                up_read()
                            futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                WAKE_Q()
                                get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                    unlikely()
                                    access_ok()
                                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                        should_fail()
                                    get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                        ihold()
                                        futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                            atomic_inc()
                                            smp_mb__after_atomic()
                                        smp_mb()
                                    get_user_pages_fast()
                                    lock_page()
                                    compound_head()
                                    PageSwapCache()
                                    unlock_page()
                                    put_page()
                                    PageAnon()
                                    basepage_index()
                                unlikely()
                                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                    jhash2()
                                hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                    atomic_read()
                                spin_lock()
                                plist_for_each_entry_safe()
                                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                    WARN()
                                    wake_q_add()
                                    smp_wmb()
                                spin_unlock()
                                wake_up_q()
                                put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                    drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                        WARN_ON_ONCE()
                                        iput()
                                        mmdrop()
                        cond_resched()
                    compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                        uninitialized_var()
                        fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                            get_user()
                            compat_ptr()
                        get_user()
                        futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                            ptr_to_compat()
                            compat_ptr()
                        handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                            uninitialized_var()
                            get_user()
                            task_pid_vnr()
                            cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                pagefault_disable()
                                futex_atomic_cmpxchg_inatomic()
                                pagefault_enable()
                            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                down_read()
                                fixup_user_fault()
                                up_read()
                            futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                WAKE_Q()
                                get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                    unlikely()
                                    access_ok()
                                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                        should_fail()
                                    get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                        ihold()
                                        futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                            atomic_inc()
                                            smp_mb__after_atomic()
                                        smp_mb()
                                    get_user_pages_fast()
                                    lock_page()
                                    compound_head()
                                    PageSwapCache()
                                    unlock_page()
                                    put_page()
                                    PageAnon()
                                    basepage_index()
                                unlikely()
                                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                    jhash2()
                                hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                    atomic_read()
                                spin_lock()
                                plist_for_each_entry_safe()
                                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                    WARN()
                                    wake_q_add()
                                    smp_wmb()
                                spin_unlock()
                                wake_up_q()
                                put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                    drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                        WARN_ON_ONCE()
                                        iput()
                                        mmdrop()
                        cond_resched()
                    list_empty()
                    exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                        raw_spin_lock_irq()
                        list_empty()
                        list_entry()
                        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                            jhash2()
                        raw_spin_unlock_irq()
                        spin_lock()
                        spin_unlock()
                        WARN_ON()
                        list_del_init()
                        rt_mutex_unlock()
                    uprobe_free_utask()
                    deactivate_mm()
                    atomic_read()
                    put_user()
                    sys_futex()
                    complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                        task_lock()
                        likely()
                        complete()
                        task_unlock()
                sync_mm_rss()
                down_read()
                up_read()
                xchg()
                atomic_dec_and_test()
                complete()
                set_task_state()
                freezable_schedule()
                atomic_inc()
                BUG_ON()
                task_lock()
                enter_lazy_tlb()
                task_unlock()
                mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                    atomic_read()
                    read_lock()
                    list_for_each_entry()
                    for_each_process()
                    for_each_thread()
                    read_unlock()
                    BUG_ON()
                    get_task_struct()
                    task_lock()
                    task_unlock()
                    put_task_struct()
                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                    might_sleep()
                    atomic_dec_and_test()
                    uprobe_clear_state()
                    exit_aio()
                    ksm_exit()
                    khugepaged_exit()
                    exit_mmap()
                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                        rcu_dereference_raw()
                        get_file()
                        rcu_assign_pointer()
                        fput()
                    list_empty()
                    spin_lock()
                    list_del()
                    spin_unlock()
                    module_put() <void module_put (struct module *module) at module.c:1098>:
                        preempt_disable()
                        atomic_dec_if_positive()
                        WARN_ON()
                        trace_module_put()
                        preempt_enable()
                    mmdrop()
                test_thread_flag()
                exit_oom_victim()
            acct_process() <void acct_process (void) at acct.c:587>:
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                unlikely()
                slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                    acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                        smp_rmb()
                        rcu_read_lock()
                        to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                            container_of()
                        ACCESS_ONCE()
                        rcu_read_unlock()
                        atomic_long_inc_not_zero()
                        cpu_relax()
                        mutex_lock()
                        mutex_unlock()
                        acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                            atomic_long_dec_and_test()
                            kfree_rcu()
                    do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                        override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                            kdebug()
                            atomic_read()
                            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                atomic_read()
                            validate_creds()
                            get_cred()
                            alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                atomic_add()
                            rcu_assign_pointer()
                        check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                            time_is_before_jiffies()
                            vfs_statfs()
                            do_div()
                            pr_info()
                        fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                            strlcpy()
                            ktime_get_ns()
                            nsec_to_AHZ()
                            encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                            encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                            encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                            do_div()
                            get_seconds()
                            spin_lock_irq()
                            old_encode_dev()
                            tty_devnum()
                            jiffies_to_AHZ()
                            cputime_to_jiffies()
                            spin_unlock_irq()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                            from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                            pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                            task_tgid()
                        rcu_read_lock()
                        rcu_dereference()
                        rcu_read_unlock()
                        file_start_write_trylock()
                        file_end_write()
                        revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                            kdebug()
                            atomic_read()
                            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                atomic_read()
                            validate_creds()
                            alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                atomic_add()
                            rcu_assign_pointer()
                            put_cred()
                    mutex_unlock()
                    acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                        atomic_long_dec_and_test()
                        kfree_rcu()
            trace_sched_process_exit()
            exit_sem()
            exit_shm()
            exit_files()
            exit_fs()
            disassociate_ctty()
            exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
                switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                    might_sleep()
                    task_lock()
                    task_unlock()
                    atomic_dec_and_test()
                    free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                        put_mnt_ns()
                        put_uts_ns()
                        put_ipc_ns()
                        put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                            kref_put()
                            free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                container_of()
                                destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                    ns_free_inum()
                                    kfree()
                                    put_user_ns()
                                    call_rcu()
                                    delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                        kmem_cache_free()
                                        container_of()
                        put_net()
                        kmem_cache_free()
            exit_task_work()
            exit_thread()
            perf_event_exit_task()
            cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
                task_css_set()
                list_empty()
                spin_lock_bh()
                css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                    lockdep_assert_held()
                    WARN_ON_ONCE()
                    list_empty()
                    list_for_each_entry_safe()
                    css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                        lockdep_assert_held()
                        WARN_ON_ONCE()
                        css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                            lockdep_assert_held()
                            container_of()
                            list_entry()
                            css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                lockdep_assert_held()
                                list_empty()
                            list_empty()
                            list_del()
                            put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                                lockdep_assert_held()
                                atomic_dec_and_test()
                                for_each_subsys()
                                list_del()
                                css_put()
                                hash_del()
                                list_for_each_entry_safe()
                                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                    container_of()
                                cgroup_put()
                                kfree()
                                kfree_rcu()
                            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                atomic_inc()
                            list_add()
                    list_del_init()
                    css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                        lockdep_assert_held()
                        list_empty()
                    css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                        lockdep_assert_held()
                        list_for_each_entry()
                        cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                            lockdep_assert_held()
                            check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                                notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                    test_bit()
                                cgroup_is_populated()
                                css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                    rcu_read_lock()
                                    css_for_each_child()
                                    rcu_read_unlock()
                                cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                                schedule_work()
                            cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                                spin_lock_irqsave()
                                kernfs_notify()
                                spin_unlock_irqrestore()
                            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                container_of()
                    rcu_assign_pointer()
                    list_add_tail()
                spin_unlock_bh()
                get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                    atomic_inc()
                for_each_subsys_which()
            flush_ptrace_hw_breakpoint()
            preempt_disable()
            preempt_enable()
            exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
                LIST_HEAD()
                write_lock_irq()
                forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                    unlikely()
                    list_empty()
                    exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                        list_for_each_entry_safe()
                        unlikely()
                        send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                            valid_signal()
                            do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                lock_task_sighand()
                                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                        SI_FROMUSER()
                                    task_pid_nr_ns()
                                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                        ns_of_pid()
                                        task_pid()
                                unlock_task_sighand()
                        list_add()
                    find_child_reaper()
                    find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                        find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                            for_each_thread()
                        same_thread_group()
                    list_for_each_entry()
                    for_each_thread()
                    BUG_ON()
                    likely()
                    group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                        rcu_read_lock()
                        check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                            valid_signal()
                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                SI_FROMUSER()
                            audit_signal_info()
                            same_thread_group()
                            kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                                current_cred()
                                uid_eq()
                                ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                    unlikely()
                                    cap_valid()
                                    pr_crit()
                                    BUG()
                                    security_capable()
                                    current_cred()
                            task_session()
                            security_task_kill()
                        rcu_read_unlock()
                        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                            lock_task_sighand()
                            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                    SI_FROMUSER()
                                task_pid_nr_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                            unlock_task_sighand()
                    same_thread_group()
                    reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                        unlikely()
                        thread_group_empty()
                        do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                            BUG_ON()
                            task_is_stopped_or_traced()
                            thread_group_empty()
                            rcu_read_lock()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            task_cred_xxx()
                            task_uid()
                            rcu_read_unlock()
                            task_cputime()
                            cputime_to_clock_t()
                            spin_lock_irqsave()
                            valid_signal()
                            spin_unlock_irqrestore()
                        list_add()
                        kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                            task_pgrp()
                            task_session()
                            will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                                do_each_pid_task()
                                thread_group_empty()
                                is_global_init()
                                task_pgrp()
                                task_session()
                                while_each_pid_task()
                            has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                                do_each_pid_task()
                                while_each_pid_task()
                    list_splice_tail_init()
                kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                    task_pgrp()
                    task_session()
                    will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                        do_each_pid_task()
                        thread_group_empty()
                        is_global_init()
                        task_pgrp()
                        task_session()
                        while_each_pid_task()
                    has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                        do_each_pid_task()
                        while_each_pid_task()
                unlikely()
                thread_group_leader()
                thread_group_empty()
                ptrace_reparented()
                do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                    BUG_ON()
                    task_is_stopped_or_traced()
                    thread_group_empty()
                    rcu_read_lock()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_cred_xxx()
                    task_uid()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_clock_t()
                    spin_lock_irqsave()
                    valid_signal()
                    spin_unlock_irqrestore()
                list_add()
                wake_up_process()
                write_unlock_irq()
                list_for_each_entry_safe()
                list_del_init()
                release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                    rcu_read_lock()
                    atomic_dec()
                    rcu_read_unlock()
                    proc_flush_task()
                    write_lock_irq()
                    ptrace_release_task()
                    thread_group_empty()
                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                        BUG_ON()
                        task_is_stopped_or_traced()
                        thread_group_empty()
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        spin_lock_irqsave()
                        valid_signal()
                        spin_unlock_irqrestore()
                    write_unlock_irq()
                    release_thread()
                    call_rcu()
                    delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                        container_of()
                        perf_event_delayed_put()
                        trace_sched_process_free()
                        put_task_struct()
                    unlikely()
            proc_exit_connector()
            task_lock()
            mpol_put()
            task_unlock()
            kfree()
            debug_check_no_locks_held()
            exit_io_context()
            free_pipe_info()
            put_page()
            check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
                stack_not_used()
                spin_lock()
                pr_warn()
                task_pid_nr()
                spin_unlock()
            exit_rcu()
            BUG()
            cpu_relax()
get_taint() <unsigned long get_taint (void) at panic.c:317>:
get_task_cred() <const struct cred *get_task_cred (struct task_struct *task) at cred.c:187>:
    rcu_read_lock()
    BUG_ON()
    atomic_inc_not_zero()
    rcu_read_unlock()
get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
    task_lock()
    atomic_inc()
    task_unlock()
get_task_pid() <struct pid *get_task_pid (struct task_struct *task, enum pid_type type) at pid.c:464>:
    rcu_read_lock()
    get_pid()
    rcu_dereference()
    rcu_read_unlock()
get_zone_device_page() <void get_zone_device_page (struct page *page) at memremap.c:174>:
    percpu_ref_get()
getrusage() <int getrusage (struct task_struct *p, int who, struct rusage __user *ru) at sys.c:1616>:
    k_getrusage() <void k_getrusage (struct task_struct *p, int who, struct rusage *r) at sys.c:1542>:
        task_cputime_adjusted()
        accumulate_thread_rusage() <void accumulate_thread_rusage (struct task_struct *t, struct rusage *r) at sys.c:1532>:
            task_io_get_inblock()
            task_io_get_oublock()
        lock_task_sighand()
        thread_group_cputime_adjusted()
        while_each_thread()
        BUG()
        unlock_task_sighand()
        cputime_to_timeval()
        get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
            task_lock()
            atomic_inc()
            task_unlock()
        setmax_mm_hiwater_rss()
        mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
            might_sleep()
            atomic_dec_and_test()
            uprobe_clear_state()
            exit_aio()
            ksm_exit()
            khugepaged_exit()
            exit_mmap()
            set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                rcu_dereference_raw()
                get_file()
                rcu_assign_pointer()
                fput()
            list_empty()
            spin_lock()
            list_del()
            spin_unlock()
            module_put() <void module_put (struct module *module) at module.c:1098>:
                preempt_disable()
                atomic_dec_if_positive()
                WARN_ON()
                trace_module_put()
                preempt_enable()
            mmdrop()
    copy_to_user()
group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
    rcu_read_lock()
    check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
        valid_signal()
        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
            SI_FROMUSER()
        audit_signal_info()
        same_thread_group()
        kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
            current_cred()
            uid_eq()
            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                unlikely()
                cap_valid()
                pr_crit()
                BUG()
                security_capable()
                current_cred()
        task_session()
        security_task_kill()
    rcu_read_unlock()
    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
        lock_task_sighand()
        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                SI_FROMUSER()
            task_pid_nr_ns()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
        unlock_task_sighand()
groups_alloc() <struct group_info *groups_alloc (int gidsetsize) at groups.c:12>:
    kmalloc()
    atomic_set()
    free_page()
    kfree()
groups_free() <void groups_free (struct group_info *group_info) at groups.c:51>:
    free_page()
    kfree()
groups_search() <int groups_search (const struct group_info *group_info, kgid_t grp) at groups.c:133>:
    gid_gt()
    GROUP_AT()
    gid_lt()
handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
    uninitialized_var()
    get_user()
    task_pid_vnr()
    cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
        pagefault_disable()
        futex_atomic_cmpxchg_inatomic()
        pagefault_enable()
    fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
        down_read()
        fixup_user_fault()
        up_read()
    futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
        WAKE_Q()
        get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
            unlikely()
            access_ok()
            should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                should_fail()
            get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                ihold()
                futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                    atomic_inc()
                    smp_mb__after_atomic()
                smp_mb()
            get_user_pages_fast()
            lock_page()
            compound_head()
            PageSwapCache()
            unlock_page()
            put_page()
            PageAnon()
            basepage_index()
        unlikely()
        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
            jhash2()
        hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
            atomic_read()
        spin_lock()
        plist_for_each_entry_safe()
        match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
        mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
            WARN()
            wake_q_add()
            smp_wmb()
        spin_unlock()
        wake_up_q()
        put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
            drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                WARN_ON_ONCE()
                iput()
                mmdrop()
hardlockup_detector_disable() <void hardlockup_detector_disable (void) at watchdog.c:127>:
has_capability() <bool has_capability (struct task_struct *t, int cap) at capability.c:317>:
    has_ns_capability() <bool has_ns_capability (struct task_struct *t, struct user_namespace *ns, int cap) at capability.c:295>:
        rcu_read_lock()
        security_capable()
        rcu_read_unlock()
has_capability_noaudit() <bool has_capability_noaudit (struct task_struct *t, int cap) at capability.c:359>:
    has_ns_capability_noaudit() <bool has_ns_capability_noaudit (struct task_struct *t, struct user_namespace *ns, int cap) at capability.c:335>:
        rcu_read_lock()
        security_capable_noaudit()
        rcu_read_unlock()
has_ns_capability() <bool has_ns_capability (struct task_struct *t, struct user_namespace *ns, int cap) at capability.c:295>:
    rcu_read_lock()
    security_capable()
    rcu_read_unlock()
has_ns_capability_noaudit() <bool has_ns_capability_noaudit (struct task_struct *t, struct user_namespace *ns, int cap) at capability.c:335>:
    rcu_read_lock()
    security_capable_noaudit()
    rcu_read_unlock()
idle_thread_get() <struct task_struct *idle_thread_get (unsigned int cpu) at smpboot.c:28>:
    per_cpu()
    ERR_PTR()
    init_idle()
idle_thread_set_boot_cpu() <void __init idle_thread_set_boot_cpu (void) at smpboot.c:38>:
    per_cpu()
    smp_processor_id()
idle_threads_init() <void __init idle_threads_init (void) at smpboot.c:65>:
    smp_processor_id()
    for_each_possible_cpu()
    idle_init() <inline void idle_init (unsigned int cpu) at smpboot.c:49>:
        per_cpu()
        fork_idle() <struct task_struct *fork_idle (int cpu) at fork.c:1673>:
            copy_process() <struct task_struct *copy_process (unsigned long clone_flags, unsigned long stack_start, unsigned long stack_size, int __user *child_tidptr, struct pid *pid, int trace, unsigned long tls) at fork.c:1242>:
                ERR_PTR()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                security_task_create()
                dup_task_struct() <struct task_struct *dup_task_struct (struct task_struct *orig) at fork.c:334>:
                    tsk_fork_get_node() <int tsk_fork_get_node (struct task_struct *tsk) at kthread.c:216>:
                    alloc_task_struct_node() <inline struct task_struct *alloc_task_struct_node (int node) at fork.c:139>:
                        kmem_cache_alloc_node()
                    alloc_thread_info_node() <struct thread_info *alloc_thread_info_node (struct task_struct *tsk, int node) at fork.c:177>:
                        alloc_kmem_pages_node()
                        page_address()
                        kmem_cache_alloc_node()
                    arch_dup_task_struct() <int __weak arch_dup_task_struct (struct task_struct *dst, struct task_struct *src) at fork.c:319>
                    setup_thread_stack()
                    clear_user_return_notifier()
                    clear_tsk_need_resched()
                    set_task_stack_end_magic() <void set_task_stack_end_magic (struct task_struct *tsk) at fork.c:326>:
                        end_of_stack()
                    get_random_int()
                    atomic_set()
                    account_kernel_stack() <void account_kernel_stack (struct thread_info *ti, int account) at fork.c:215>:
                        page_zone()
                        virt_to_page()
                        mod_zone_page_state()
                    free_thread_info() <void free_thread_info (struct thread_info *ti) at fork.c:183>:
                        free_kmem_pages()
                        kmem_cache_free()
                    free_task_struct() <inline void free_task_struct (struct task_struct *tsk) at fork.c:144>:
                        kmem_cache_free()
                ftrace_graph_init_task()
                rt_mutex_init_task() <void rt_mutex_init_task (struct task_struct *p) at fork.c:1205>:
                    raw_spin_lock_init()
                DEBUG_LOCKS_WARN_ON()
                atomic_read()
                task_rlimit()
                capable() <bool capable (int cap) at capability.c:401>:
                    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                        unlikely()
                        cap_valid()
                        pr_crit()
                        BUG()
                        security_capable()
                        current_cred()
                copy_creds() <int copy_creds (struct task_struct *p, unsigned long clone_flags) at cred.c:322>:
                    get_cred()
                    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                        atomic_add()
                    kdebug()
                    atomic_read()
                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                        atomic_read()
                    atomic_inc()
                    prepare_creds() <struct cred *prepare_creds (void) at cred.c:243>:
                        validate_process_creds()
                        kmem_cache_alloc()
                        kdebug()
                        atomic_set()
                        set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
                            atomic_set()
                        get_group_info()
                        get_uid()
                        get_user_ns()
                        key_get()
                        security_prepare_creds()
                        validate_creds()
                        abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
                            kdebug()
                            atomic_read()
                            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                atomic_read()
                            BUG_ON()
                            put_cred()
                    create_user_ns() <int create_user_ns (struct cred *new) at user_namespace.c:60>:
                        current_chrooted()
                        kuid_has_mapping()
                        kgid_has_mapping()
                        kmem_cache_zalloc()
                        ns_alloc_inum()
                        kmem_cache_free()
                        atomic_set()
                        mutex_lock()
                        mutex_unlock()
                        set_cred_user_ns() <void set_cred_user_ns (struct cred *cred, struct user_namespace *user_ns) at user_namespace.c:33>:
                            key_put()
                        init_rwsem()
                    key_put()
                    install_thread_keyring_to_cred()
                    validate_creds()
                    put_cred()
                delayacct_tsk_init()
                INIT_LIST_HEAD()
                rcu_copy_process()
                spin_lock_init()
                init_sigpending()
                prev_cputime_init()
                seqcount_init()
                task_io_accounting_init()
                acct_clear_integrals() <void acct_clear_integrals (struct task_struct *tsk) at tsacct.c:174>
                posix_cpu_timers_init() <void posix_cpu_timers_init (struct task_struct *tsk) at fork.c:1218>:
                    INIT_LIST_HEAD()
                ktime_get_ns()
                ktime_get_boot_ns()
                threadgroup_change_begin()
                cgroup_fork() <void cgroup_fork (struct task_struct *child) at cgroup.c:5497>:
                    RCU_INIT_POINTER()
                    INIT_LIST_HEAD()
                mpol_dup()
                IS_ERR()
                PTR_ERR()
                sched_fork()
                perf_event_init_task()
                audit_alloc() <int audit_alloc (struct task_struct *tsk) at auditsc.c:920>:
                    likely()
                    audit_filter_task() <enum audit_state audit_filter_task (struct task_struct *tsk, char **key) at auditsc.c:708>:
                        rcu_read_lock()
                        list_for_each_entry_rcu()
                        audit_filter_rules() <int audit_filter_rules (struct task_struct *tsk, struct audit_krule *rule, struct audit_context *ctx, struct audit_names *name, enum audit_state *state, bool task_creation) at auditsc.c:438>:
                            rcu_dereference_check()
                            task_pid_nr()
                            audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                                BUG()
                            task_ppid_nr()
                            audit_exe_compare() <int audit_exe_compare (struct task_struct *tsk, struct audit_fsnotify_mark *mark) at audit_watch.c:541>:
                                rcu_read_lock()
                                rcu_dereference()
                                rcu_read_unlock()
                                audit_mark_compare() <int audit_mark_compare (struct audit_fsnotify_mark *mark, unsigned long ino, dev_t dev) at audit_fsnotify.c:69>:
                            audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
                                uid_eq()
                                uid_lt()
                                uid_lte()
                                uid_gt()
                                uid_gte()
                                BUG()
                            audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
                                gid_eq()
                                gid_lt()
                                gid_lte()
                                gid_gt()
                                gid_gte()
                                BUG()
                            in_group_p() <int in_group_p (kgid_t grp) at groups.c:255>:
                                current_cred()
                                gid_eq()
                                groups_search() <int groups_search (const struct group_info *group_info, kgid_t grp) at groups.c:133>:
                                    gid_gt()
                                    GROUP_AT()
                                    gid_lt()
                            in_egroup_p() <int in_egroup_p (kgid_t grp) at groups.c:267>:
                                current_cred()
                                gid_eq()
                                groups_search() <int groups_search (const struct group_info *group_info, kgid_t grp) at groups.c:133>:
                                    gid_gt()
                                    GROUP_AT()
                                    gid_lt()
                            MAJOR()
                            list_for_each_entry()
                            MINOR()
                            audit_watch_compare() <int audit_watch_compare (struct audit_watch *watch, unsigned long ino, dev_t dev) at audit_watch.c:139>:
                            match_tree_refs() <int match_tree_refs (struct audit_context *ctx, struct audit_tree *tree) at auditsc.c:287>:
                                audit_tree_match() <bool audit_tree_match (struct audit_chunk *chunk, struct audit_tree *tree) at audit_tree.c:200>:
                            audit_loginuid_set()
                            security_task_getsecid()
                            security_audit_rule_match()
                            audit_match_perm() <int audit_match_perm (struct audit_context *ctx, int mask) at auditsc.c:131>:
                                unlikely()
                                audit_classify_syscall()
                                audit_match_class() <int audit_match_class (int class, unsigned syscall) at auditfilter.c:197>:
                                    unlikely()
                                    AUDIT_WORD()
                                    AUDIT_BIT()
                                ACC_MODE()
                            audit_match_filetype() <int audit_match_filetype (struct audit_context *ctx, int val) at auditsc.c:174>:
                                unlikely()
                                list_for_each_entry()
                            audit_field_compare() <int audit_field_compare (struct task_struct *tsk, const struct cred *cred, struct audit_field *f, struct audit_context *ctx, struct audit_names *name) at auditsc.c:358>:
                                audit_compare_uid() <int audit_compare_uid (kuid_t uid, struct audit_names *name, struct audit_field *f, struct audit_context *ctx) at auditsc.c:310>:
                                    audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
                                        uid_eq()
                                        uid_lt()
                                        uid_lte()
                                        uid_gt()
                                        uid_gte()
                                        BUG()
                                    list_for_each_entry()
                                audit_compare_gid() <int audit_compare_gid (kgid_t gid, struct audit_names *name, struct audit_field *f, struct audit_context *ctx) at auditsc.c:334>:
                                    audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
                                        gid_eq()
                                        gid_lt()
                                        gid_lte()
                                        gid_gt()
                                        gid_gte()
                                        BUG()
                                    list_for_each_entry()
                                audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
                                    uid_eq()
                                    uid_lt()
                                    uid_lte()
                                    uid_gt()
                                    uid_gte()
                                    BUG()
                                audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
                                    gid_eq()
                                    gid_lt()
                                    gid_lte()
                                    gid_gt()
                                    gid_gte()
                                    BUG()
                                WARN()
                            kfree()
                            kstrdup()
                        kstrdup()
                        rcu_read_unlock()
                    clear_tsk_thread_flag()
                    audit_alloc_context() <inline struct audit_context *audit_alloc_context (enum audit_state state) at auditsc.c:897>:
                        kzalloc()
                        INIT_LIST_HEAD()
                    kfree()
                    audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                        atomic_inc()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                        printk_ratelimit()
                        pr_warn()
                        atomic_read()
                        audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                            printk_ratelimit()
                            pr_err()
                            panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                local_irq_disable()
                                raw_smp_processor_id()
                                atomic_cmpxchg()
                                panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                    cpu_relax()
                                console_verbose()
                                bust_spinlocks()
                                pr_emerg()
                                test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                    test_bit()
                                dump_stack()
                                smp_send_stop()
                                atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                kmsg_dump()
                                debug_locks_off()
                                console_flush_on_panic()
                                panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                no_blink() <long no_blink (int state) at panic.c:46>
                                touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                    raw_cpu_write()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                                mdelay()
                                emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                    kmsg_dump()
                                    machine_emergency_restart()
                                disabled_wait()
                                local_irq_enable()
                                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                        raw_cpu_write()
                                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                        per_cpu()
                                    raw_smp_processor_id()
                    set_tsk_thread_flag()
                shm_init_task()
                copy_semundo()
                copy_files() <int copy_files (unsigned long clone_flags, struct task_struct *tsk) at fork.c:1013>:
                    atomic_inc()
                    dup_fd()
                copy_fs() <int copy_fs (unsigned long clone_flags, struct task_struct *tsk) at fork.c:993>:
                    spin_lock()
                    spin_unlock()
                    copy_fs_struct()
                copy_sighand() <int copy_sighand (unsigned long clone_flags, struct task_struct *tsk) at fork.c:1066>:
                    atomic_inc()
                    kmem_cache_alloc()
                    rcu_assign_pointer()
                    atomic_set()
                copy_signal() <int copy_signal (unsigned long clone_flags, struct task_struct *tsk) at fork.c:1115>:
                    kmem_cache_zalloc()
                    atomic_set()
                    LIST_HEAD_INIT()
                    init_waitqueue_head()
                    init_sigpending()
                    INIT_LIST_HEAD()
                    seqlock_init()
                    prev_cputime_init()
                    hrtimer_init()
                    task_lock()
                    task_unlock()
                    posix_cpu_timers_init_group() <void posix_cpu_timers_init_group (struct signal_struct *sig) at fork.c:1099>:
                        READ_ONCE()
                        secs_to_cputime()
                        INIT_LIST_HEAD()
                    tty_audit_fork()
                    sched_autogroup_fork()
                    mutex_init()
                copy_mm() <int copy_mm (unsigned long clone_flags, struct task_struct *tsk) at fork.c:947>:
                    vmacache_flush()
                    atomic_inc()
                    dup_mm() <struct mm_struct *dup_mm (struct task_struct *tsk) at fork.c:912>:
                        allocate_mm()
                        mm_init() <struct mm_struct *mm_init (struct mm_struct *mm, struct task_struct *p) at fork.c:587>:
                            atomic_set()
                            init_rwsem()
                            INIT_LIST_HEAD()
                            atomic_long_set()
                            mm_nr_pmds_init()
                            spin_lock_init()
                            mm_init_cpumask()
                            mm_init_aio() <void mm_init_aio (struct mm_struct *mm) at fork.c:572>:
                                spin_lock_init()
                            mm_init_owner() <void mm_init_owner (struct mm_struct *mm, struct task_struct *p) at fork.c:580>
                            mmu_notifier_mm_init()
                            clear_tlb_flush_pending()
                            mm_alloc_pgd() <inline int mm_alloc_pgd (struct mm_struct *mm) at fork.c:529>:
                                pgd_alloc()
                                unlikely()
                            init_new_context()
                            mm_free_pgd() <inline void mm_free_pgd (struct mm_struct *mm) at fork.c:537>:
                                pgd_free()
                            free_mm()
                        dup_mmap() <int dup_mmap (struct mm_struct *mm, struct mm_struct *oldmm) at fork.c:542>:
                            uprobe_start_dup_mmap()
                            down_write()
                            flush_cache_dup_mm()
                            uprobe_dup_mmap()
                            down_write_nested()
                            RCU_INIT_POINTER()
                            get_mm_exe_file() <struct file *get_mm_exe_file (struct mm_struct *mm) at fork.c:752>:
                                rcu_read_lock()
                                rcu_dereference()
                                get_file_rcu()
                                rcu_read_unlock()
                            ksm_fork()
                            khugepaged_fork()
                            vm_stat_account()
                            vma_pages()
                            security_vm_enough_memory_mm()
                            kmem_cache_alloc()
                            INIT_LIST_HEAD()
                            vma_dup_policy()
                            anon_vma_fork()
                            file_inode()
                            get_file()
                            atomic_dec()
                            i_mmap_lock_write()
                            atomic_inc()
                            flush_dcache_mmap_lock()
                            vma_interval_tree_insert_after()
                            flush_dcache_mmap_unlock()
                            i_mmap_unlock_write()
                            is_vm_hugetlb_page()
                            reset_vma_resv_huge_pages()
                            copy_page_range()
                            arch_dup_mmap()
                            up_write()
                            flush_tlb_mm()
                            uprobe_end_dup_mmap()
                            mpol_put()
                            vma_policy()
                            kmem_cache_free()
                            vm_unacct_memory()
                        get_mm_rss()
                        try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
                            preempt_disable()
                            likely()
                            module_is_live()
                            atomic_inc_not_zero()
                            trace_module_get()
                            preempt_enable()
                        mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                            might_sleep()
                            atomic_dec_and_test()
                            uprobe_clear_state()
                            exit_aio()
                            ksm_exit()
                            khugepaged_exit()
                            exit_mmap()
                            set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                rcu_dereference_raw()
                                get_file()
                                rcu_assign_pointer()
                                fput()
                            list_empty()
                            spin_lock()
                            list_del()
                            spin_unlock()
                            module_put() <void module_put (struct module *module) at module.c:1098>:
                                preempt_disable()
                                atomic_dec_if_positive()
                                WARN_ON()
                                trace_module_put()
                                preempt_enable()
                            mmdrop()
                copy_namespaces() <int copy_namespaces (unsigned long flags, struct task_struct *tsk) at nsproxy.c:124>:
                    task_cred_xxx()
                    likely()
                    get_nsproxy()
                    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                        unlikely()
                        cap_valid()
                        pr_crit()
                        BUG()
                        security_capable()
                        current_cred()
                    create_new_namespaces() <struct nsproxy *create_new_namespaces (unsigned long flags, struct task_struct *tsk, struct user_namespace *user_ns, struct fs_struct *new_fs) at nsproxy.c:59>:
                        create_nsproxy() <inline struct nsproxy *create_nsproxy (void) at nsproxy.c:44>:
                            kmem_cache_alloc()
                            atomic_set()
                        ERR_PTR()
                        copy_mnt_ns()
                        IS_ERR()
                        PTR_ERR()
                        copy_utsname() <struct uts_namespace *copy_utsname (unsigned long flags, struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:66>:
                            BUG_ON()
                            get_uts_ns()
                            clone_uts_ns() <struct uts_namespace *clone_uts_ns (struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:35>:
                                create_uts_ns() <struct uts_namespace *create_uts_ns (void) at utsname.c:20>:
                                    kmalloc()
                                    kref_init()
                                ERR_PTR()
                                ns_alloc_inum()
                                kfree()
                                down_read()
                                get_user_ns()
                                up_read()
                            put_uts_ns()
                        copy_ipcs()
                        copy_pid_ns() <struct pid_namespace *copy_pid_ns (unsigned long flags, struct user_namespace *user_ns, struct pid_namespace *old_ns) at pid_namespace.c:153>:
                            get_pid_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                            ERR_PTR()
                            create_pid_namespace() <struct pid_namespace *create_pid_namespace (struct user_namespace *user_ns, struct pid_namespace *parent_pid_ns) at pid_namespace.c:82>:
                                kmem_cache_zalloc()
                                kzalloc()
                                create_pid_cachep() <struct kmem_cache *create_pid_cachep (int nr_ids) at pid_namespace.c:38>:
                                    mutex_lock()
                                    list_for_each_entry()
                                    kmalloc()
                                    kmem_cache_create()
                                    list_add()
                                    mutex_unlock()
                                    kfree()
                                ns_alloc_inum()
                                kref_init()
                                get_pid_ns()
                                get_user_ns()
                                INIT_WORK()
                                proc_cleanup_work() <void proc_cleanup_work (struct work_struct *work) at pid_namespace.c:73>:
                                    container_of()
                                    pid_ns_release_proc()
                                set_bit()
                                atomic_set()
                                kfree()
                                kmem_cache_free()
                                ERR_PTR()
                        copy_net_ns()
                        put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                            kref_put()
                            free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                container_of()
                                destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                    ns_free_inum()
                                    kfree()
                                    put_user_ns()
                                    call_rcu()
                                    delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                        kmem_cache_free()
                                        container_of()
                        put_ipc_ns()
                        put_uts_ns()
                        put_mnt_ns()
                        kmem_cache_free()
                    IS_ERR()
                    PTR_ERR()
                copy_io() <int copy_io (unsigned long clone_flags, struct task_struct *tsk) at fork.c:1040>:
                    ioc_task_link()
                    ioprio_valid()
                    get_task_io_context()
                    unlikely()
                    put_io_context()
                copy_thread_tls()
                alloc_pid() <struct pid *alloc_pid (struct pid_namespace *ns) at pid.c:297>:
                    kmem_cache_alloc()
                    ERR_PTR()
                    alloc_pidmap() <int alloc_pidmap (struct pid_namespace *pid_ns) at pid.c:154>:
                        DIV_ROUND_UP()
                        unlikely()
                        kzalloc()
                        spin_lock_irq()
                        spin_unlock_irq()
                        kfree()
                        likely()
                        atomic_read()
                        test_and_set_bit()
                        atomic_dec()
                        set_last_pid() <void set_last_pid (struct pid_namespace *pid_ns, int base, int pid) at pid.c:144>:
                            cmpxchg()
                            pid_before() <int pid_before (int base, int a, int b) at pid.c:118>
                        find_next_offset()
                        mk_pid() <inline int mk_pid (struct pid_namespace *pid_ns, struct pidmap *map, int off) at pid.c:55>:
                    IS_ERR_VALUE()
                    unlikely()
                    is_child_reaper()
                    pid_ns_prepare_proc()
                    get_pid_ns()
                    atomic_set()
                    INIT_HLIST_HEAD()
                    spin_lock_irq()
                    hlist_add_head_rcu()
                    pid_hashfn()
                    spin_unlock_irq()
                    put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                        kref_put()
                        free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                            container_of()
                            destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                ns_free_inum()
                                kfree()
                                put_user_ns()
                                call_rcu()
                                delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                    kmem_cache_free()
                                    container_of()
                    free_pidmap() <void free_pidmap (struct upid *upid) at pid.c:105>:
                        clear_bit()
                        atomic_inc()
                    kmem_cache_free()
                user_disable_single_step()
                clear_tsk_thread_flag()
                clear_all_latency_tracing() <void clear_all_latency_tracing (struct task_struct *p) at latencytop.c:68>:
                    raw_spin_lock_irqsave()
                    raw_spin_unlock_irqrestore()
                pid_nr()
                cgroup_can_fork() <int cgroup_can_fork (struct task_struct *child) at cgroup.c:5511>:
                    for_each_subsys_which()
                    for_each_subsys()
                write_lock_irq()
                spin_lock()
                copy_seccomp() <void copy_seccomp (struct task_struct *p) at fork.c:1165>:
                    assert_spin_locked()
                    get_seccomp_filter() <void get_seccomp_filter (struct task_struct *tsk) at seccomp.c:461>:
                        atomic_inc()
                    task_no_new_privs()
                    task_set_no_new_privs()
                    set_tsk_thread_flag()
                recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
                    recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                        PENDING()
                        set_tsk_thread_flag()
                    freezing()
                    clear_thread_flag()
                signal_pending()
                spin_unlock()
                write_unlock_irq()
                likely()
                ptrace_init_task()
                init_task_pid() <inline void init_task_pid (struct task_struct *task, enum pid_type type, struct pid *pid) at fork.c:1229>
                thread_group_leader()
                task_pgrp()
                task_session()
                is_child_reaper()
                ns_of_pid()
                tty_kref_get()
                list_add_tail()
                list_add_tail_rcu()
                attach_pid() <void attach_pid (struct task_struct *task, enum pid_type type) at pid.c:389>:
                    hlist_add_head_rcu()
                atomic_inc()
                syscall_tracepoint_update()
                proc_fork_connector()
                cgroup_post_fork() <void cgroup_post_fork (struct task_struct *child) at cgroup.c:5562>:
                    spin_lock_bh()
                    task_css_set()
                    list_empty()
                    get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                        atomic_inc()
                    css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                        lockdep_assert_held()
                        WARN_ON_ONCE()
                        list_empty()
                        list_for_each_entry_safe()
                        css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                            lockdep_assert_held()
                            WARN_ON_ONCE()
                            css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                                lockdep_assert_held()
                                container_of()
                                list_entry()
                                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                    lockdep_assert_held()
                                    list_empty()
                                list_empty()
                                list_del()
                                put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                                    lockdep_assert_held()
                                    atomic_dec_and_test()
                                    for_each_subsys()
                                    list_del()
                                    css_put()
                                    hash_del()
                                    list_for_each_entry_safe()
                                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                        container_of()
                                    cgroup_put()
                                    kfree()
                                    kfree_rcu()
                                get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                    atomic_inc()
                                list_add()
                        list_del_init()
                        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                            lockdep_assert_held()
                            list_empty()
                        css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                            lockdep_assert_held()
                            list_for_each_entry()
                            cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                                lockdep_assert_held()
                                check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                                    notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                        test_bit()
                                    cgroup_is_populated()
                                    css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                        rcu_read_lock()
                                        css_for_each_child()
                                        rcu_read_unlock()
                                    cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                                    schedule_work()
                                cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                                    spin_lock_irqsave()
                                    kernfs_notify()
                                    spin_unlock_irqrestore()
                                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                    container_of()
                        rcu_assign_pointer()
                        list_add_tail()
                    spin_unlock_bh()
                    for_each_subsys_which()
                threadgroup_change_end()
                perf_event_fork()
                trace_task_newtask()
                uprobe_copy_process()
                cgroup_cancel_fork() <void cgroup_cancel_fork (struct task_struct *child) at cgroup.c:5542>:
                    for_each_subsys()
                free_pid() <void free_pid (struct pid *pid) at pid.c:259>:
                    spin_lock_irqsave()
                    hlist_del_rcu()
                    wake_up_process()
                    WARN_ON()
                    schedule_work()
                    spin_unlock_irqrestore()
                    free_pidmap() <void free_pidmap (struct upid *upid) at pid.c:105>:
                        clear_bit()
                        atomic_inc()
                    call_rcu()
                    delayed_put_pid() <void delayed_put_pid (struct rcu_head *rhp) at pid.c:253>:
                        container_of()
                        put_pid() <void put_pid (struct pid *pid) at pid.c:237>:
                            atomic_read()
                            atomic_dec_and_test()
                            kmem_cache_free()
                            put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                                kref_put()
                                free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                    container_of()
                                    destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                        ns_free_inum()
                                        kfree()
                                        put_user_ns()
                                        call_rcu()
                                        delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                            kmem_cache_free()
                                            container_of()
                exit_io_context()
                exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
                    switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                        might_sleep()
                        task_lock()
                        task_unlock()
                        atomic_dec_and_test()
                        free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                            put_mnt_ns()
                            put_uts_ns()
                            put_ipc_ns()
                            put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                                kref_put()
                                free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                    container_of()
                                    destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                        ns_free_inum()
                                        kfree()
                                        put_user_ns()
                                        call_rcu()
                                        delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                            kmem_cache_free()
                                            container_of()
                            put_net()
                            kmem_cache_free()
                mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                    might_sleep()
                    atomic_dec_and_test()
                    uprobe_clear_state()
                    exit_aio()
                    ksm_exit()
                    khugepaged_exit()
                    exit_mmap()
                    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                        rcu_dereference_raw()
                        get_file()
                        rcu_assign_pointer()
                        fput()
                    list_empty()
                    spin_lock()
                    list_del()
                    spin_unlock()
                    module_put() <void module_put (struct module *module) at module.c:1098>:
                        preempt_disable()
                        atomic_dec_if_positive()
                        WARN_ON()
                        trace_module_put()
                        preempt_enable()
                    mmdrop()
                free_signal_struct() <inline void free_signal_struct (struct signal_struct *sig) at fork.c:235>:
                    taskstats_tgid_free()
                    sched_autogroup_exit()
                    kmem_cache_free()
                exit_fs()
                exit_files()
                exit_sem()
                audit_free()
                perf_event_free_task()
                mpol_put()
                delayacct_tsk_free()
                atomic_dec()
                exit_creds() <void exit_creds (struct task_struct *tsk) at cred.c:156>:
                    kdebug()
                    atomic_read()
                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                        atomic_read()
                    validate_creds()
                    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                        atomic_add()
                    put_cred()
                free_task() <void free_task (struct task_struct *tsk) at fork.c:222>:
                    account_kernel_stack() <void account_kernel_stack (struct thread_info *ti, int account) at fork.c:215>:
                        page_zone()
                        virt_to_page()
                        mod_zone_page_state()
                    arch_release_thread_info() <void __weak arch_release_thread_info (struct thread_info *ti) at fork.c:150>
                    free_thread_info() <void free_thread_info (struct thread_info *ti) at fork.c:183>:
                        free_kmem_pages()
                        kmem_cache_free()
                    rt_mutex_debug_task_free()
                    ftrace_graph_exit_task()
                    put_seccomp_filter() <void put_seccomp_filter (struct task_struct *tsk) at seccomp.c:479>:
                        atomic_dec_and_test()
                        seccomp_filter_free() <inline void seccomp_filter_free (struct seccomp_filter *filter) at seccomp.c:470>:
                            bpf_prog_destroy()
                            kfree()
                    arch_release_task_struct() <void __weak arch_release_task_struct (struct task_struct *tsk) at fork.c:132>
                    free_task_struct() <inline void free_task_struct (struct task_struct *tsk) at fork.c:144>:
                        kmem_cache_free()
            IS_ERR()
            init_idle_pids() <inline void init_idle_pids (struct pid_link *links) at fork.c:1663>:
                INIT_HLIST_NODE()
            init_idle()
        IS_ERR()
        pr_err()
ignore_signals() <void ignore_signals (struct task_struct *t) at signal.c:464>:
    flush_signals() <void flush_signals (struct task_struct *t) at signal.c:419>:
        spin_lock_irqsave()
        clear_tsk_thread_flag()
        flush_sigqueue() <void flush_sigqueue (struct sigpending *queue) at signal.c:404>:
            list_empty()
            list_entry()
            list_del_init()
        spin_unlock_irqrestore()
in_egroup_p() <int in_egroup_p (kgid_t grp) at groups.c:267>:
    current_cred()
    gid_eq()
    groups_search() <int groups_search (const struct group_info *group_info, kgid_t grp) at groups.c:133>:
        gid_gt()
        GROUP_AT()
        gid_lt()
in_group_p() <int in_group_p (kgid_t grp) at groups.c:255>:
    current_cred()
    gid_eq()
    groups_search() <int groups_search (const struct group_info *group_info, kgid_t grp) at groups.c:133>:
        gid_gt()
        GROUP_AT()
        gid_lt()
init_cpu_online() <void init_cpu_online (const struct cpumask *src) at cpu.c:788>:
    cpumask_copy()
init_cpu_possible() <void init_cpu_possible (const struct cpumask *src) at cpu.c:783>:
    cpumask_copy()
init_cpu_present() <void init_cpu_present (const struct cpumask *src) at cpu.c:778>:
    cpumask_copy()
init_test_probes() <int init_test_probes (void) at test_kprobes.c:337>:
    target()
    kprobe_target() <noinline u32 kprobe_target (u32 value) at test_kprobes.c:30>:
    target2()
    kprobe_target2() <noinline u32 kprobe_target2 (u32 value) at test_kprobes.c:83>:
    prandom_u32()
    pr_info()
    test_kprobe() <int test_kprobe (void) at test_kprobes.c:57>:
        register_kprobe() <int register_kprobe (struct kprobe *p) at kprobes.c:1481>:
            kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
                kprobe_lookup_name()
                ERR_PTR()
            IS_ERR()
            PTR_ERR()
            check_kprobe_rereg() <inline int check_kprobe_rereg (struct kprobe *p) at kprobes.c:1402>:
                mutex_lock()
                mutex_unlock()
            INIT_LIST_HEAD()
            check_kprobe_address_safe() <int check_kprobe_address_safe (struct kprobe *p, struct module **probed_mod) at kprobes.c:1432>:
                arch_check_ftrace_location() <int __weak arch_check_ftrace_location (struct kprobe *p) at kprobes.c:1414>:
                    ftrace_location()
                jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                    mutex_lock()
                preempt_disable()
                kernel_text_address() <int kernel_text_address (unsigned long addr) at extable.c:120>:
                    core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
                        init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
                    is_module_text_address() <bool is_module_text_address (unsigned long addr) at module.c:4052>:
                        preempt_disable()
                        preempt_enable()
                    is_ftrace_trampoline()
                within_kprobe_blacklist() <bool within_kprobe_blacklist (unsigned long addr) at kprobes.c:1335>:
                    arch_within_kprobe_blacklist() <bool __weak arch_within_kprobe_blacklist (unsigned long addr) at kprobes.c:1328>:
                    list_for_each_entry()
                jump_label_text_reserved() <int jump_label_text_reserved (void *start, void *end) at jump_label.c:451>:
                unlikely()
                try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
                    preempt_disable()
                    likely()
                    module_is_live()
                    atomic_inc_not_zero()
                    trace_module_get()
                    preempt_enable()
                within_module_init()
                module_put() <void module_put (struct module *module) at module.c:1098>:
                    preempt_disable()
                    atomic_dec_if_positive()
                    WARN_ON()
                    trace_module_put()
                    preempt_enable()
                preempt_enable()
                jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                    mutex_unlock()
            mutex_lock()
            get_kprobe() <struct kprobe *get_kprobe (void *addr) at kprobes.c:304>:
                hash_ptr()
                hlist_for_each_entry_rcu()
            register_aggr_kprobe() <int register_aggr_kprobe (struct kprobe *orig_p, struct kprobe *p) at kprobes.c:1257>:
                jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                    mutex_lock()
                get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                    might_sleep()
                    cpuhp_lock_acquire_read()
                    mutex_lock()
                    atomic_inc()
                    mutex_unlock()
                mutex_lock()
                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                    kzalloc()
                    INIT_LIST_HEAD()
                    arch_prepare_optimized_kprobe()
                init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                    copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                    flush_insn_slot()
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                    kprobe_gone()
                    aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    INIT_LIST_HEAD()
                    INIT_HLIST_NODE()
                    list_add_rcu()
                    hlist_replace_rcu()
                kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    kprobe_disabled()
                    list_empty()
                reuse_unused_kprobe() <void reuse_unused_kprobe (struct kprobe *ap) at kprobes.c:898>:
                    BUG_ON()
                    kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        kprobe_disabled()
                        list_empty()
                    container_of()
                    unlikely()
                    list_empty()
                    printk()
                    kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        container_of()
                        arch_prepared_optinsn()
                    optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                        kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            container_of()
                            arch_prepared_optinsn()
                        kprobe_disabled()
                        container_of()
                        arch_check_optimized_kprobe()
                        list_empty()
                        list_del_init()
                        list_add()
                        kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                            schedule_delayed_work()
                kprobe_gone()
                arch_prepare_kprobe()
                prepare_optimized_kprobe() <void prepare_optimized_kprobe (struct kprobe *p) at kprobes.c:715>:
                    container_of()
                    arch_prepare_optimized_kprobe()
                copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                add_new_kprobe() <int add_new_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1207>:
                    BUG_ON()
                    kprobe_gone()
                    unoptimize_kprobe() <void unoptimize_kprobe (struct kprobe *p, bool force) at kprobes.c:629>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        kprobe_disarmed() <inline int kprobe_disarmed (struct kprobe *p) at kprobes.c:390>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            kprobe_disabled()
                            container_of()
                            list_empty()
                        container_of()
                        kprobe_optimized()
                        list_empty()
                        list_del_init()
                        force_unoptimize_kprobe() <void force_unoptimize_kprobe (struct optimized_kprobe *op) at kprobes.c:619>:
                            get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                                might_sleep()
                                cpuhp_lock_acquire_read()
                                mutex_lock()
                                atomic_inc()
                                mutex_unlock()
                            arch_unoptimize_kprobe()
                            put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                                atomic_dec_return()
                                WARN_ON()
                                atomic_inc()
                                waitqueue_active()
                                wake_up()
                                cpuhp_lock_release()
                            kprobe_disabled()
                            arch_disarm_kprobe()
                        list_add()
                        kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                            schedule_delayed_work()
                    list_add_tail_rcu()
                    aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    list_add_rcu()
                    aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                mutex_unlock()
                put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                    atomic_dec_return()
                    WARN_ON()
                    atomic_inc()
                    waitqueue_active()
                    wake_up()
                    cpuhp_lock_release()
                jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                    mutex_unlock()
                kprobe_disabled()
                arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                    unlikely()
                    kprobe_ftrace()
                    arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                        ftrace_set_filter_ip()
                        WARN()
                        register_ftrace_function()
                    mutex_lock()
                    mutex_unlock()
            prepare_kprobe() <int prepare_kprobe (struct kprobe *p) at kprobes.c:924>:
                kprobe_ftrace()
                arch_prepare_kprobe()
                arch_prepare_kprobe_ftrace()
            mutex_unlock()
            INIT_HLIST_NODE()
            hlist_add_head_rcu()
            hash_ptr()
            kprobe_disabled()
            arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                unlikely()
                kprobe_ftrace()
                arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                    ftrace_set_filter_ip()
                    WARN()
                    register_ftrace_function()
                mutex_lock()
                mutex_unlock()
            try_to_optimize_kprobe() <void try_to_optimize_kprobe (struct kprobe *p) at kprobes.c:745>:
                kprobe_ftrace()
                jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                    mutex_lock()
                mutex_lock()
                alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                    kzalloc()
                    INIT_LIST_HEAD()
                    arch_prepare_optimized_kprobe()
                container_of()
                arch_prepared_optinsn()
                arch_remove_optimized_kprobe()
                kfree()
                init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                    copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                    flush_insn_slot()
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                    kprobe_gone()
                    aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    INIT_LIST_HEAD()
                    INIT_HLIST_NODE()
                    list_add_rcu()
                    hlist_replace_rcu()
                optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                    kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        container_of()
                        arch_prepared_optinsn()
                    kprobe_disabled()
                    container_of()
                    arch_check_optimized_kprobe()
                    list_empty()
                    list_del_init()
                    list_add()
                    kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                        schedule_delayed_work()
                mutex_unlock()
                jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                    mutex_unlock()
            module_put() <void module_put (struct module *module) at module.c:1098>:
                preempt_disable()
                atomic_dec_if_positive()
                WARN_ON()
                trace_module_put()
                preempt_enable()
        pr_err()
        target()
        unregister_kprobe() <void unregister_kprobe (struct kprobe *p) at kprobes.c:1683>:
            unregister_kprobes() <void unregister_kprobes (struct kprobe **kps, int num) at kprobes.c:1689>:
                mutex_lock()
                mutex_unlock()
                synchronize_sched()
    test_kprobes() <int test_kprobes (void) at test_kprobes.c:110>:
        register_kprobes() <int register_kprobes (struct kprobe **kps, int num) at kprobes.c:1665>:
            register_kprobe() <int register_kprobe (struct kprobe *p) at kprobes.c:1481>:
                kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
                    kprobe_lookup_name()
                    ERR_PTR()
                IS_ERR()
                PTR_ERR()
                check_kprobe_rereg() <inline int check_kprobe_rereg (struct kprobe *p) at kprobes.c:1402>:
                    mutex_lock()
                    mutex_unlock()
                INIT_LIST_HEAD()
                check_kprobe_address_safe() <int check_kprobe_address_safe (struct kprobe *p, struct module **probed_mod) at kprobes.c:1432>:
                    arch_check_ftrace_location() <int __weak arch_check_ftrace_location (struct kprobe *p) at kprobes.c:1414>:
                        ftrace_location()
                    jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                        mutex_lock()
                    preempt_disable()
                    kernel_text_address() <int kernel_text_address (unsigned long addr) at extable.c:120>:
                        core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
                            init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
                        is_module_text_address() <bool is_module_text_address (unsigned long addr) at module.c:4052>:
                            preempt_disable()
                            preempt_enable()
                        is_ftrace_trampoline()
                    within_kprobe_blacklist() <bool within_kprobe_blacklist (unsigned long addr) at kprobes.c:1335>:
                        arch_within_kprobe_blacklist() <bool __weak arch_within_kprobe_blacklist (unsigned long addr) at kprobes.c:1328>:
                        list_for_each_entry()
                    jump_label_text_reserved() <int jump_label_text_reserved (void *start, void *end) at jump_label.c:451>:
                    unlikely()
                    try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
                        preempt_disable()
                        likely()
                        module_is_live()
                        atomic_inc_not_zero()
                        trace_module_get()
                        preempt_enable()
                    within_module_init()
                    module_put() <void module_put (struct module *module) at module.c:1098>:
                        preempt_disable()
                        atomic_dec_if_positive()
                        WARN_ON()
                        trace_module_put()
                        preempt_enable()
                    preempt_enable()
                    jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                        mutex_unlock()
                mutex_lock()
                get_kprobe() <struct kprobe *get_kprobe (void *addr) at kprobes.c:304>:
                    hash_ptr()
                    hlist_for_each_entry_rcu()
                register_aggr_kprobe() <int register_aggr_kprobe (struct kprobe *orig_p, struct kprobe *p) at kprobes.c:1257>:
                    jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                        mutex_lock()
                    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                        might_sleep()
                        cpuhp_lock_acquire_read()
                        mutex_lock()
                        atomic_inc()
                        mutex_unlock()
                    mutex_lock()
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                        kzalloc()
                        INIT_LIST_HEAD()
                        arch_prepare_optimized_kprobe()
                    init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                        copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                        flush_insn_slot()
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                        kprobe_gone()
                        aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        INIT_LIST_HEAD()
                        INIT_HLIST_NODE()
                        list_add_rcu()
                        hlist_replace_rcu()
                    kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        kprobe_disabled()
                        list_empty()
                    reuse_unused_kprobe() <void reuse_unused_kprobe (struct kprobe *ap) at kprobes.c:898>:
                        BUG_ON()
                        kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            kprobe_disabled()
                            list_empty()
                        container_of()
                        unlikely()
                        list_empty()
                        printk()
                        kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            container_of()
                            arch_prepared_optinsn()
                        optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                            kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                        list_for_each_entry_rcu()
                                        likely()
                                        kprobe_disabled()
                                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                container_of()
                                arch_prepared_optinsn()
                            kprobe_disabled()
                            container_of()
                            arch_check_optimized_kprobe()
                            list_empty()
                            list_del_init()
                            list_add()
                            kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                                schedule_delayed_work()
                    kprobe_gone()
                    arch_prepare_kprobe()
                    prepare_optimized_kprobe() <void prepare_optimized_kprobe (struct kprobe *p) at kprobes.c:715>:
                        container_of()
                        arch_prepare_optimized_kprobe()
                    copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                    add_new_kprobe() <int add_new_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1207>:
                        BUG_ON()
                        kprobe_gone()
                        unoptimize_kprobe() <void unoptimize_kprobe (struct kprobe *p, bool force) at kprobes.c:629>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            kprobe_disarmed() <inline int kprobe_disarmed (struct kprobe *p) at kprobes.c:390>:
                                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                        list_for_each_entry_rcu()
                                        likely()
                                        kprobe_disabled()
                                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                kprobe_disabled()
                                container_of()
                                list_empty()
                            container_of()
                            kprobe_optimized()
                            list_empty()
                            list_del_init()
                            force_unoptimize_kprobe() <void force_unoptimize_kprobe (struct optimized_kprobe *op) at kprobes.c:619>:
                                get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                                    might_sleep()
                                    cpuhp_lock_acquire_read()
                                    mutex_lock()
                                    atomic_inc()
                                    mutex_unlock()
                                arch_unoptimize_kprobe()
                                put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                                    atomic_dec_return()
                                    WARN_ON()
                                    atomic_inc()
                                    waitqueue_active()
                                    wake_up()
                                    cpuhp_lock_release()
                                kprobe_disabled()
                                arch_disarm_kprobe()
                            list_add()
                            kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                                schedule_delayed_work()
                        list_add_tail_rcu()
                        aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        list_add_rcu()
                        aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    mutex_unlock()
                    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                        atomic_dec_return()
                        WARN_ON()
                        atomic_inc()
                        waitqueue_active()
                        wake_up()
                        cpuhp_lock_release()
                    jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                        mutex_unlock()
                    kprobe_disabled()
                    arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                        unlikely()
                        kprobe_ftrace()
                        arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                            ftrace_set_filter_ip()
                            WARN()
                            register_ftrace_function()
                        mutex_lock()
                        mutex_unlock()
                prepare_kprobe() <int prepare_kprobe (struct kprobe *p) at kprobes.c:924>:
                    kprobe_ftrace()
                    arch_prepare_kprobe()
                    arch_prepare_kprobe_ftrace()
                mutex_unlock()
                INIT_HLIST_NODE()
                hlist_add_head_rcu()
                hash_ptr()
                kprobe_disabled()
                arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                    unlikely()
                    kprobe_ftrace()
                    arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                        ftrace_set_filter_ip()
                        WARN()
                        register_ftrace_function()
                    mutex_lock()
                    mutex_unlock()
                try_to_optimize_kprobe() <void try_to_optimize_kprobe (struct kprobe *p) at kprobes.c:745>:
                    kprobe_ftrace()
                    jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                        mutex_lock()
                    mutex_lock()
                    alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                        kzalloc()
                        INIT_LIST_HEAD()
                        arch_prepare_optimized_kprobe()
                    container_of()
                    arch_prepared_optinsn()
                    arch_remove_optimized_kprobe()
                    kfree()
                    init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                        copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                        flush_insn_slot()
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                        kprobe_gone()
                        aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        INIT_LIST_HEAD()
                        INIT_HLIST_NODE()
                        list_add_rcu()
                        hlist_replace_rcu()
                    optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                        kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            container_of()
                            arch_prepared_optinsn()
                        kprobe_disabled()
                        container_of()
                        arch_check_optimized_kprobe()
                        list_empty()
                        list_del_init()
                        list_add()
                        kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                            schedule_delayed_work()
                    mutex_unlock()
                    jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                        mutex_unlock()
                module_put() <void module_put (struct module *module) at module.c:1098>:
                    preempt_disable()
                    atomic_dec_if_positive()
                    WARN_ON()
                    trace_module_put()
                    preempt_enable()
            unregister_kprobes() <void unregister_kprobes (struct kprobe **kps, int num) at kprobes.c:1689>:
                mutex_lock()
                mutex_unlock()
                synchronize_sched()
        pr_err()
        target()
        target2()
        unregister_kprobes() <void unregister_kprobes (struct kprobe **kps, int num) at kprobes.c:1689>:
            mutex_lock()
            mutex_unlock()
            synchronize_sched()
    test_jprobe() <int test_jprobe (void) at test_kprobes.c:174>:
        register_jprobe() <int register_jprobe (struct jprobe *jp) at kprobes.c:1749>:
            register_jprobes() <int register_jprobes (struct jprobe **jps, int num) at kprobes.c:1718>:
                arch_deref_entry_point() <unsigned long __weak arch_deref_entry_point (void *entry) at kprobes.c:1713>
                kallsyms_lookup_size_offset() <int kallsyms_lookup_size_offset (unsigned long addr, unsigned long *symbolsize, unsigned long *offset) at kallsyms.c:275>:
                    is_ksym_addr() <int is_ksym_addr (unsigned long addr) at kallsyms.c:78>:
                        is_kernel() <inline int is_kernel (unsigned long addr) at kallsyms.c:71>:
                            in_gate_area_no_mm()
                        is_kernel_text() <inline int is_kernel_text (unsigned long addr) at kallsyms.c:63>:
                            arch_is_kernel_text()
                            in_gate_area_no_mm()
                        is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
                    get_symbol_pos() <unsigned long get_symbol_pos (unsigned long addr, unsigned long *symbolsize, unsigned long *offset) at kallsyms.c:215>:
                        BUG_ON()
                        is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
                    module_address_lookup() <const char *module_address_lookup (unsigned long addr, unsigned long *size, unsigned long *offset, char **modname, char *namebuf) at module.c:3704>:
                        preempt_disable()
                        get_ksymbol() <const char *get_ksymbol (struct module *mod, unsigned long addr, unsigned long *size, unsigned long *offset) at module.c:3657>:
                            rcu_dereference_sched()
                            within_module_init()
                            symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
                            is_arm_mapping_symbol() <inline int is_arm_mapping_symbol (const char *str) at module.c:3644>:
                        preempt_enable()
                register_kprobe() <int register_kprobe (struct kprobe *p) at kprobes.c:1481>:
                    kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
                        kprobe_lookup_name()
                        ERR_PTR()
                    IS_ERR()
                    PTR_ERR()
                    check_kprobe_rereg() <inline int check_kprobe_rereg (struct kprobe *p) at kprobes.c:1402>:
                        mutex_lock()
                        mutex_unlock()
                    INIT_LIST_HEAD()
                    check_kprobe_address_safe() <int check_kprobe_address_safe (struct kprobe *p, struct module **probed_mod) at kprobes.c:1432>:
                        arch_check_ftrace_location() <int __weak arch_check_ftrace_location (struct kprobe *p) at kprobes.c:1414>:
                            ftrace_location()
                        jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                            mutex_lock()
                        preempt_disable()
                        kernel_text_address() <int kernel_text_address (unsigned long addr) at extable.c:120>:
                            core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
                                init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
                            is_module_text_address() <bool is_module_text_address (unsigned long addr) at module.c:4052>:
                                preempt_disable()
                                preempt_enable()
                            is_ftrace_trampoline()
                        within_kprobe_blacklist() <bool within_kprobe_blacklist (unsigned long addr) at kprobes.c:1335>:
                            arch_within_kprobe_blacklist() <bool __weak arch_within_kprobe_blacklist (unsigned long addr) at kprobes.c:1328>:
                            list_for_each_entry()
                        jump_label_text_reserved() <int jump_label_text_reserved (void *start, void *end) at jump_label.c:451>:
                        unlikely()
                        try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
                            preempt_disable()
                            likely()
                            module_is_live()
                            atomic_inc_not_zero()
                            trace_module_get()
                            preempt_enable()
                        within_module_init()
                        module_put() <void module_put (struct module *module) at module.c:1098>:
                            preempt_disable()
                            atomic_dec_if_positive()
                            WARN_ON()
                            trace_module_put()
                            preempt_enable()
                        preempt_enable()
                        jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                            mutex_unlock()
                    mutex_lock()
                    get_kprobe() <struct kprobe *get_kprobe (void *addr) at kprobes.c:304>:
                        hash_ptr()
                        hlist_for_each_entry_rcu()
                    register_aggr_kprobe() <int register_aggr_kprobe (struct kprobe *orig_p, struct kprobe *p) at kprobes.c:1257>:
                        jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                            mutex_lock()
                        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                            might_sleep()
                            cpuhp_lock_acquire_read()
                            mutex_lock()
                            atomic_inc()
                            mutex_unlock()
                        mutex_lock()
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                            kzalloc()
                            INIT_LIST_HEAD()
                            arch_prepare_optimized_kprobe()
                        init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                            copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                            flush_insn_slot()
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                            kprobe_gone()
                            aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            INIT_LIST_HEAD()
                            INIT_HLIST_NODE()
                            list_add_rcu()
                            hlist_replace_rcu()
                        kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            kprobe_disabled()
                            list_empty()
                        reuse_unused_kprobe() <void reuse_unused_kprobe (struct kprobe *ap) at kprobes.c:898>:
                            BUG_ON()
                            kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                        list_for_each_entry_rcu()
                                        likely()
                                        kprobe_disabled()
                                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                kprobe_disabled()
                                list_empty()
                            container_of()
                            unlikely()
                            list_empty()
                            printk()
                            kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                        list_for_each_entry_rcu()
                                        likely()
                                        kprobe_disabled()
                                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                container_of()
                                arch_prepared_optinsn()
                            optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                                kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                            list_for_each_entry_rcu()
                                            likely()
                                            kprobe_disabled()
                                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                    container_of()
                                    arch_prepared_optinsn()
                                kprobe_disabled()
                                container_of()
                                arch_check_optimized_kprobe()
                                list_empty()
                                list_del_init()
                                list_add()
                                kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                                    schedule_delayed_work()
                        kprobe_gone()
                        arch_prepare_kprobe()
                        prepare_optimized_kprobe() <void prepare_optimized_kprobe (struct kprobe *p) at kprobes.c:715>:
                            container_of()
                            arch_prepare_optimized_kprobe()
                        copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                        add_new_kprobe() <int add_new_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1207>:
                            BUG_ON()
                            kprobe_gone()
                            unoptimize_kprobe() <void unoptimize_kprobe (struct kprobe *p, bool force) at kprobes.c:629>:
                                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                        list_for_each_entry_rcu()
                                        likely()
                                        kprobe_disabled()
                                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                kprobe_disarmed() <inline int kprobe_disarmed (struct kprobe *p) at kprobes.c:390>:
                                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                            list_for_each_entry_rcu()
                                            likely()
                                            kprobe_disabled()
                                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                    kprobe_disabled()
                                    container_of()
                                    list_empty()
                                container_of()
                                kprobe_optimized()
                                list_empty()
                                list_del_init()
                                force_unoptimize_kprobe() <void force_unoptimize_kprobe (struct optimized_kprobe *op) at kprobes.c:619>:
                                    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                                        might_sleep()
                                        cpuhp_lock_acquire_read()
                                        mutex_lock()
                                        atomic_inc()
                                        mutex_unlock()
                                    arch_unoptimize_kprobe()
                                    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                                        atomic_dec_return()
                                        WARN_ON()
                                        atomic_inc()
                                        waitqueue_active()
                                        wake_up()
                                        cpuhp_lock_release()
                                    kprobe_disabled()
                                    arch_disarm_kprobe()
                                list_add()
                                kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                                    schedule_delayed_work()
                            list_add_tail_rcu()
                            aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            list_add_rcu()
                            aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        mutex_unlock()
                        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                            atomic_dec_return()
                            WARN_ON()
                            atomic_inc()
                            waitqueue_active()
                            wake_up()
                            cpuhp_lock_release()
                        jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                            mutex_unlock()
                        kprobe_disabled()
                        arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                            unlikely()
                            kprobe_ftrace()
                            arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                                ftrace_set_filter_ip()
                                WARN()
                                register_ftrace_function()
                            mutex_lock()
                            mutex_unlock()
                    prepare_kprobe() <int prepare_kprobe (struct kprobe *p) at kprobes.c:924>:
                        kprobe_ftrace()
                        arch_prepare_kprobe()
                        arch_prepare_kprobe_ftrace()
                    mutex_unlock()
                    INIT_HLIST_NODE()
                    hlist_add_head_rcu()
                    hash_ptr()
                    kprobe_disabled()
                    arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                        unlikely()
                        kprobe_ftrace()
                        arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                            ftrace_set_filter_ip()
                            WARN()
                            register_ftrace_function()
                        mutex_lock()
                        mutex_unlock()
                    try_to_optimize_kprobe() <void try_to_optimize_kprobe (struct kprobe *p) at kprobes.c:745>:
                        kprobe_ftrace()
                        jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                            mutex_lock()
                        mutex_lock()
                        alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                            kzalloc()
                            INIT_LIST_HEAD()
                            arch_prepare_optimized_kprobe()
                        container_of()
                        arch_prepared_optinsn()
                        arch_remove_optimized_kprobe()
                        kfree()
                        init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                            copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                            flush_insn_slot()
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                            kprobe_gone()
                            aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            INIT_LIST_HEAD()
                            INIT_HLIST_NODE()
                            list_add_rcu()
                            hlist_replace_rcu()
                        optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                            kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                        list_for_each_entry_rcu()
                                        likely()
                                        kprobe_disabled()
                                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                container_of()
                                arch_prepared_optinsn()
                            kprobe_disabled()
                            container_of()
                            arch_check_optimized_kprobe()
                            list_empty()
                            list_del_init()
                            list_add()
                            kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                                schedule_delayed_work()
                        mutex_unlock()
                        jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                            mutex_unlock()
                    module_put() <void module_put (struct module *module) at module.c:1098>:
                        preempt_disable()
                        atomic_dec_if_positive()
                        WARN_ON()
                        trace_module_put()
                        preempt_enable()
                unregister_jprobes() <void unregister_jprobes (struct jprobe **jps, int num) at kprobes.c:1761>:
                    mutex_lock()
                    mutex_unlock()
                    synchronize_sched()
        pr_err()
        target()
        unregister_jprobe() <void unregister_jprobe (struct jprobe *jp) at kprobes.c:1755>:
            unregister_jprobes() <void unregister_jprobes (struct jprobe **jps, int num) at kprobes.c:1761>:
                mutex_lock()
                mutex_unlock()
                synchronize_sched()
    test_jprobes() <int test_jprobes (void) at test_kprobes.c:199>:
        register_jprobes() <int register_jprobes (struct jprobe **jps, int num) at kprobes.c:1718>:
            arch_deref_entry_point() <unsigned long __weak arch_deref_entry_point (void *entry) at kprobes.c:1713>
            kallsyms_lookup_size_offset() <int kallsyms_lookup_size_offset (unsigned long addr, unsigned long *symbolsize, unsigned long *offset) at kallsyms.c:275>:
                is_ksym_addr() <int is_ksym_addr (unsigned long addr) at kallsyms.c:78>:
                    is_kernel() <inline int is_kernel (unsigned long addr) at kallsyms.c:71>:
                        in_gate_area_no_mm()
                    is_kernel_text() <inline int is_kernel_text (unsigned long addr) at kallsyms.c:63>:
                        arch_is_kernel_text()
                        in_gate_area_no_mm()
                    is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
                get_symbol_pos() <unsigned long get_symbol_pos (unsigned long addr, unsigned long *symbolsize, unsigned long *offset) at kallsyms.c:215>:
                    BUG_ON()
                    is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
                module_address_lookup() <const char *module_address_lookup (unsigned long addr, unsigned long *size, unsigned long *offset, char **modname, char *namebuf) at module.c:3704>:
                    preempt_disable()
                    get_ksymbol() <const char *get_ksymbol (struct module *mod, unsigned long addr, unsigned long *size, unsigned long *offset) at module.c:3657>:
                        rcu_dereference_sched()
                        within_module_init()
                        symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
                        is_arm_mapping_symbol() <inline int is_arm_mapping_symbol (const char *str) at module.c:3644>:
                    preempt_enable()
            register_kprobe() <int register_kprobe (struct kprobe *p) at kprobes.c:1481>:
                kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
                    kprobe_lookup_name()
                    ERR_PTR()
                IS_ERR()
                PTR_ERR()
                check_kprobe_rereg() <inline int check_kprobe_rereg (struct kprobe *p) at kprobes.c:1402>:
                    mutex_lock()
                    mutex_unlock()
                INIT_LIST_HEAD()
                check_kprobe_address_safe() <int check_kprobe_address_safe (struct kprobe *p, struct module **probed_mod) at kprobes.c:1432>:
                    arch_check_ftrace_location() <int __weak arch_check_ftrace_location (struct kprobe *p) at kprobes.c:1414>:
                        ftrace_location()
                    jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                        mutex_lock()
                    preempt_disable()
                    kernel_text_address() <int kernel_text_address (unsigned long addr) at extable.c:120>:
                        core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
                            init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
                        is_module_text_address() <bool is_module_text_address (unsigned long addr) at module.c:4052>:
                            preempt_disable()
                            preempt_enable()
                        is_ftrace_trampoline()
                    within_kprobe_blacklist() <bool within_kprobe_blacklist (unsigned long addr) at kprobes.c:1335>:
                        arch_within_kprobe_blacklist() <bool __weak arch_within_kprobe_blacklist (unsigned long addr) at kprobes.c:1328>:
                        list_for_each_entry()
                    jump_label_text_reserved() <int jump_label_text_reserved (void *start, void *end) at jump_label.c:451>:
                    unlikely()
                    try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
                        preempt_disable()
                        likely()
                        module_is_live()
                        atomic_inc_not_zero()
                        trace_module_get()
                        preempt_enable()
                    within_module_init()
                    module_put() <void module_put (struct module *module) at module.c:1098>:
                        preempt_disable()
                        atomic_dec_if_positive()
                        WARN_ON()
                        trace_module_put()
                        preempt_enable()
                    preempt_enable()
                    jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                        mutex_unlock()
                mutex_lock()
                get_kprobe() <struct kprobe *get_kprobe (void *addr) at kprobes.c:304>:
                    hash_ptr()
                    hlist_for_each_entry_rcu()
                register_aggr_kprobe() <int register_aggr_kprobe (struct kprobe *orig_p, struct kprobe *p) at kprobes.c:1257>:
                    jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                        mutex_lock()
                    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                        might_sleep()
                        cpuhp_lock_acquire_read()
                        mutex_lock()
                        atomic_inc()
                        mutex_unlock()
                    mutex_lock()
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                        kzalloc()
                        INIT_LIST_HEAD()
                        arch_prepare_optimized_kprobe()
                    init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                        copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                        flush_insn_slot()
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                        kprobe_gone()
                        aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        INIT_LIST_HEAD()
                        INIT_HLIST_NODE()
                        list_add_rcu()
                        hlist_replace_rcu()
                    kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        kprobe_disabled()
                        list_empty()
                    reuse_unused_kprobe() <void reuse_unused_kprobe (struct kprobe *ap) at kprobes.c:898>:
                        BUG_ON()
                        kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            kprobe_disabled()
                            list_empty()
                        container_of()
                        unlikely()
                        list_empty()
                        printk()
                        kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            container_of()
                            arch_prepared_optinsn()
                        optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                            kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                        list_for_each_entry_rcu()
                                        likely()
                                        kprobe_disabled()
                                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                container_of()
                                arch_prepared_optinsn()
                            kprobe_disabled()
                            container_of()
                            arch_check_optimized_kprobe()
                            list_empty()
                            list_del_init()
                            list_add()
                            kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                                schedule_delayed_work()
                    kprobe_gone()
                    arch_prepare_kprobe()
                    prepare_optimized_kprobe() <void prepare_optimized_kprobe (struct kprobe *p) at kprobes.c:715>:
                        container_of()
                        arch_prepare_optimized_kprobe()
                    copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                    add_new_kprobe() <int add_new_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1207>:
                        BUG_ON()
                        kprobe_gone()
                        unoptimize_kprobe() <void unoptimize_kprobe (struct kprobe *p, bool force) at kprobes.c:629>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            kprobe_disarmed() <inline int kprobe_disarmed (struct kprobe *p) at kprobes.c:390>:
                                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                        list_for_each_entry_rcu()
                                        likely()
                                        kprobe_disabled()
                                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                kprobe_disabled()
                                container_of()
                                list_empty()
                            container_of()
                            kprobe_optimized()
                            list_empty()
                            list_del_init()
                            force_unoptimize_kprobe() <void force_unoptimize_kprobe (struct optimized_kprobe *op) at kprobes.c:619>:
                                get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                                    might_sleep()
                                    cpuhp_lock_acquire_read()
                                    mutex_lock()
                                    atomic_inc()
                                    mutex_unlock()
                                arch_unoptimize_kprobe()
                                put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                                    atomic_dec_return()
                                    WARN_ON()
                                    atomic_inc()
                                    waitqueue_active()
                                    wake_up()
                                    cpuhp_lock_release()
                                kprobe_disabled()
                                arch_disarm_kprobe()
                            list_add()
                            kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                                schedule_delayed_work()
                        list_add_tail_rcu()
                        aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        list_add_rcu()
                        aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    mutex_unlock()
                    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                        atomic_dec_return()
                        WARN_ON()
                        atomic_inc()
                        waitqueue_active()
                        wake_up()
                        cpuhp_lock_release()
                    jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                        mutex_unlock()
                    kprobe_disabled()
                    arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                        unlikely()
                        kprobe_ftrace()
                        arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                            ftrace_set_filter_ip()
                            WARN()
                            register_ftrace_function()
                        mutex_lock()
                        mutex_unlock()
                prepare_kprobe() <int prepare_kprobe (struct kprobe *p) at kprobes.c:924>:
                    kprobe_ftrace()
                    arch_prepare_kprobe()
                    arch_prepare_kprobe_ftrace()
                mutex_unlock()
                INIT_HLIST_NODE()
                hlist_add_head_rcu()
                hash_ptr()
                kprobe_disabled()
                arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                    unlikely()
                    kprobe_ftrace()
                    arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                        ftrace_set_filter_ip()
                        WARN()
                        register_ftrace_function()
                    mutex_lock()
                    mutex_unlock()
                try_to_optimize_kprobe() <void try_to_optimize_kprobe (struct kprobe *p) at kprobes.c:745>:
                    kprobe_ftrace()
                    jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                        mutex_lock()
                    mutex_lock()
                    alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                        kzalloc()
                        INIT_LIST_HEAD()
                        arch_prepare_optimized_kprobe()
                    container_of()
                    arch_prepared_optinsn()
                    arch_remove_optimized_kprobe()
                    kfree()
                    init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                        copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                        flush_insn_slot()
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                        kprobe_gone()
                        aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        INIT_LIST_HEAD()
                        INIT_HLIST_NODE()
                        list_add_rcu()
                        hlist_replace_rcu()
                    optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                        kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            container_of()
                            arch_prepared_optinsn()
                        kprobe_disabled()
                        container_of()
                        arch_check_optimized_kprobe()
                        list_empty()
                        list_del_init()
                        list_add()
                        kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                            schedule_delayed_work()
                    mutex_unlock()
                    jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                        mutex_unlock()
                module_put() <void module_put (struct module *module) at module.c:1098>:
                    preempt_disable()
                    atomic_dec_if_positive()
                    WARN_ON()
                    trace_module_put()
                    preempt_enable()
            unregister_jprobes() <void unregister_jprobes (struct jprobe **jps, int num) at kprobes.c:1761>:
                mutex_lock()
                mutex_unlock()
                synchronize_sched()
        pr_err()
        target()
        target2()
        unregister_jprobes() <void unregister_jprobes (struct jprobe **jps, int num) at kprobes.c:1761>:
            mutex_lock()
            mutex_unlock()
            synchronize_sched()
    test_kretprobe() <int test_kretprobe (void) at test_kprobes.c:262>:
        register_kretprobe() <int register_kretprobe (struct kretprobe *rp) at kprobes.c:1937>:
            kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
                kprobe_lookup_name()
                ERR_PTR()
            IS_ERR()
            PTR_ERR()
            pre_handler_kretprobe() <int pre_handler_kretprobe (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1959>:
                container_of()
                unlikely()
                in_nmi()
                hash_ptr()
                raw_spin_lock_irqsave()
                hlist_empty()
                hlist_entry()
                hlist_del()
                raw_spin_unlock_irqrestore()
                hlist_add_head()
                arch_prepare_kretprobe()
                INIT_HLIST_NODE()
                kretprobe_table_lock() < at kprobes.c:1108>:
                    kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                    raw_spin_lock_irqsave()
                kretprobe_table_unlock() < at kprobes.c:1129>:
                    kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                    raw_spin_unlock_irqrestore()
            max_t()
            num_possible_cpus()
            raw_spin_lock_init()
            INIT_HLIST_HEAD()
            kmalloc()
            free_rp_inst() <inline void free_rp_inst (struct kretprobe *rp) at kprobes.c:1171>:
                hlist_for_each_entry_safe()
                hlist_del()
                kfree()
            INIT_HLIST_NODE()
            hlist_add_head()
            register_kprobe() <int register_kprobe (struct kprobe *p) at kprobes.c:1481>:
                kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
                    kprobe_lookup_name()
                    ERR_PTR()
                IS_ERR()
                PTR_ERR()
                check_kprobe_rereg() <inline int check_kprobe_rereg (struct kprobe *p) at kprobes.c:1402>:
                    mutex_lock()
                    mutex_unlock()
                INIT_LIST_HEAD()
                check_kprobe_address_safe() <int check_kprobe_address_safe (struct kprobe *p, struct module **probed_mod) at kprobes.c:1432>:
                    arch_check_ftrace_location() <int __weak arch_check_ftrace_location (struct kprobe *p) at kprobes.c:1414>:
                        ftrace_location()
                    jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                        mutex_lock()
                    preempt_disable()
                    kernel_text_address() <int kernel_text_address (unsigned long addr) at extable.c:120>:
                        core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
                            init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
                        is_module_text_address() <bool is_module_text_address (unsigned long addr) at module.c:4052>:
                            preempt_disable()
                            preempt_enable()
                        is_ftrace_trampoline()
                    within_kprobe_blacklist() <bool within_kprobe_blacklist (unsigned long addr) at kprobes.c:1335>:
                        arch_within_kprobe_blacklist() <bool __weak arch_within_kprobe_blacklist (unsigned long addr) at kprobes.c:1328>:
                        list_for_each_entry()
                    jump_label_text_reserved() <int jump_label_text_reserved (void *start, void *end) at jump_label.c:451>:
                    unlikely()
                    try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
                        preempt_disable()
                        likely()
                        module_is_live()
                        atomic_inc_not_zero()
                        trace_module_get()
                        preempt_enable()
                    within_module_init()
                    module_put() <void module_put (struct module *module) at module.c:1098>:
                        preempt_disable()
                        atomic_dec_if_positive()
                        WARN_ON()
                        trace_module_put()
                        preempt_enable()
                    preempt_enable()
                    jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                        mutex_unlock()
                mutex_lock()
                get_kprobe() <struct kprobe *get_kprobe (void *addr) at kprobes.c:304>:
                    hash_ptr()
                    hlist_for_each_entry_rcu()
                register_aggr_kprobe() <int register_aggr_kprobe (struct kprobe *orig_p, struct kprobe *p) at kprobes.c:1257>:
                    jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                        mutex_lock()
                    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                        might_sleep()
                        cpuhp_lock_acquire_read()
                        mutex_lock()
                        atomic_inc()
                        mutex_unlock()
                    mutex_lock()
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                        kzalloc()
                        INIT_LIST_HEAD()
                        arch_prepare_optimized_kprobe()
                    init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                        copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                        flush_insn_slot()
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                        kprobe_gone()
                        aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        INIT_LIST_HEAD()
                        INIT_HLIST_NODE()
                        list_add_rcu()
                        hlist_replace_rcu()
                    kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        kprobe_disabled()
                        list_empty()
                    reuse_unused_kprobe() <void reuse_unused_kprobe (struct kprobe *ap) at kprobes.c:898>:
                        BUG_ON()
                        kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            kprobe_disabled()
                            list_empty()
                        container_of()
                        unlikely()
                        list_empty()
                        printk()
                        kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            container_of()
                            arch_prepared_optinsn()
                        optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                            kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                        list_for_each_entry_rcu()
                                        likely()
                                        kprobe_disabled()
                                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                container_of()
                                arch_prepared_optinsn()
                            kprobe_disabled()
                            container_of()
                            arch_check_optimized_kprobe()
                            list_empty()
                            list_del_init()
                            list_add()
                            kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                                schedule_delayed_work()
                    kprobe_gone()
                    arch_prepare_kprobe()
                    prepare_optimized_kprobe() <void prepare_optimized_kprobe (struct kprobe *p) at kprobes.c:715>:
                        container_of()
                        arch_prepare_optimized_kprobe()
                    copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                    add_new_kprobe() <int add_new_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1207>:
                        BUG_ON()
                        kprobe_gone()
                        unoptimize_kprobe() <void unoptimize_kprobe (struct kprobe *p, bool force) at kprobes.c:629>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            kprobe_disarmed() <inline int kprobe_disarmed (struct kprobe *p) at kprobes.c:390>:
                                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                        list_for_each_entry_rcu()
                                        likely()
                                        kprobe_disabled()
                                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                kprobe_disabled()
                                container_of()
                                list_empty()
                            container_of()
                            kprobe_optimized()
                            list_empty()
                            list_del_init()
                            force_unoptimize_kprobe() <void force_unoptimize_kprobe (struct optimized_kprobe *op) at kprobes.c:619>:
                                get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                                    might_sleep()
                                    cpuhp_lock_acquire_read()
                                    mutex_lock()
                                    atomic_inc()
                                    mutex_unlock()
                                arch_unoptimize_kprobe()
                                put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                                    atomic_dec_return()
                                    WARN_ON()
                                    atomic_inc()
                                    waitqueue_active()
                                    wake_up()
                                    cpuhp_lock_release()
                                kprobe_disabled()
                                arch_disarm_kprobe()
                            list_add()
                            kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                                schedule_delayed_work()
                        list_add_tail_rcu()
                        aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        list_add_rcu()
                        aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    mutex_unlock()
                    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                        atomic_dec_return()
                        WARN_ON()
                        atomic_inc()
                        waitqueue_active()
                        wake_up()
                        cpuhp_lock_release()
                    jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                        mutex_unlock()
                    kprobe_disabled()
                    arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                        unlikely()
                        kprobe_ftrace()
                        arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                            ftrace_set_filter_ip()
                            WARN()
                            register_ftrace_function()
                        mutex_lock()
                        mutex_unlock()
                prepare_kprobe() <int prepare_kprobe (struct kprobe *p) at kprobes.c:924>:
                    kprobe_ftrace()
                    arch_prepare_kprobe()
                    arch_prepare_kprobe_ftrace()
                mutex_unlock()
                INIT_HLIST_NODE()
                hlist_add_head_rcu()
                hash_ptr()
                kprobe_disabled()
                arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                    unlikely()
                    kprobe_ftrace()
                    arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                        ftrace_set_filter_ip()
                        WARN()
                        register_ftrace_function()
                    mutex_lock()
                    mutex_unlock()
                try_to_optimize_kprobe() <void try_to_optimize_kprobe (struct kprobe *p) at kprobes.c:745>:
                    kprobe_ftrace()
                    jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                        mutex_lock()
                    mutex_lock()
                    alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                        kzalloc()
                        INIT_LIST_HEAD()
                        arch_prepare_optimized_kprobe()
                    container_of()
                    arch_prepared_optinsn()
                    arch_remove_optimized_kprobe()
                    kfree()
                    init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                        copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                        flush_insn_slot()
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                        kprobe_gone()
                        aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        INIT_LIST_HEAD()
                        INIT_HLIST_NODE()
                        list_add_rcu()
                        hlist_replace_rcu()
                    optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                        kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            container_of()
                            arch_prepared_optinsn()
                        kprobe_disabled()
                        container_of()
                        arch_check_optimized_kprobe()
                        list_empty()
                        list_del_init()
                        list_add()
                        kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                            schedule_delayed_work()
                    mutex_unlock()
                    jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                        mutex_unlock()
                module_put() <void module_put (struct module *module) at module.c:1098>:
                    preempt_disable()
                    atomic_dec_if_positive()
                    WARN_ON()
                    trace_module_put()
                    preempt_enable()
        pr_err()
        target()
        unregister_kretprobe() <void unregister_kretprobe (struct kretprobe *rp) at kprobes.c:1949>:
            unregister_kretprobes() <void unregister_kretprobes (struct kretprobe **rps, int num) at kprobes.c:1954>:
                mutex_lock()
                mutex_unlock()
                synchronize_sched()
                cleanup_rp_inst() <void cleanup_rp_inst (struct kretprobe *rp) at kprobes.c:1182>:
                    kretprobe_table_lock() < at kprobes.c:1108>:
                        kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                        raw_spin_lock_irqsave()
                    hlist_for_each_entry_safe()
                    kretprobe_table_unlock() < at kprobes.c:1129>:
                        kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                        raw_spin_unlock_irqrestore()
                    free_rp_inst() <inline void free_rp_inst (struct kretprobe *rp) at kprobes.c:1171>:
                        hlist_for_each_entry_safe()
                        hlist_del()
                        kfree()
    test_kretprobes() <int test_kretprobes (void) at test_kprobes.c:305>:
        register_kretprobes() <int register_kretprobes (struct kretprobe **rps, int num) at kprobes.c:1943>:
            register_kretprobe() <int register_kretprobe (struct kretprobe *rp) at kprobes.c:1937>:
                kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
                    kprobe_lookup_name()
                    ERR_PTR()
                IS_ERR()
                PTR_ERR()
                pre_handler_kretprobe() <int pre_handler_kretprobe (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1959>:
                    container_of()
                    unlikely()
                    in_nmi()
                    hash_ptr()
                    raw_spin_lock_irqsave()
                    hlist_empty()
                    hlist_entry()
                    hlist_del()
                    raw_spin_unlock_irqrestore()
                    hlist_add_head()
                    arch_prepare_kretprobe()
                    INIT_HLIST_NODE()
                    kretprobe_table_lock() < at kprobes.c:1108>:
                        kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                        raw_spin_lock_irqsave()
                    kretprobe_table_unlock() < at kprobes.c:1129>:
                        kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                        raw_spin_unlock_irqrestore()
                max_t()
                num_possible_cpus()
                raw_spin_lock_init()
                INIT_HLIST_HEAD()
                kmalloc()
                free_rp_inst() <inline void free_rp_inst (struct kretprobe *rp) at kprobes.c:1171>:
                    hlist_for_each_entry_safe()
                    hlist_del()
                    kfree()
                INIT_HLIST_NODE()
                hlist_add_head()
                register_kprobe() <int register_kprobe (struct kprobe *p) at kprobes.c:1481>:
                    kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
                        kprobe_lookup_name()
                        ERR_PTR()
                    IS_ERR()
                    PTR_ERR()
                    check_kprobe_rereg() <inline int check_kprobe_rereg (struct kprobe *p) at kprobes.c:1402>:
                        mutex_lock()
                        mutex_unlock()
                    INIT_LIST_HEAD()
                    check_kprobe_address_safe() <int check_kprobe_address_safe (struct kprobe *p, struct module **probed_mod) at kprobes.c:1432>:
                        arch_check_ftrace_location() <int __weak arch_check_ftrace_location (struct kprobe *p) at kprobes.c:1414>:
                            ftrace_location()
                        jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                            mutex_lock()
                        preempt_disable()
                        kernel_text_address() <int kernel_text_address (unsigned long addr) at extable.c:120>:
                            core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
                                init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
                            is_module_text_address() <bool is_module_text_address (unsigned long addr) at module.c:4052>:
                                preempt_disable()
                                preempt_enable()
                            is_ftrace_trampoline()
                        within_kprobe_blacklist() <bool within_kprobe_blacklist (unsigned long addr) at kprobes.c:1335>:
                            arch_within_kprobe_blacklist() <bool __weak arch_within_kprobe_blacklist (unsigned long addr) at kprobes.c:1328>:
                            list_for_each_entry()
                        jump_label_text_reserved() <int jump_label_text_reserved (void *start, void *end) at jump_label.c:451>:
                        unlikely()
                        try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
                            preempt_disable()
                            likely()
                            module_is_live()
                            atomic_inc_not_zero()
                            trace_module_get()
                            preempt_enable()
                        within_module_init()
                        module_put() <void module_put (struct module *module) at module.c:1098>:
                            preempt_disable()
                            atomic_dec_if_positive()
                            WARN_ON()
                            trace_module_put()
                            preempt_enable()
                        preempt_enable()
                        jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                            mutex_unlock()
                    mutex_lock()
                    get_kprobe() <struct kprobe *get_kprobe (void *addr) at kprobes.c:304>:
                        hash_ptr()
                        hlist_for_each_entry_rcu()
                    register_aggr_kprobe() <int register_aggr_kprobe (struct kprobe *orig_p, struct kprobe *p) at kprobes.c:1257>:
                        jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                            mutex_lock()
                        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                            might_sleep()
                            cpuhp_lock_acquire_read()
                            mutex_lock()
                            atomic_inc()
                            mutex_unlock()
                        mutex_lock()
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                            kzalloc()
                            INIT_LIST_HEAD()
                            arch_prepare_optimized_kprobe()
                        init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                            copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                            flush_insn_slot()
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                            kprobe_gone()
                            aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            INIT_LIST_HEAD()
                            INIT_HLIST_NODE()
                            list_add_rcu()
                            hlist_replace_rcu()
                        kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            kprobe_disabled()
                            list_empty()
                        reuse_unused_kprobe() <void reuse_unused_kprobe (struct kprobe *ap) at kprobes.c:898>:
                            BUG_ON()
                            kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                        list_for_each_entry_rcu()
                                        likely()
                                        kprobe_disabled()
                                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                kprobe_disabled()
                                list_empty()
                            container_of()
                            unlikely()
                            list_empty()
                            printk()
                            kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                        list_for_each_entry_rcu()
                                        likely()
                                        kprobe_disabled()
                                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                container_of()
                                arch_prepared_optinsn()
                            optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                                kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                            list_for_each_entry_rcu()
                                            likely()
                                            kprobe_disabled()
                                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                    container_of()
                                    arch_prepared_optinsn()
                                kprobe_disabled()
                                container_of()
                                arch_check_optimized_kprobe()
                                list_empty()
                                list_del_init()
                                list_add()
                                kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                                    schedule_delayed_work()
                        kprobe_gone()
                        arch_prepare_kprobe()
                        prepare_optimized_kprobe() <void prepare_optimized_kprobe (struct kprobe *p) at kprobes.c:715>:
                            container_of()
                            arch_prepare_optimized_kprobe()
                        copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                        add_new_kprobe() <int add_new_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1207>:
                            BUG_ON()
                            kprobe_gone()
                            unoptimize_kprobe() <void unoptimize_kprobe (struct kprobe *p, bool force) at kprobes.c:629>:
                                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                        list_for_each_entry_rcu()
                                        likely()
                                        kprobe_disabled()
                                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                kprobe_disarmed() <inline int kprobe_disarmed (struct kprobe *p) at kprobes.c:390>:
                                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                            list_for_each_entry_rcu()
                                            likely()
                                            kprobe_disabled()
                                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                    kprobe_disabled()
                                    container_of()
                                    list_empty()
                                container_of()
                                kprobe_optimized()
                                list_empty()
                                list_del_init()
                                force_unoptimize_kprobe() <void force_unoptimize_kprobe (struct optimized_kprobe *op) at kprobes.c:619>:
                                    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                                        might_sleep()
                                        cpuhp_lock_acquire_read()
                                        mutex_lock()
                                        atomic_inc()
                                        mutex_unlock()
                                    arch_unoptimize_kprobe()
                                    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                                        atomic_dec_return()
                                        WARN_ON()
                                        atomic_inc()
                                        waitqueue_active()
                                        wake_up()
                                        cpuhp_lock_release()
                                    kprobe_disabled()
                                    arch_disarm_kprobe()
                                list_add()
                                kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                                    schedule_delayed_work()
                            list_add_tail_rcu()
                            aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            list_add_rcu()
                            aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        mutex_unlock()
                        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                            atomic_dec_return()
                            WARN_ON()
                            atomic_inc()
                            waitqueue_active()
                            wake_up()
                            cpuhp_lock_release()
                        jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                            mutex_unlock()
                        kprobe_disabled()
                        arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                            unlikely()
                            kprobe_ftrace()
                            arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                                ftrace_set_filter_ip()
                                WARN()
                                register_ftrace_function()
                            mutex_lock()
                            mutex_unlock()
                    prepare_kprobe() <int prepare_kprobe (struct kprobe *p) at kprobes.c:924>:
                        kprobe_ftrace()
                        arch_prepare_kprobe()
                        arch_prepare_kprobe_ftrace()
                    mutex_unlock()
                    INIT_HLIST_NODE()
                    hlist_add_head_rcu()
                    hash_ptr()
                    kprobe_disabled()
                    arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                        unlikely()
                        kprobe_ftrace()
                        arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                            ftrace_set_filter_ip()
                            WARN()
                            register_ftrace_function()
                        mutex_lock()
                        mutex_unlock()
                    try_to_optimize_kprobe() <void try_to_optimize_kprobe (struct kprobe *p) at kprobes.c:745>:
                        kprobe_ftrace()
                        jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                            mutex_lock()
                        mutex_lock()
                        alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                            kzalloc()
                            INIT_LIST_HEAD()
                            arch_prepare_optimized_kprobe()
                        container_of()
                        arch_prepared_optinsn()
                        arch_remove_optimized_kprobe()
                        kfree()
                        init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                            copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                            flush_insn_slot()
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                            kprobe_gone()
                            aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            INIT_LIST_HEAD()
                            INIT_HLIST_NODE()
                            list_add_rcu()
                            hlist_replace_rcu()
                        optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                            kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                        list_for_each_entry_rcu()
                                        likely()
                                        kprobe_disabled()
                                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                                container_of()
                                arch_prepared_optinsn()
                            kprobe_disabled()
                            container_of()
                            arch_check_optimized_kprobe()
                            list_empty()
                            list_del_init()
                            list_add()
                            kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                                schedule_delayed_work()
                        mutex_unlock()
                        jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                            mutex_unlock()
                    module_put() <void module_put (struct module *module) at module.c:1098>:
                        preempt_disable()
                        atomic_dec_if_positive()
                        WARN_ON()
                        trace_module_put()
                        preempt_enable()
            unregister_kretprobes() <void unregister_kretprobes (struct kretprobe **rps, int num) at kprobes.c:1954>:
                mutex_lock()
                mutex_unlock()
                synchronize_sched()
                cleanup_rp_inst() <void cleanup_rp_inst (struct kretprobe *rp) at kprobes.c:1182>:
                    kretprobe_table_lock() < at kprobes.c:1108>:
                        kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                        raw_spin_lock_irqsave()
                    hlist_for_each_entry_safe()
                    kretprobe_table_unlock() < at kprobes.c:1129>:
                        kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                        raw_spin_unlock_irqrestore()
                    free_rp_inst() <inline void free_rp_inst (struct kretprobe *rp) at kprobes.c:1171>:
                        hlist_for_each_entry_safe()
                        hlist_del()
                        kfree()
        pr_err()
        target()
        target2()
        unregister_kretprobes() <void unregister_kretprobes (struct kretprobe **rps, int num) at kprobes.c:1954>:
            mutex_lock()
            mutex_unlock()
            synchronize_sched()
            cleanup_rp_inst() <void cleanup_rp_inst (struct kretprobe *rp) at kprobes.c:1182>:
                kretprobe_table_lock() < at kprobes.c:1108>:
                    kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                    raw_spin_lock_irqsave()
                hlist_for_each_entry_safe()
                kretprobe_table_unlock() < at kprobes.c:1129>:
                    kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                    raw_spin_unlock_irqrestore()
                free_rp_inst() <inline void free_rp_inst (struct kretprobe *rp) at kprobes.c:1171>:
                    hlist_for_each_entry_safe()
                    hlist_del()
                    kfree()
    pr_err()
insert_resource() <int insert_resource (struct resource *parent, struct resource *new) at resource.c:834>:
    insert_resource_conflict() <struct resource *insert_resource_conflict (struct resource *parent, struct resource *new) at resource.c:817>:
        write_lock()
        write_unlock()
insert_resource_conflict() <struct resource *insert_resource_conflict (struct resource *parent, struct resource *new) at resource.c:817>:
    write_lock()
    write_unlock()
insert_resource_expand_to_fit() <void insert_resource_expand_to_fit (struct resource *root, struct resource *new) at resource.c:850>:
    write_lock()
    printk()
    write_unlock()
iomem_is_exclusive() <int iomem_is_exclusive (u64 addr) at resource.c:1480>:
    read_lock()
    r_next() <void *r_next (struct seq_file *m, void *v, loff_t *pos) at resource.c:76>:
        next_resource() <struct resource *next_resource (struct resource *p, bool sibling_only) at resource.c:63>
    IS_ENABLED()
    read_unlock()
iomem_map_sanity_check() <int iomem_map_sanity_check (resource_size_t addr, unsigned long size) at resource.c:1430>:
    read_lock()
    r_next() <void *r_next (struct seq_file *m, void *v, loff_t *pos) at resource.c:76>:
        next_resource() <struct resource *next_resource (struct resource *p, bool sibling_only) at resource.c:63>
    PFN_DOWN()
    printk()
    read_unlock()
ioremap_cache() <__weak void __iomem *ioremap_cache (resource_size_t offset, unsigned long size) at memremap.c:24>:
    ioremap()
irq_enter() <void irq_enter (void) at softirq.c:325>:
    rcu_irq_enter()
    is_idle_task()
    in_interrupt()
    local_bh_disable()
    tick_irq_enter()
irq_exit() <void irq_exit (void) at softirq.c:380>:
    local_irq_disable()
    WARN_ON_ONCE()
    irqs_disabled()
    account_irq_exit_time()
    preempt_count_sub()
    in_interrupt()
    local_softirq_pending()
    invoke_softirq() <inline void invoke_softirq (void) at softirq.c:341>:
        do_softirq_own_stack()
        wakeup_softirqd() <void wakeup_softirqd (void) at softirq.c:71>:
            wake_up_process()
    tick_irq_exit() <inline void tick_irq_exit (void) at softirq.c:364>:
        smp_processor_id()
        idle_cpu()
        need_resched()
        tick_nohz_full_cpu()
        in_interrupt()
        tick_nohz_irq_exit()
    rcu_irq_exit()
    trace_hardirq_exit()
irq_work_needs_cpu() <bool irq_work_needs_cpu (void) at irq_work.c:112>:
    this_cpu_ptr()
    llist_empty()
    arch_irq_work_has_interrupt()
    WARN_ON_ONCE()
    cpu_is_offline()
    smp_processor_id()
irq_work_queue() <bool irq_work_queue (struct irq_work *work) at irq_work.c:87>:
    irq_work_claim() <bool irq_work_claim (struct irq_work *work) at irq_work.c:29>:
        cmpxchg()
        cpu_relax()
    preempt_disable()
    llist_add()
    this_cpu_ptr()
    tick_nohz_tick_stopped()
    arch_irq_work_raise() <void __weak arch_irq_work_raise (void) at irq_work.c:52>
    preempt_enable()
irq_work_queue_on() <bool irq_work_queue_on (struct irq_work *work, int cpu) at irq_work.c:66>:
    WARN_ON_ONCE()
    cpu_is_offline()
    in_nmi()
    irq_work_claim() <bool irq_work_claim (struct irq_work *work) at irq_work.c:29>:
        cmpxchg()
        cpu_relax()
    llist_add()
    per_cpu()
    arch_send_call_function_single_ipi()
irq_work_run() <void irq_work_run (void) at irq_work.c:169>:
    irq_work_run_list() <void irq_work_run_list (struct llist_head *list) at irq_work.c:129>:
        BUG_ON()
        irqs_disabled()
        llist_empty()
        llist_del_all()
        llist_entry()
        llist_next()
        xchg()
        cmpxchg()
    this_cpu_ptr()
irq_work_sync() <void irq_work_sync (struct irq_work *work) at irq_work.c:189>:
    WARN_ON_ONCE()
    irqs_disabled()
    cpu_relax()
irq_work_tick() <void irq_work_tick (void) at irq_work.c:176>:
    this_cpu_ptr()
    llist_empty()
    arch_irq_work_has_interrupt()
    irq_work_run_list() <void irq_work_run_list (struct llist_head *list) at irq_work.c:129>:
        BUG_ON()
        irqs_disabled()
        llist_empty()
        llist_del_all()
        llist_entry()
        llist_next()
        xchg()
        cmpxchg()
is_audit_feature_set() <int is_audit_feature_set (int i) at audit.c:721>:
    AUDIT_FEATURE_TO_MASK()
is_current_pgrp_orphaned() <int is_current_pgrp_orphaned (void) at exit.c:239>:
    read_lock()
    will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
        do_each_pid_task()
        thread_group_empty()
        is_global_init()
        task_pgrp()
        task_session()
        while_each_pid_task()
    task_pgrp()
    read_unlock()
is_module_address() <bool is_module_address (unsigned long addr) at module.c:4007>:
    preempt_disable()
    preempt_enable()
is_module_percpu_address() <bool is_module_percpu_address (unsigned long addr) at module.c:723>:
    preempt_disable()
    list_for_each_entry_rcu()
    for_each_possible_cpu()
    per_cpu_ptr()
    preempt_enable()
is_module_text_address() <bool is_module_text_address (unsigned long addr) at module.c:4052>:
    preempt_disable()
    preempt_enable()
jump_label_apply_nops() <void jump_label_apply_nops (struct module *mod) at jump_label.c:288>:
    jump_label_init_type() <enum jump_label_type jump_label_init_type (struct jump_entry *entry) at jump_label.c:237>:
        jump_entry_key() <inline struct static_key *jump_entry_key (struct jump_entry *entry) at jump_label.c:166>:
        static_key_type() <inline bool static_key_type (struct static_key *key) at jump_label.c:161>:
        jump_entry_branch() <bool jump_entry_branch (struct jump_entry *entry) at jump_label.c:171>:
    arch_jump_label_transform_static() <void __weak __init_or_module arch_jump_label_transform_static (struct jump_entry *entry, enum jump_label_type type) at jump_label.c:150>:
        arch_jump_label_transform()
jump_label_init() <void __init jump_label_init (void) at jump_label.c:201>:
    jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
        mutex_lock()
    jump_label_sort_entries() <void jump_label_sort_entries (struct jump_entry *start, struct jump_entry *stop) at jump_label.c:48>:
        sort()
        jump_label_cmp() <int jump_label_cmp (const void *a, const void *b) at jump_label.c:33>:
    jump_label_type() <enum jump_label_type jump_label_type (struct jump_entry *entry) at jump_label.c:176>:
        jump_entry_key() <inline struct static_key *jump_entry_key (struct jump_entry *entry) at jump_label.c:166>:
        static_key_enabled()
        jump_entry_branch() <bool jump_entry_branch (struct jump_entry *entry) at jump_label.c:171>:
    arch_jump_label_transform_static() <void __weak __init_or_module arch_jump_label_transform_static (struct jump_entry *entry, enum jump_label_type type) at jump_label.c:150>:
        arch_jump_label_transform()
    jump_entry_key() <inline struct static_key *jump_entry_key (struct jump_entry *entry) at jump_label.c:166>:
    jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
        mutex_unlock()
jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
    mutex_lock()
jump_label_rate_limit() <void jump_label_rate_limit (struct static_key_deferred *key, unsigned long rl) at jump_label.c:111>:
    STATIC_KEY_CHECK_USE()
    INIT_DELAYED_WORK()
    jump_label_update_timeout() <void jump_label_update_timeout (struct work_struct *work) at jump_label.c:90>:
        container_of()
jump_label_text_reserved() <int jump_label_text_reserved (void *start, void *end) at jump_label.c:451>:
jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
    mutex_unlock()
kallsyms_lookup() <const char *kallsyms_lookup (unsigned long addr, unsigned long *symbolsize, unsigned long *offset, char **modname, char *namebuf) at kallsyms.c:292>:
    is_ksym_addr() <int is_ksym_addr (unsigned long addr) at kallsyms.c:78>:
        is_kernel() <inline int is_kernel (unsigned long addr) at kallsyms.c:71>:
            in_gate_area_no_mm()
        is_kernel_text() <inline int is_kernel_text (unsigned long addr) at kallsyms.c:63>:
            arch_is_kernel_text()
            in_gate_area_no_mm()
        is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
    get_symbol_pos() <unsigned long get_symbol_pos (unsigned long addr, unsigned long *symbolsize, unsigned long *offset) at kallsyms.c:215>:
        BUG_ON()
        is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
    kallsyms_expand_symbol() <unsigned int kallsyms_expand_symbol (unsigned int off, char *result, size_t maxlen) at kallsyms.c:91>:
    get_symbol_offset() <unsigned int get_symbol_offset (unsigned long pos) at kallsyms.c:156>:
    module_address_lookup() <const char *module_address_lookup (unsigned long addr, unsigned long *size, unsigned long *offset, char **modname, char *namebuf) at module.c:3704>:
        preempt_disable()
        get_ksymbol() <const char *get_ksymbol (struct module *mod, unsigned long addr, unsigned long *size, unsigned long *offset) at module.c:3657>:
            rcu_dereference_sched()
            within_module_init()
            symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
            is_arm_mapping_symbol() <inline int is_arm_mapping_symbol (const char *str) at module.c:3644>:
        preempt_enable()
kallsyms_lookup_name() <unsigned long kallsyms_lookup_name (const char *name) at kallsyms.c:180>:
    kallsyms_expand_symbol() <unsigned int kallsyms_expand_symbol (unsigned int off, char *result, size_t maxlen) at kallsyms.c:91>:
    ARRAY_SIZE()
    module_kallsyms_lookup_name() <unsigned long module_kallsyms_lookup_name (const char *name) at module.c:3822>:
        preempt_disable()
        find_module_all() <struct module *find_module_all (const char *name, size_t len, bool even_unformed) at module.c:588>:
            module_assert_mutex_or_preempt() <void module_assert_mutex_or_preempt (void) at module.c:260>:
                unlikely()
                WARN_ON()
                rcu_read_lock_sched_held()
                lockdep_is_held()
            list_for_each_entry()
        mod_find_symname() <unsigned long mod_find_symname (struct module *mod, const char *name) at module.c:3809>:
            rcu_dereference_sched()
            symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
        list_for_each_entry_rcu()
        preempt_enable()
kallsyms_lookup_size_offset() <int kallsyms_lookup_size_offset (unsigned long addr, unsigned long *symbolsize, unsigned long *offset) at kallsyms.c:275>:
    is_ksym_addr() <int is_ksym_addr (unsigned long addr) at kallsyms.c:78>:
        is_kernel() <inline int is_kernel (unsigned long addr) at kallsyms.c:71>:
            in_gate_area_no_mm()
        is_kernel_text() <inline int is_kernel_text (unsigned long addr) at kallsyms.c:63>:
            arch_is_kernel_text()
            in_gate_area_no_mm()
        is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
    get_symbol_pos() <unsigned long get_symbol_pos (unsigned long addr, unsigned long *symbolsize, unsigned long *offset) at kallsyms.c:215>:
        BUG_ON()
        is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
    module_address_lookup() <const char *module_address_lookup (unsigned long addr, unsigned long *size, unsigned long *offset, char **modname, char *namebuf) at module.c:3704>:
        preempt_disable()
        get_ksymbol() <const char *get_ksymbol (struct module *mod, unsigned long addr, unsigned long *size, unsigned long *offset) at module.c:3657>:
            rcu_dereference_sched()
            within_module_init()
            symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
            is_arm_mapping_symbol() <inline int is_arm_mapping_symbol (const char *str) at module.c:3644>:
        preempt_enable()
kallsyms_on_each_symbol() <int kallsyms_on_each_symbol (int (*fn) (void *, const char *, struct module *, unsigned long), void *data) at kallsyms.c:196>:
    kallsyms_expand_symbol() <unsigned int kallsyms_expand_symbol (unsigned int off, char *result, size_t maxlen) at kallsyms.c:91>:
    ARRAY_SIZE()
    module_kallsyms_on_each_symbol() <int module_kallsyms_on_each_symbol (int (*fn) (void *, const char *, struct module *, unsigned long), void *data) at module.c:3845>:
        module_assert_mutex() <void module_assert_mutex (void) at module.c:255>:
            lockdep_assert_held()
        list_for_each_entry()
        symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
kdb_send_sig_info() <void kdb_send_sig_info (struct task_struct *t, struct siginfo *info) at signal.c:3596>:
    spin_trylock()
    kdb_printf()
    spin_unlock()
    send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
        valid_signal()
        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
            lock_task_sighand()
            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                    SI_FROMUSER()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
            unlock_task_sighand()
kdb_walk_kallsyms() <const char *kdb_walk_kallsyms (loff_t *pos) at kallsyms.c:577>:
    reset_iter() <void reset_iter (struct kallsym_iter *iter, loff_t new_pos) at kallsyms.c:482>:
        get_symbol_offset() <unsigned int get_symbol_offset (unsigned long pos) at kallsyms.c:156>:
    update_iter() <int update_iter (struct kallsym_iter *iter, loff_t pos) at kallsyms.c:490>:
        get_ksymbol_mod() <int get_ksymbol_mod (struct kallsym_iter *iter) at kallsyms.c:458>:
            module_get_kallsym() <int module_get_kallsym (unsigned int symnum, unsigned long *value, char *type, char *name, char *module_name, int *exported) at module.c:3782>:
                preempt_disable()
                list_for_each_entry_rcu()
                rcu_dereference_sched()
                strlcpy()
                symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
                is_exported() <int is_exported (const char *name, unsigned long value, const struct module *mod) at module.c:2367>:
                    lookup_symbol() <const struct kernel_symbol *lookup_symbol (const char *name, const struct kernel_symbol *start, const struct kernel_symbol *stop) at module.c:2359>:
                        cmp_name() <int cmp_name (const void *va, const void *vb) at module.c:533>:
                preempt_enable()
        reset_iter() <void reset_iter (struct kallsym_iter *iter, loff_t new_pos) at kallsyms.c:482>:
            get_symbol_offset() <unsigned int get_symbol_offset (unsigned long pos) at kallsyms.c:156>:
        get_ksymbol_core() <unsigned long get_ksymbol_core (struct kallsym_iter *iter) at kallsyms.c:468>:
            kallsyms_get_symbol_type() <char kallsyms_get_symbol_type (unsigned int off) at kallsyms.c:142>:
            kallsyms_expand_symbol() <unsigned int kallsyms_expand_symbol (unsigned int off, char *result, size_t maxlen) at kallsyms.c:91>:
            ARRAY_SIZE()
kernel_halt() <void kernel_halt (void) at reboot.c:241>:
    kernel_shutdown_prepare() <void kernel_shutdown_prepare (enum system_states state) at reboot.c:228>:
        blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
        usermodehelper_disable()
        device_shutdown()
    migrate_to_reboot_cpu() <void migrate_to_reboot_cpu (void) at reboot.c:188>:
        cpu_hotplug_disable() <void cpu_hotplug_disable (void) at cpu.c:178>:
            cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
                mutex_lock()
            cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
                mutex_unlock()
        cpu_online()
        cpumask_first()
        set_cpus_allowed_ptr()
        cpumask_of()
    syscore_shutdown()
    pr_emerg()
    kmsg_dump()
    machine_halt()
kernel_kexec() <int kernel_kexec (void) at kexec_core.c:1464>:
    mutex_trylock()
    lock_system_sleep()
    pm_prepare_console()
    freeze_processes()
    suspend_console()
    dpm_suspend_start()
    dpm_suspend_end()
    disable_nonboot_cpus() <int disable_nonboot_cpus (void) at cpu.c:572>:
        cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
            mutex_lock()
        cpumask_first()
        cpumask_clear()
        pr_info()
        for_each_online_cpu()
        trace_suspend_resume()
        TPS()
        cpumask_set_cpu()
        pr_err()
        BUG_ON()
        num_online_cpus()
        cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
            mutex_unlock()
    local_irq_disable()
    syscore_suspend()
    kernel_restart_prepare() <void kernel_restart_prepare (char *cmd) at reboot.c:68>:
        blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
        usermodehelper_disable()
        device_shutdown()
    migrate_to_reboot_cpu() <void migrate_to_reboot_cpu (void) at reboot.c:188>:
        cpu_hotplug_disable() <void cpu_hotplug_disable (void) at cpu.c:178>:
            cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
                mutex_lock()
            cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
                mutex_unlock()
        cpu_online()
        cpumask_first()
        set_cpus_allowed_ptr()
        cpumask_of()
    cpu_hotplug_enable() <void cpu_hotplug_enable (void) at cpu.c:186>:
        cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
            mutex_lock()
        WARN_ON()
        cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
            mutex_unlock()
    pr_emerg()
    machine_shutdown()
    machine_kexec()
    syscore_resume()
    local_irq_enable()
    enable_nonboot_cpus() <void enable_nonboot_cpus (void) at cpu.c:623>:
        cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
            mutex_lock()
        WARN_ON()
        cpumask_empty()
        pr_info()
        arch_enable_nonboot_cpus_begin() <void __weak arch_enable_nonboot_cpus_begin (void) at cpu.c:615>
        for_each_cpu()
        trace_suspend_resume()
        TPS()
        pr_warn()
        arch_enable_nonboot_cpus_end() <void __weak arch_enable_nonboot_cpus_end (void) at cpu.c:619>
        cpumask_clear()
        cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
            mutex_unlock()
    dpm_resume_start()
    dpm_resume_end()
    resume_console()
    thaw_processes()
    pm_restore_console()
    unlock_system_sleep()
    mutex_unlock()
kernel_param_lock() <void kernel_param_lock (struct module *mod) at params.c:639>:
    mutex_lock()
    KPARAM_MUTEX()
kernel_param_unlock() <void kernel_param_unlock (struct module *mod) at params.c:644>:
    mutex_unlock()
    KPARAM_MUTEX()
kernel_power_off() <void kernel_power_off (void) at reboot.c:257>:
    kernel_shutdown_prepare() <void kernel_shutdown_prepare (enum system_states state) at reboot.c:228>:
        blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
        usermodehelper_disable()
        device_shutdown()
    pm_power_off_prepare() <void (*pm_power_off_prepare) (void) at reboot.c:51>
    migrate_to_reboot_cpu() <void migrate_to_reboot_cpu (void) at reboot.c:188>:
        cpu_hotplug_disable() <void cpu_hotplug_disable (void) at cpu.c:178>:
            cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
                mutex_lock()
            cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
                mutex_unlock()
        cpu_online()
        cpumask_first()
        set_cpus_allowed_ptr()
        cpumask_of()
    syscore_shutdown()
    pr_emerg()
    kmsg_dump()
    machine_power_off()
kernel_restart() <void kernel_restart (char *cmd) at reboot.c:214>:
    kernel_restart_prepare() <void kernel_restart_prepare (char *cmd) at reboot.c:68>:
        blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
        usermodehelper_disable()
        device_shutdown()
    migrate_to_reboot_cpu() <void migrate_to_reboot_cpu (void) at reboot.c:188>:
        cpu_hotplug_disable() <void cpu_hotplug_disable (void) at cpu.c:178>:
            cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
                mutex_lock()
            cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
                mutex_unlock()
        cpu_online()
        cpumask_first()
        set_cpus_allowed_ptr()
        cpumask_of()
    syscore_shutdown()
    pr_emerg()
    kmsg_dump()
    machine_restart()
kernel_restart_prepare() <void kernel_restart_prepare (char *cmd) at reboot.c:68>:
    blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
    usermodehelper_disable()
    device_shutdown()
kernel_sigaction() <void kernel_sigaction (int sig, __sighandler_t action) at signal.c:3029>:
    spin_lock_irq()
    flush_sigqueue_mask() <int flush_sigqueue_mask (sigset_t *mask, struct sigpending *s) at signal.c:659>:
        sigandsets()
        sigisemptyset()
        sigandnsets()
        list_for_each_entry_safe()
        list_del_init()
    recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
        recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
            PENDING()
            set_tsk_thread_flag()
        freezing()
        clear_thread_flag()
    spin_unlock_irq()
kernel_text_address() <int kernel_text_address (unsigned long addr) at extable.c:120>:
    core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
        init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
    is_module_text_address() <bool is_module_text_address (unsigned long addr) at module.c:4052>:
        preempt_disable()
        preempt_enable()
    is_ftrace_trampoline()
kernel_thread() <pid_t kernel_thread (int (*fn) (void *), void *arg, unsigned long flags) at fork.c:1779>:
kexec_add_buffer() <int kexec_add_buffer (struct kimage *image, char *buffer, unsigned long bufsz, unsigned long memsz, unsigned long buf_align, unsigned long buf_min, unsigned long buf_max, bool top_down, unsigned long *load_addr) at kexec_file.c:484>:
    list_empty()
    WARN_ON()
    ALIGN()
    max()
    walk_iomem_res() <int walk_iomem_res (char *name, unsigned long flags, u64 start, u64 end, void *arg, int (*func) (u64, u64, void *)) at resource.c:395>:
        find_next_iomem_res() <int find_next_iomem_res (struct resource *res, char *name, bool first_level_children_only) at resource.c:342>:
            start()
            BUG_ON()
            read_lock()
            next_resource() <struct resource *next_resource (struct resource *p, bool sibling_only) at resource.c:63>
            read_unlock()
    locate_mem_hole_callback() <int locate_mem_hole_callback (u64 start, u64 end, void *arg) at kexec_file.c:459>:
        locate_mem_hole_top_down() <int locate_mem_hole_top_down (unsigned long start, unsigned long end, struct kexec_buf *kbuf) at kexec_file.c:387>:
            min()
            kimage_is_destination_range() <int kimage_is_destination_range (struct kimage *image, unsigned long start, unsigned long end) at kexec_core.c:264>:
        locate_mem_hole_bottom_up() <int locate_mem_hole_bottom_up (unsigned long start, unsigned long end, struct kexec_buf *kbuf) at kexec_file.c:425>:
            max()
            ALIGN()
            kimage_is_destination_range() <int kimage_is_destination_range (struct kimage *image, unsigned long start, unsigned long end) at kexec_core.c:264>:
    walk_system_ram_res() <int walk_system_ram_res (u64 start, u64 end, void *arg, int (*func) (u64, u64, void *)) at resource.c:424>:
        find_next_iomem_res() <int find_next_iomem_res (struct resource *res, char *name, bool first_level_children_only) at resource.c:342>:
            start()
            BUG_ON()
            read_lock()
            next_resource() <struct resource *next_resource (struct resource *p, bool sibling_only) at resource.c:63>
            read_unlock()
kexec_load_purgatory() <int kexec_load_purgatory (struct kimage *image, unsigned long min, unsigned long max, int top_down, unsigned long *load_addr) at kexec_file.c:901>:
    elf_check_arch()
    kexec_apply_relocations() <int kexec_apply_relocations (struct kimage *image) at kexec_file.c:845>:
        arch_kexec_apply_relocations_add() <int __weak arch_kexec_apply_relocations_add (const Elf_Ehdr *ehdr, Elf_Shdr *sechdrs, unsigned int relsec) at kexec_file.c:122>:
            pr_err()
        arch_kexec_apply_relocations() <int __weak arch_kexec_apply_relocations (const Elf_Ehdr *ehdr, Elf_Shdr *sechdrs, unsigned int relsec) at kexec_file.c:131>:
            pr_err()
    vfree()
kexec_purgatory_get_set_symbol() <int kexec_purgatory_get_set_symbol (struct kimage *image, const char *name, void *buf, unsigned int size, bool get_value) at kexec_file.c:1014>:
    kexec_purgatory_find_symbol() <Elf_Sym *kexec_purgatory_find_symbol (struct purgatory_info *pi, const char *name) at kexec_file.c:943>:
        ELF_ST_BIND()
        pr_debug()
    pr_err()
kexec_purgatory_get_symbol_addr() <void *kexec_purgatory_get_symbol_addr (struct kimage *image, const char *name) at kexec_file.c:991>:
    kexec_purgatory_find_symbol() <Elf_Sym *kexec_purgatory_find_symbol (struct purgatory_info *pi, const char *name) at kexec_file.c:943>:
        ELF_ST_BIND()
        pr_debug()
    ERR_PTR()
kexec_should_crash() <int kexec_should_crash (struct task_struct *p) at kexec_core.c:78>:
    in_interrupt()
    is_global_init()
kick_all_cpus_sync() <void kick_all_cpus_sync (void) at smp.c:714>:
    smp_mb()
    smp_call_function() <int smp_call_function (smp_call_func_t func, void *info, int wait) at smp.c:488>:
        preempt_disable()
        smp_call_function_many() <void smp_call_function_many (const struct cpumask *mask, smp_call_func_t func, void *info, bool wait) at smp.c:404>:
            smp_processor_id()
            WARN_ON_ONCE()
            cpu_online()
            irqs_disabled()
            cpumask_first_and()
            cpumask_next_and()
            smp_call_function_single() <int smp_call_function_single (int cpu, void (*func) (void *info), void *info, int wait) at up.c:10>:
                get_cpu()
                WARN_ON_ONCE()
                cpu_online()
                irqs_disabled()
                this_cpu_ptr()
                csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
                    csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                        smp_load_acquire()
                        cpu_relax()
                    smp_wmb()
                generic_exec_single() <int generic_exec_single (int cpu, struct call_single_data *csd, smp_call_func_t func, void *info) at smp.c:144>:
                    smp_processor_id()
                    csd_unlock() <void csd_unlock (struct call_single_data *csd) at smp.c:127>:
                        WARN_ON()
                        smp_store_release()
                    local_irq_save()
                    local_irq_restore()
                    cpu_online()
                    llist_add()
                    per_cpu()
                    arch_send_call_function_single_ipi()
                csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                    smp_load_acquire()
                    cpu_relax()
                put_cpu()
                WARN_ON()
                local_irq_save()
                local_irq_restore()
            this_cpu_ptr()
            cpumask_and()
            cpumask_clear_cpu()
            unlikely()
            cpumask_weight()
            for_each_cpu()
            per_cpu_ptr()
            csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
                csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                    smp_load_acquire()
                    cpu_relax()
                smp_wmb()
            llist_add()
            per_cpu()
            arch_send_call_function_ipi_mask()
            csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                smp_load_acquire()
                cpu_relax()
        preempt_enable()
    do_nothing() <void do_nothing (void *unused) at smp.c:699>
kill_pgrp() <int kill_pgrp (struct pid *pid, int sig, int priv) at signal.c:1459>:
    read_lock()
    read_unlock()
kill_pid() <int kill_pid (struct pid *pid, int sig, int priv) at signal.c:1471>:
    kill_pid_info() <int kill_pid_info (int sig, struct siginfo *info, struct pid *pid) at signal.c:1288>:
        rcu_read_lock()
        pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
            rcu_dereference_check()
            hlist_first_rcu()
            lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                lockdep_is_held()
            hlist_entry()
        group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
            rcu_read_lock()
            check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                valid_signal()
                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                    SI_FROMUSER()
                audit_signal_info()
                same_thread_group()
                kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                    current_cred()
                    uid_eq()
                    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                        unlikely()
                        cap_valid()
                        pr_crit()
                        BUG()
                        security_capable()
                        current_cred()
                task_session()
                security_task_kill()
            rcu_read_unlock()
            do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                lock_task_sighand()
                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                        SI_FROMUSER()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                unlock_task_sighand()
        rcu_read_unlock()
        likely()
kill_pid_info() <int kill_pid_info (int sig, struct siginfo *info, struct pid *pid) at signal.c:1288>:
    rcu_read_lock()
    pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
        rcu_dereference_check()
        hlist_first_rcu()
        lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
            lockdep_is_held()
        hlist_entry()
    group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
        rcu_read_lock()
        check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
            valid_signal()
            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                SI_FROMUSER()
            audit_signal_info()
            same_thread_group()
            kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                current_cred()
                uid_eq()
                ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                    unlikely()
                    cap_valid()
                    pr_crit()
                    BUG()
                    security_capable()
                    current_cred()
            task_session()
            security_task_kill()
        rcu_read_unlock()
        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
            lock_task_sighand()
            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                    SI_FROMUSER()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
            unlock_task_sighand()
    rcu_read_unlock()
    likely()
kill_pid_info_as_cred() <int kill_pid_info_as_cred (int sig, struct siginfo *info, struct pid *pid, const struct cred *cred, u32 secid) at signal.c:1330>:
    valid_signal()
    rcu_read_lock()
    pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
        rcu_dereference_check()
        hlist_first_rcu()
        lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
            lockdep_is_held()
        hlist_entry()
    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
        SI_FROMUSER()
    kill_as_cred_perm() <int kill_as_cred_perm (const struct cred *cred, struct task_struct *target) at signal.c:1319>:
        uid_eq()
    security_task_kill()
    lock_task_sighand()
    unlock_task_sighand()
    rcu_read_unlock()
kill_proc_info() <int kill_proc_info (int sig, struct siginfo *info, pid_t pid) at signal.c:1310>:
    rcu_read_lock()
    kill_pid_info() <int kill_pid_info (int sig, struct siginfo *info, struct pid *pid) at signal.c:1288>:
        rcu_read_lock()
        pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
            rcu_dereference_check()
            hlist_first_rcu()
            lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
                lockdep_is_held()
            hlist_entry()
        group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
            rcu_read_lock()
            check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                valid_signal()
                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                    SI_FROMUSER()
                audit_signal_info()
                same_thread_group()
                kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                    current_cred()
                    uid_eq()
                    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                        unlikely()
                        cap_valid()
                        pr_crit()
                        BUG()
                        security_capable()
                        current_cred()
                task_session()
                security_task_kill()
            rcu_read_unlock()
            do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                lock_task_sighand()
                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                        SI_FROMUSER()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                unlock_task_sighand()
        rcu_read_unlock()
        likely()
    find_vpid() <struct pid *find_vpid (int nr) at pid.c:380>:
        find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
            hlist_for_each_entry_rcu()
            pid_hashfn()
            container_of()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
    rcu_read_unlock()
kimage_alloc_control_pages() <struct page *kimage_alloc_control_pages (struct kimage *image, unsigned int order) at kexec_core.c:448>:
    kimage_alloc_normal_control_pages() <struct page *kimage_alloc_normal_control_pages (struct kimage *image, unsigned int order) at kexec_core.c:321>:
        INIT_LIST_HEAD()
        kimage_alloc_pages() <struct page *kimage_alloc_pages (gfp_t gfp_mask, unsigned int order) at kexec_core.c:282>:
            alloc_pages()
            set_page_private()
            SetPageReserved()
        page_to_pfn()
        kimage_is_destination_range() <int kimage_is_destination_range (struct kimage *image, unsigned long start, unsigned long end) at kexec_core.c:264>:
        list_add()
        kimage_free_page_list() <void kimage_free_page_list (struct list_head *list) at kexec_core.c:311>:
            list_for_each_entry_safe()
            list_del()
            kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                page_private()
                ClearPageReserved()
    kimage_alloc_crash_control_pages() <struct page *kimage_alloc_crash_control_pages (struct kimage *image, unsigned int order) at kexec_core.c:387>:
        pfn_to_page()
kimage_file_post_load_cleanup() <void kimage_file_post_load_cleanup (struct kimage *image) at kexec_file.c:143>:
    vfree()
    kfree()
    arch_kimage_file_post_load_cleanup() <int __weak arch_kimage_file_post_load_cleanup (struct kimage *image) at kexec_file.c:107>:
kimage_free() <void kimage_free (struct kimage *image) at kexec_core.c:544>:
    kimage_free_extra_pages() <void kimage_free_extra_pages (struct kimage *image) at kexec_core.c:514>:
        kimage_free_page_list() <void kimage_free_page_list (struct list_head *list) at kexec_core.c:311>:
            list_for_each_entry_safe()
            list_del()
            kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                page_private()
                ClearPageReserved()
    for_each_kimage_entry()
    kimage_free_entry() <void kimage_free_entry (kimage_entry_t entry) at kexec_core.c:536>:
        pfn_to_page()
        kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
            page_private()
            ClearPageReserved()
    machine_kexec_cleanup()
    kimage_free_page_list() <void kimage_free_page_list (struct list_head *list) at kexec_core.c:311>:
        list_for_each_entry_safe()
        list_del()
        kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
            page_private()
            ClearPageReserved()
    kimage_file_post_load_cleanup() <void kimage_file_post_load_cleanup (struct kimage *image) at kexec_file.c:143>:
        vfree()
        kfree()
        arch_kimage_file_post_load_cleanup() <int __weak arch_kimage_file_post_load_cleanup (struct kimage *image) at kexec_file.c:107>:
    kfree()
kimage_free_page_list() <void kimage_free_page_list (struct list_head *list) at kexec_core.c:311>:
    list_for_each_entry_safe()
    list_del()
    kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
        page_private()
        ClearPageReserved()
kimage_is_destination_range() <int kimage_is_destination_range (struct kimage *image, unsigned long start, unsigned long end) at kexec_core.c:264>:
kimage_load_segment() <int kimage_load_segment (struct kimage *image, struct kexec_segment *segment) at kexec_core.c:832>:
    kimage_load_normal_segment() <int kimage_load_normal_segment (struct kimage *image, struct kexec_segment *segment) at kexec_core.c:701>:
        kimage_set_destination() <int kimage_set_destination (struct kimage *image, unsigned long destination) at kexec_core.c:491>:
            kimage_add_entry() <int kimage_add_entry (struct kimage *image, kimage_entry_t entry) at kexec_core.c:465>:
                kimage_alloc_page() <struct page *kimage_alloc_page (struct kimage *image, gfp_t gfp_mask, unsigned long destination) at kexec_core.c:604>:
                    list_for_each_entry()
                    page_to_pfn()
                    list_del()
                    kimage_alloc_pages() <struct page *kimage_alloc_pages (gfp_t gfp_mask, unsigned int order) at kexec_core.c:282>:
                        alloc_pages()
                        set_page_private()
                        SetPageReserved()
                    list_add()
                    kimage_is_destination_range() <int kimage_is_destination_range (struct kimage *image, unsigned long start, unsigned long end) at kexec_core.c:264>:
                    kimage_dst_used() <kimage_entry_t *kimage_dst_used (struct kimage *image, unsigned long page) at kexec_core.c:585>:
                        for_each_kimage_entry()
                    pfn_to_page()
                    copy_highpage()
                    PageHighMem()
                    kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                        page_private()
                        ClearPageReserved()
                page_address()
                virt_to_phys()
        kimage_alloc_page() <struct page *kimage_alloc_page (struct kimage *image, gfp_t gfp_mask, unsigned long destination) at kexec_core.c:604>:
            list_for_each_entry()
            page_to_pfn()
            list_del()
            kimage_alloc_pages() <struct page *kimage_alloc_pages (gfp_t gfp_mask, unsigned int order) at kexec_core.c:282>:
                alloc_pages()
                set_page_private()
                SetPageReserved()
            list_add()
            kimage_is_destination_range() <int kimage_is_destination_range (struct kimage *image, unsigned long start, unsigned long end) at kexec_core.c:264>:
            kimage_dst_used() <kimage_entry_t *kimage_dst_used (struct kimage *image, unsigned long page) at kexec_core.c:585>:
                for_each_kimage_entry()
            pfn_to_page()
            copy_highpage()
            PageHighMem()
            kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                page_private()
                ClearPageReserved()
        kimage_add_page() <int kimage_add_page (struct kimage *image, unsigned long page) at kexec_core.c:503>:
            kimage_add_entry() <int kimage_add_entry (struct kimage *image, kimage_entry_t entry) at kexec_core.c:465>:
                kimage_alloc_page() <struct page *kimage_alloc_page (struct kimage *image, gfp_t gfp_mask, unsigned long destination) at kexec_core.c:604>:
                    list_for_each_entry()
                    page_to_pfn()
                    list_del()
                    kimage_alloc_pages() <struct page *kimage_alloc_pages (gfp_t gfp_mask, unsigned int order) at kexec_core.c:282>:
                        alloc_pages()
                        set_page_private()
                        SetPageReserved()
                    list_add()
                    kimage_is_destination_range() <int kimage_is_destination_range (struct kimage *image, unsigned long start, unsigned long end) at kexec_core.c:264>:
                    kimage_dst_used() <kimage_entry_t *kimage_dst_used (struct kimage *image, unsigned long page) at kexec_core.c:585>:
                        for_each_kimage_entry()
                    pfn_to_page()
                    copy_highpage()
                    PageHighMem()
                    kimage_free_pages() <void kimage_free_pages (struct page *page) at kexec_core.c:300>:
                        page_private()
                        ClearPageReserved()
                page_address()
                virt_to_phys()
        page_to_pfn()
        kmap()
        clear_page()
        min_t()
        min()
        copy_from_user()
        kunmap()
    kimage_load_crash_segment() <int kimage_load_crash_segment (struct kimage *image, struct kexec_segment *segment) at kexec_core.c:768>:
        pfn_to_page()
        kmap()
        min_t()
        min()
        copy_from_user()
        kexec_flush_icache_page()
        kunmap()
kimage_terminate() <void kimage_terminate (struct kimage *image) at kexec_core.c:523>:
kprobe_flush_task() <void kprobe_flush_task (struct task_struct *tk) at kprobes.c:1144>:
    unlikely()
    INIT_HLIST_HEAD()
    hash_ptr()
    kretprobe_table_lock() < at kprobes.c:1108>:
        kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
        raw_spin_lock_irqsave()
    hlist_for_each_entry_safe()
    recycle_rp_inst() <void recycle_rp_inst (struct kretprobe_instance *ri, struct hlist_head *head) at kprobes.c:1077>:
        hlist_del()
        INIT_HLIST_NODE()
        likely()
        raw_spin_lock()
        hlist_add_head()
        raw_spin_unlock()
    kretprobe_table_unlock() < at kprobes.c:1129>:
        kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
        raw_spin_unlock_irqrestore()
    hlist_del()
    kfree()
kprobes_inc_nmissed_count() <void kprobes_inc_nmissed_count (struct kprobe *p) at kprobes.c:1064>:
    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
            list_for_each_entry_rcu()
            likely()
            kprobe_disabled()
            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
    list_for_each_entry_rcu()
kretprobe_hash_lock() < at kprobes.c:1095>:
    hash_ptr()
    kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
    raw_spin_lock_irqsave()
kretprobe_hash_unlock() < at kprobes.c:1117>:
    hash_ptr()
    kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
    raw_spin_unlock_irqrestore()
kthread_bind() <void kthread_bind (struct task_struct *p, unsigned int cpu) at kthread.c:366>:
kthread_bind_mask() <void kthread_bind_mask (struct task_struct *p, const struct cpumask *mask) at kthread.c:352>:
kthread_create_on_cpu() <struct task_struct *kthread_create_on_cpu (int (*threadfn) (void *data), void *data, unsigned int cpu, const char *namefmt) at kthread.c:383>:
    kthread_create_on_node() <struct task_struct *kthread_create_on_node (int (*threadfn) (void *data), void *data, int node, const char namefmt[], ...) at kthread.c:270>:
        DECLARE_COMPLETION_ONSTACK()
        kmalloc()
        ERR_PTR()
        spin_lock()
        list_add_tail()
        spin_unlock()
        wake_up_process()
        unlikely()
        wait_for_completion_killable()
        xchg()
        wait_for_completion()
        IS_ERR()
        sched_setscheduler_nocheck()
        set_cpus_allowed_ptr()
        kfree()
    cpu_to_node()
    IS_ERR()
    set_bit()
    to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
    kthread_park() <int kthread_park (struct task_struct *k) at kthread.c:445>:
        to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
            ACCESS_ONCE()
            likely()
        test_bit()
        set_bit()
        wake_up_process()
        wait_for_completion()
kthread_create_on_node() <struct task_struct *kthread_create_on_node (int (*threadfn) (void *data), void *data, int node, const char namefmt[], ...) at kthread.c:270>:
    DECLARE_COMPLETION_ONSTACK()
    kmalloc()
    ERR_PTR()
    spin_lock()
    list_add_tail()
    spin_unlock()
    wake_up_process()
    unlikely()
    wait_for_completion_killable()
    xchg()
    wait_for_completion()
    IS_ERR()
    sched_setscheduler_nocheck()
    set_cpus_allowed_ptr()
    kfree()
kthread_data() <void *kthread_data (struct task_struct *task) at kthread.c:135>:
    to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
kthread_freezable_should_stop() <bool kthread_freezable_should_stop (bool *was_frozen) at kthread.c:111>:
    frozen()
    might_sleep()
    unlikely()
    freezing()
    kthread_should_stop() <bool kthread_should_stop (void) at kthread.c:79>:
        test_bit()
        to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
kthread_park() <int kthread_park (struct task_struct *k) at kthread.c:445>:
    to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
        ACCESS_ONCE()
        likely()
    test_bit()
    set_bit()
    wake_up_process()
    wait_for_completion()
kthread_parkme() <void kthread_parkme (void) at kthread.c:171>:
    to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
kthread_should_park() <bool kthread_should_park (void) at kthread.c:96>:
    test_bit()
    to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
kthread_should_stop() <bool kthread_should_stop (void) at kthread.c:79>:
    test_bit()
    to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
    trace_sched_kthread_stop()
    get_task_struct()
    to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
        ACCESS_ONCE()
        likely()
    set_bit()
    wake_up_process()
    wait_for_completion()
    put_task_struct()
    trace_sched_kthread_stop_ret()
kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
    to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
        ACCESS_ONCE()
        likely()
kthread_worker_fn() <int kthread_worker_fn (void *worker_ptr) at kthread.c:565>:
    WARN_ON()
    set_current_state()
    kthread_should_stop() <bool kthread_should_stop (void) at kthread.c:79>:
        test_bit()
        to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
    spin_lock_irq()
    spin_unlock_irq()
    list_empty()
    list_first_entry()
    list_del_init()
    freezing()
    schedule()
    try_to_freeze()
kthreadd() <int kthreadd (void *unused) at kthread.c:502>:
    set_task_comm()
    ignore_signals() <void ignore_signals (struct task_struct *t) at signal.c:464>:
        flush_signals() <void flush_signals (struct task_struct *t) at signal.c:419>:
            spin_lock_irqsave()
            clear_tsk_thread_flag()
            flush_sigqueue() <void flush_sigqueue (struct sigpending *queue) at signal.c:404>:
                list_empty()
                list_entry()
                list_del_init()
            spin_unlock_irqrestore()
    set_cpus_allowed_ptr()
    set_mems_allowed()
    set_current_state()
    list_empty()
    schedule()
    spin_lock()
    list_entry()
    list_del_init()
    spin_unlock()
    create_kthread() <void create_kthread (struct kthread_create_info *create) at kthread.c:225>:
        kernel_thread() <pid_t kernel_thread (int (*fn) (void *), void *arg, unsigned long flags) at fork.c:1779>:
        kthread() <int kthread (void *_create) at kthread.c:177>:
            init_completion()
            xchg()
            kfree()
            do_exit() <void do_exit (long code) at exit.c:651>:
                TASKS_RCU()
                profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
                    blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
                WARN_ON()
                blk_needs_flush_plug()
                unlikely()
                in_interrupt()
                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                    local_irq_disable()
                    raw_smp_processor_id()
                    atomic_cmpxchg()
                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                        cpu_relax()
                    console_verbose()
                    bust_spinlocks()
                    pr_emerg()
                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                        test_bit()
                    dump_stack()
                    smp_send_stop()
                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                    kmsg_dump()
                    debug_locks_off()
                    console_flush_on_panic()
                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                    no_blink() <long no_blink (int state) at panic.c:46>
                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                        raw_cpu_write()
                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                raw_cpu_write()
                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                per_cpu()
                            raw_smp_processor_id()
                    mdelay()
                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                        kmsg_dump()
                        machine_emergency_restart()
                    disabled_wait()
                    local_irq_enable()
                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                            raw_cpu_write()
                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                            per_cpu()
                        raw_smp_processor_id()
                set_fs()
                ptrace_event()
                validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
                    kdebug()
                    atomic_read()
                    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                        atomic_read()
                pr_alert()
                set_current_state()
                schedule()
                exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
                    threadgroup_change_begin()
                    thread_group_empty()
                    signal_group_exit()
                    threadgroup_change_end()
                    spin_lock_irq()
                    signal_pending()
                    signotset()
                    retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                        sigandsets()
                        sigisemptyset()
                        while_each_thread()
                        has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                        signal_pending()
                        signal_wake_up()
                    unlikely()
                    task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                        WARN_ON_ONCE()
                        task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                            BUG_ON()
                            task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                                unlikely()
                                smp_mb()
                                wake_up_bit()
                    spin_unlock_irq()
                    read_lock()
                    do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        BUG()
                        spin_lock_irqsave()
                        spin_unlock_irqrestore()
                    read_unlock()
                smp_mb()
                raw_spin_unlock_wait()
                in_atomic()
                pr_info()
                task_pid_nr()
                preempt_count()
                preempt_count_set()
                sync_mm_rss()
                acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
                    task_cputime()
                atomic_dec_and_test()
                hrtimer_cancel()
                exit_itimers()
                setmax_mm_hiwater_rss()
                acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
                    down_read()
                    up_read()
                    spin_lock_irq()
                    thread_group_leader()
                    task_cputime()
                    spin_unlock_irq()
                tty_audit_exit()
                audit_free()
                taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
                    taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                        nla_total_size()
                    taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                        thread_group_empty()
                        kmem_cache_zalloc()
                        spin_lock_irq()
                        spin_unlock_irq()
                        kmem_cache_free()
                    fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                        spin_lock_irqsave()
                        delayacct_add_tsk()
                        spin_unlock_irqrestore()
                    raw_cpu_ptr()
                    list_empty()
                    prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                        genlmsg_new()
                        this_cpu_inc_return()
                        genlmsg_put()
                        genlmsg_put_reply()
                        nlmsg_free()
                    mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                        nla_put()
                        nla_nest_start()
                        nla_nest_cancel()
                        nla_reserve()
                        nla_nest_end()
                        nla_data()
                    task_pid_nr_ns()
                    fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                        delayacct_add_tsk()
                        bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                            BUILD_BUG_ON()
                            ktime_get_ns()
                            do_div()
                            get_seconds()
                            thread_group_leader()
                            task_nice()
                            task_pid_nr_ns()
                            rcu_read_lock()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                                from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            pid_alive()
                            task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                task_tgid()
                            rcu_dereference()
                            rcu_read_unlock()
                            task_cputime()
                            cputime_to_usecs()
                            task_cputime_scaled()
                        xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                            get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                                task_lock()
                                atomic_inc()
                                task_unlock()
                            get_mm_hiwater_rss()
                            get_mm_hiwater_vm()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                        task_tgid()
                    send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                        nlmsg_data()
                        nlmsg_hdr()
                        genlmsg_data()
                        genlmsg_end()
                        down_read()
                        list_for_each_entry()
                        list_is_last()
                        skb_clone()
                        genlmsg_unicast()
                        up_read()
                        nlmsg_free()
                        down_write()
                        list_for_each_entry_safe()
                        list_del()
                        kfree()
                        up_write()
                    nlmsg_free()
                exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
                    mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                        unlikely()
                        exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                            uninitialized_var()
                            fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                                get_user()
                            get_user()
                            handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                                uninitialized_var()
                                get_user()
                                task_pid_vnr()
                                cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                    pagefault_disable()
                                    futex_atomic_cmpxchg_inatomic()
                                    pagefault_enable()
                                fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                    down_read()
                                    fixup_user_fault()
                                    up_read()
                                futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                    WAKE_Q()
                                    get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                        unlikely()
                                        access_ok()
                                        should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                            should_fail()
                                        get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                            ihold()
                                            futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                                atomic_inc()
                                                smp_mb__after_atomic()
                                            smp_mb()
                                        get_user_pages_fast()
                                        lock_page()
                                        compound_head()
                                        PageSwapCache()
                                        unlock_page()
                                        put_page()
                                        PageAnon()
                                        basepage_index()
                                    unlikely()
                                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                        jhash2()
                                    hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                        atomic_read()
                                    spin_lock()
                                    plist_for_each_entry_safe()
                                    match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                    mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                        WARN()
                                        wake_q_add()
                                        smp_wmb()
                                    spin_unlock()
                                    wake_up_q()
                                    put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                        drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                            WARN_ON_ONCE()
                                            iput()
                                            mmdrop()
                            cond_resched()
                        compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                            uninitialized_var()
                            fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                                get_user()
                                compat_ptr()
                            get_user()
                            futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                                ptr_to_compat()
                                compat_ptr()
                            handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                                uninitialized_var()
                                get_user()
                                task_pid_vnr()
                                cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                                    pagefault_disable()
                                    futex_atomic_cmpxchg_inatomic()
                                    pagefault_enable()
                                fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                                    down_read()
                                    fixup_user_fault()
                                    up_read()
                                futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                                    WAKE_Q()
                                    get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                        unlikely()
                                        access_ok()
                                        should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                            should_fail()
                                        get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                            ihold()
                                            futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                                atomic_inc()
                                                smp_mb__after_atomic()
                                            smp_mb()
                                        get_user_pages_fast()
                                        lock_page()
                                        compound_head()
                                        PageSwapCache()
                                        unlock_page()
                                        put_page()
                                        PageAnon()
                                        basepage_index()
                                    unlikely()
                                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                        jhash2()
                                    hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                        atomic_read()
                                    spin_lock()
                                    plist_for_each_entry_safe()
                                    match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                                    mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                        WARN()
                                        wake_q_add()
                                        smp_wmb()
                                    spin_unlock()
                                    wake_up_q()
                                    put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                        drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                            WARN_ON_ONCE()
                                            iput()
                                            mmdrop()
                            cond_resched()
                        list_empty()
                        exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                            raw_spin_lock_irq()
                            list_empty()
                            list_entry()
                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                jhash2()
                            raw_spin_unlock_irq()
                            spin_lock()
                            spin_unlock()
                            WARN_ON()
                            list_del_init()
                            rt_mutex_unlock()
                        uprobe_free_utask()
                        deactivate_mm()
                        atomic_read()
                        put_user()
                        sys_futex()
                        complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                            task_lock()
                            likely()
                            complete()
                            task_unlock()
                    sync_mm_rss()
                    down_read()
                    up_read()
                    xchg()
                    atomic_dec_and_test()
                    complete()
                    set_task_state()
                    freezable_schedule()
                    atomic_inc()
                    BUG_ON()
                    task_lock()
                    enter_lazy_tlb()
                    task_unlock()
                    mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                        atomic_read()
                        read_lock()
                        list_for_each_entry()
                        for_each_process()
                        for_each_thread()
                        read_unlock()
                        BUG_ON()
                        get_task_struct()
                        task_lock()
                        task_unlock()
                        put_task_struct()
                    mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                        might_sleep()
                        atomic_dec_and_test()
                        uprobe_clear_state()
                        exit_aio()
                        ksm_exit()
                        khugepaged_exit()
                        exit_mmap()
                        set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                            rcu_dereference_raw()
                            get_file()
                            rcu_assign_pointer()
                            fput()
                        list_empty()
                        spin_lock()
                        list_del()
                        spin_unlock()
                        module_put() <void module_put (struct module *module) at module.c:1098>:
                            preempt_disable()
                            atomic_dec_if_positive()
                            WARN_ON()
                            trace_module_put()
                            preempt_enable()
                        mmdrop()
                    test_thread_flag()
                    exit_oom_victim()
                acct_process() <void acct_process (void) at acct.c:587>:
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    unlikely()
                    slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                        acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                            smp_rmb()
                            rcu_read_lock()
                            to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                                container_of()
                            ACCESS_ONCE()
                            rcu_read_unlock()
                            atomic_long_inc_not_zero()
                            cpu_relax()
                            mutex_lock()
                            mutex_unlock()
                            acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                                atomic_long_dec_and_test()
                                kfree_rcu()
                        do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                            override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                                kdebug()
                                atomic_read()
                                read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                    atomic_read()
                                validate_creds()
                                get_cred()
                                alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                    atomic_add()
                                rcu_assign_pointer()
                            check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                                time_is_before_jiffies()
                                vfs_statfs()
                                do_div()
                                pr_info()
                            fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                                strlcpy()
                                ktime_get_ns()
                                nsec_to_AHZ()
                                encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                                encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                                encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                                do_div()
                                get_seconds()
                                spin_lock_irq()
                                old_encode_dev()
                                tty_devnum()
                                jiffies_to_AHZ()
                                cputime_to_jiffies()
                                spin_unlock_irq()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                                from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                                pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                                task_tgid()
                            rcu_read_lock()
                            rcu_dereference()
                            rcu_read_unlock()
                            file_start_write_trylock()
                            file_end_write()
                            revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                                kdebug()
                                atomic_read()
                                read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                    atomic_read()
                                validate_creds()
                                alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                                    atomic_add()
                                rcu_assign_pointer()
                                put_cred()
                        mutex_unlock()
                        acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                            atomic_long_dec_and_test()
                            kfree_rcu()
                trace_sched_process_exit()
                exit_sem()
                exit_shm()
                exit_files()
                exit_fs()
                disassociate_ctty()
                exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
                    switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                        might_sleep()
                        task_lock()
                        task_unlock()
                        atomic_dec_and_test()
                        free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                            put_mnt_ns()
                            put_uts_ns()
                            put_ipc_ns()
                            put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                                kref_put()
                                free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                    container_of()
                                    destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                        ns_free_inum()
                                        kfree()
                                        put_user_ns()
                                        call_rcu()
                                        delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                            kmem_cache_free()
                                            container_of()
                            put_net()
                            kmem_cache_free()
                exit_task_work()
                exit_thread()
                perf_event_exit_task()
                cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
                    task_css_set()
                    list_empty()
                    spin_lock_bh()
                    css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                        lockdep_assert_held()
                        WARN_ON_ONCE()
                        list_empty()
                        list_for_each_entry_safe()
                        css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                            lockdep_assert_held()
                            WARN_ON_ONCE()
                            css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                                lockdep_assert_held()
                                container_of()
                                list_entry()
                                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                    lockdep_assert_held()
                                    list_empty()
                                list_empty()
                                list_del()
                                put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                                    lockdep_assert_held()
                                    atomic_dec_and_test()
                                    for_each_subsys()
                                    list_del()
                                    css_put()
                                    hash_del()
                                    list_for_each_entry_safe()
                                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                        container_of()
                                    cgroup_put()
                                    kfree()
                                    kfree_rcu()
                                get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                    atomic_inc()
                                list_add()
                        list_del_init()
                        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                            lockdep_assert_held()
                            list_empty()
                        css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                            lockdep_assert_held()
                            list_for_each_entry()
                            cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                                lockdep_assert_held()
                                check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                                    notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                        test_bit()
                                    cgroup_is_populated()
                                    css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                        rcu_read_lock()
                                        css_for_each_child()
                                        rcu_read_unlock()
                                    cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                                    schedule_work()
                                cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                                    spin_lock_irqsave()
                                    kernfs_notify()
                                    spin_unlock_irqrestore()
                                cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                    container_of()
                        rcu_assign_pointer()
                        list_add_tail()
                    spin_unlock_bh()
                    get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                        atomic_inc()
                    for_each_subsys_which()
                flush_ptrace_hw_breakpoint()
                preempt_disable()
                preempt_enable()
                exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
                    LIST_HEAD()
                    write_lock_irq()
                    forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                        unlikely()
                        list_empty()
                        exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                            list_for_each_entry_safe()
                            unlikely()
                            send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                                valid_signal()
                                do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                    lock_task_sighand()
                                    send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                            SI_FROMUSER()
                                        task_pid_nr_ns()
                                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                            ns_of_pid()
                                            task_pid()
                                    unlock_task_sighand()
                            list_add()
                        find_child_reaper()
                        find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                            find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                                for_each_thread()
                            same_thread_group()
                        list_for_each_entry()
                        for_each_thread()
                        BUG_ON()
                        likely()
                        group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                            rcu_read_lock()
                            check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                                valid_signal()
                                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                    SI_FROMUSER()
                                audit_signal_info()
                                same_thread_group()
                                kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                                    current_cred()
                                    uid_eq()
                                    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                        unlikely()
                                        cap_valid()
                                        pr_crit()
                                        BUG()
                                        security_capable()
                                        current_cred()
                                task_session()
                                security_task_kill()
                            rcu_read_unlock()
                            do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                                lock_task_sighand()
                                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                        SI_FROMUSER()
                                    task_pid_nr_ns()
                                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                        ns_of_pid()
                                        task_pid()
                                unlock_task_sighand()
                        same_thread_group()
                        reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                            unlikely()
                            thread_group_empty()
                            do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                                BUG_ON()
                                task_is_stopped_or_traced()
                                thread_group_empty()
                                rcu_read_lock()
                                task_pid_nr_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                            smp_rmb()
                                task_cred_xxx()
                                task_uid()
                                rcu_read_unlock()
                                task_cputime()
                                cputime_to_clock_t()
                                spin_lock_irqsave()
                                valid_signal()
                                spin_unlock_irqrestore()
                            list_add()
                            kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                                task_pgrp()
                                task_session()
                                will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                                    do_each_pid_task()
                                    thread_group_empty()
                                    is_global_init()
                                    task_pgrp()
                                    task_session()
                                    while_each_pid_task()
                                has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                                    do_each_pid_task()
                                    while_each_pid_task()
                        list_splice_tail_init()
                    kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                        task_pgrp()
                        task_session()
                        will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                            do_each_pid_task()
                            thread_group_empty()
                            is_global_init()
                            task_pgrp()
                            task_session()
                            while_each_pid_task()
                        has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                            do_each_pid_task()
                            while_each_pid_task()
                    unlikely()
                    thread_group_leader()
                    thread_group_empty()
                    ptrace_reparented()
                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                        BUG_ON()
                        task_is_stopped_or_traced()
                        thread_group_empty()
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        spin_lock_irqsave()
                        valid_signal()
                        spin_unlock_irqrestore()
                    list_add()
                    wake_up_process()
                    write_unlock_irq()
                    list_for_each_entry_safe()
                    list_del_init()
                    release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                        rcu_read_lock()
                        atomic_dec()
                        rcu_read_unlock()
                        proc_flush_task()
                        write_lock_irq()
                        ptrace_release_task()
                        thread_group_empty()
                        do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                            BUG_ON()
                            task_is_stopped_or_traced()
                            thread_group_empty()
                            rcu_read_lock()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                        smp_rmb()
                            task_cred_xxx()
                            task_uid()
                            rcu_read_unlock()
                            task_cputime()
                            cputime_to_clock_t()
                            spin_lock_irqsave()
                            valid_signal()
                            spin_unlock_irqrestore()
                        write_unlock_irq()
                        release_thread()
                        call_rcu()
                        delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                            container_of()
                            perf_event_delayed_put()
                            trace_sched_process_free()
                            put_task_struct()
                        unlikely()
                proc_exit_connector()
                task_lock()
                mpol_put()
                task_unlock()
                kfree()
                debug_check_no_locks_held()
                exit_io_context()
                free_pipe_info()
                put_page()
                check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
                    stack_not_used()
                    spin_lock()
                    pr_warn()
                    task_pid_nr()
                    spin_unlock()
                exit_rcu()
                BUG()
                cpu_relax()
            complete()
            schedule()
            test_bit()
        xchg()
        kfree()
        ERR_PTR()
        complete()
lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
    lockdep_is_held()
lockup_detector_init() <void __init lockup_detector_init (void) at watchdog.c:1047>:
    set_sample_period() <void set_sample_period (void) at watchdog.c:211>:
        get_softlockup_thresh() <int get_softlockup_thresh (void) at watchdog.c:196>:
    tick_nohz_full_enabled()
    pr_info()
    cpumask_copy()
    watchdog_enable_all_cpus() <int watchdog_enable_all_cpus (void) at watchdog.c:797>:
        smpboot_register_percpu_thread_cpumask() <int smpboot_register_percpu_thread_cpumask (struct smp_hotplug_thread *plug_thread, const struct cpumask *cpumask) at smpboot.c:282>:
            alloc_cpumask_var()
            cpumask_copy()
            get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                might_sleep()
                cpuhp_lock_acquire_read()
                mutex_lock()
                atomic_inc()
                mutex_unlock()
            mutex_lock()
            for_each_online_cpu()
            smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
                for_each_possible_cpu()
                per_cpu_ptr()
                kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
                    trace_sched_kthread_stop()
                    get_task_struct()
                    to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                        ACCESS_ONCE()
                        likely()
                    set_bit()
                    wake_up_process()
                    wait_for_completion()
                    put_task_struct()
                    trace_sched_kthread_stop_ret()
                put_task_struct()
            free_cpumask_var()
            cpumask_test_cpu()
            smpboot_unpark_thread() <void smpboot_unpark_thread (struct smp_hotplug_thread *ht, unsigned int cpu) at smpboot.c:221>:
                per_cpu_ptr()
                kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
                    to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                        ACCESS_ONCE()
                        likely()
            list_add()
            mutex_unlock()
            put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                atomic_dec_return()
                WARN_ON()
                atomic_inc()
                waitqueue_active()
                wake_up()
                cpuhp_lock_release()
        pr_err()
        update_watchdog_all_cpus() <int update_watchdog_all_cpus (void) at watchdog.c:784>:
            watchdog_park_threads() <int watchdog_park_threads (void) at watchdog.c:706>:
                for_each_watchdog_cpu()
                kthread_park() <int kthread_park (struct task_struct *k) at kthread.c:445>:
                    to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                        ACCESS_ONCE()
                        likely()
                    test_bit()
                    set_bit()
                    wake_up_process()
                    wait_for_completion()
                per_cpu()
            watchdog_unpark_threads() <void watchdog_unpark_threads (void) at watchdog.c:725>:
                for_each_watchdog_cpu()
                kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
                    to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                        ACCESS_ONCE()
                        likely()
                per_cpu()
        watchdog_disable_all_cpus() <void watchdog_disable_all_cpus (void) at watchdog.c:827>:
            smpboot_unregister_percpu_thread() <void smpboot_unregister_percpu_thread (struct smp_hotplug_thread *plug_thread) at smpboot.c:318>:
                get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                    might_sleep()
                    cpuhp_lock_acquire_read()
                    mutex_lock()
                    atomic_inc()
                    mutex_unlock()
                mutex_lock()
                list_del()
                smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
                    for_each_possible_cpu()
                    per_cpu_ptr()
                    kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
                        trace_sched_kthread_stop()
                        get_task_struct()
                        to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                            ACCESS_ONCE()
                            likely()
                        set_bit()
                        wake_up_process()
                        wait_for_completion()
                        put_task_struct()
                        trace_sched_kthread_stop_ret()
                    put_task_struct()
                mutex_unlock()
                put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                    atomic_dec_return()
                    WARN_ON()
                    atomic_inc()
                    waitqueue_active()
                    wake_up()
                    cpuhp_lock_release()
                free_cpumask_var()
lockup_detector_resume() <void lockup_detector_resume (void) at watchdog.c:768>:
    mutex_lock()
    watchdog_unpark_threads() <void watchdog_unpark_threads (void) at watchdog.c:725>:
        for_each_watchdog_cpu()
        kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                ACCESS_ONCE()
                likely()
        per_cpu()
    mutex_unlock()
    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
        atomic_dec_return()
        WARN_ON()
        atomic_inc()
        waitqueue_active()
        wake_up()
        cpuhp_lock_release()
lockup_detector_suspend() <int lockup_detector_suspend (void) at watchdog.c:736>:
    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
        might_sleep()
        cpuhp_lock_acquire_read()
        mutex_lock()
        atomic_inc()
        mutex_unlock()
    mutex_lock()
    watchdog_park_threads() <int watchdog_park_threads (void) at watchdog.c:706>:
        for_each_watchdog_cpu()
        kthread_park() <int kthread_park (struct task_struct *k) at kthread.c:445>:
            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                ACCESS_ONCE()
                likely()
            test_bit()
            set_bit()
            wake_up_process()
            wait_for_completion()
        per_cpu()
    watchdog_disable_all_cpus() <void watchdog_disable_all_cpus (void) at watchdog.c:827>:
        smpboot_unregister_percpu_thread() <void smpboot_unregister_percpu_thread (struct smp_hotplug_thread *plug_thread) at smpboot.c:318>:
            get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                might_sleep()
                cpuhp_lock_acquire_read()
                mutex_lock()
                atomic_inc()
                mutex_unlock()
            mutex_lock()
            list_del()
            smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
                for_each_possible_cpu()
                per_cpu_ptr()
                kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
                    trace_sched_kthread_stop()
                    get_task_struct()
                    to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                        ACCESS_ONCE()
                        likely()
                    set_bit()
                    wake_up_process()
                    wait_for_completion()
                    put_task_struct()
                    trace_sched_kthread_stop_ret()
                put_task_struct()
            mutex_unlock()
            put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                atomic_dec_return()
                WARN_ON()
                atomic_inc()
                waitqueue_active()
                wake_up()
                cpuhp_lock_release()
            free_cpumask_var()
    pr_err()
    mutex_unlock()
lookup_module_symbol_attrs() <int lookup_module_symbol_attrs (unsigned long addr, unsigned long *size, unsigned long *offset, char *modname, char *name) at module.c:3754>:
    preempt_disable()
    list_for_each_entry_rcu()
    within_module()
    get_ksymbol() <const char *get_ksymbol (struct module *mod, unsigned long addr, unsigned long *size, unsigned long *offset) at module.c:3657>:
        rcu_dereference_sched()
        within_module_init()
        symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
        is_arm_mapping_symbol() <inline int is_arm_mapping_symbol (const char *str) at module.c:3644>:
    strlcpy()
    preempt_enable()
lookup_module_symbol_name() <int lookup_module_symbol_name (unsigned long addr, char *symname) at module.c:3730>:
    preempt_disable()
    list_for_each_entry_rcu()
    within_module()
    get_ksymbol() <const char *get_ksymbol (struct module *mod, unsigned long addr, unsigned long *size, unsigned long *offset) at module.c:3657>:
        rcu_dereference_sched()
        within_module_init()
        symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
        is_arm_mapping_symbol() <inline int is_arm_mapping_symbol (const char *str) at module.c:3644>:
    strlcpy()
    preempt_enable()
lookup_resource() <struct resource *lookup_resource (struct resource *root, resource_size_t start) at resource.c:737>:
    read_lock()
    read_unlock()
lookup_symbol_attrs() <int lookup_symbol_attrs (unsigned long addr, unsigned long *size, unsigned long *offset, char *modname, char *name) at kallsyms.c:335>:
    is_ksym_addr() <int is_ksym_addr (unsigned long addr) at kallsyms.c:78>:
        is_kernel() <inline int is_kernel (unsigned long addr) at kallsyms.c:71>:
            in_gate_area_no_mm()
        is_kernel_text() <inline int is_kernel_text (unsigned long addr) at kallsyms.c:63>:
            arch_is_kernel_text()
            in_gate_area_no_mm()
        is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
    get_symbol_pos() <unsigned long get_symbol_pos (unsigned long addr, unsigned long *symbolsize, unsigned long *offset) at kallsyms.c:215>:
        BUG_ON()
        is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
    kallsyms_expand_symbol() <unsigned int kallsyms_expand_symbol (unsigned int off, char *result, size_t maxlen) at kallsyms.c:91>:
    get_symbol_offset() <unsigned int get_symbol_offset (unsigned long pos) at kallsyms.c:156>:
    lookup_module_symbol_attrs() <int lookup_module_symbol_attrs (unsigned long addr, unsigned long *size, unsigned long *offset, char *modname, char *name) at module.c:3754>:
        preempt_disable()
        list_for_each_entry_rcu()
        within_module()
        get_ksymbol() <const char *get_ksymbol (struct module *mod, unsigned long addr, unsigned long *size, unsigned long *offset) at module.c:3657>:
            rcu_dereference_sched()
            within_module_init()
            symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
            is_arm_mapping_symbol() <inline int is_arm_mapping_symbol (const char *str) at module.c:3644>:
        strlcpy()
        preempt_enable()
lookup_symbol_name() <int lookup_symbol_name (unsigned long addr, char *symname) at kallsyms.c:317>:
    is_ksym_addr() <int is_ksym_addr (unsigned long addr) at kallsyms.c:78>:
        is_kernel() <inline int is_kernel (unsigned long addr) at kallsyms.c:71>:
            in_gate_area_no_mm()
        is_kernel_text() <inline int is_kernel_text (unsigned long addr) at kallsyms.c:63>:
            arch_is_kernel_text()
            in_gate_area_no_mm()
        is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
    get_symbol_pos() <unsigned long get_symbol_pos (unsigned long addr, unsigned long *symbolsize, unsigned long *offset) at kallsyms.c:215>:
        BUG_ON()
        is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
    kallsyms_expand_symbol() <unsigned int kallsyms_expand_symbol (unsigned int off, char *result, size_t maxlen) at kallsyms.c:91>:
    get_symbol_offset() <unsigned int get_symbol_offset (unsigned long pos) at kallsyms.c:156>:
    lookup_module_symbol_name() <int lookup_module_symbol_name (unsigned long addr, char *symname) at module.c:3730>:
        preempt_disable()
        list_for_each_entry_rcu()
        within_module()
        get_ksymbol() <const char *get_ksymbol (struct module *mod, unsigned long addr, unsigned long *size, unsigned long *offset) at module.c:3657>:
            rcu_dereference_sched()
            within_module_init()
            symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
            is_arm_mapping_symbol() <inline int is_arm_mapping_symbol (const char *str) at module.c:3644>:
        strlcpy()
        preempt_enable()
make_kgid() <kgid_t make_kgid (struct user_namespace *ns, gid_t gid) at user_namespace.c:307>:
    KGIDT_INIT()
    map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
        smp_rmb()
make_kprojid() <kprojid_t make_kprojid (struct user_namespace *ns, projid_t projid) at user_namespace.c:374>:
    KPROJIDT_INIT()
    map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
        smp_rmb()
make_kuid() <kuid_t make_kuid (struct user_namespace *ns, uid_t uid) at user_namespace.c:239>:
    KUIDT_INIT()
    map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
        smp_rmb()
may_setgroups() <bool may_setgroups (void) at groups.c:214>:
    current_user_ns()
    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
        unlikely()
        cap_valid()
        pr_crit()
        BUG()
        security_capable()
        current_cred()
    userns_may_setgroups() <bool userns_may_setgroups (const struct user_namespace *ns) at user_namespace.c:925>:
        mutex_lock()
        mutex_unlock()
memremap() <void *memremap (resource_size_t offset, size_t size, unsigned long flags) at memremap.c:61>:
    region_intersects() <int region_intersects (resource_size_t start, size_t size, const char *name) at resource.c:513>:
        read_lock()
        read_unlock()
    WARN_ONCE()
    try_ram_remap() <void *try_ram_remap (resource_size_t offset, size_t size) at memremap.c:30>:
        PHYS_PFN()
        pfn_valid()
        PageHighMem()
        pfn_to_page()
    ioremap_cache() <__weak void __iomem *ioremap_cache (resource_size_t offset, unsigned long size) at memremap.c:24>:
        ioremap()
    ioremap_wt()
memunmap() <void memunmap (void *addr) at memremap.c:108>:
    is_vmalloc_addr()
    iounmap()
migrate_to_reboot_cpu() <void migrate_to_reboot_cpu (void) at reboot.c:188>:
    cpu_hotplug_disable() <void cpu_hotplug_disable (void) at cpu.c:178>:
        cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
            mutex_lock()
        cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
            mutex_unlock()
    cpu_online()
    cpumask_first()
    set_cpus_allowed_ptr()
    cpumask_of()
mm_access() <struct mm_struct *mm_access (struct task_struct *task, unsigned int mode) at fork.c:791>:
    mutex_lock_killable()
    ERR_PTR()
    get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
        task_lock()
        atomic_inc()
        task_unlock()
    ptrace_may_access() <bool ptrace_may_access (struct task_struct *task, unsigned int mode) at ptrace.c:287>:
        task_lock()
        task_unlock()
    mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
        might_sleep()
        atomic_dec_and_test()
        uprobe_clear_state()
        exit_aio()
        ksm_exit()
        khugepaged_exit()
        exit_mmap()
        set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
            rcu_dereference_raw()
            get_file()
            rcu_assign_pointer()
            fput()
        list_empty()
        spin_lock()
        list_del()
        spin_unlock()
        module_put() <void module_put (struct module *module) at module.c:1098>:
            preempt_disable()
            atomic_dec_if_positive()
            WARN_ON()
            trace_module_put()
            preempt_enable()
        mmdrop()
    mutex_unlock()
mm_alloc() <struct mm_struct *mm_alloc (void) at fork.c:663>:
    allocate_mm()
    mm_init() <struct mm_struct *mm_init (struct mm_struct *mm, struct task_struct *p) at fork.c:587>:
        atomic_set()
        init_rwsem()
        INIT_LIST_HEAD()
        atomic_long_set()
        mm_nr_pmds_init()
        spin_lock_init()
        mm_init_cpumask()
        mm_init_aio() <void mm_init_aio (struct mm_struct *mm) at fork.c:572>:
            spin_lock_init()
        mm_init_owner() <void mm_init_owner (struct mm_struct *mm, struct task_struct *p) at fork.c:580>
        mmu_notifier_mm_init()
        clear_tlb_flush_pending()
        mm_alloc_pgd() <inline int mm_alloc_pgd (struct mm_struct *mm) at fork.c:529>:
            pgd_alloc()
            unlikely()
        init_new_context()
        mm_free_pgd() <inline void mm_free_pgd (struct mm_struct *mm) at fork.c:537>:
            pgd_free()
        free_mm()
mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
    unlikely()
    exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
        uninitialized_var()
        fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
            get_user()
        get_user()
        handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
            uninitialized_var()
            get_user()
            task_pid_vnr()
            cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                pagefault_disable()
                futex_atomic_cmpxchg_inatomic()
                pagefault_enable()
            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                down_read()
                fixup_user_fault()
                up_read()
            futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                WAKE_Q()
                get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                    unlikely()
                    access_ok()
                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                        should_fail()
                    get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                        ihold()
                        futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                            atomic_inc()
                            smp_mb__after_atomic()
                        smp_mb()
                    get_user_pages_fast()
                    lock_page()
                    compound_head()
                    PageSwapCache()
                    unlock_page()
                    put_page()
                    PageAnon()
                    basepage_index()
                unlikely()
                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                    jhash2()
                hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                    atomic_read()
                spin_lock()
                plist_for_each_entry_safe()
                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                    WARN()
                    wake_q_add()
                    smp_wmb()
                spin_unlock()
                wake_up_q()
                put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                    drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                        WARN_ON_ONCE()
                        iput()
                        mmdrop()
        cond_resched()
    compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
        uninitialized_var()
        fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
            get_user()
            compat_ptr()
        get_user()
        futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
            ptr_to_compat()
            compat_ptr()
        handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
            uninitialized_var()
            get_user()
            task_pid_vnr()
            cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                pagefault_disable()
                futex_atomic_cmpxchg_inatomic()
                pagefault_enable()
            fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                down_read()
                fixup_user_fault()
                up_read()
            futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                WAKE_Q()
                get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                    unlikely()
                    access_ok()
                    should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                        should_fail()
                    get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                        ihold()
                        futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                            atomic_inc()
                            smp_mb__after_atomic()
                        smp_mb()
                    get_user_pages_fast()
                    lock_page()
                    compound_head()
                    PageSwapCache()
                    unlock_page()
                    put_page()
                    PageAnon()
                    basepage_index()
                unlikely()
                hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                    jhash2()
                hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                    atomic_read()
                spin_lock()
                plist_for_each_entry_safe()
                match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                    WARN()
                    wake_q_add()
                    smp_wmb()
                spin_unlock()
                wake_up_q()
                put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                    drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                        WARN_ON_ONCE()
                        iput()
                        mmdrop()
        cond_resched()
    list_empty()
    exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
        raw_spin_lock_irq()
        list_empty()
        list_entry()
        hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
            jhash2()
        raw_spin_unlock_irq()
        spin_lock()
        spin_unlock()
        WARN_ON()
        list_del_init()
        rt_mutex_unlock()
    uprobe_free_utask()
    deactivate_mm()
    atomic_read()
    put_user()
    sys_futex()
    complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
        task_lock()
        likely()
        complete()
        task_unlock()
mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
    atomic_read()
    read_lock()
    list_for_each_entry()
    for_each_process()
    for_each_thread()
    read_unlock()
    BUG_ON()
    get_task_struct()
    task_lock()
    task_unlock()
    put_task_struct()
mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
    might_sleep()
    atomic_dec_and_test()
    uprobe_clear_state()
    exit_aio()
    ksm_exit()
    khugepaged_exit()
    exit_mmap()
    set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
        rcu_dereference_raw()
        get_file()
        rcu_assign_pointer()
        fput()
    list_empty()
    spin_lock()
    list_del()
    spin_unlock()
    module_put() <void module_put (struct module *module) at module.c:1098>:
        preempt_disable()
        atomic_dec_if_positive()
        WARN_ON()
        trace_module_put()
        preempt_enable()
    mmdrop()
mod_delayed_work_on() <bool mod_delayed_work_on (int cpu, struct workqueue_struct *wq, struct delayed_work *dwork, unsigned long delay) at workqueue.c:1584>:
    try_to_grab_pending() <int try_to_grab_pending (struct work_struct *work, bool is_dwork, unsigned long *flags) at workqueue.c:1203>:
        local_irq_save()
        to_delayed_work()
        likely()
        del_timer()
        test_and_set_bit()
        work_data_bits()
        get_work_pool() <struct worker_pool *get_work_pool (struct work_struct *work) at workqueue.c:703>:
            atomic_long_read()
            assert_rcu_or_pool_mutex()
            idr_find()
        spin_lock()
        get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
            atomic_long_read()
        debug_work_deactivate() <inline void debug_work_deactivate (struct work_struct *work) at workqueue.c:548>:
            debug_object_deactivate()
        pwq_activate_delayed_work() <void pwq_activate_delayed_work (struct work_struct *work) at workqueue.c:1109>:
            get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                atomic_long_read()
            trace_workqueue_activate_work()
            list_empty()
            move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                list_for_each_entry_safe_from()
                list_move_tail()
                work_data_bits()
            work_data_bits()
        list_del_init()
        pwq_dec_nr_in_flight() <void pwq_dec_nr_in_flight (struct pool_workqueue *pwq, int color) at workqueue.c:1140>:
            list_empty()
            pwq_activate_first_delayed() <void pwq_activate_first_delayed (struct pool_workqueue *pwq) at workqueue.c:1121>:
                list_first_entry()
                pwq_activate_delayed_work() <void pwq_activate_delayed_work (struct work_struct *work) at workqueue.c:1109>:
                    get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                        atomic_long_read()
                    trace_workqueue_activate_work()
                    list_empty()
                    move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                        list_for_each_entry_safe_from()
                        list_move_tail()
                        work_data_bits()
                    work_data_bits()
            likely()
            atomic_dec_and_test()
            complete()
            put_pwq() <void put_pwq (struct pool_workqueue *pwq) at workqueue.c:1072>:
                lockdep_assert_held()
                likely()
                WARN_ON_ONCE()
                schedule_work()
        get_work_color() <int get_work_color (struct work_struct *work) at workqueue.c:607>:
            work_data_bits()
        set_work_pool_and_keep_pending() <void set_work_pool_and_keep_pending (struct work_struct *work, int pool_id) at workqueue.c:652>:
            set_work_data() <inline void set_work_data (struct work_struct *work, unsigned long data, unsigned long flags) at workqueue.c:638>:
                WARN_ON_ONCE()
                work_pending()
                atomic_long_set()
                work_static()
        spin_unlock()
        local_irq_restore()
        work_is_canceling() <bool work_is_canceling (struct work_struct *work) at workqueue.c:747>:
            atomic_long_read()
        cpu_relax()
    unlikely()
    likely()
    local_irq_restore()
mod_verify_sig() <int mod_verify_sig (const void *mod, unsigned long *_modlen) at module_signing.c:41>:
    pr_devel()
    be32_to_cpu()
    pr_err()
    system_verify_data()
module_address_lookup() <const char *module_address_lookup (unsigned long addr, unsigned long *size, unsigned long *offset, char **modname, char *namebuf) at module.c:3704>:
    preempt_disable()
    get_ksymbol() <const char *get_ksymbol (struct module *mod, unsigned long addr, unsigned long *size, unsigned long *offset) at module.c:3657>:
        rcu_dereference_sched()
        within_module_init()
        symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
        is_arm_mapping_symbol() <inline int is_arm_mapping_symbol (const char *str) at module.c:3644>:
    preempt_enable()
module_alloc() <void *__weak module_alloc (unsigned long size) at module.c:2567>:
    vmalloc_exec()
module_disable_ro() <void module_disable_ro (const struct module *mod) at module.c:1896>:
    frob_text() <void frob_text (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1866>:
        BUG_ON()
    frob_rodata() <void frob_rodata (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1875>:
        BUG_ON()
module_enable_ro() <void module_enable_ro (const struct module *mod) at module.c:1904>:
    frob_text() <void frob_text (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1866>:
        BUG_ON()
    frob_rodata() <void frob_rodata (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1875>:
        BUG_ON()
module_get_kallsym() <int module_get_kallsym (unsigned int symnum, unsigned long *value, char *type, char *name, char *module_name, int *exported) at module.c:3782>:
    preempt_disable()
    list_for_each_entry_rcu()
    rcu_dereference_sched()
    strlcpy()
    symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
    is_exported() <int is_exported (const char *name, unsigned long value, const struct module *mod) at module.c:2367>:
        lookup_symbol() <const struct kernel_symbol *lookup_symbol (const char *name, const struct kernel_symbol *start, const struct kernel_symbol *stop) at module.c:2359>:
            cmp_name() <int cmp_name (const void *va, const void *vb) at module.c:533>:
    preempt_enable()
module_kallsyms_lookup_name() <unsigned long module_kallsyms_lookup_name (const char *name) at module.c:3822>:
    preempt_disable()
    find_module_all() <struct module *find_module_all (const char *name, size_t len, bool even_unformed) at module.c:588>:
        module_assert_mutex_or_preempt() <void module_assert_mutex_or_preempt (void) at module.c:260>:
            unlikely()
            WARN_ON()
            rcu_read_lock_sched_held()
            lockdep_is_held()
        list_for_each_entry()
    mod_find_symname() <unsigned long mod_find_symname (struct module *mod, const char *name) at module.c:3809>:
        rcu_dereference_sched()
        symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
    list_for_each_entry_rcu()
    preempt_enable()
module_kallsyms_on_each_symbol() <int module_kallsyms_on_each_symbol (int (*fn) (void *, const char *, struct module *, unsigned long), void *data) at module.c:3845>:
    module_assert_mutex() <void module_assert_mutex (void) at module.c:255>:
        lockdep_assert_held()
    list_for_each_entry()
    symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
module_memfree() <void __weak module_memfree (void *module_region) at module.c:1974>:
    vfree()
module_param_sysfs_remove() <void module_param_sysfs_remove (struct module *mod) at params.c:778>:
    sysfs_remove_group()
    free_module_param_attrs() <void free_module_param_attrs (struct module_kobject *mk) at params.c:726>:
        kfree()
module_param_sysfs_setup() <int module_param_sysfs_setup (struct module *mod, const struct kernel_param *kparam, unsigned int num_params) at params.c:743>:
    add_sysfs_param() <__modinit int add_sysfs_param (struct module_kobject *mk, const struct kernel_param *kp, const char *name) at params.c:662>:
        BUG_ON()
        kzalloc()
        krealloc()
        sysfs_attr_init()
        param_attr_show() <ssize_t param_attr_show (struct module_attribute *mattr, struct module_kobject *mk, char *buf) at params.c:592>:
            to_param_attr()
            kernel_param_lock() <void kernel_param_lock (struct module *mod) at params.c:639>:
                mutex_lock()
                KPARAM_MUTEX()
            kernel_param_unlock() <void kernel_param_unlock (struct module *mod) at params.c:644>:
                mutex_unlock()
                KPARAM_MUTEX()
        param_attr_store() <ssize_t param_attr_store (struct module_attribute *mattr, struct module_kobject *mk, const char *buf, size_t len) at params.c:612>:
            to_param_attr()
            kernel_param_lock() <void kernel_param_lock (struct module *mod) at params.c:639>:
                mutex_lock()
                KPARAM_MUTEX()
            param_check_unsafe() <void param_check_unsafe (const struct kernel_param *kp) at params.c:111>:
                pr_warn()
                add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
                    pr_warn()
                    set_bit()
            kernel_param_unlock() <void kernel_param_unlock (struct module *mod) at params.c:644>:
                mutex_unlock()
                KPARAM_MUTEX()
    free_module_param_attrs() <void free_module_param_attrs (struct module_kobject *mk) at params.c:726>:
        kfree()
    sysfs_create_group()
module_put() <void module_put (struct module *module) at module.c:1098>:
    preempt_disable()
    atomic_dec_if_positive()
    WARN_ON()
    trace_module_put()
    preempt_enable()
module_refcount() <int module_refcount (struct module *mod) at module.c:920>:
    atomic_read()
next_pidmap() <int next_pidmap (struct pid_namespace *pid_ns, unsigned int last) at pid.c:216>:
    unlikely()
    find_next_bit()
    mk_pid() <inline int mk_pid (struct pid_namespace *pid_ns, struct pidmap *map, int off) at pid.c:55>:
next_signal() <int next_signal (struct sigpending *pending, sigset_t *mask) at signal.c:171>:
    ffz()
nmi_panic_self_stop() <void __weak nmi_panic_self_stop (struct pt_regs *regs) at panic.c:68>:
    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
        cpu_relax()
notify_cpu_starting() <void notify_cpu_starting (unsigned int cpu) at cpu.c:720>:
    cpumask_test_cpu()
    cpu_notify() <int cpu_notify (unsigned long val, void *v) at cpu.c:221>:
notify_die() <int notrace notify_die (enum die_val val, const char *str, struct pt_regs *regs, long err, int trap, int sig) at notifier.c:536>:
    RCU_LOCKDEP_WARN()
    rcu_is_watching()
    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
nr_processes() <int nr_processes (void) at fork.c:121>:
    for_each_possible_cpu()
    per_cpu()
ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
    unlikely()
    cap_valid()
    pr_crit()
    BUG()
    security_capable()
    current_cred()
nsproxy_cache_init() <int __init nsproxy_cache_init (void) at nsproxy.c:255>:
    KMEM_CACHE()
of_css() <struct cgroup_subsys_state *of_css (struct kernfs_open_file *of) at cgroup.c:445>:
    of_cft()
    rcu_dereference_raw()
on_each_cpu() <int on_each_cpu (smp_call_func_t func, void *info, int wait) at up.c:36>:
    preempt_disable()
    smp_call_function() <int smp_call_function (smp_call_func_t func, void *info, int wait) at smp.c:488>:
        preempt_disable()
        smp_call_function_many() <void smp_call_function_many (const struct cpumask *mask, smp_call_func_t func, void *info, bool wait) at smp.c:404>:
            smp_processor_id()
            WARN_ON_ONCE()
            cpu_online()
            irqs_disabled()
            cpumask_first_and()
            cpumask_next_and()
            smp_call_function_single() <int smp_call_function_single (int cpu, void (*func) (void *info), void *info, int wait) at up.c:10>:
                get_cpu()
                WARN_ON_ONCE()
                cpu_online()
                irqs_disabled()
                this_cpu_ptr()
                csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
                    csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                        smp_load_acquire()
                        cpu_relax()
                    smp_wmb()
                generic_exec_single() <int generic_exec_single (int cpu, struct call_single_data *csd, smp_call_func_t func, void *info) at smp.c:144>:
                    smp_processor_id()
                    csd_unlock() <void csd_unlock (struct call_single_data *csd) at smp.c:127>:
                        WARN_ON()
                        smp_store_release()
                    local_irq_save()
                    local_irq_restore()
                    cpu_online()
                    llist_add()
                    per_cpu()
                    arch_send_call_function_single_ipi()
                csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                    smp_load_acquire()
                    cpu_relax()
                put_cpu()
                WARN_ON()
                local_irq_save()
                local_irq_restore()
            this_cpu_ptr()
            cpumask_and()
            cpumask_clear_cpu()
            unlikely()
            cpumask_weight()
            for_each_cpu()
            per_cpu_ptr()
            csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
                csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                    smp_load_acquire()
                    cpu_relax()
                smp_wmb()
            llist_add()
            per_cpu()
            arch_send_call_function_ipi_mask()
            csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                smp_load_acquire()
                cpu_relax()
        preempt_enable()
    local_irq_save()
    local_irq_restore()
    preempt_enable()
on_each_cpu_cond() <void on_each_cpu_cond (bool (*cond_func) (int cpu, void *info), smp_call_func_t func, void *info, bool wait, gfp_t gfp_flags) at up.c:70>:
    might_sleep_if()
    gfpflags_allow_blocking()
    likely()
    zalloc_cpumask_var()
    preempt_disable()
    for_each_online_cpu()
    cond_func()
    cpumask_set_cpu()
    on_each_cpu_mask() <void on_each_cpu_mask (const struct cpumask *mask, smp_call_func_t func, void *info, bool wait) at up.c:53>:
        get_cpu()
        smp_call_function_many() <void smp_call_function_many (const struct cpumask *mask, smp_call_func_t func, void *info, bool wait) at smp.c:404>:
            smp_processor_id()
            WARN_ON_ONCE()
            cpu_online()
            irqs_disabled()
            cpumask_first_and()
            cpumask_next_and()
            smp_call_function_single() <int smp_call_function_single (int cpu, void (*func) (void *info), void *info, int wait) at up.c:10>:
                get_cpu()
                WARN_ON_ONCE()
                cpu_online()
                irqs_disabled()
                this_cpu_ptr()
                csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
                    csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                        smp_load_acquire()
                        cpu_relax()
                    smp_wmb()
                generic_exec_single() <int generic_exec_single (int cpu, struct call_single_data *csd, smp_call_func_t func, void *info) at smp.c:144>:
                    smp_processor_id()
                    csd_unlock() <void csd_unlock (struct call_single_data *csd) at smp.c:127>:
                        WARN_ON()
                        smp_store_release()
                    local_irq_save()
                    local_irq_restore()
                    cpu_online()
                    llist_add()
                    per_cpu()
                    arch_send_call_function_single_ipi()
                csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                    smp_load_acquire()
                    cpu_relax()
                put_cpu()
                WARN_ON()
                local_irq_save()
                local_irq_restore()
            this_cpu_ptr()
            cpumask_and()
            cpumask_clear_cpu()
            unlikely()
            cpumask_weight()
            for_each_cpu()
            per_cpu_ptr()
            csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
                csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                    smp_load_acquire()
                    cpu_relax()
                smp_wmb()
            llist_add()
            per_cpu()
            arch_send_call_function_ipi_mask()
            csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                smp_load_acquire()
                cpu_relax()
        cpumask_test_cpu()
        local_irq_save()
        local_irq_restore()
        put_cpu()
    preempt_enable()
    free_cpumask_var()
    smp_call_function_single() <int smp_call_function_single (int cpu, void (*func) (void *info), void *info, int wait) at up.c:10>:
        get_cpu()
        WARN_ON_ONCE()
        cpu_online()
        irqs_disabled()
        this_cpu_ptr()
        csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
            csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                smp_load_acquire()
                cpu_relax()
            smp_wmb()
        generic_exec_single() <int generic_exec_single (int cpu, struct call_single_data *csd, smp_call_func_t func, void *info) at smp.c:144>:
            smp_processor_id()
            csd_unlock() <void csd_unlock (struct call_single_data *csd) at smp.c:127>:
                WARN_ON()
                smp_store_release()
            local_irq_save()
            local_irq_restore()
            cpu_online()
            llist_add()
            per_cpu()
            arch_send_call_function_single_ipi()
        csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
            smp_load_acquire()
            cpu_relax()
        put_cpu()
        WARN_ON()
        local_irq_save()
        local_irq_restore()
    WARN_ON_ONCE()
    local_irq_save()
    local_irq_restore()
on_each_cpu_mask() <void on_each_cpu_mask (const struct cpumask *mask, smp_call_func_t func, void *info, bool wait) at up.c:53>:
    get_cpu()
    smp_call_function_many() <void smp_call_function_many (const struct cpumask *mask, smp_call_func_t func, void *info, bool wait) at smp.c:404>:
        smp_processor_id()
        WARN_ON_ONCE()
        cpu_online()
        irqs_disabled()
        cpumask_first_and()
        cpumask_next_and()
        smp_call_function_single() <int smp_call_function_single (int cpu, void (*func) (void *info), void *info, int wait) at up.c:10>:
            get_cpu()
            WARN_ON_ONCE()
            cpu_online()
            irqs_disabled()
            this_cpu_ptr()
            csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
                csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                    smp_load_acquire()
                    cpu_relax()
                smp_wmb()
            generic_exec_single() <int generic_exec_single (int cpu, struct call_single_data *csd, smp_call_func_t func, void *info) at smp.c:144>:
                smp_processor_id()
                csd_unlock() <void csd_unlock (struct call_single_data *csd) at smp.c:127>:
                    WARN_ON()
                    smp_store_release()
                local_irq_save()
                local_irq_restore()
                cpu_online()
                llist_add()
                per_cpu()
                arch_send_call_function_single_ipi()
            csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                smp_load_acquire()
                cpu_relax()
            put_cpu()
            WARN_ON()
            local_irq_save()
            local_irq_restore()
        this_cpu_ptr()
        cpumask_and()
        cpumask_clear_cpu()
        unlikely()
        cpumask_weight()
        for_each_cpu()
        per_cpu_ptr()
        csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
            csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                smp_load_acquire()
                cpu_relax()
            smp_wmb()
        llist_add()
        per_cpu()
        arch_send_call_function_ipi_mask()
        csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
            smp_load_acquire()
            cpu_relax()
    cpumask_test_cpu()
    local_irq_save()
    local_irq_restore()
    put_cpu()
oops_enter() <void oops_enter (void) at panic.c:411>:
    tracing_off()
    debug_locks_off()
    do_oops_enter_exit() <void do_oops_enter_exit (void) at panic.c:353>:
        spin_lock_irqsave()
        spin_unlock()
        spin_msec() <void spin_msec (int msecs) at panic.c:339>:
            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                raw_cpu_write()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            mdelay()
        spin_lock()
        spin_unlock_irqrestore()
oops_exit() <void oops_exit (void) at panic.c:445>:
    do_oops_enter_exit() <void do_oops_enter_exit (void) at panic.c:353>:
        spin_lock_irqsave()
        spin_unlock()
        spin_msec() <void spin_msec (int msecs) at panic.c:339>:
            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                raw_cpu_write()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            mdelay()
        spin_lock()
        spin_unlock_irqrestore()
    print_oops_end_marker() <void print_oops_end_marker (void) at panic.c:435>:
        init_oops_id() <int init_oops_id (void) at panic.c:424>:
            get_random_bytes()
        pr_warn()
    kmsg_dump()
oops_may_print() <int oops_may_print (void) at panic.c:392>:
open_softirq() <void open_softirq (int nr, void (*action) (struct softirq_action *)) at softirq.c:433>:
opt_pre_handler() <void opt_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:351>:
    list_for_each_entry_rcu()
    likely()
    kprobe_disabled()
    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
orderly_poweroff() <void orderly_poweroff (bool force) at reboot.c:464>:
    schedule_work()
orderly_reboot() <void orderly_reboot (void) at reboot.c:485>:
    schedule_work()
override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
    kdebug()
    atomic_read()
    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
        atomic_read()
    validate_creds()
    get_cred()
    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
        atomic_add()
    rcu_assign_pointer()
padata_add_cpu() <int padata_add_cpu (struct padata_instance *pinst, int cpu, int mask) at padata.c:709>:
    mutex_lock()
    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
        might_sleep()
        cpuhp_lock_acquire_read()
        mutex_lock()
        atomic_inc()
        mutex_unlock()
    cpumask_set_cpu()
    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
        atomic_dec_return()
        WARN_ON()
        atomic_inc()
        waitqueue_active()
        wake_up()
        cpuhp_lock_release()
    mutex_unlock()
padata_alloc() <struct padata_instance *padata_alloc (struct workqueue_struct *wq, const struct cpumask *pcpumask, const struct cpumask *cbcpumask) at padata.c:1036>:
    kzalloc()
    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
        might_sleep()
        cpuhp_lock_acquire_read()
        mutex_lock()
        atomic_inc()
        mutex_unlock()
    alloc_cpumask_var()
    free_cpumask_var()
    padata_validate_cpumask() <bool padata_validate_cpumask (struct padata_instance *pinst, const struct cpumask *cpumask) at padata.c:564>:
        cpumask_intersects()
    padata_alloc_pd() <struct parallel_data *padata_alloc_pd (struct padata_instance *pinst, const struct cpumask *pcpumask, const struct cpumask *cbcpumask) at padata.c:408>:
        kzalloc()
        alloc_percpu()
        padata_setup_cpumasks() <int padata_setup_cpumasks (struct parallel_data *pd, const struct cpumask *pcpumask, const struct cpumask *cbcpumask) at padata.c:350>:
            alloc_cpumask_var()
            cpumask_and()
            free_cpumask_var()
        padata_init_pqueues() <void padata_init_pqueues (struct parallel_data *pd) at padata.c:388>:
            for_each_cpu()
            per_cpu_ptr()
            INIT_WORK()
            padata_parallel_worker() <void padata_parallel_worker (struct work_struct *parallel_work) at padata.c:63>:
                LIST_HEAD()
                local_bh_disable()
                container_of()
                spin_lock()
                list_replace_init()
                spin_unlock()
                list_empty()
                list_entry()
                list_del_init()
                local_bh_enable()
            atomic_set()
        padata_init_squeues() <void padata_init_squeues (struct parallel_data *pd) at padata.c:374>:
            for_each_cpu()
            per_cpu_ptr()
            INIT_WORK()
            padata_serial_worker() <void padata_serial_worker (struct work_struct *serial_work) at padata.c:292>:
                LIST_HEAD()
                local_bh_disable()
                container_of()
                spin_lock()
                list_replace_init()
                spin_unlock()
                list_empty()
                list_entry()
                list_del_init()
                atomic_dec()
                local_bh_enable()
        setup_timer()
        padata_reorder_timer() <void padata_reorder_timer (unsigned long arg) at padata.c:285>:
            padata_reorder() <void padata_reorder (struct parallel_data *pd) at padata.c:216>:
                spin_trylock_bh()
                padata_get_next() <struct padata_priv *padata_get_next (struct parallel_data *pd) at padata.c:169>:
                    cpumask_weight()
                    padata_index_to_cpu() <int padata_index_to_cpu (struct parallel_data *pd, int cpu_index) at padata.c:36>:
                        cpumask_first()
                        cpumask_next()
                    per_cpu_ptr()
                    list_empty()
                    list_entry()
                    spin_lock()
                    list_del_init()
                    atomic_dec()
                    spin_unlock()
                    ERR_PTR()
                PTR_ERR()
                del_timer()
                spin_unlock_bh()
                per_cpu_ptr()
                spin_lock()
                list_add_tail()
                spin_unlock()
                queue_work_on() <bool queue_work_on (int cpu, struct workqueue_struct *wq, struct work_struct *work) at workqueue.c:1474>:
                    local_irq_save()
                    test_and_set_bit()
                    work_data_bits()
                    local_irq_restore()
                atomic_read()
                mod_timer()
        atomic_set()
        spin_lock_init()
        free_percpu()
        kfree()
    rcu_assign_pointer()
    cpumask_copy()
    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
        atomic_dec_return()
        WARN_ON()
        atomic_inc()
        waitqueue_active()
        wake_up()
        cpuhp_lock_release()
    BLOCKING_INIT_NOTIFIER_HEAD()
    kobject_init()
    mutex_init()
    padata_cpu_callback() <int padata_cpu_callback (struct notifier_block *nfb, unsigned long action, void *hcpu) at padata.c:836>:
        container_of()
        cpu_notifier()
        pinst_has_cpu() <inline int pinst_has_cpu (struct padata_instance *pinst, int cpu) at padata.c:829>:
            cpumask_test_cpu()
        mutex_lock()
        mutex_unlock()
        notifier_from_errno()
    register_hotcpu_notifier()
    kfree()
padata_alloc_possible() <struct padata_instance *padata_alloc_possible (struct workqueue_struct *wq) at padata.c:1022>:
    padata_alloc() <struct padata_instance *padata_alloc (struct workqueue_struct *wq, const struct cpumask *pcpumask, const struct cpumask *cbcpumask) at padata.c:1036>:
        kzalloc()
        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
            might_sleep()
            cpuhp_lock_acquire_read()
            mutex_lock()
            atomic_inc()
            mutex_unlock()
        alloc_cpumask_var()
        free_cpumask_var()
        padata_validate_cpumask() <bool padata_validate_cpumask (struct padata_instance *pinst, const struct cpumask *cpumask) at padata.c:564>:
            cpumask_intersects()
        padata_alloc_pd() <struct parallel_data *padata_alloc_pd (struct padata_instance *pinst, const struct cpumask *pcpumask, const struct cpumask *cbcpumask) at padata.c:408>:
            kzalloc()
            alloc_percpu()
            padata_setup_cpumasks() <int padata_setup_cpumasks (struct parallel_data *pd, const struct cpumask *pcpumask, const struct cpumask *cbcpumask) at padata.c:350>:
                alloc_cpumask_var()
                cpumask_and()
                free_cpumask_var()
            padata_init_pqueues() <void padata_init_pqueues (struct parallel_data *pd) at padata.c:388>:
                for_each_cpu()
                per_cpu_ptr()
                INIT_WORK()
                padata_parallel_worker() <void padata_parallel_worker (struct work_struct *parallel_work) at padata.c:63>:
                    LIST_HEAD()
                    local_bh_disable()
                    container_of()
                    spin_lock()
                    list_replace_init()
                    spin_unlock()
                    list_empty()
                    list_entry()
                    list_del_init()
                    local_bh_enable()
                atomic_set()
            padata_init_squeues() <void padata_init_squeues (struct parallel_data *pd) at padata.c:374>:
                for_each_cpu()
                per_cpu_ptr()
                INIT_WORK()
                padata_serial_worker() <void padata_serial_worker (struct work_struct *serial_work) at padata.c:292>:
                    LIST_HEAD()
                    local_bh_disable()
                    container_of()
                    spin_lock()
                    list_replace_init()
                    spin_unlock()
                    list_empty()
                    list_entry()
                    list_del_init()
                    atomic_dec()
                    local_bh_enable()
            setup_timer()
            padata_reorder_timer() <void padata_reorder_timer (unsigned long arg) at padata.c:285>:
                padata_reorder() <void padata_reorder (struct parallel_data *pd) at padata.c:216>:
                    spin_trylock_bh()
                    padata_get_next() <struct padata_priv *padata_get_next (struct parallel_data *pd) at padata.c:169>:
                        cpumask_weight()
                        padata_index_to_cpu() <int padata_index_to_cpu (struct parallel_data *pd, int cpu_index) at padata.c:36>:
                            cpumask_first()
                            cpumask_next()
                        per_cpu_ptr()
                        list_empty()
                        list_entry()
                        spin_lock()
                        list_del_init()
                        atomic_dec()
                        spin_unlock()
                        ERR_PTR()
                    PTR_ERR()
                    del_timer()
                    spin_unlock_bh()
                    per_cpu_ptr()
                    spin_lock()
                    list_add_tail()
                    spin_unlock()
                    queue_work_on() <bool queue_work_on (int cpu, struct workqueue_struct *wq, struct work_struct *work) at workqueue.c:1474>:
                        local_irq_save()
                        test_and_set_bit()
                        work_data_bits()
                        local_irq_restore()
                    atomic_read()
                    mod_timer()
            atomic_set()
            spin_lock_init()
            free_percpu()
            kfree()
        rcu_assign_pointer()
        cpumask_copy()
        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
            atomic_dec_return()
            WARN_ON()
            atomic_inc()
            waitqueue_active()
            wake_up()
            cpuhp_lock_release()
        BLOCKING_INIT_NOTIFIER_HEAD()
        kobject_init()
        mutex_init()
        padata_cpu_callback() <int padata_cpu_callback (struct notifier_block *nfb, unsigned long action, void *hcpu) at padata.c:836>:
            container_of()
            cpu_notifier()
            pinst_has_cpu() <inline int pinst_has_cpu (struct padata_instance *pinst, int cpu) at padata.c:829>:
                cpumask_test_cpu()
            mutex_lock()
            mutex_unlock()
            notifier_from_errno()
        register_hotcpu_notifier()
        kfree()
padata_do_parallel() <int padata_do_parallel (struct padata_instance *pinst, struct padata_priv *padata, int cb_cpu) at padata.c:106>:
    rcu_read_lock_bh()
    rcu_dereference_bh()
    cpumask_test_cpu()
    atomic_read()
    atomic_inc()
    padata_cpu_hash() <int padata_cpu_hash (struct parallel_data *pd) at padata.c:47>:
        atomic_inc_return()
        cpumask_weight()
        padata_index_to_cpu() <int padata_index_to_cpu (struct parallel_data *pd, int cpu_index) at padata.c:36>:
            cpumask_first()
            cpumask_next()
    per_cpu_ptr()
    spin_lock()
    list_add_tail()
    spin_unlock()
    queue_work_on() <bool queue_work_on (int cpu, struct workqueue_struct *wq, struct work_struct *work) at workqueue.c:1474>:
        local_irq_save()
        test_and_set_bit()
        work_data_bits()
        local_irq_restore()
    rcu_read_unlock_bh()
padata_do_serial() <void padata_do_serial (struct padata_priv *padata) at padata.c:328>:
    get_cpu()
    per_cpu_ptr()
    spin_lock()
    atomic_inc()
    list_add_tail()
    spin_unlock()
    put_cpu()
    padata_reorder() <void padata_reorder (struct parallel_data *pd) at padata.c:216>:
        spin_trylock_bh()
        padata_get_next() <struct padata_priv *padata_get_next (struct parallel_data *pd) at padata.c:169>:
            cpumask_weight()
            padata_index_to_cpu() <int padata_index_to_cpu (struct parallel_data *pd, int cpu_index) at padata.c:36>:
                cpumask_first()
                cpumask_next()
            per_cpu_ptr()
            list_empty()
            list_entry()
            spin_lock()
            list_del_init()
            atomic_dec()
            spin_unlock()
            ERR_PTR()
        PTR_ERR()
        del_timer()
        spin_unlock_bh()
        per_cpu_ptr()
        spin_lock()
        list_add_tail()
        spin_unlock()
        queue_work_on() <bool queue_work_on (int cpu, struct workqueue_struct *wq, struct work_struct *work) at workqueue.c:1474>:
            local_irq_save()
            test_and_set_bit()
            work_data_bits()
            local_irq_restore()
        atomic_read()
        mod_timer()
padata_free() <void padata_free (struct padata_instance *pinst) at padata.c:1101>:
    kobject_put()
padata_register_cpumask_notifier() <int padata_register_cpumask_notifier (struct padata_instance *pinst, struct notifier_block *nblock) at padata.c:538>:
    blocking_notifier_chain_register() <int blocking_notifier_chain_register (struct blocking_notifier_head *nh, struct notifier_block *n) at notifier.c:213>:
        unlikely()
        notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
            rcu_assign_pointer()
        down_write()
        up_write()
padata_remove_cpu() <int padata_remove_cpu (struct padata_instance *pinst, int cpu, int mask) at padata.c:768>:
    mutex_lock()
    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
        might_sleep()
        cpuhp_lock_acquire_read()
        mutex_lock()
        atomic_inc()
        mutex_unlock()
    cpumask_clear_cpu()
    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
        atomic_dec_return()
        WARN_ON()
        atomic_inc()
        waitqueue_active()
        wake_up()
        cpuhp_lock_release()
    mutex_unlock()
padata_set_cpumask() <int padata_set_cpumask (struct padata_instance *pinst, int cpumask_type, cpumask_var_t cpumask) at padata.c:645>:
    mutex_lock()
    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
        might_sleep()
        cpuhp_lock_acquire_read()
        mutex_lock()
        atomic_inc()
        mutex_unlock()
    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
        atomic_dec_return()
        WARN_ON()
        atomic_inc()
        waitqueue_active()
        wake_up()
        cpuhp_lock_release()
    mutex_unlock()
padata_set_cpumasks() <int padata_set_cpumasks (struct padata_instance *pinst, cpumask_var_t pcpumask, cpumask_var_t cbcpumask) at padata.c:618>:
    mutex_lock()
    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
        might_sleep()
        cpuhp_lock_acquire_read()
        mutex_lock()
        atomic_inc()
        mutex_unlock()
    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
        atomic_dec_return()
        WARN_ON()
        atomic_inc()
        waitqueue_active()
        wake_up()
        cpuhp_lock_release()
    mutex_unlock()
padata_start() <int padata_start (struct padata_instance *pinst) at padata.c:797>:
    mutex_lock()
    mutex_unlock()
padata_stop() <void padata_stop (struct padata_instance *pinst) at padata.c:819>:
    mutex_lock()
    mutex_unlock()
padata_unregister_cpumask_notifier() <int padata_unregister_cpumask_notifier (struct padata_instance *pinst, struct notifier_block *nblock) at padata.c:553>:
    blocking_notifier_chain_unregister() <int blocking_notifier_chain_unregister (struct blocking_notifier_head *nh, struct notifier_block *n) at notifier.c:266>:
        unlikely()
        notifier_chain_unregister() <int notifier_chain_unregister (struct notifier_block **nl, struct notifier_block *n) at notifier.c:49>:
            rcu_assign_pointer()
        down_write()
        up_write()
paddr_vmcoreinfo_note() <unsigned long __weak paddr_vmcoreinfo_note (void) at kexec_core.c:1376>:
page_is_ram() <int __weak page_is_ram (unsigned long pfn) at resource.c:489>:
    walk_system_ram_range() <int walk_system_ram_range (unsigned long start_pfn, unsigned long nr_pages, void *arg, int (*func) (unsigned long, unsigned long, void *)) at resource.c:453>:
        find_next_iomem_res() <int find_next_iomem_res (struct resource *res, char *name, bool first_level_children_only) at resource.c:342>:
            start()
            BUG_ON()
            read_lock()
            next_resource() <struct resource *next_resource (struct resource *p, bool sibling_only) at resource.c:63>
            read_unlock()
panic() <void panic (const char *fmt, ...) at panic.c:83>:
    local_irq_disable()
    raw_smp_processor_id()
    atomic_cmpxchg()
    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
        cpu_relax()
    console_verbose()
    bust_spinlocks()
    pr_emerg()
    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
        test_bit()
    dump_stack()
    smp_send_stop()
    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
    kmsg_dump()
    debug_locks_off()
    console_flush_on_panic()
    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
    no_blink() <long no_blink (int state) at panic.c:46>
    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
        raw_cpu_write()
        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                raw_cpu_write()
            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                per_cpu()
            raw_smp_processor_id()
    mdelay()
    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
        kmsg_dump()
        machine_emergency_restart()
    disabled_wait()
    local_irq_enable()
    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
            raw_cpu_write()
        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
            per_cpu()
        raw_smp_processor_id()
panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
    cpu_relax()
param_free_charp() <void param_free_charp (void *arg) at params.c:329>:
    maybe_kfree_parameter() <void maybe_kfree_parameter (void *param) at params.c:73>:
        spin_lock()
        list_for_each_entry()
        list_del()
        kfree()
        spin_unlock()
param_get_bool() <int param_get_bool (char *buffer, const struct kernel_param *kp) at params.c:353>:
param_get_charp() <int param_get_charp (char *buffer, const struct kernel_param *kp) at params.c:323>:
    scnprintf()
param_get_invbool() <int param_get_invbool (char *buffer, const struct kernel_param *kp) at params.c:413>:
param_get_string() <int param_get_string (char *buffer, const struct kernel_param *kp) at params.c:559>:
    strlcpy()
param_set_bint() <int param_set_bint (const char *val, const struct kernel_param *kp) at params.c:425>:
    param_set_bool() <int param_set_bool (const char *val, const struct kernel_param *kp) at params.c:343>:
        strtobool()
param_set_bool() <int param_set_bool (const char *val, const struct kernel_param *kp) at params.c:343>:
    strtobool()
param_set_bool_enable_only() <int param_set_bool_enable_only (const char *val, const struct kernel_param *kp) at params.c:367>:
    param_set_bool() <int param_set_bool (const char *val, const struct kernel_param *kp) at params.c:343>:
        strtobool()
param_set_charp() <int param_set_charp (const char *val, const struct kernel_param *kp) at params.c:300>:
    pr_err()
    maybe_kfree_parameter() <void maybe_kfree_parameter (void *param) at params.c:73>:
        spin_lock()
        list_for_each_entry()
        list_del()
        kfree()
        spin_unlock()
    slab_is_available()
    kmalloc_parameter() <void *kmalloc_parameter (unsigned int size) at params.c:57>:
        kmalloc()
        spin_lock()
        list_add()
        spin_unlock()
param_set_copystring() <int param_set_copystring (const char *val, const struct kernel_param *kp) at params.c:545>:
    pr_err()
param_set_invbool() <int param_set_invbool (const char *val, const struct kernel_param *kp) at params.c:399>:
    param_set_bool() <int param_set_bool (const char *val, const struct kernel_param *kp) at params.c:343>:
        strtobool()
parameq() <bool parameq (const char *a, const char *b) at params.c:106>:
    parameqn() <bool parameqn (const char *a, const char *b, size_t n) at params.c:95>:
        dash2underscore() <char dash2underscore (char c) at params.c:88>
parameqn() <bool parameqn (const char *a, const char *b, size_t n) at params.c:95>:
    dash2underscore() <char dash2underscore (char c) at params.c:88>
parent_len() <int parent_len (const char *path) at auditfilter.c:1240>:
parse_args() <char *parse_args (const char *doing, char *args, const struct kernel_param *params, unsigned num, s16 min_level, s16 max_level, void *arg, int (*unknown) (char *param, char *val, const char *doing, void *arg)) at params.c:216>:
    skip_spaces()
    pr_debug()
    next_arg() <char *next_arg (char *args, char **param, char **val) at params.c:165>:
        skip_spaces()
    irqs_disabled()
    parse_one() <int parse_one (char *param, char *val, const char *doing, const struct kernel_param *params, unsigned num_params, s16 min_level, s16 max_level, void *arg, int (*handle_unknown) (char *param, char *val, const char *doing, void *arg)) at params.c:120>:
        parameq() <bool parameq (const char *a, const char *b) at params.c:106>:
            parameqn() <bool parameqn (const char *a, const char *b, size_t n) at params.c:95>:
                dash2underscore() <char dash2underscore (char c) at params.c:88>
        pr_debug()
        kernel_param_lock() <void kernel_param_lock (struct module *mod) at params.c:639>:
            mutex_lock()
            KPARAM_MUTEX()
        param_check_unsafe() <void param_check_unsafe (const struct kernel_param *kp) at params.c:111>:
            pr_warn()
            add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
                pr_warn()
                set_bit()
        kernel_param_unlock() <void kernel_param_unlock (struct module *mod) at params.c:644>:
            mutex_unlock()
            KPARAM_MUTEX()
    pr_warn()
    pr_err()
    ERR_PTR()
parse_crashkernel() <int __init parse_crashkernel (char *cmdline, unsigned long long system_ram, unsigned long long *crash_size, unsigned long long *crash_base) at kexec_core.c:1308>:
parse_crashkernel_high() <int __init parse_crashkernel_high (char *cmdline, unsigned long long system_ram, unsigned long long *crash_size, unsigned long long *crash_base) at kexec_core.c:1317>:
parse_crashkernel_low() <int __init parse_crashkernel_low (char *cmdline, unsigned long long system_ram, unsigned long long *crash_size, unsigned long long *crash_base) at kexec_core.c:1326>:
phys_to_pfn_t() <pfn_t phys_to_pfn_t (phys_addr_t addr, u64 flags) at memremap.c:155>:
pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
    rcu_dereference_check()
    hlist_first_rcu()
    lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
        lockdep_is_held()
    hlist_entry()
pid_vnr() <pid_t pid_vnr (struct pid *pid) at pid.c:514>:
    pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
        ns_of_pid()
        task_pid()
pidhash_init() <void __init pidhash_init (void) at pid.c:575>:
    alloc_large_system_hash()
    INIT_HLIST_HEAD()
pidmap_init() <void __init pidmap_init (void) at pid.c:589>:
    BUILD_BUG_ON()
    min()
    max_t()
    num_possible_cpus()
    pr_info()
    kzalloc()
    set_bit()
    atomic_dec()
    KMEM_CACHE()
prctl_get_seccomp() <long prctl_get_seccomp (void) at seccomp.c:716>:
prctl_set_seccomp() <long prctl_set_seccomp (unsigned long seccomp_mode, char __user *filter) at seccomp.c:845>:
    do_seccomp() <long do_seccomp (unsigned int op, unsigned int flags, const char __user *uargs) at seccomp.c:817>:
        seccomp_set_mode_strict() <long seccomp_set_mode_strict (void) at seccomp.c:728>:
            seccomp_mode()
            spin_lock_irq()
            seccomp_may_assign_mode() <inline bool seccomp_may_assign_mode (unsigned long seccomp_mode) at seccomp.c:207>:
                assert_spin_locked()
            disable_TSC()
            seccomp_assign_mode() <inline void seccomp_assign_mode (struct task_struct *task, unsigned long seccomp_mode) at seccomp.c:217>:
                assert_spin_locked()
                smp_mb__before_atomic()
                set_tsk_thread_flag()
            spin_unlock_irq()
        seccomp_set_mode_filter() <inline long seccomp_set_mode_filter (unsigned int flags, const char __user *filter) at seccomp.c:809>:
            seccomp_mode()
            seccomp_prepare_user_filter() <struct seccomp_filter *seccomp_prepare_user_filter (const char __user *user_filter) at seccomp.c:392>:
                ERR_PTR()
                is_compat_task()
                copy_from_user()
                compat_ptr()
                seccomp_prepare_filter() <struct seccomp_filter *seccomp_prepare_filter (struct sock_fprog *fprog) at seccomp.c:346>:
                    config_enabled()
                    ERR_PTR()
                    BUG_ON()
                    task_no_new_privs()
                    security_capable_noaudit()
                    current_cred()
                    current_user_ns()
                    kzalloc()
                    bpf_prog_create_from_user()
                    seccomp_check_filter() <int seccomp_check_filter (struct sock_filter *filter, unsigned int flen) at seccomp.c:100>:
                    kfree()
                    atomic_set()
            IS_ERR()
            PTR_ERR()
            mutex_lock_killable()
            spin_lock_irq()
            seccomp_may_assign_mode() <inline bool seccomp_may_assign_mode (unsigned long seccomp_mode) at seccomp.c:207>:
                assert_spin_locked()
            seccomp_attach_filter() <long seccomp_attach_filter (unsigned int flags, struct seccomp_filter *filter) at seccomp.c:422>:
                assert_spin_locked()
                seccomp_can_sync_threads() <inline pid_t seccomp_can_sync_threads (void) at seccomp.c:254>:
                    BUG_ON()
                    mutex_is_locked()
                    assert_spin_locked()
                    for_each_thread()
                    is_ancestor() <int is_ancestor (struct seccomp_filter *parent, struct seccomp_filter *child) at seccomp.c:233>:
                    task_pid_vnr()
                    unlikely()
                    WARN_ON()
                seccomp_sync_threads() <inline void seccomp_sync_threads (void) at seccomp.c:295>:
                    BUG_ON()
                    mutex_is_locked()
                    assert_spin_locked()
                    for_each_thread()
                    get_seccomp_filter() <void get_seccomp_filter (struct task_struct *tsk) at seccomp.c:461>:
                        atomic_inc()
                    put_seccomp_filter() <void put_seccomp_filter (struct task_struct *tsk) at seccomp.c:479>:
                        atomic_dec_and_test()
                        seccomp_filter_free() <inline void seccomp_filter_free (struct seccomp_filter *filter) at seccomp.c:470>:
                            bpf_prog_destroy()
                            kfree()
                    smp_store_release()
                    task_no_new_privs()
                    task_set_no_new_privs()
                    seccomp_assign_mode() <inline void seccomp_assign_mode (struct task_struct *task, unsigned long seccomp_mode) at seccomp.c:217>:
                        assert_spin_locked()
                        smp_mb__before_atomic()
                        set_tsk_thread_flag()
            seccomp_assign_mode() <inline void seccomp_assign_mode (struct task_struct *task, unsigned long seccomp_mode) at seccomp.c:217>:
                assert_spin_locked()
                smp_mb__before_atomic()
                set_tsk_thread_flag()
            spin_unlock_irq()
            mutex_unlock()
            seccomp_filter_free() <inline void seccomp_filter_free (struct seccomp_filter *filter) at seccomp.c:470>:
                bpf_prog_destroy()
                kfree()
prepare_creds() <struct cred *prepare_creds (void) at cred.c:243>:
    validate_process_creds()
    kmem_cache_alloc()
    kdebug()
    atomic_set()
    set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
        atomic_set()
    get_group_info()
    get_uid()
    get_user_ns()
    key_get()
    security_prepare_creds()
    validate_creds()
    abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
        kdebug()
        atomic_read()
        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
            atomic_read()
        BUG_ON()
        put_cred()
prepare_exec_creds() <struct cred *prepare_exec_creds (void) at cred.c:292>:
    prepare_creds() <struct cred *prepare_creds (void) at cred.c:243>:
        validate_process_creds()
        kmem_cache_alloc()
        kdebug()
        atomic_set()
        set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
            atomic_set()
        get_group_info()
        get_uid()
        get_user_ns()
        key_get()
        security_prepare_creds()
        validate_creds()
        abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
            BUG_ON()
            put_cred()
    key_put()
prepare_kernel_cred() <struct cred *prepare_kernel_cred (struct task_struct *daemon) at cred.c:594>:
    kmem_cache_alloc()
    kdebug()
    get_task_cred() <const struct cred *get_task_cred (struct task_struct *task) at cred.c:187>:
        rcu_read_lock()
        BUG_ON()
        atomic_inc_not_zero()
        rcu_read_unlock()
    get_cred()
    validate_creds()
    atomic_set()
    set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
        atomic_set()
    get_uid()
    get_user_ns()
    get_group_info()
    security_prepare_creds()
    put_cred()
print_modules() <void print_modules (void) at module.c:4084>:
    printk()
    preempt_disable()
    list_for_each_entry_rcu()
    pr_cont()
    module_flags() <char *module_flags (struct module *mod, char *buf) at module.c:3872>:
        BUG_ON()
        module_flags_taint() <size_t module_flags_taint (struct module *mod, char *buf) at module.c:1135>:
    preempt_enable()
print_oops_end_marker() <void print_oops_end_marker (void) at panic.c:435>:
    init_oops_id() <int init_oops_id (void) at panic.c:424>:
        get_random_bytes()
    pr_warn()
print_stack_trace() <void print_stack_trace (struct stack_trace *trace, int spaces) at stacktrace.c:14>:
    WARN_ON()
    printk()
    print_ip_sym()
print_tainted() <const char *print_tainted (void) at panic.c:290>:
    ARRAY_SIZE()
    test_bit()
print_worker_info() <void print_worker_info (const char *log_lvl, struct task_struct *task) at workqueue.c:4234>:
    fn()
    probe_kthread_data() <void *probe_kthread_data (struct task_struct *task) at kthread.c:149>:
        to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
        probe_kernel_read()
    probe_kernel_read()
    printk()
    pr_cont()
probe_kthread_data() <void *probe_kthread_data (struct task_struct *task) at kthread.c:149>:
    to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
    probe_kernel_read()
proc_caches_init() <void __init proc_caches_init (void) at fork.c:1845>:
    kmem_cache_create()
    sighand_ctor() <void sighand_ctor (void *data) at fork.c:1837>:
        spin_lock_init()
        init_waitqueue_head()
    KMEM_CACHE()
    mmap_init()
    nsproxy_cache_init() <int __init nsproxy_cache_init (void) at nsproxy.c:255>:
        KMEM_CACHE()
proc_cgroup_show() <int proc_cgroup_show (struct seq_file *m, struct pid_namespace *ns, struct pid *pid, struct task_struct *tsk) at cgroup.c:5381>:
    kmalloc()
    mutex_lock()
    spin_lock_bh()
    for_each_root()
    seq_printf()
    for_each_subsys()
    seq_putc()
    task_cgroup_from_root() <struct cgroup *task_cgroup_from_root (struct task_struct *task, struct cgroup_root *root) at cgroup.c:1172>:
        cset_cgroup_from_root() <struct cgroup *cset_cgroup_from_root (struct css_set *cset, struct cgroup_root *root) at cgroup.c:1141>:
            lockdep_assert_held()
            list_for_each_entry()
            BUG_ON()
        task_css_set()
    cgroup_on_dfl() <bool cgroup_on_dfl (const struct cgroup *cgrp) at cgroup.c:297>:
    cgroup_path()
    seq_puts()
    cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
    spin_unlock_bh()
    mutex_unlock()
    kfree()
proc_cpuset_show() <int proc_cpuset_show (struct seq_file *m, struct pid_namespace *ns, struct pid *pid, struct task_struct *tsk) at cpuset.c:2704>:
    kmalloc()
    rcu_read_lock()
    task_css()
    cgroup_path()
    rcu_read_unlock()
    seq_puts()
    seq_putc()
    kfree()
proc_do_large_bitmap() <int proc_do_large_bitmap (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2656>:
    memdup_user_nul()
    IS_ERR()
    PTR_ERR()
    kzalloc()
    BITS_TO_LONGS()
    kfree()
    proc_skip_char() <void proc_skip_char (char **buf, size_t *size, const char v) at sysctl.c:1933>
    proc_get_long() <int proc_get_long (char **buf, size_t *size, unsigned long *val, bool *neg, const char *perm_tr, unsigned perm_tr_len, char *tr) at sysctl.c:1960>:
        simple_strtoul()
    bitmap_set()
    find_next_bit()
    find_next_zero_bit()
    proc_put_char() <int proc_put_char (void __user **buf, size_t *size, char c) at sysctl.c:2037>:
        put_user()
    proc_put_long() <int proc_put_long (void __user **buf, size_t *size, unsigned long val, bool neg) at sysctl.c:2019>:
        copy_to_user()
    bitmap_or()
    bitmap_copy()
proc_dohung_task_timeout_secs() <int proc_dohung_task_timeout_secs (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at hung_task.c:197>:
    proc_doulongvec_minmax() <int proc_doulongvec_minmax (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2818>:
        do_proc_doulongvec_minmax() <int do_proc_doulongvec_minmax (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos, unsigned long convmul, unsigned long convdiv) at sysctl.c:2421>:
    wake_up_process()
proc_dointvec() <int proc_dointvec (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2788>:
    do_proc_dointvec() <int do_proc_dointvec (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos, int (*conv) (bool *negp, unsigned long *lvalp, int *valp, int write, void *data), void *data) at sysctl.c:2169>:
proc_dointvec_jiffies() <int proc_dointvec_jiffies (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2800>:
    do_proc_dointvec() <int do_proc_dointvec (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos, int (*conv) (bool *negp, unsigned long *lvalp, int *valp, int write, void *data), void *data) at sysctl.c:2169>:
    do_proc_dointvec_jiffies_conv() <int do_proc_dointvec_jiffies_conv (bool *negp, unsigned long *lvalp, int *valp, int write, void *data) at sysctl.c:2479>:
proc_dointvec_minmax() <int proc_dointvec_minmax (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2794>:
    min()
    max()
    do_proc_dointvec() <int do_proc_dointvec (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos, int (*conv) (bool *negp, unsigned long *lvalp, int *valp, int write, void *data), void *data) at sysctl.c:2169>:
    do_proc_dointvec_minmax_conv() <int do_proc_dointvec_minmax_conv (bool *negp, unsigned long *lvalp, int *valp, int write, void *data) at sysctl.c:2250>:
proc_dointvec_ms_jiffies() <int proc_dointvec_ms_jiffies (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2812>:
    do_proc_dointvec() <int do_proc_dointvec (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos, int (*conv) (bool *negp, unsigned long *lvalp, int *valp, int write, void *data), void *data) at sysctl.c:2169>:
    do_proc_dointvec_ms_jiffies_conv() <int do_proc_dointvec_ms_jiffies_conv (bool *negp, unsigned long *lvalp, int *valp, int write, void *data) at sysctl.c:2525>:
        msecs_to_jiffies()
        jiffies_to_msecs()
proc_dointvec_userhz_jiffies() <int proc_dointvec_userhz_jiffies (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2806>:
    do_proc_dointvec() <int do_proc_dointvec (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos, int (*conv) (bool *negp, unsigned long *lvalp, int *valp, int write, void *data), void *data) at sysctl.c:2169>:
    do_proc_dointvec_userhz_jiffies_conv() <int do_proc_dointvec_userhz_jiffies_conv (bool *negp, unsigned long *lvalp, int *valp, int write, void *data) at sysctl.c:2502>:
        clock_t_to_jiffies()
        jiffies_to_clock_t()
proc_dostring() <int proc_dostring (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2782>:
    warn_sysctl_write() <void warn_sysctl_write (struct ctl_table *table) at sysctl.c:1889>:
        pr_warn_once()
proc_doulongvec_minmax() <int proc_doulongvec_minmax (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2818>:
    do_proc_doulongvec_minmax() <int do_proc_doulongvec_minmax (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos, unsigned long convmul, unsigned long convdiv) at sysctl.c:2421>:
proc_doulongvec_ms_jiffies_minmax() <int proc_doulongvec_ms_jiffies_minmax (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2824>:
    do_proc_doulongvec_minmax() <int do_proc_doulongvec_minmax (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos, unsigned long convmul, unsigned long convdiv) at sysctl.c:2421>:
proc_gid_map_write() <ssize_t proc_gid_map_write (struct file *file, const char __user *buf, size_t size, loff_t *ppos) at user_namespace.c:774>:
    seq_user_ns()
    map_write() <ssize_t map_write (struct file *file, const char __user *buf, size_t count, loff_t *ppos, int cap_setid, struct uid_gid_map *map, struct uid_gid_map *parent_map) at user_namespace.c:594>:
        mutex_lock()
        cap_valid()
        file_ns_capable() <bool file_ns_capable (const struct file *file, struct user_namespace *ns, int cap) at capability.c:420>:
            WARN_ON_ONCE()
            cap_valid()
            security_capable()
        memdup_user_nul()
        IS_ERR()
        PTR_ERR()
        skip_spaces()
        simple_strtoul()
        mappings_overlap() <bool mappings_overlap (struct uid_gid_map *new_map, struct uid_gid_extent *extent) at user_namespace.c:558>:
        new_idmap_permitted() <bool new_idmap_permitted (const struct file *file, struct user_namespace *ns, int cap_setid, struct uid_gid_map *new_map) at user_namespace.c:809>:
            uid_eq()
            make_kuid() <kuid_t make_kuid (struct user_namespace *ns, uid_t uid) at user_namespace.c:239>:
                KUIDT_INIT()
                map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
                    smp_rmb()
            make_kgid() <kgid_t make_kgid (struct user_namespace *ns, gid_t gid) at user_namespace.c:307>:
                KGIDT_INIT()
                map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
                    smp_rmb()
            gid_eq()
            cap_valid()
            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                unlikely()
                cap_valid()
                pr_crit()
                BUG()
                security_capable()
                current_cred()
            file_ns_capable() <bool file_ns_capable (const struct file *file, struct user_namespace *ns, int cap) at capability.c:420>:
                WARN_ON_ONCE()
                cap_valid()
                security_capable()
        map_id_range_down() <u32 map_id_range_down (struct uid_gid_map *map, u32 id, u32 count) at user_namespace.c:154>:
            smp_rmb()
        smp_wmb()
        mutex_unlock()
        kfree()
proc_kprobes_optimization_handler() <int proc_kprobes_optimization_handler (struct ctl_table *table, int write, void __user *buffer, size_t *length, loff_t *ppos) at kprobes.c:832>:
    mutex_lock()
    proc_dointvec_minmax() <int proc_dointvec_minmax (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2794>:
        min()
        max()
        do_proc_dointvec() <int do_proc_dointvec (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos, int (*conv) (bool *negp, unsigned long *lvalp, int *valp, int write, void *data), void *data) at sysctl.c:2169>:
        do_proc_dointvec_minmax_conv() <int do_proc_dointvec_minmax_conv (bool *negp, unsigned long *lvalp, int *valp, int write, void *data) at sysctl.c:2250>:
    optimize_all_kprobes() <void optimize_all_kprobes (void) at kprobes.c:779>:
        mutex_lock()
        hlist_for_each_entry_rcu()
        kprobe_disabled()
        optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
            kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                container_of()
                arch_prepared_optinsn()
            kprobe_disabled()
            container_of()
            arch_check_optimized_kprobe()
            list_empty()
            list_del_init()
            list_add()
            kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                schedule_delayed_work()
        printk()
        mutex_unlock()
    unoptimize_all_kprobes() <void unoptimize_all_kprobes (void) at kprobes.c:802>:
        mutex_lock()
        mutex_unlock()
        hlist_for_each_entry_rcu()
        kprobe_disabled()
        unoptimize_kprobe() <void unoptimize_kprobe (struct kprobe *p, bool force) at kprobes.c:629>:
            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
            kprobe_disarmed() <inline int kprobe_disarmed (struct kprobe *p) at kprobes.c:390>:
                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                kprobe_disabled()
                container_of()
                list_empty()
            container_of()
            kprobe_optimized()
            list_empty()
            list_del_init()
            force_unoptimize_kprobe() <void force_unoptimize_kprobe (struct optimized_kprobe *op) at kprobes.c:619>:
                get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                    might_sleep()
                    cpuhp_lock_acquire_read()
                    mutex_lock()
                    atomic_inc()
                    mutex_unlock()
                arch_unoptimize_kprobe()
                put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                    atomic_dec_return()
                    WARN_ON()
                    atomic_inc()
                    waitqueue_active()
                    wake_up()
                    cpuhp_lock_release()
                kprobe_disabled()
                arch_disarm_kprobe()
            list_add()
            kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                schedule_delayed_work()
        wait_for_kprobe_optimizer() <void wait_for_kprobe_optimizer (void) at kprobes.c:566>:
            mutex_lock()
            list_empty()
            mutex_unlock()
            flush_delayed_work() <bool flush_delayed_work (struct delayed_work *dwork) at workqueue.c:2966>:
                local_irq_disable()
                del_timer_sync()
                local_irq_enable()
                flush_work() <bool flush_work (struct work_struct *work) at workqueue.c:2841>:
                    lock_map_acquire()
                    lock_map_release()
                    start_flush_work() <bool start_flush_work (struct work_struct *work, struct wq_barrier *barr) at workqueue.c:2779>:
                        might_sleep()
                        local_irq_disable()
                        get_work_pool() <struct worker_pool *get_work_pool (struct work_struct *work) at workqueue.c:703>:
                            atomic_long_read()
                            assert_rcu_or_pool_mutex()
                            idr_find()
                        local_irq_enable()
                        spin_lock()
                        get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                            atomic_long_read()
                        unlikely()
                        find_worker_executing_work() <struct worker *find_worker_executing_work (struct worker_pool *pool, struct work_struct *work) at workqueue.c:996>:
                            hash_for_each_possible()
                        check_flush_dependency() <void check_flush_dependency (struct workqueue_struct *target_wq, struct work_struct *target_work) at workqueue.c:2403>:
                            current_wq_worker()
                            WARN_ONCE()
                        insert_wq_barrier() <void insert_wq_barrier (struct pool_workqueue *pwq, struct wq_barrier *barr, struct work_struct *target, struct worker *worker) at workqueue.c:2460>:
                            INIT_WORK_ONSTACK()
                            wq_barrier_func() <void wq_barrier_func (struct work_struct *work) at workqueue.c:2430>:
                                container_of()
                                complete()
                            work_data_bits()
                            init_completion()
                            debug_work_activate() <inline void debug_work_activate (struct work_struct *work) at workqueue.c:547>:
                                debug_object_activate()
                            insert_work() <void insert_work (struct pool_workqueue *pwq, struct work_struct *work, struct list_head *head, unsigned int extra_flags) at workqueue.c:1290>:
                                set_work_pwq() <void set_work_pwq (struct work_struct *work, struct pool_workqueue *pwq, unsigned long extra_flags) at workqueue.c:645>:
                                    set_work_data() <inline void set_work_data (struct work_struct *work, unsigned long data, unsigned long flags) at workqueue.c:638>:
                                        WARN_ON_ONCE()
                                        work_pending()
                                        atomic_long_set()
                                        work_static()
                                list_add_tail()
                                get_pwq() <void get_pwq (struct pool_workqueue *pwq) at workqueue.c:1058>:
                                    lockdep_assert_held()
                                    WARN_ON_ONCE()
                                smp_mb()
                                wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
                                    first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                                        unlikely()
                                        list_empty()
                                        list_first_entry()
                                    likely()
                                    wake_up_process()
                            work_color_to_flags() <unsigned int work_color_to_flags (int color) at workqueue.c:602>:
                        spin_unlock_irq()
                        lock_map_acquire()
                        lock_map_acquire_read()
                        lock_map_release()
                    wait_for_completion()
                    destroy_work_on_stack() <void destroy_work_on_stack (struct work_struct *work) at workqueue.c:533>:
                        debug_object_free()
            cpu_relax()
        printk()
    mutex_unlock()
proc_nmi_watchdog() <int proc_nmi_watchdog (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at watchdog.c:947>:
    proc_watchdog_common() <int proc_watchdog_common (int which, struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at watchdog.c:872>:
        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
            might_sleep()
            cpuhp_lock_acquire_read()
            mutex_lock()
            atomic_inc()
            mutex_unlock()
        mutex_lock()
        proc_dointvec_minmax() <int proc_dointvec_minmax (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2794>:
            min()
            max()
            do_proc_dointvec() <int do_proc_dointvec (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos, int (*conv) (bool *negp, unsigned long *lvalp, int *valp, int write, void *data), void *data) at sysctl.c:2169>:
            do_proc_dointvec_minmax_conv() <int do_proc_dointvec_minmax_conv (bool *negp, unsigned long *lvalp, int *valp, int write, void *data) at sysctl.c:2250>:
        cmpxchg()
        proc_watchdog_update() <int proc_watchdog_update (void) at watchdog.c:840>:
            watchdog_enable_all_cpus() <int watchdog_enable_all_cpus (void) at watchdog.c:797>:
                smpboot_register_percpu_thread_cpumask() <int smpboot_register_percpu_thread_cpumask (struct smp_hotplug_thread *plug_thread, const struct cpumask *cpumask) at smpboot.c:282>:
                    alloc_cpumask_var()
                    cpumask_copy()
                    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                        might_sleep()
                        cpuhp_lock_acquire_read()
                        mutex_lock()
                        atomic_inc()
                        mutex_unlock()
                    mutex_lock()
                    for_each_online_cpu()
                    smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
                        for_each_possible_cpu()
                        per_cpu_ptr()
                        kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
                            trace_sched_kthread_stop()
                            get_task_struct()
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                            set_bit()
                            wake_up_process()
                            wait_for_completion()
                            put_task_struct()
                            trace_sched_kthread_stop_ret()
                        put_task_struct()
                    free_cpumask_var()
                    cpumask_test_cpu()
                    smpboot_unpark_thread() <void smpboot_unpark_thread (struct smp_hotplug_thread *ht, unsigned int cpu) at smpboot.c:221>:
                        per_cpu_ptr()
                        kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                    list_add()
                    mutex_unlock()
                    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                        atomic_dec_return()
                        WARN_ON()
                        atomic_inc()
                        waitqueue_active()
                        wake_up()
                        cpuhp_lock_release()
                pr_err()
                update_watchdog_all_cpus() <int update_watchdog_all_cpus (void) at watchdog.c:784>:
                    watchdog_park_threads() <int watchdog_park_threads (void) at watchdog.c:706>:
                        for_each_watchdog_cpu()
                        kthread_park() <int kthread_park (struct task_struct *k) at kthread.c:445>:
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                            test_bit()
                            set_bit()
                            wake_up_process()
                            wait_for_completion()
                        per_cpu()
                    watchdog_unpark_threads() <void watchdog_unpark_threads (void) at watchdog.c:725>:
                        for_each_watchdog_cpu()
                        kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                        per_cpu()
                watchdog_disable_all_cpus() <void watchdog_disable_all_cpus (void) at watchdog.c:827>:
                    smpboot_unregister_percpu_thread() <void smpboot_unregister_percpu_thread (struct smp_hotplug_thread *plug_thread) at smpboot.c:318>:
                        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                            might_sleep()
                            cpuhp_lock_acquire_read()
                            mutex_lock()
                            atomic_inc()
                            mutex_unlock()
                        mutex_lock()
                        list_del()
                        smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
                            for_each_possible_cpu()
                            per_cpu_ptr()
                            kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
                                trace_sched_kthread_stop()
                                get_task_struct()
                                to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                    ACCESS_ONCE()
                                    likely()
                                set_bit()
                                wake_up_process()
                                wait_for_completion()
                                put_task_struct()
                                trace_sched_kthread_stop_ret()
                            put_task_struct()
                        mutex_unlock()
                        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                            atomic_dec_return()
                            WARN_ON()
                            atomic_inc()
                            waitqueue_active()
                            wake_up()
                            cpuhp_lock_release()
                        free_cpumask_var()
            watchdog_disable_all_cpus() <void watchdog_disable_all_cpus (void) at watchdog.c:827>:
                smpboot_unregister_percpu_thread() <void smpboot_unregister_percpu_thread (struct smp_hotplug_thread *plug_thread) at smpboot.c:318>:
                    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                        might_sleep()
                        cpuhp_lock_acquire_read()
                        mutex_lock()
                        atomic_inc()
                        mutex_unlock()
                    mutex_lock()
                    list_del()
                    smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
                        for_each_possible_cpu()
                        per_cpu_ptr()
                        kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
                            trace_sched_kthread_stop()
                            get_task_struct()
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                            set_bit()
                            wake_up_process()
                            wait_for_completion()
                            put_task_struct()
                            trace_sched_kthread_stop_ret()
                        put_task_struct()
                    mutex_unlock()
                    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                        atomic_dec_return()
                        WARN_ON()
                        atomic_inc()
                        waitqueue_active()
                        wake_up()
                        cpuhp_lock_release()
                    free_cpumask_var()
        mutex_unlock()
        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
            atomic_dec_return()
            WARN_ON()
            atomic_inc()
            waitqueue_active()
            wake_up()
            cpuhp_lock_release()
proc_projid_map_write() <ssize_t proc_projid_map_write (struct file *file, const char __user *buf, size_t size, loff_t *ppos) at user_namespace.c:791>:
    seq_user_ns()
    map_write() <ssize_t map_write (struct file *file, const char __user *buf, size_t count, loff_t *ppos, int cap_setid, struct uid_gid_map *map, struct uid_gid_map *parent_map) at user_namespace.c:594>:
        mutex_lock()
        cap_valid()
        file_ns_capable() <bool file_ns_capable (const struct file *file, struct user_namespace *ns, int cap) at capability.c:420>:
            WARN_ON_ONCE()
            cap_valid()
            security_capable()
        memdup_user_nul()
        IS_ERR()
        PTR_ERR()
        skip_spaces()
        simple_strtoul()
        mappings_overlap() <bool mappings_overlap (struct uid_gid_map *new_map, struct uid_gid_extent *extent) at user_namespace.c:558>:
        new_idmap_permitted() <bool new_idmap_permitted (const struct file *file, struct user_namespace *ns, int cap_setid, struct uid_gid_map *new_map) at user_namespace.c:809>:
            uid_eq()
            make_kuid() <kuid_t make_kuid (struct user_namespace *ns, uid_t uid) at user_namespace.c:239>:
                KUIDT_INIT()
                map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
                    smp_rmb()
            make_kgid() <kgid_t make_kgid (struct user_namespace *ns, gid_t gid) at user_namespace.c:307>:
                KGIDT_INIT()
                map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
                    smp_rmb()
            gid_eq()
            cap_valid()
            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                unlikely()
                cap_valid()
                pr_crit()
                BUG()
                security_capable()
                current_cred()
            file_ns_capable() <bool file_ns_capable (const struct file *file, struct user_namespace *ns, int cap) at capability.c:420>:
                WARN_ON_ONCE()
                cap_valid()
                security_capable()
        map_id_range_down() <u32 map_id_range_down (struct uid_gid_map *map, u32 id, u32 count) at user_namespace.c:154>:
            smp_rmb()
        smp_wmb()
        mutex_unlock()
        kfree()
proc_setgroups_show() <int proc_setgroups_show (struct seq_file *seq, void *v) at user_namespace.c:847>:
    ACCESS_ONCE()
    seq_printf()
proc_setgroups_write() <ssize_t proc_setgroups_write (struct file *file, const char __user *buf, size_t count, loff_t *ppos) at user_namespace.c:858>:
    copy_from_user()
    skip_spaces()
    mutex_lock()
    mutex_unlock()
proc_soft_watchdog() <int proc_soft_watchdog (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at watchdog.c:957>:
    proc_watchdog_common() <int proc_watchdog_common (int which, struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at watchdog.c:872>:
        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
            might_sleep()
            cpuhp_lock_acquire_read()
            mutex_lock()
            atomic_inc()
            mutex_unlock()
        mutex_lock()
        proc_dointvec_minmax() <int proc_dointvec_minmax (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2794>:
            min()
            max()
            do_proc_dointvec() <int do_proc_dointvec (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos, int (*conv) (bool *negp, unsigned long *lvalp, int *valp, int write, void *data), void *data) at sysctl.c:2169>:
            do_proc_dointvec_minmax_conv() <int do_proc_dointvec_minmax_conv (bool *negp, unsigned long *lvalp, int *valp, int write, void *data) at sysctl.c:2250>:
        cmpxchg()
        proc_watchdog_update() <int proc_watchdog_update (void) at watchdog.c:840>:
            watchdog_enable_all_cpus() <int watchdog_enable_all_cpus (void) at watchdog.c:797>:
                smpboot_register_percpu_thread_cpumask() <int smpboot_register_percpu_thread_cpumask (struct smp_hotplug_thread *plug_thread, const struct cpumask *cpumask) at smpboot.c:282>:
                    alloc_cpumask_var()
                    cpumask_copy()
                    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                        might_sleep()
                        cpuhp_lock_acquire_read()
                        mutex_lock()
                        atomic_inc()
                        mutex_unlock()
                    mutex_lock()
                    for_each_online_cpu()
                    smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
                        for_each_possible_cpu()
                        per_cpu_ptr()
                        kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
                            trace_sched_kthread_stop()
                            get_task_struct()
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                            set_bit()
                            wake_up_process()
                            wait_for_completion()
                            put_task_struct()
                            trace_sched_kthread_stop_ret()
                        put_task_struct()
                    free_cpumask_var()
                    cpumask_test_cpu()
                    smpboot_unpark_thread() <void smpboot_unpark_thread (struct smp_hotplug_thread *ht, unsigned int cpu) at smpboot.c:221>:
                        per_cpu_ptr()
                        kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                    list_add()
                    mutex_unlock()
                    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                        atomic_dec_return()
                        WARN_ON()
                        atomic_inc()
                        waitqueue_active()
                        wake_up()
                        cpuhp_lock_release()
                pr_err()
                update_watchdog_all_cpus() <int update_watchdog_all_cpus (void) at watchdog.c:784>:
                    watchdog_park_threads() <int watchdog_park_threads (void) at watchdog.c:706>:
                        for_each_watchdog_cpu()
                        kthread_park() <int kthread_park (struct task_struct *k) at kthread.c:445>:
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                            test_bit()
                            set_bit()
                            wake_up_process()
                            wait_for_completion()
                        per_cpu()
                    watchdog_unpark_threads() <void watchdog_unpark_threads (void) at watchdog.c:725>:
                        for_each_watchdog_cpu()
                        kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                        per_cpu()
                watchdog_disable_all_cpus() <void watchdog_disable_all_cpus (void) at watchdog.c:827>:
                    smpboot_unregister_percpu_thread() <void smpboot_unregister_percpu_thread (struct smp_hotplug_thread *plug_thread) at smpboot.c:318>:
                        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                            might_sleep()
                            cpuhp_lock_acquire_read()
                            mutex_lock()
                            atomic_inc()
                            mutex_unlock()
                        mutex_lock()
                        list_del()
                        smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
                            for_each_possible_cpu()
                            per_cpu_ptr()
                            kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
                                trace_sched_kthread_stop()
                                get_task_struct()
                                to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                    ACCESS_ONCE()
                                    likely()
                                set_bit()
                                wake_up_process()
                                wait_for_completion()
                                put_task_struct()
                                trace_sched_kthread_stop_ret()
                            put_task_struct()
                        mutex_unlock()
                        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                            atomic_dec_return()
                            WARN_ON()
                            atomic_inc()
                            waitqueue_active()
                            wake_up()
                            cpuhp_lock_release()
                        free_cpumask_var()
            watchdog_disable_all_cpus() <void watchdog_disable_all_cpus (void) at watchdog.c:827>:
                smpboot_unregister_percpu_thread() <void smpboot_unregister_percpu_thread (struct smp_hotplug_thread *plug_thread) at smpboot.c:318>:
                    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                        might_sleep()
                        cpuhp_lock_acquire_read()
                        mutex_lock()
                        atomic_inc()
                        mutex_unlock()
                    mutex_lock()
                    list_del()
                    smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
                        for_each_possible_cpu()
                        per_cpu_ptr()
                        kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
                            trace_sched_kthread_stop()
                            get_task_struct()
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                            set_bit()
                            wake_up_process()
                            wait_for_completion()
                            put_task_struct()
                            trace_sched_kthread_stop_ret()
                        put_task_struct()
                    mutex_unlock()
                    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                        atomic_dec_return()
                        WARN_ON()
                        atomic_inc()
                        waitqueue_active()
                        wake_up()
                        cpuhp_lock_release()
                    free_cpumask_var()
        mutex_unlock()
        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
            atomic_dec_return()
            WARN_ON()
            atomic_inc()
            waitqueue_active()
            wake_up()
            cpuhp_lock_release()
proc_uid_map_write() <ssize_t proc_uid_map_write (struct file *file, const char __user *buf, size_t size, loff_t *ppos) at user_namespace.c:757>:
    seq_user_ns()
    map_write() <ssize_t map_write (struct file *file, const char __user *buf, size_t count, loff_t *ppos, int cap_setid, struct uid_gid_map *map, struct uid_gid_map *parent_map) at user_namespace.c:594>:
        mutex_lock()
        cap_valid()
        file_ns_capable() <bool file_ns_capable (const struct file *file, struct user_namespace *ns, int cap) at capability.c:420>:
            WARN_ON_ONCE()
            cap_valid()
            security_capable()
        memdup_user_nul()
        IS_ERR()
        PTR_ERR()
        skip_spaces()
        simple_strtoul()
        mappings_overlap() <bool mappings_overlap (struct uid_gid_map *new_map, struct uid_gid_extent *extent) at user_namespace.c:558>:
        new_idmap_permitted() <bool new_idmap_permitted (const struct file *file, struct user_namespace *ns, int cap_setid, struct uid_gid_map *new_map) at user_namespace.c:809>:
            uid_eq()
            make_kuid() <kuid_t make_kuid (struct user_namespace *ns, uid_t uid) at user_namespace.c:239>:
                KUIDT_INIT()
                map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
                    smp_rmb()
            make_kgid() <kgid_t make_kgid (struct user_namespace *ns, gid_t gid) at user_namespace.c:307>:
                KGIDT_INIT()
                map_id_down() <u32 map_id_down (struct uid_gid_map *map, u32 id) at user_namespace.c:180>:
                    smp_rmb()
            gid_eq()
            cap_valid()
            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                unlikely()
                cap_valid()
                pr_crit()
                BUG()
                security_capable()
                current_cred()
            file_ns_capable() <bool file_ns_capable (const struct file *file, struct user_namespace *ns, int cap) at capability.c:420>:
                WARN_ON_ONCE()
                cap_valid()
                security_capable()
        map_id_range_down() <u32 map_id_range_down (struct uid_gid_map *map, u32 id, u32 count) at user_namespace.c:154>:
            smp_rmb()
        smp_wmb()
        mutex_unlock()
        kfree()
proc_watchdog() <int proc_watchdog (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at watchdog.c:937>:
    proc_watchdog_common() <int proc_watchdog_common (int which, struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at watchdog.c:872>:
        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
            might_sleep()
            cpuhp_lock_acquire_read()
            mutex_lock()
            atomic_inc()
            mutex_unlock()
        mutex_lock()
        proc_dointvec_minmax() <int proc_dointvec_minmax (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2794>:
            min()
            max()
            do_proc_dointvec() <int do_proc_dointvec (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos, int (*conv) (bool *negp, unsigned long *lvalp, int *valp, int write, void *data), void *data) at sysctl.c:2169>:
            do_proc_dointvec_minmax_conv() <int do_proc_dointvec_minmax_conv (bool *negp, unsigned long *lvalp, int *valp, int write, void *data) at sysctl.c:2250>:
        cmpxchg()
        proc_watchdog_update() <int proc_watchdog_update (void) at watchdog.c:840>:
            watchdog_enable_all_cpus() <int watchdog_enable_all_cpus (void) at watchdog.c:797>:
                smpboot_register_percpu_thread_cpumask() <int smpboot_register_percpu_thread_cpumask (struct smp_hotplug_thread *plug_thread, const struct cpumask *cpumask) at smpboot.c:282>:
                    alloc_cpumask_var()
                    cpumask_copy()
                    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                        might_sleep()
                        cpuhp_lock_acquire_read()
                        mutex_lock()
                        atomic_inc()
                        mutex_unlock()
                    mutex_lock()
                    for_each_online_cpu()
                    smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
                        for_each_possible_cpu()
                        per_cpu_ptr()
                        kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
                            trace_sched_kthread_stop()
                            get_task_struct()
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                            set_bit()
                            wake_up_process()
                            wait_for_completion()
                            put_task_struct()
                            trace_sched_kthread_stop_ret()
                        put_task_struct()
                    free_cpumask_var()
                    cpumask_test_cpu()
                    smpboot_unpark_thread() <void smpboot_unpark_thread (struct smp_hotplug_thread *ht, unsigned int cpu) at smpboot.c:221>:
                        per_cpu_ptr()
                        kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                    list_add()
                    mutex_unlock()
                    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                        atomic_dec_return()
                        WARN_ON()
                        atomic_inc()
                        waitqueue_active()
                        wake_up()
                        cpuhp_lock_release()
                pr_err()
                update_watchdog_all_cpus() <int update_watchdog_all_cpus (void) at watchdog.c:784>:
                    watchdog_park_threads() <int watchdog_park_threads (void) at watchdog.c:706>:
                        for_each_watchdog_cpu()
                        kthread_park() <int kthread_park (struct task_struct *k) at kthread.c:445>:
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                            test_bit()
                            set_bit()
                            wake_up_process()
                            wait_for_completion()
                        per_cpu()
                    watchdog_unpark_threads() <void watchdog_unpark_threads (void) at watchdog.c:725>:
                        for_each_watchdog_cpu()
                        kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                        per_cpu()
                watchdog_disable_all_cpus() <void watchdog_disable_all_cpus (void) at watchdog.c:827>:
                    smpboot_unregister_percpu_thread() <void smpboot_unregister_percpu_thread (struct smp_hotplug_thread *plug_thread) at smpboot.c:318>:
                        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                            might_sleep()
                            cpuhp_lock_acquire_read()
                            mutex_lock()
                            atomic_inc()
                            mutex_unlock()
                        mutex_lock()
                        list_del()
                        smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
                            for_each_possible_cpu()
                            per_cpu_ptr()
                            kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
                                trace_sched_kthread_stop()
                                get_task_struct()
                                to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                    ACCESS_ONCE()
                                    likely()
                                set_bit()
                                wake_up_process()
                                wait_for_completion()
                                put_task_struct()
                                trace_sched_kthread_stop_ret()
                            put_task_struct()
                        mutex_unlock()
                        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                            atomic_dec_return()
                            WARN_ON()
                            atomic_inc()
                            waitqueue_active()
                            wake_up()
                            cpuhp_lock_release()
                        free_cpumask_var()
            watchdog_disable_all_cpus() <void watchdog_disable_all_cpus (void) at watchdog.c:827>:
                smpboot_unregister_percpu_thread() <void smpboot_unregister_percpu_thread (struct smp_hotplug_thread *plug_thread) at smpboot.c:318>:
                    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                        might_sleep()
                        cpuhp_lock_acquire_read()
                        mutex_lock()
                        atomic_inc()
                        mutex_unlock()
                    mutex_lock()
                    list_del()
                    smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
                        for_each_possible_cpu()
                        per_cpu_ptr()
                        kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
                            trace_sched_kthread_stop()
                            get_task_struct()
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                            set_bit()
                            wake_up_process()
                            wait_for_completion()
                            put_task_struct()
                            trace_sched_kthread_stop_ret()
                        put_task_struct()
                    mutex_unlock()
                    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                        atomic_dec_return()
                        WARN_ON()
                        atomic_inc()
                        waitqueue_active()
                        wake_up()
                        cpuhp_lock_release()
                    free_cpumask_var()
        mutex_unlock()
        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
            atomic_dec_return()
            WARN_ON()
            atomic_inc()
            waitqueue_active()
            wake_up()
            cpuhp_lock_release()
proc_watchdog_cpumask() <int proc_watchdog_cpumask (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at watchdog.c:1008>:
    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
        might_sleep()
        cpuhp_lock_acquire_read()
        mutex_lock()
        atomic_inc()
        mutex_unlock()
    mutex_lock()
    proc_do_large_bitmap() <int proc_do_large_bitmap (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2656>:
        memdup_user_nul()
        IS_ERR()
        PTR_ERR()
        kzalloc()
        BITS_TO_LONGS()
        kfree()
        proc_skip_char() <void proc_skip_char (char **buf, size_t *size, const char v) at sysctl.c:1933>
        proc_get_long() <int proc_get_long (char **buf, size_t *size, unsigned long *val, bool *neg, const char *perm_tr, unsigned perm_tr_len, char *tr) at sysctl.c:1960>:
            simple_strtoul()
        bitmap_set()
        find_next_bit()
        find_next_zero_bit()
        proc_put_char() <int proc_put_char (void __user **buf, size_t *size, char c) at sysctl.c:2037>:
            put_user()
        proc_put_long() <int proc_put_long (void __user **buf, size_t *size, unsigned long val, bool neg) at sysctl.c:2019>:
            copy_to_user()
        bitmap_or()
        bitmap_copy()
    cpumask_and()
    smpboot_update_cpumask_percpu_thread() <int smpboot_update_cpumask_percpu_thread (struct smp_hotplug_thread *plug_thread, const struct cpumask *new) at smpboot.c:339>:
        alloc_cpumask_var()
        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
            might_sleep()
            cpuhp_lock_acquire_read()
            mutex_lock()
            atomic_inc()
            mutex_unlock()
        mutex_lock()
        cpumask_andnot()
        for_each_cpu_and()
        smpboot_park_thread() <void smpboot_park_thread (struct smp_hotplug_thread *ht, unsigned int cpu) at smpboot.c:240>:
            per_cpu_ptr()
            kthread_park() <int kthread_park (struct task_struct *k) at kthread.c:445>:
                to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                    ACCESS_ONCE()
                    likely()
                test_bit()
                set_bit()
                wake_up_process()
                wait_for_completion()
        smpboot_unpark_thread() <void smpboot_unpark_thread (struct smp_hotplug_thread *ht, unsigned int cpu) at smpboot.c:221>:
            per_cpu_ptr()
            kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
                to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                    ACCESS_ONCE()
                    likely()
        cpumask_copy()
        mutex_unlock()
        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
            atomic_dec_return()
            WARN_ON()
            atomic_inc()
            waitqueue_active()
            wake_up()
            cpuhp_lock_release()
        free_cpumask_var()
    pr_err()
    mutex_unlock()
    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
        atomic_dec_return()
        WARN_ON()
        atomic_inc()
        waitqueue_active()
        wake_up()
        cpuhp_lock_release()
proc_watchdog_thresh() <int proc_watchdog_thresh (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at watchdog.c:967>:
    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
        might_sleep()
        cpuhp_lock_acquire_read()
        mutex_lock()
        atomic_inc()
        mutex_unlock()
    mutex_lock()
    ACCESS_ONCE()
    proc_dointvec_minmax() <int proc_dointvec_minmax (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2794>:
        min()
        max()
        do_proc_dointvec() <int do_proc_dointvec (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos, int (*conv) (bool *negp, unsigned long *lvalp, int *valp, int write, void *data), void *data) at sysctl.c:2169>:
        do_proc_dointvec_minmax_conv() <int do_proc_dointvec_minmax_conv (bool *negp, unsigned long *lvalp, int *valp, int write, void *data) at sysctl.c:2250>:
    set_sample_period() <void set_sample_period (void) at watchdog.c:211>:
        get_softlockup_thresh() <int get_softlockup_thresh (void) at watchdog.c:196>:
    proc_watchdog_update() <int proc_watchdog_update (void) at watchdog.c:840>:
        watchdog_enable_all_cpus() <int watchdog_enable_all_cpus (void) at watchdog.c:797>:
            smpboot_register_percpu_thread_cpumask() <int smpboot_register_percpu_thread_cpumask (struct smp_hotplug_thread *plug_thread, const struct cpumask *cpumask) at smpboot.c:282>:
                alloc_cpumask_var()
                cpumask_copy()
                get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                    might_sleep()
                    cpuhp_lock_acquire_read()
                    mutex_lock()
                    atomic_inc()
                    mutex_unlock()
                mutex_lock()
                for_each_online_cpu()
                smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
                    for_each_possible_cpu()
                    per_cpu_ptr()
                    kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
                        trace_sched_kthread_stop()
                        get_task_struct()
                        to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                            ACCESS_ONCE()
                            likely()
                        set_bit()
                        wake_up_process()
                        wait_for_completion()
                        put_task_struct()
                        trace_sched_kthread_stop_ret()
                    put_task_struct()
                free_cpumask_var()
                cpumask_test_cpu()
                smpboot_unpark_thread() <void smpboot_unpark_thread (struct smp_hotplug_thread *ht, unsigned int cpu) at smpboot.c:221>:
                    per_cpu_ptr()
                    kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
                        to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                            ACCESS_ONCE()
                            likely()
                list_add()
                mutex_unlock()
                put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                    atomic_dec_return()
                    WARN_ON()
                    atomic_inc()
                    waitqueue_active()
                    wake_up()
                    cpuhp_lock_release()
            pr_err()
            update_watchdog_all_cpus() <int update_watchdog_all_cpus (void) at watchdog.c:784>:
                watchdog_park_threads() <int watchdog_park_threads (void) at watchdog.c:706>:
                    for_each_watchdog_cpu()
                    kthread_park() <int kthread_park (struct task_struct *k) at kthread.c:445>:
                        to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                            ACCESS_ONCE()
                            likely()
                        test_bit()
                        set_bit()
                        wake_up_process()
                        wait_for_completion()
                    per_cpu()
                watchdog_unpark_threads() <void watchdog_unpark_threads (void) at watchdog.c:725>:
                    for_each_watchdog_cpu()
                    kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
                        to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                            ACCESS_ONCE()
                            likely()
                    per_cpu()
            watchdog_disable_all_cpus() <void watchdog_disable_all_cpus (void) at watchdog.c:827>:
                smpboot_unregister_percpu_thread() <void smpboot_unregister_percpu_thread (struct smp_hotplug_thread *plug_thread) at smpboot.c:318>:
                    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                        might_sleep()
                        cpuhp_lock_acquire_read()
                        mutex_lock()
                        atomic_inc()
                        mutex_unlock()
                    mutex_lock()
                    list_del()
                    smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
                        for_each_possible_cpu()
                        per_cpu_ptr()
                        kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
                            trace_sched_kthread_stop()
                            get_task_struct()
                            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                                ACCESS_ONCE()
                                likely()
                            set_bit()
                            wake_up_process()
                            wait_for_completion()
                            put_task_struct()
                            trace_sched_kthread_stop_ret()
                        put_task_struct()
                    mutex_unlock()
                    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                        atomic_dec_return()
                        WARN_ON()
                        atomic_inc()
                        waitqueue_active()
                        wake_up()
                        cpuhp_lock_release()
                    free_cpumask_var()
        watchdog_disable_all_cpus() <void watchdog_disable_all_cpus (void) at watchdog.c:827>:
            smpboot_unregister_percpu_thread() <void smpboot_unregister_percpu_thread (struct smp_hotplug_thread *plug_thread) at smpboot.c:318>:
                get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                    might_sleep()
                    cpuhp_lock_acquire_read()
                    mutex_lock()
                    atomic_inc()
                    mutex_unlock()
                mutex_lock()
                list_del()
                smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
                    for_each_possible_cpu()
                    per_cpu_ptr()
                    kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
                        trace_sched_kthread_stop()
                        get_task_struct()
                        to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                            ACCESS_ONCE()
                            likely()
                        set_bit()
                        wake_up_process()
                        wait_for_completion()
                        put_task_struct()
                        trace_sched_kthread_stop_ret()
                    put_task_struct()
                mutex_unlock()
                put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                    atomic_dec_return()
                    WARN_ON()
                    atomic_inc()
                    waitqueue_active()
                    wake_up()
                    cpuhp_lock_release()
                free_cpumask_var()
    mutex_unlock()
    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
        atomic_dec_return()
        WARN_ON()
        atomic_inc()
        waitqueue_active()
        wake_up()
        cpuhp_lock_release()
profile_event_register() <int profile_event_register (enum profile_type type, struct notifier_block *n) at profile.c:166>:
    blocking_notifier_chain_register() <int blocking_notifier_chain_register (struct blocking_notifier_head *nh, struct notifier_block *n) at notifier.c:213>:
        unlikely()
        notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
            rcu_assign_pointer()
        down_write()
        up_write()
profile_event_unregister() <int profile_event_unregister (enum profile_type type, struct notifier_block *n) at profile.c:185>:
    blocking_notifier_chain_unregister() <int blocking_notifier_chain_unregister (struct blocking_notifier_head *nh, struct notifier_block *n) at notifier.c:266>:
        unlikely()
        notifier_chain_unregister() <int notifier_chain_unregister (struct notifier_block **nl, struct notifier_block *n) at notifier.c:49>:
            rcu_assign_pointer()
        down_write()
        up_write()
profile_handoff_task() <int profile_handoff_task (struct task_struct *task) at profile.c:142>:
    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
profile_hits() <void profile_hits (int type, void *__pc, unsigned int nr_hits) at profile.c:401>:
    do_profile_hits() <void do_profile_hits (int type, void *__pc, unsigned int nr_hits) at profile.c:393>:
        min()
        get_cpu()
        per_cpu()
        put_cpu()
        local_irq_save()
        atomic_add()
        local_irq_restore()
profile_init() <int __ref profile_init (void) at profile.c:99>:
    alloc_cpumask_var()
    cpumask_copy()
    kzalloc()
    alloc_pages_exact()
    vzalloc()
    free_cpumask_var()
profile_munmap() <void profile_munmap (unsigned long addr) at profile.c:149>:
    blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
profile_setup() <int profile_setup (char *str) at profile.c:53>:
    get_option()
    pr_info()
    pr_warn()
profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
    blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
profile_tick() <void profile_tick (int type) at profile.c:409>:
    get_irq_regs()
    user_mode()
    cpumask_test_cpu()
    smp_processor_id()
    profile_hit()
    profile_pc()
ptrace_may_access() <bool ptrace_may_access (struct task_struct *task, unsigned int mode) at ptrace.c:287>:
    task_lock()
    task_unlock()
ptrace_notify() <void ptrace_notify (int exit_code) at signal.c:1913>:
    BUG_ON()
    unlikely()
    task_work_run() <void task_work_run (void) at task_work.c:87>:
        ACCESS_ONCE()
        cmpxchg()
        raw_spin_unlock_wait()
        smp_mb()
        cond_resched()
    spin_lock_irq()
    ptrace_do_notify() <void ptrace_do_notify (int signr, int exit_code, int why) at signal.c:1899>:
        task_pid_vnr()
        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                    smp_rmb()
        current_user_ns()
        current_uid()
        ptrace_stop() <void ptrace_stop (int exit_code, int why, int clear_code, siginfo_t *info) at signal.c:1777>:
            arch_ptrace_stop_needed()
            spin_unlock_irq()
            arch_ptrace_stop()
            spin_lock_irq()
            sigkill_pending() <int sigkill_pending (struct task_struct *tsk) at signal.c:1760>:
            set_current_state()
            task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                WARN_ON_ONCE()
                task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                    BUG_ON()
                    task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                        unlikely()
                        smp_mb()
                        wake_up_bit()
            task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                BUG_ON()
                task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                    unlikely()
                    smp_mb()
                    wake_up_bit()
            task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                unlikely()
                smp_mb()
                wake_up_bit()
            read_lock()
            may_ptrace_stop() <inline int may_ptrace_stop (void) at signal.c:1732>:
                likely()
                unlikely()
            do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                BUG()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
            ptrace_reparented()
            preempt_disable()
            read_unlock()
            preempt_enable_no_resched()
            freezable_schedule()
            recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                PENDING()
                set_tsk_thread_flag()
    spin_unlock_irq()
ptrace_readdata() <int ptrace_readdata (struct task_struct *tsk, unsigned long src, char __user *dst, int len) at ptrace.c:531>:
    access_process_vm()
    copy_to_user()
ptrace_request() <int ptrace_request (struct task_struct *child, long request, unsigned long addr, unsigned long data) at ptrace.c:841>:
    generic_ptrace_peekdata() <int generic_ptrace_peekdata (struct task_struct *tsk, unsigned long addr, unsigned long data) at ptrace.c:1124>:
        access_process_vm()
        put_user()
    generic_ptrace_pokedata() <int generic_ptrace_pokedata (struct task_struct *tsk, unsigned long addr, unsigned long data) at ptrace.c:1136>:
        access_process_vm()
    ptrace_setoptions() <int ptrace_setoptions (struct task_struct *child, unsigned long data) at ptrace.c:581>:
        unlikely()
        config_enabled()
        capable() <bool capable (int cap) at capability.c:401>:
            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                unlikely()
                cap_valid()
                pr_crit()
                BUG()
                security_capable()
                current_cred()
        seccomp_mode()
    put_user()
    ptrace_peek_siginfo() <int ptrace_peek_siginfo (struct task_struct *child, unsigned long addr, unsigned long data) at ptrace.c:642>:
        copy_from_user()
        spin_lock_irq()
        list_for_each_entry()
        copy_siginfo()
        spin_unlock_irq()
        unlikely()
        is_compat_task()
        compat_ptr()
        copy_siginfo_to_user32()
        copy_siginfo_to_user() <int copy_siginfo_to_user (siginfo_t __user *to, const siginfo_t *from) at signal.c:2657>:
            access_ok()
        signal_pending()
        cond_resched()
    ptrace_getsiginfo() <int ptrace_getsiginfo (struct task_struct *child, siginfo_t *info) at ptrace.c:610>:
        lock_task_sighand()
        likely()
        unlock_task_sighand()
    copy_siginfo_to_user() <int copy_siginfo_to_user (siginfo_t __user *to, const siginfo_t *from) at signal.c:2657>:
        access_ok()
    copy_from_user()
    ptrace_setsiginfo() <int ptrace_setsiginfo (struct task_struct *child, const siginfo_t *info) at ptrace.c:626>:
        lock_task_sighand()
        likely()
        unlock_task_sighand()
    copy_to_user()
    sigdelsetmask()
    spin_lock_irq()
    spin_unlock_irq()
    unlikely()
    lock_task_sighand()
    likely()
    task_set_jobctl_pending() <bool task_set_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:248>:
        BUG_ON()
        unlikely()
        fatal_signal_pending()
    ptrace_signal_wake_up()
    unlock_task_sighand()
    ptrace_detach() <int ptrace_detach (struct task_struct *child, unsigned int data) at ptrace.c:486>:
        valid_signal()
        ptrace_disable()
        clear_tsk_thread_flag()
        write_lock_irq()
        WARN_ON()
        write_unlock_irq()
        proc_ptrace_connector()
    get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
        task_lock()
        atomic_inc()
        task_unlock()
    mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
        might_sleep()
        atomic_dec_and_test()
        uprobe_clear_state()
        exit_aio()
        ksm_exit()
        khugepaged_exit()
        exit_mmap()
        set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
            rcu_dereference_raw()
            get_file()
            rcu_assign_pointer()
            fput()
        list_empty()
        spin_lock()
        list_del()
        spin_unlock()
        module_put() <void module_put (struct module *module) at module.c:1098>:
            preempt_disable()
            atomic_dec_if_positive()
            WARN_ON()
            trace_module_put()
            preempt_enable()
        mmdrop()
    ptrace_resume() <int ptrace_resume (struct task_struct *child, long request, unsigned long data) at ptrace.c:738>:
        valid_signal()
        set_tsk_thread_flag()
        clear_tsk_thread_flag()
        is_singleblock()
        unlikely()
        arch_has_block_step()
        user_enable_block_step()
        is_singlestep()
        is_sysemu_singlestep()
        arch_has_single_step()
        user_enable_single_step()
        user_disable_single_step()
        thread_group_empty()
        spin_lock_irq()
        wake_up_state()
        spin_unlock_irq()
    access_ok()
    ptrace_regset() <int ptrace_regset (struct task_struct *task, int req, unsigned int type, struct iovec *kiov) at ptrace.c:811>:
        task_user_regset_view()
        find_regset() <const struct user_regset *find_regset (const struct user_regset_view *view, unsigned int type) at ptrace.c:797>:
        min()
        copy_regset_to_user()
        copy_regset_from_user()
    seccomp_get_filter() <long seccomp_get_filter (struct task_struct *task, unsigned long filter_off, void __user *data) at seccomp.c:873>:
        capable() <bool capable (int cap) at capability.c:401>:
            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                unlikely()
                cap_valid()
                pr_crit()
                BUG()
                security_capable()
                current_cred()
        spin_lock_irq()
        WARN_ON()
        get_seccomp_filter() <void get_seccomp_filter (struct task_struct *tsk) at seccomp.c:461>:
            atomic_inc()
        spin_unlock_irq()
        copy_to_user()
        bpf_classic_proglen()
        put_seccomp_filter() <void put_seccomp_filter (struct task_struct *tsk) at seccomp.c:479>:
            atomic_dec_and_test()
            seccomp_filter_free() <inline void seccomp_filter_free (struct seccomp_filter *filter) at seccomp.c:470>:
                bpf_prog_destroy()
                kfree()
ptrace_writedata() <int ptrace_writedata (struct task_struct *tsk, char __user *src, unsigned long dst, int len) at ptrace.c:556>:
    copy_from_user()
    access_process_vm()
put_compat_itimerspec() <int put_compat_itimerspec (struct compat_itimerspec __user *dst, const struct itimerspec *src) at compat.c:673>:
put_compat_rusage() <int put_compat_rusage (const struct rusage *r, struct compat_rusage __user *ru) at compat.c:511>:
    access_ok()
put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
    atomic_dec_return()
    WARN_ON()
    atomic_inc()
    waitqueue_active()
    wake_up()
    cpuhp_lock_release()
put_pid() <void put_pid (struct pid *pid) at pid.c:237>:
    atomic_read()
    atomic_dec_and_test()
    kmem_cache_free()
    put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
        kref_put()
        free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
            container_of()
            destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                ns_free_inum()
                kfree()
                put_user_ns()
                call_rcu()
                delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                    kmem_cache_free()
                    container_of()
put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
    kref_put()
    free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
        container_of()
        destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
            ns_free_inum()
            kfree()
            put_user_ns()
            call_rcu()
            delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                kmem_cache_free()
                container_of()
put_seccomp_filter() <void put_seccomp_filter (struct task_struct *tsk) at seccomp.c:479>:
    atomic_dec_and_test()
    seccomp_filter_free() <inline void seccomp_filter_free (struct seccomp_filter *filter) at seccomp.c:470>:
        bpf_prog_destroy()
        kfree()
put_zone_device_page() <void put_zone_device_page (struct page *page) at memremap.c:180>:
    put_dev_pagemap()
queue_delayed_work_on() <bool queue_delayed_work_on (int cpu, struct workqueue_struct *wq, struct delayed_work *dwork, unsigned long delay) at workqueue.c:1546>:
    local_irq_save()
    test_and_set_bit()
    work_data_bits()
    local_irq_restore()
queue_kthread_work() <bool queue_kthread_work (struct kthread_worker *worker, struct kthread_work *work) at kthread.c:626>:
    spin_lock_irqsave()
    list_empty()
    insert_kthread_work() <void insert_kthread_work (struct kthread_worker *worker, struct kthread_work *work, struct list_head *pos) at kthread.c:605>:
        lockdep_assert_held()
        list_add_tail()
        likely()
        wake_up_process()
    spin_unlock_irqrestore()
queue_work_on() <bool queue_work_on (int cpu, struct workqueue_struct *wq, struct work_struct *work) at workqueue.c:1474>:
    local_irq_save()
    test_and_set_bit()
    work_data_bits()
    local_irq_restore()
raise_softirq() <void raise_softirq (unsigned int nr) at softirq.c:418>:
    local_irq_save()
    raise_softirq_irqoff() <inline void raise_softirq_irqoff (unsigned int nr) at softirq.c:401>:
        in_interrupt()
        wakeup_softirqd() <void wakeup_softirqd (void) at softirq.c:71>:
            wake_up_process()
    local_irq_restore()
raise_softirq_irqoff() <inline void raise_softirq_irqoff (unsigned int nr) at softirq.c:401>:
    in_interrupt()
    wakeup_softirqd() <void wakeup_softirqd (void) at softirq.c:71>:
        wake_up_process()
raw_notifier_call_chain() <int raw_notifier_call_chain (struct raw_notifier_head *nh, unsigned long val, void *v) at notifier.c:398>:
raw_notifier_chain_register() <int raw_notifier_chain_register (struct raw_notifier_head *nh, struct notifier_block *n) at notifier.c:347>:
    notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
        rcu_assign_pointer()
raw_notifier_chain_unregister() <int raw_notifier_chain_unregister (struct raw_notifier_head *nh, struct notifier_block *n) at notifier.c:364>:
    notifier_chain_unregister() <int notifier_chain_unregister (struct notifier_block **nl, struct notifier_block *n) at notifier.c:49>:
        rcu_assign_pointer()
reboot_pid_ns() <int reboot_pid_ns (struct pid_namespace *pid_ns, int cmd) at pid_namespace.c:308>:
    read_lock()
    force_sig() <void force_sig (int sig, struct task_struct *p) at signal.c:1435>:
        force_sig_info() <int force_sig_info (int sig, struct siginfo *info, struct task_struct *t) at signal.c:1160>:
            spin_lock_irqsave()
            recalc_sigpending_and_wake() <void recalc_sigpending_and_wake (struct task_struct *t) at signal.c:152>:
                recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                    PENDING()
                    set_tsk_thread_flag()
                signal_wake_up()
            specific_send_sig_info() <int specific_send_sig_info (int sig, struct siginfo *info, struct task_struct *t) at signal.c:1129>:
                send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                    si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                        is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                        SI_FROMUSER()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
            spin_unlock_irqrestore()
    read_unlock()
    do_exit() <void do_exit (long code) at exit.c:651>:
        TASKS_RCU()
        profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
            blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
        WARN_ON()
        blk_needs_flush_plug()
        unlikely()
        in_interrupt()
        panic() <void panic (const char *fmt, ...) at panic.c:83>:
            local_irq_disable()
            raw_smp_processor_id()
            atomic_cmpxchg()
            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                cpu_relax()
            console_verbose()
            bust_spinlocks()
            pr_emerg()
            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                test_bit()
            dump_stack()
            smp_send_stop()
            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
            kmsg_dump()
            debug_locks_off()
            console_flush_on_panic()
            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
            no_blink() <long no_blink (int state) at panic.c:46>
            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                raw_cpu_write()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            mdelay()
            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                kmsg_dump()
                machine_emergency_restart()
            disabled_wait()
            local_irq_enable()
            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                    raw_cpu_write()
                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                    per_cpu()
                raw_smp_processor_id()
        set_fs()
        ptrace_event()
        validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
        pr_alert()
        set_current_state()
        schedule()
        exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
            threadgroup_change_begin()
            thread_group_empty()
            signal_group_exit()
            threadgroup_change_end()
            spin_lock_irq()
            signal_pending()
            signotset()
            retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                sigandsets()
                sigisemptyset()
                while_each_thread()
                has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                signal_pending()
                signal_wake_up()
            unlikely()
            task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                WARN_ON_ONCE()
                task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                    BUG_ON()
                    task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                        unlikely()
                        smp_mb()
                        wake_up_bit()
            spin_unlock_irq()
            read_lock()
            do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                BUG()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
            read_unlock()
        smp_mb()
        raw_spin_unlock_wait()
        in_atomic()
        pr_info()
        task_pid_nr()
        preempt_count()
        preempt_count_set()
        sync_mm_rss()
        acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
            task_cputime()
        atomic_dec_and_test()
        hrtimer_cancel()
        exit_itimers()
        setmax_mm_hiwater_rss()
        acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
            down_read()
            up_read()
            spin_lock_irq()
            thread_group_leader()
            task_cputime()
            spin_unlock_irq()
        tty_audit_exit()
        audit_free()
        taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
            taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                nla_total_size()
            taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                thread_group_empty()
                kmem_cache_zalloc()
                spin_lock_irq()
                spin_unlock_irq()
                kmem_cache_free()
            fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                spin_lock_irqsave()
                delayacct_add_tsk()
                spin_unlock_irqrestore()
            raw_cpu_ptr()
            list_empty()
            prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                genlmsg_new()
                this_cpu_inc_return()
                genlmsg_put()
                genlmsg_put_reply()
                nlmsg_free()
            mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                nla_put()
                nla_nest_start()
                nla_nest_cancel()
                nla_reserve()
                nla_nest_end()
                nla_data()
            task_pid_nr_ns()
            fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                delayacct_add_tsk()
                bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                    BUILD_BUG_ON()
                    ktime_get_ns()
                    do_div()
                    get_seconds()
                    thread_group_leader()
                    task_nice()
                    task_pid_nr_ns()
                    rcu_read_lock()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    pid_alive()
                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                        task_tgid()
                    rcu_dereference()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_usecs()
                    task_cputime_scaled()
                xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                    get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                        task_lock()
                        atomic_inc()
                        task_unlock()
                    get_mm_hiwater_rss()
                    get_mm_hiwater_vm()
                    mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                        might_sleep()
                        atomic_dec_and_test()
                        uprobe_clear_state()
                        exit_aio()
                        ksm_exit()
                        khugepaged_exit()
                        exit_mmap()
                        set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                            rcu_dereference_raw()
                            get_file()
                            rcu_assign_pointer()
                            fput()
                        list_empty()
                        spin_lock()
                        list_del()
                        spin_unlock()
                        module_put() <void module_put (struct module *module) at module.c:1098>:
                            preempt_disable()
                            atomic_dec_if_positive()
                            WARN_ON()
                            trace_module_put()
                            preempt_enable()
                        mmdrop()
            task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                task_tgid()
            send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                nlmsg_data()
                nlmsg_hdr()
                genlmsg_data()
                genlmsg_end()
                down_read()
                list_for_each_entry()
                list_is_last()
                skb_clone()
                genlmsg_unicast()
                up_read()
                nlmsg_free()
                down_write()
                list_for_each_entry_safe()
                list_del()
                kfree()
                up_write()
            nlmsg_free()
        exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
            mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                unlikely()
                exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                    uninitialized_var()
                    fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                        get_user()
                    get_user()
                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                        uninitialized_var()
                        get_user()
                        task_pid_vnr()
                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                            pagefault_disable()
                            futex_atomic_cmpxchg_inatomic()
                            pagefault_enable()
                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                            down_read()
                            fixup_user_fault()
                            up_read()
                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                            WAKE_Q()
                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                unlikely()
                                access_ok()
                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                    should_fail()
                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                    ihold()
                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                        atomic_inc()
                                        smp_mb__after_atomic()
                                    smp_mb()
                                get_user_pages_fast()
                                lock_page()
                                compound_head()
                                PageSwapCache()
                                unlock_page()
                                put_page()
                                PageAnon()
                                basepage_index()
                            unlikely()
                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                jhash2()
                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                atomic_read()
                            spin_lock()
                            plist_for_each_entry_safe()
                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                WARN()
                                wake_q_add()
                                smp_wmb()
                            spin_unlock()
                            wake_up_q()
                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                    WARN_ON_ONCE()
                                    iput()
                                    mmdrop()
                    cond_resched()
                compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                    uninitialized_var()
                    fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                        get_user()
                        compat_ptr()
                    get_user()
                    futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                        ptr_to_compat()
                        compat_ptr()
                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                        uninitialized_var()
                        get_user()
                        task_pid_vnr()
                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                            pagefault_disable()
                            futex_atomic_cmpxchg_inatomic()
                            pagefault_enable()
                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                            down_read()
                            fixup_user_fault()
                            up_read()
                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                            WAKE_Q()
                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                unlikely()
                                access_ok()
                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                    should_fail()
                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                    ihold()
                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                        atomic_inc()
                                        smp_mb__after_atomic()
                                    smp_mb()
                                get_user_pages_fast()
                                lock_page()
                                compound_head()
                                PageSwapCache()
                                unlock_page()
                                put_page()
                                PageAnon()
                                basepage_index()
                            unlikely()
                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                jhash2()
                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                atomic_read()
                            spin_lock()
                            plist_for_each_entry_safe()
                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                WARN()
                                wake_q_add()
                                smp_wmb()
                            spin_unlock()
                            wake_up_q()
                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                    WARN_ON_ONCE()
                                    iput()
                                    mmdrop()
                    cond_resched()
                list_empty()
                exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                    raw_spin_lock_irq()
                    list_empty()
                    list_entry()
                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                        jhash2()
                    raw_spin_unlock_irq()
                    spin_lock()
                    spin_unlock()
                    WARN_ON()
                    list_del_init()
                    rt_mutex_unlock()
                uprobe_free_utask()
                deactivate_mm()
                atomic_read()
                put_user()
                sys_futex()
                complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                    task_lock()
                    likely()
                    complete()
                    task_unlock()
            sync_mm_rss()
            down_read()
            up_read()
            xchg()
            atomic_dec_and_test()
            complete()
            set_task_state()
            freezable_schedule()
            atomic_inc()
            BUG_ON()
            task_lock()
            enter_lazy_tlb()
            task_unlock()
            mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                atomic_read()
                read_lock()
                list_for_each_entry()
                for_each_process()
                for_each_thread()
                read_unlock()
                BUG_ON()
                get_task_struct()
                task_lock()
                task_unlock()
                put_task_struct()
            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                might_sleep()
                atomic_dec_and_test()
                uprobe_clear_state()
                exit_aio()
                ksm_exit()
                khugepaged_exit()
                exit_mmap()
                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                    rcu_dereference_raw()
                    get_file()
                    rcu_assign_pointer()
                    fput()
                list_empty()
                spin_lock()
                list_del()
                spin_unlock()
                module_put() <void module_put (struct module *module) at module.c:1098>:
                    preempt_disable()
                    atomic_dec_if_positive()
                    WARN_ON()
                    trace_module_put()
                    preempt_enable()
                mmdrop()
            test_thread_flag()
            exit_oom_victim()
        acct_process() <void acct_process (void) at acct.c:587>:
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
            unlikely()
            slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                    smp_rmb()
                    rcu_read_lock()
                    to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                        container_of()
                    ACCESS_ONCE()
                    rcu_read_unlock()
                    atomic_long_inc_not_zero()
                    cpu_relax()
                    mutex_lock()
                    mutex_unlock()
                    acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                        atomic_long_dec_and_test()
                        kfree_rcu()
                do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                    override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        validate_creds()
                        get_cred()
                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                            atomic_add()
                        rcu_assign_pointer()
                    check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                        time_is_before_jiffies()
                        vfs_statfs()
                        do_div()
                        pr_info()
                    fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                        strlcpy()
                        ktime_get_ns()
                        nsec_to_AHZ()
                        encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                        encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                        encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                        do_div()
                        get_seconds()
                        spin_lock_irq()
                        old_encode_dev()
                        tty_devnum()
                        jiffies_to_AHZ()
                        cputime_to_jiffies()
                        spin_unlock_irq()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                        task_tgid()
                    rcu_read_lock()
                    rcu_dereference()
                    rcu_read_unlock()
                    file_start_write_trylock()
                    file_end_write()
                    revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        validate_creds()
                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                            atomic_add()
                        rcu_assign_pointer()
                        put_cred()
                mutex_unlock()
                acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                    atomic_long_dec_and_test()
                    kfree_rcu()
        trace_sched_process_exit()
        exit_sem()
        exit_shm()
        exit_files()
        exit_fs()
        disassociate_ctty()
        exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
            switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                might_sleep()
                task_lock()
                task_unlock()
                atomic_dec_and_test()
                free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                    put_mnt_ns()
                    put_uts_ns()
                    put_ipc_ns()
                    put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                        kref_put()
                        free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                            container_of()
                            destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                ns_free_inum()
                                kfree()
                                put_user_ns()
                                call_rcu()
                                delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                    kmem_cache_free()
                                    container_of()
                    put_net()
                    kmem_cache_free()
        exit_task_work()
        exit_thread()
        perf_event_exit_task()
        cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
            task_css_set()
            list_empty()
            spin_lock_bh()
            css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                lockdep_assert_held()
                WARN_ON_ONCE()
                list_empty()
                list_for_each_entry_safe()
                css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                    lockdep_assert_held()
                    WARN_ON_ONCE()
                    css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                        lockdep_assert_held()
                        container_of()
                        list_entry()
                        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                            lockdep_assert_held()
                            list_empty()
                        list_empty()
                        list_del()
                        put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                            lockdep_assert_held()
                            atomic_dec_and_test()
                            for_each_subsys()
                            list_del()
                            css_put()
                            hash_del()
                            list_for_each_entry_safe()
                            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                container_of()
                            cgroup_put()
                            kfree()
                            kfree_rcu()
                        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                            atomic_inc()
                        list_add()
                list_del_init()
                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                    lockdep_assert_held()
                    list_empty()
                css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                    lockdep_assert_held()
                    list_for_each_entry()
                    cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                        lockdep_assert_held()
                        check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                            notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                test_bit()
                            cgroup_is_populated()
                            css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                rcu_read_lock()
                                css_for_each_child()
                                rcu_read_unlock()
                            cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                            schedule_work()
                        cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                            spin_lock_irqsave()
                            kernfs_notify()
                            spin_unlock_irqrestore()
                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                            container_of()
                rcu_assign_pointer()
                list_add_tail()
            spin_unlock_bh()
            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                atomic_inc()
            for_each_subsys_which()
        flush_ptrace_hw_breakpoint()
        preempt_disable()
        preempt_enable()
        exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
            LIST_HEAD()
            write_lock_irq()
            forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                unlikely()
                list_empty()
                exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                    list_for_each_entry_safe()
                    unlikely()
                    send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                        valid_signal()
                        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                            lock_task_sighand()
                            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                    SI_FROMUSER()
                                task_pid_nr_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                            unlock_task_sighand()
                    list_add()
                find_child_reaper()
                find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                    find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                        for_each_thread()
                    same_thread_group()
                list_for_each_entry()
                for_each_thread()
                BUG_ON()
                likely()
                group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                    rcu_read_lock()
                    check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                        valid_signal()
                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                            SI_FROMUSER()
                        audit_signal_info()
                        same_thread_group()
                        kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                            current_cred()
                            uid_eq()
                            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                unlikely()
                                cap_valid()
                                pr_crit()
                                BUG()
                                security_capable()
                                current_cred()
                        task_session()
                        security_task_kill()
                    rcu_read_unlock()
                    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                        lock_task_sighand()
                        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                SI_FROMUSER()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                        unlock_task_sighand()
                same_thread_group()
                reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                    unlikely()
                    thread_group_empty()
                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                        BUG_ON()
                        task_is_stopped_or_traced()
                        thread_group_empty()
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        spin_lock_irqsave()
                        valid_signal()
                        spin_unlock_irqrestore()
                    list_add()
                    kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                        task_pgrp()
                        task_session()
                        will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                            do_each_pid_task()
                            thread_group_empty()
                            is_global_init()
                            task_pgrp()
                            task_session()
                            while_each_pid_task()
                        has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                            do_each_pid_task()
                            while_each_pid_task()
                list_splice_tail_init()
            kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                task_pgrp()
                task_session()
                will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                    do_each_pid_task()
                    thread_group_empty()
                    is_global_init()
                    task_pgrp()
                    task_session()
                    while_each_pid_task()
                has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                    do_each_pid_task()
                    while_each_pid_task()
            unlikely()
            thread_group_leader()
            thread_group_empty()
            ptrace_reparented()
            do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                BUG_ON()
                task_is_stopped_or_traced()
                thread_group_empty()
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                spin_lock_irqsave()
                valid_signal()
                spin_unlock_irqrestore()
            list_add()
            wake_up_process()
            write_unlock_irq()
            list_for_each_entry_safe()
            list_del_init()
            release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                rcu_read_lock()
                atomic_dec()
                rcu_read_unlock()
                proc_flush_task()
                write_lock_irq()
                ptrace_release_task()
                thread_group_empty()
                do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                    BUG_ON()
                    task_is_stopped_or_traced()
                    thread_group_empty()
                    rcu_read_lock()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_cred_xxx()
                    task_uid()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_clock_t()
                    spin_lock_irqsave()
                    valid_signal()
                    spin_unlock_irqrestore()
                write_unlock_irq()
                release_thread()
                call_rcu()
                delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                    container_of()
                    perf_event_delayed_put()
                    trace_sched_process_free()
                    put_task_struct()
                unlikely()
        proc_exit_connector()
        task_lock()
        mpol_put()
        task_unlock()
        kfree()
        debug_check_no_locks_held()
        exit_io_context()
        free_pipe_info()
        put_page()
        check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
            stack_not_used()
            spin_lock()
            pr_warn()
            task_pid_nr()
            spin_unlock()
        exit_rcu()
        BUG()
        cpu_relax()
rebuild_sched_domains() <void rebuild_sched_domains (void) at cpuset.c:832>:
    mutex_lock()
    rebuild_sched_domains_locked() <void rebuild_sched_domains_locked (void) at cpuset.c:827>:
        lockdep_assert_held()
        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
            might_sleep()
            cpuhp_lock_acquire_read()
            mutex_lock()
            atomic_inc()
            mutex_unlock()
        cpumask_equal()
        generate_sched_domains() <int generate_sched_domains (cpumask_var_t **domains, struct sched_domain_attr **attributes) at cpuset.c:621>:
            alloc_cpumask_var()
            cpumask_andnot()
            is_sched_load_balance() <inline int is_sched_load_balance (const struct cpuset *cs) at cpuset.c:198>:
                test_bit()
            alloc_sched_domains()
            kmalloc()
            update_domain_attr_tree() <void update_domain_attr_tree (struct sched_domain_attr *dattr, struct cpuset *root_cs) at cpuset.c:547>:
                rcu_read_lock()
                cpuset_for_each_descendant_pre()
                cpumask_empty()
                css_rightmost_descendant() <struct cgroup_subsys_state *css_rightmost_descendant (struct cgroup_subsys_state *pos) at cgroup.c:3738>:
                    cgroup_assert_mutex_or_rcu_locked()
                    css_for_each_child()
                is_sched_load_balance() <inline int is_sched_load_balance (const struct cpuset *cs) at cpuset.c:198>:
                    test_bit()
                update_domain_attr() <void update_domain_attr (struct sched_domain_attr *dattr, struct cpuset *c) at cpuset.c:540>
                rcu_read_unlock()
            cpumask_and()
            nr_cpusets()
            rcu_read_lock()
            cpuset_for_each_descendant_pre()
            cpumask_empty()
            cpumask_intersects()
            css_rightmost_descendant() <struct cgroup_subsys_state *css_rightmost_descendant (struct cgroup_subsys_state *pos) at cgroup.c:3738>:
                cgroup_assert_mutex_or_rcu_locked()
                css_for_each_child()
            rcu_read_unlock()
            cpusets_overlap() <int cpusets_overlap (struct cpuset *a, struct cpuset *b) at cpuset.c:534>:
                cpumask_intersects()
            pr_warn()
            cpumask_clear()
            cpumask_or()
            BUG_ON()
            free_cpumask_var()
            kfree()
        partition_sched_domains()
        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
            atomic_dec_return()
            WARN_ON()
            atomic_inc()
            waitqueue_active()
            wake_up()
            cpuhp_lock_release()
    mutex_unlock()
recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
    recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
        PENDING()
        set_tsk_thread_flag()
    freezing()
    clear_thread_flag()
recalc_sigpending_and_wake() <void recalc_sigpending_and_wake (struct task_struct *t) at signal.c:152>:
    recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
        PENDING()
        set_tsk_thread_flag()
    signal_wake_up()
recycle_rp_inst() <void recycle_rp_inst (struct kretprobe_instance *ri, struct hlist_head *head) at kprobes.c:1077>:
    hlist_del()
    INIT_HLIST_NODE()
    likely()
    raw_spin_lock()
    hlist_add_head()
    raw_spin_unlock()
ref_module() <int ref_module (struct module *a, struct module *b) at module.c:1123>:
    already_uses() <int already_uses (struct module *a, struct module *b) at module.c:788>:
        list_for_each_entry()
        pr_debug()
    strong_try_module_get() <inline int strong_try_module_get (struct module *mod) at module.c:316>:
        BUG_ON()
        try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
            preempt_disable()
            likely()
            module_is_live()
            atomic_inc_not_zero()
            trace_module_get()
            preempt_enable()
    add_module_usage() <int add_module_usage (struct module *a, struct module *b) at module.c:809>:
        pr_debug()
        kmalloc()
        pr_warn()
        list_add()
    module_put() <void module_put (struct module *module) at module.c:1098>:
        preempt_disable()
        atomic_dec_if_positive()
        WARN_ON()
        trace_module_put()
        preempt_enable()
region_intersects() <int region_intersects (resource_size_t start, size_t size, const char *name) at resource.c:513>:
    read_lock()
    read_unlock()
register_cpu_notifier() <int register_cpu_notifier (struct notifier_block *nb) at cpu.c:196>:
    cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
        mutex_lock()
    raw_notifier_chain_register() <int raw_notifier_chain_register (struct raw_notifier_head *nh, struct notifier_block *n) at notifier.c:347>:
        notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
            rcu_assign_pointer()
    cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
        mutex_unlock()
register_die_notifier() <int register_die_notifier (struct notifier_block *nb) at notifier.c:553>:
    vmalloc_sync_all()
    atomic_notifier_chain_register() <int atomic_notifier_chain_register (struct atomic_notifier_head *nh, struct notifier_block *n) at notifier.c:121>:
        spin_lock_irqsave()
        notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
            rcu_assign_pointer()
        spin_unlock_irqrestore()
register_jprobe() <int register_jprobe (struct jprobe *jp) at kprobes.c:1749>:
    register_jprobes() <int register_jprobes (struct jprobe **jps, int num) at kprobes.c:1718>:
        arch_deref_entry_point() <unsigned long __weak arch_deref_entry_point (void *entry) at kprobes.c:1713>
        kallsyms_lookup_size_offset() <int kallsyms_lookup_size_offset (unsigned long addr, unsigned long *symbolsize, unsigned long *offset) at kallsyms.c:275>:
            is_ksym_addr() <int is_ksym_addr (unsigned long addr) at kallsyms.c:78>:
                is_kernel() <inline int is_kernel (unsigned long addr) at kallsyms.c:71>:
                    in_gate_area_no_mm()
                is_kernel_text() <inline int is_kernel_text (unsigned long addr) at kallsyms.c:63>:
                    arch_is_kernel_text()
                    in_gate_area_no_mm()
                is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
            get_symbol_pos() <unsigned long get_symbol_pos (unsigned long addr, unsigned long *symbolsize, unsigned long *offset) at kallsyms.c:215>:
                BUG_ON()
                is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
            module_address_lookup() <const char *module_address_lookup (unsigned long addr, unsigned long *size, unsigned long *offset, char **modname, char *namebuf) at module.c:3704>:
                preempt_disable()
                get_ksymbol() <const char *get_ksymbol (struct module *mod, unsigned long addr, unsigned long *size, unsigned long *offset) at module.c:3657>:
                    rcu_dereference_sched()
                    within_module_init()
                    symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
                    is_arm_mapping_symbol() <inline int is_arm_mapping_symbol (const char *str) at module.c:3644>:
                preempt_enable()
        register_kprobe() <int register_kprobe (struct kprobe *p) at kprobes.c:1481>:
            kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
                kprobe_lookup_name()
                ERR_PTR()
            IS_ERR()
            PTR_ERR()
            check_kprobe_rereg() <inline int check_kprobe_rereg (struct kprobe *p) at kprobes.c:1402>:
                mutex_lock()
                mutex_unlock()
            INIT_LIST_HEAD()
            check_kprobe_address_safe() <int check_kprobe_address_safe (struct kprobe *p, struct module **probed_mod) at kprobes.c:1432>:
                arch_check_ftrace_location() <int __weak arch_check_ftrace_location (struct kprobe *p) at kprobes.c:1414>:
                    ftrace_location()
                jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                    mutex_lock()
                preempt_disable()
                kernel_text_address() <int kernel_text_address (unsigned long addr) at extable.c:120>:
                    core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
                        init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
                    is_module_text_address() <bool is_module_text_address (unsigned long addr) at module.c:4052>:
                        preempt_disable()
                        preempt_enable()
                    is_ftrace_trampoline()
                within_kprobe_blacklist() <bool within_kprobe_blacklist (unsigned long addr) at kprobes.c:1335>:
                    arch_within_kprobe_blacklist() <bool __weak arch_within_kprobe_blacklist (unsigned long addr) at kprobes.c:1328>:
                    list_for_each_entry()
                jump_label_text_reserved() <int jump_label_text_reserved (void *start, void *end) at jump_label.c:451>:
                unlikely()
                try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
                    preempt_disable()
                    likely()
                    module_is_live()
                    atomic_inc_not_zero()
                    trace_module_get()
                    preempt_enable()
                within_module_init()
                module_put() <void module_put (struct module *module) at module.c:1098>:
                    preempt_disable()
                    atomic_dec_if_positive()
                    WARN_ON()
                    trace_module_put()
                    preempt_enable()
                preempt_enable()
                jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                    mutex_unlock()
            mutex_lock()
            get_kprobe() <struct kprobe *get_kprobe (void *addr) at kprobes.c:304>:
                hash_ptr()
                hlist_for_each_entry_rcu()
            register_aggr_kprobe() <int register_aggr_kprobe (struct kprobe *orig_p, struct kprobe *p) at kprobes.c:1257>:
                jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                    mutex_lock()
                get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                    might_sleep()
                    cpuhp_lock_acquire_read()
                    mutex_lock()
                    atomic_inc()
                    mutex_unlock()
                mutex_lock()
                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                    kzalloc()
                    INIT_LIST_HEAD()
                    arch_prepare_optimized_kprobe()
                init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                    copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                    flush_insn_slot()
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                    kprobe_gone()
                    aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    INIT_LIST_HEAD()
                    INIT_HLIST_NODE()
                    list_add_rcu()
                    hlist_replace_rcu()
                kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    kprobe_disabled()
                    list_empty()
                reuse_unused_kprobe() <void reuse_unused_kprobe (struct kprobe *ap) at kprobes.c:898>:
                    BUG_ON()
                    kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        kprobe_disabled()
                        list_empty()
                    container_of()
                    unlikely()
                    list_empty()
                    printk()
                    kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        container_of()
                        arch_prepared_optinsn()
                    optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                        kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            container_of()
                            arch_prepared_optinsn()
                        kprobe_disabled()
                        container_of()
                        arch_check_optimized_kprobe()
                        list_empty()
                        list_del_init()
                        list_add()
                        kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                            schedule_delayed_work()
                kprobe_gone()
                arch_prepare_kprobe()
                prepare_optimized_kprobe() <void prepare_optimized_kprobe (struct kprobe *p) at kprobes.c:715>:
                    container_of()
                    arch_prepare_optimized_kprobe()
                copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                add_new_kprobe() <int add_new_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1207>:
                    BUG_ON()
                    kprobe_gone()
                    unoptimize_kprobe() <void unoptimize_kprobe (struct kprobe *p, bool force) at kprobes.c:629>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        kprobe_disarmed() <inline int kprobe_disarmed (struct kprobe *p) at kprobes.c:390>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            kprobe_disabled()
                            container_of()
                            list_empty()
                        container_of()
                        kprobe_optimized()
                        list_empty()
                        list_del_init()
                        force_unoptimize_kprobe() <void force_unoptimize_kprobe (struct optimized_kprobe *op) at kprobes.c:619>:
                            get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                                might_sleep()
                                cpuhp_lock_acquire_read()
                                mutex_lock()
                                atomic_inc()
                                mutex_unlock()
                            arch_unoptimize_kprobe()
                            put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                                atomic_dec_return()
                                WARN_ON()
                                atomic_inc()
                                waitqueue_active()
                                wake_up()
                                cpuhp_lock_release()
                            kprobe_disabled()
                            arch_disarm_kprobe()
                        list_add()
                        kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                            schedule_delayed_work()
                    list_add_tail_rcu()
                    aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    list_add_rcu()
                    aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                mutex_unlock()
                put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                    atomic_dec_return()
                    WARN_ON()
                    atomic_inc()
                    waitqueue_active()
                    wake_up()
                    cpuhp_lock_release()
                jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                    mutex_unlock()
                kprobe_disabled()
                arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                    unlikely()
                    kprobe_ftrace()
                    arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                        ftrace_set_filter_ip()
                        WARN()
                        register_ftrace_function()
                    mutex_lock()
                    mutex_unlock()
            prepare_kprobe() <int prepare_kprobe (struct kprobe *p) at kprobes.c:924>:
                kprobe_ftrace()
                arch_prepare_kprobe()
                arch_prepare_kprobe_ftrace()
            mutex_unlock()
            INIT_HLIST_NODE()
            hlist_add_head_rcu()
            hash_ptr()
            kprobe_disabled()
            arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                unlikely()
                kprobe_ftrace()
                arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                    ftrace_set_filter_ip()
                    WARN()
                    register_ftrace_function()
                mutex_lock()
                mutex_unlock()
            try_to_optimize_kprobe() <void try_to_optimize_kprobe (struct kprobe *p) at kprobes.c:745>:
                kprobe_ftrace()
                jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                    mutex_lock()
                mutex_lock()
                alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                    kzalloc()
                    INIT_LIST_HEAD()
                    arch_prepare_optimized_kprobe()
                container_of()
                arch_prepared_optinsn()
                arch_remove_optimized_kprobe()
                kfree()
                init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                    copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                    flush_insn_slot()
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                    kprobe_gone()
                    aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    INIT_LIST_HEAD()
                    INIT_HLIST_NODE()
                    list_add_rcu()
                    hlist_replace_rcu()
                optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                    kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        container_of()
                        arch_prepared_optinsn()
                    kprobe_disabled()
                    container_of()
                    arch_check_optimized_kprobe()
                    list_empty()
                    list_del_init()
                    list_add()
                    kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                        schedule_delayed_work()
                mutex_unlock()
                jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                    mutex_unlock()
            module_put() <void module_put (struct module *module) at module.c:1098>:
                preempt_disable()
                atomic_dec_if_positive()
                WARN_ON()
                trace_module_put()
                preempt_enable()
        unregister_jprobes() <void unregister_jprobes (struct jprobe **jps, int num) at kprobes.c:1761>:
            mutex_lock()
            mutex_unlock()
            synchronize_sched()
register_jprobes() <int register_jprobes (struct jprobe **jps, int num) at kprobes.c:1718>:
    arch_deref_entry_point() <unsigned long __weak arch_deref_entry_point (void *entry) at kprobes.c:1713>
    kallsyms_lookup_size_offset() <int kallsyms_lookup_size_offset (unsigned long addr, unsigned long *symbolsize, unsigned long *offset) at kallsyms.c:275>:
        is_ksym_addr() <int is_ksym_addr (unsigned long addr) at kallsyms.c:78>:
            is_kernel() <inline int is_kernel (unsigned long addr) at kallsyms.c:71>:
                in_gate_area_no_mm()
            is_kernel_text() <inline int is_kernel_text (unsigned long addr) at kallsyms.c:63>:
                arch_is_kernel_text()
                in_gate_area_no_mm()
            is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
        get_symbol_pos() <unsigned long get_symbol_pos (unsigned long addr, unsigned long *symbolsize, unsigned long *offset) at kallsyms.c:215>:
            BUG_ON()
            is_kernel_inittext() <inline int is_kernel_inittext (unsigned long addr) at kallsyms.c:55>:
        module_address_lookup() <const char *module_address_lookup (unsigned long addr, unsigned long *size, unsigned long *offset, char **modname, char *namebuf) at module.c:3704>:
            preempt_disable()
            get_ksymbol() <const char *get_ksymbol (struct module *mod, unsigned long addr, unsigned long *size, unsigned long *offset) at module.c:3657>:
                rcu_dereference_sched()
                within_module_init()
                symname() <const char *symname (struct mod_kallsyms *kallsyms, unsigned int symnum) at module.c:3652>:
                is_arm_mapping_symbol() <inline int is_arm_mapping_symbol (const char *str) at module.c:3644>:
            preempt_enable()
    register_kprobe() <int register_kprobe (struct kprobe *p) at kprobes.c:1481>:
        kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
            kprobe_lookup_name()
            ERR_PTR()
        IS_ERR()
        PTR_ERR()
        check_kprobe_rereg() <inline int check_kprobe_rereg (struct kprobe *p) at kprobes.c:1402>:
            mutex_lock()
            mutex_unlock()
        INIT_LIST_HEAD()
        check_kprobe_address_safe() <int check_kprobe_address_safe (struct kprobe *p, struct module **probed_mod) at kprobes.c:1432>:
            arch_check_ftrace_location() <int __weak arch_check_ftrace_location (struct kprobe *p) at kprobes.c:1414>:
                ftrace_location()
            jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                mutex_lock()
            preempt_disable()
            kernel_text_address() <int kernel_text_address (unsigned long addr) at extable.c:120>:
                core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
                    init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
                is_module_text_address() <bool is_module_text_address (unsigned long addr) at module.c:4052>:
                    preempt_disable()
                    preempt_enable()
                is_ftrace_trampoline()
            within_kprobe_blacklist() <bool within_kprobe_blacklist (unsigned long addr) at kprobes.c:1335>:
                arch_within_kprobe_blacklist() <bool __weak arch_within_kprobe_blacklist (unsigned long addr) at kprobes.c:1328>:
                list_for_each_entry()
            jump_label_text_reserved() <int jump_label_text_reserved (void *start, void *end) at jump_label.c:451>:
            unlikely()
            try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
                preempt_disable()
                likely()
                module_is_live()
                atomic_inc_not_zero()
                trace_module_get()
                preempt_enable()
            within_module_init()
            module_put() <void module_put (struct module *module) at module.c:1098>:
                preempt_disable()
                atomic_dec_if_positive()
                WARN_ON()
                trace_module_put()
                preempt_enable()
            preempt_enable()
            jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                mutex_unlock()
        mutex_lock()
        get_kprobe() <struct kprobe *get_kprobe (void *addr) at kprobes.c:304>:
            hash_ptr()
            hlist_for_each_entry_rcu()
        register_aggr_kprobe() <int register_aggr_kprobe (struct kprobe *orig_p, struct kprobe *p) at kprobes.c:1257>:
            jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                mutex_lock()
            get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                might_sleep()
                cpuhp_lock_acquire_read()
                mutex_lock()
                atomic_inc()
                mutex_unlock()
            mutex_lock()
            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
            alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                kzalloc()
                INIT_LIST_HEAD()
                arch_prepare_optimized_kprobe()
            init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                flush_insn_slot()
                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                kprobe_gone()
                aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                INIT_LIST_HEAD()
                INIT_HLIST_NODE()
                list_add_rcu()
                hlist_replace_rcu()
            kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                kprobe_disabled()
                list_empty()
            reuse_unused_kprobe() <void reuse_unused_kprobe (struct kprobe *ap) at kprobes.c:898>:
                BUG_ON()
                kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    kprobe_disabled()
                    list_empty()
                container_of()
                unlikely()
                list_empty()
                printk()
                kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    container_of()
                    arch_prepared_optinsn()
                optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                    kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        container_of()
                        arch_prepared_optinsn()
                    kprobe_disabled()
                    container_of()
                    arch_check_optimized_kprobe()
                    list_empty()
                    list_del_init()
                    list_add()
                    kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                        schedule_delayed_work()
            kprobe_gone()
            arch_prepare_kprobe()
            prepare_optimized_kprobe() <void prepare_optimized_kprobe (struct kprobe *p) at kprobes.c:715>:
                container_of()
                arch_prepare_optimized_kprobe()
            copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
            add_new_kprobe() <int add_new_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1207>:
                BUG_ON()
                kprobe_gone()
                unoptimize_kprobe() <void unoptimize_kprobe (struct kprobe *p, bool force) at kprobes.c:629>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    kprobe_disarmed() <inline int kprobe_disarmed (struct kprobe *p) at kprobes.c:390>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        kprobe_disabled()
                        container_of()
                        list_empty()
                    container_of()
                    kprobe_optimized()
                    list_empty()
                    list_del_init()
                    force_unoptimize_kprobe() <void force_unoptimize_kprobe (struct optimized_kprobe *op) at kprobes.c:619>:
                        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                            might_sleep()
                            cpuhp_lock_acquire_read()
                            mutex_lock()
                            atomic_inc()
                            mutex_unlock()
                        arch_unoptimize_kprobe()
                        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                            atomic_dec_return()
                            WARN_ON()
                            atomic_inc()
                            waitqueue_active()
                            wake_up()
                            cpuhp_lock_release()
                        kprobe_disabled()
                        arch_disarm_kprobe()
                    list_add()
                    kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                        schedule_delayed_work()
                list_add_tail_rcu()
                aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                list_add_rcu()
                aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
            mutex_unlock()
            put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                atomic_dec_return()
                WARN_ON()
                atomic_inc()
                waitqueue_active()
                wake_up()
                cpuhp_lock_release()
            jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                mutex_unlock()
            kprobe_disabled()
            arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                unlikely()
                kprobe_ftrace()
                arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                    ftrace_set_filter_ip()
                    WARN()
                    register_ftrace_function()
                mutex_lock()
                mutex_unlock()
        prepare_kprobe() <int prepare_kprobe (struct kprobe *p) at kprobes.c:924>:
            kprobe_ftrace()
            arch_prepare_kprobe()
            arch_prepare_kprobe_ftrace()
        mutex_unlock()
        INIT_HLIST_NODE()
        hlist_add_head_rcu()
        hash_ptr()
        kprobe_disabled()
        arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
            unlikely()
            kprobe_ftrace()
            arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                ftrace_set_filter_ip()
                WARN()
                register_ftrace_function()
            mutex_lock()
            mutex_unlock()
        try_to_optimize_kprobe() <void try_to_optimize_kprobe (struct kprobe *p) at kprobes.c:745>:
            kprobe_ftrace()
            jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                mutex_lock()
            mutex_lock()
            alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                kzalloc()
                INIT_LIST_HEAD()
                arch_prepare_optimized_kprobe()
            container_of()
            arch_prepared_optinsn()
            arch_remove_optimized_kprobe()
            kfree()
            init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                flush_insn_slot()
                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                kprobe_gone()
                aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                INIT_LIST_HEAD()
                INIT_HLIST_NODE()
                list_add_rcu()
                hlist_replace_rcu()
            optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    container_of()
                    arch_prepared_optinsn()
                kprobe_disabled()
                container_of()
                arch_check_optimized_kprobe()
                list_empty()
                list_del_init()
                list_add()
                kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                    schedule_delayed_work()
            mutex_unlock()
            jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                mutex_unlock()
        module_put() <void module_put (struct module *module) at module.c:1098>:
            preempt_disable()
            atomic_dec_if_positive()
            WARN_ON()
            trace_module_put()
            preempt_enable()
    unregister_jprobes() <void unregister_jprobes (struct jprobe **jps, int num) at kprobes.c:1761>:
        mutex_lock()
        mutex_unlock()
        synchronize_sched()
register_kprobe() <int register_kprobe (struct kprobe *p) at kprobes.c:1481>:
    kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
        kprobe_lookup_name()
        ERR_PTR()
    IS_ERR()
    PTR_ERR()
    check_kprobe_rereg() <inline int check_kprobe_rereg (struct kprobe *p) at kprobes.c:1402>:
        mutex_lock()
        mutex_unlock()
    INIT_LIST_HEAD()
    check_kprobe_address_safe() <int check_kprobe_address_safe (struct kprobe *p, struct module **probed_mod) at kprobes.c:1432>:
        arch_check_ftrace_location() <int __weak arch_check_ftrace_location (struct kprobe *p) at kprobes.c:1414>:
            ftrace_location()
        jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
            mutex_lock()
        preempt_disable()
        kernel_text_address() <int kernel_text_address (unsigned long addr) at extable.c:120>:
            core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
                init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
            is_module_text_address() <bool is_module_text_address (unsigned long addr) at module.c:4052>:
                preempt_disable()
                preempt_enable()
            is_ftrace_trampoline()
        within_kprobe_blacklist() <bool within_kprobe_blacklist (unsigned long addr) at kprobes.c:1335>:
            arch_within_kprobe_blacklist() <bool __weak arch_within_kprobe_blacklist (unsigned long addr) at kprobes.c:1328>:
            list_for_each_entry()
        jump_label_text_reserved() <int jump_label_text_reserved (void *start, void *end) at jump_label.c:451>:
        unlikely()
        try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
            preempt_disable()
            likely()
            module_is_live()
            atomic_inc_not_zero()
            trace_module_get()
            preempt_enable()
        within_module_init()
        module_put() <void module_put (struct module *module) at module.c:1098>:
            preempt_disable()
            atomic_dec_if_positive()
            WARN_ON()
            trace_module_put()
            preempt_enable()
        preempt_enable()
        jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
            mutex_unlock()
    mutex_lock()
    get_kprobe() <struct kprobe *get_kprobe (void *addr) at kprobes.c:304>:
        hash_ptr()
        hlist_for_each_entry_rcu()
    register_aggr_kprobe() <int register_aggr_kprobe (struct kprobe *orig_p, struct kprobe *p) at kprobes.c:1257>:
        jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
            mutex_lock()
        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
            might_sleep()
            cpuhp_lock_acquire_read()
            mutex_lock()
            atomic_inc()
            mutex_unlock()
        mutex_lock()
        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                list_for_each_entry_rcu()
                likely()
                kprobe_disabled()
                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
        alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
            kzalloc()
            INIT_LIST_HEAD()
            arch_prepare_optimized_kprobe()
        init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
            copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
            flush_insn_slot()
            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                list_for_each_entry_rcu()
                likely()
                kprobe_disabled()
                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
            aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
            kprobe_gone()
            aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                list_for_each_entry_rcu()
                likely()
                kprobe_disabled()
                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
            aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
            INIT_LIST_HEAD()
            INIT_HLIST_NODE()
            list_add_rcu()
            hlist_replace_rcu()
        kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
            kprobe_disabled()
            list_empty()
        reuse_unused_kprobe() <void reuse_unused_kprobe (struct kprobe *ap) at kprobes.c:898>:
            BUG_ON()
            kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                kprobe_disabled()
                list_empty()
            container_of()
            unlikely()
            list_empty()
            printk()
            kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                container_of()
                arch_prepared_optinsn()
            optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    container_of()
                    arch_prepared_optinsn()
                kprobe_disabled()
                container_of()
                arch_check_optimized_kprobe()
                list_empty()
                list_del_init()
                list_add()
                kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                    schedule_delayed_work()
        kprobe_gone()
        arch_prepare_kprobe()
        prepare_optimized_kprobe() <void prepare_optimized_kprobe (struct kprobe *p) at kprobes.c:715>:
            container_of()
            arch_prepare_optimized_kprobe()
        copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
        add_new_kprobe() <int add_new_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1207>:
            BUG_ON()
            kprobe_gone()
            unoptimize_kprobe() <void unoptimize_kprobe (struct kprobe *p, bool force) at kprobes.c:629>:
                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                kprobe_disarmed() <inline int kprobe_disarmed (struct kprobe *p) at kprobes.c:390>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    kprobe_disabled()
                    container_of()
                    list_empty()
                container_of()
                kprobe_optimized()
                list_empty()
                list_del_init()
                force_unoptimize_kprobe() <void force_unoptimize_kprobe (struct optimized_kprobe *op) at kprobes.c:619>:
                    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                        might_sleep()
                        cpuhp_lock_acquire_read()
                        mutex_lock()
                        atomic_inc()
                        mutex_unlock()
                    arch_unoptimize_kprobe()
                    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                        atomic_dec_return()
                        WARN_ON()
                        atomic_inc()
                        waitqueue_active()
                        wake_up()
                        cpuhp_lock_release()
                    kprobe_disabled()
                    arch_disarm_kprobe()
                list_add()
                kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                    schedule_delayed_work()
            list_add_tail_rcu()
            aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
            list_add_rcu()
            aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                list_for_each_entry_rcu()
                likely()
                kprobe_disabled()
                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
        mutex_unlock()
        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
            atomic_dec_return()
            WARN_ON()
            atomic_inc()
            waitqueue_active()
            wake_up()
            cpuhp_lock_release()
        jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
            mutex_unlock()
        kprobe_disabled()
        arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
            unlikely()
            kprobe_ftrace()
            arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                ftrace_set_filter_ip()
                WARN()
                register_ftrace_function()
            mutex_lock()
            mutex_unlock()
    prepare_kprobe() <int prepare_kprobe (struct kprobe *p) at kprobes.c:924>:
        kprobe_ftrace()
        arch_prepare_kprobe()
        arch_prepare_kprobe_ftrace()
    mutex_unlock()
    INIT_HLIST_NODE()
    hlist_add_head_rcu()
    hash_ptr()
    kprobe_disabled()
    arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
        unlikely()
        kprobe_ftrace()
        arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
            ftrace_set_filter_ip()
            WARN()
            register_ftrace_function()
        mutex_lock()
        mutex_unlock()
    try_to_optimize_kprobe() <void try_to_optimize_kprobe (struct kprobe *p) at kprobes.c:745>:
        kprobe_ftrace()
        jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
            mutex_lock()
        mutex_lock()
        alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
            kzalloc()
            INIT_LIST_HEAD()
            arch_prepare_optimized_kprobe()
        container_of()
        arch_prepared_optinsn()
        arch_remove_optimized_kprobe()
        kfree()
        init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
            copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
            flush_insn_slot()
            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                list_for_each_entry_rcu()
                likely()
                kprobe_disabled()
                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
            aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
            kprobe_gone()
            aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                list_for_each_entry_rcu()
                likely()
                kprobe_disabled()
                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
            aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
            INIT_LIST_HEAD()
            INIT_HLIST_NODE()
            list_add_rcu()
            hlist_replace_rcu()
        optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
            kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                container_of()
                arch_prepared_optinsn()
            kprobe_disabled()
            container_of()
            arch_check_optimized_kprobe()
            list_empty()
            list_del_init()
            list_add()
            kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                schedule_delayed_work()
        mutex_unlock()
        jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
            mutex_unlock()
    module_put() <void module_put (struct module *module) at module.c:1098>:
        preempt_disable()
        atomic_dec_if_positive()
        WARN_ON()
        trace_module_put()
        preempt_enable()
register_kprobes() <int register_kprobes (struct kprobe **kps, int num) at kprobes.c:1665>:
    register_kprobe() <int register_kprobe (struct kprobe *p) at kprobes.c:1481>:
        kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
            kprobe_lookup_name()
            ERR_PTR()
        IS_ERR()
        PTR_ERR()
        check_kprobe_rereg() <inline int check_kprobe_rereg (struct kprobe *p) at kprobes.c:1402>:
            mutex_lock()
            mutex_unlock()
        INIT_LIST_HEAD()
        check_kprobe_address_safe() <int check_kprobe_address_safe (struct kprobe *p, struct module **probed_mod) at kprobes.c:1432>:
            arch_check_ftrace_location() <int __weak arch_check_ftrace_location (struct kprobe *p) at kprobes.c:1414>:
                ftrace_location()
            jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                mutex_lock()
            preempt_disable()
            kernel_text_address() <int kernel_text_address (unsigned long addr) at extable.c:120>:
                core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
                    init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
                is_module_text_address() <bool is_module_text_address (unsigned long addr) at module.c:4052>:
                    preempt_disable()
                    preempt_enable()
                is_ftrace_trampoline()
            within_kprobe_blacklist() <bool within_kprobe_blacklist (unsigned long addr) at kprobes.c:1335>:
                arch_within_kprobe_blacklist() <bool __weak arch_within_kprobe_blacklist (unsigned long addr) at kprobes.c:1328>:
                list_for_each_entry()
            jump_label_text_reserved() <int jump_label_text_reserved (void *start, void *end) at jump_label.c:451>:
            unlikely()
            try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
                preempt_disable()
                likely()
                module_is_live()
                atomic_inc_not_zero()
                trace_module_get()
                preempt_enable()
            within_module_init()
            module_put() <void module_put (struct module *module) at module.c:1098>:
                preempt_disable()
                atomic_dec_if_positive()
                WARN_ON()
                trace_module_put()
                preempt_enable()
            preempt_enable()
            jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                mutex_unlock()
        mutex_lock()
        get_kprobe() <struct kprobe *get_kprobe (void *addr) at kprobes.c:304>:
            hash_ptr()
            hlist_for_each_entry_rcu()
        register_aggr_kprobe() <int register_aggr_kprobe (struct kprobe *orig_p, struct kprobe *p) at kprobes.c:1257>:
            jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                mutex_lock()
            get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                might_sleep()
                cpuhp_lock_acquire_read()
                mutex_lock()
                atomic_inc()
                mutex_unlock()
            mutex_lock()
            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
            alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                kzalloc()
                INIT_LIST_HEAD()
                arch_prepare_optimized_kprobe()
            init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                flush_insn_slot()
                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                kprobe_gone()
                aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                INIT_LIST_HEAD()
                INIT_HLIST_NODE()
                list_add_rcu()
                hlist_replace_rcu()
            kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                kprobe_disabled()
                list_empty()
            reuse_unused_kprobe() <void reuse_unused_kprobe (struct kprobe *ap) at kprobes.c:898>:
                BUG_ON()
                kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    kprobe_disabled()
                    list_empty()
                container_of()
                unlikely()
                list_empty()
                printk()
                kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    container_of()
                    arch_prepared_optinsn()
                optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                    kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        container_of()
                        arch_prepared_optinsn()
                    kprobe_disabled()
                    container_of()
                    arch_check_optimized_kprobe()
                    list_empty()
                    list_del_init()
                    list_add()
                    kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                        schedule_delayed_work()
            kprobe_gone()
            arch_prepare_kprobe()
            prepare_optimized_kprobe() <void prepare_optimized_kprobe (struct kprobe *p) at kprobes.c:715>:
                container_of()
                arch_prepare_optimized_kprobe()
            copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
            add_new_kprobe() <int add_new_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1207>:
                BUG_ON()
                kprobe_gone()
                unoptimize_kprobe() <void unoptimize_kprobe (struct kprobe *p, bool force) at kprobes.c:629>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    kprobe_disarmed() <inline int kprobe_disarmed (struct kprobe *p) at kprobes.c:390>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        kprobe_disabled()
                        container_of()
                        list_empty()
                    container_of()
                    kprobe_optimized()
                    list_empty()
                    list_del_init()
                    force_unoptimize_kprobe() <void force_unoptimize_kprobe (struct optimized_kprobe *op) at kprobes.c:619>:
                        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                            might_sleep()
                            cpuhp_lock_acquire_read()
                            mutex_lock()
                            atomic_inc()
                            mutex_unlock()
                        arch_unoptimize_kprobe()
                        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                            atomic_dec_return()
                            WARN_ON()
                            atomic_inc()
                            waitqueue_active()
                            wake_up()
                            cpuhp_lock_release()
                        kprobe_disabled()
                        arch_disarm_kprobe()
                    list_add()
                    kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                        schedule_delayed_work()
                list_add_tail_rcu()
                aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                list_add_rcu()
                aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
            mutex_unlock()
            put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                atomic_dec_return()
                WARN_ON()
                atomic_inc()
                waitqueue_active()
                wake_up()
                cpuhp_lock_release()
            jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                mutex_unlock()
            kprobe_disabled()
            arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                unlikely()
                kprobe_ftrace()
                arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                    ftrace_set_filter_ip()
                    WARN()
                    register_ftrace_function()
                mutex_lock()
                mutex_unlock()
        prepare_kprobe() <int prepare_kprobe (struct kprobe *p) at kprobes.c:924>:
            kprobe_ftrace()
            arch_prepare_kprobe()
            arch_prepare_kprobe_ftrace()
        mutex_unlock()
        INIT_HLIST_NODE()
        hlist_add_head_rcu()
        hash_ptr()
        kprobe_disabled()
        arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
            unlikely()
            kprobe_ftrace()
            arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                ftrace_set_filter_ip()
                WARN()
                register_ftrace_function()
            mutex_lock()
            mutex_unlock()
        try_to_optimize_kprobe() <void try_to_optimize_kprobe (struct kprobe *p) at kprobes.c:745>:
            kprobe_ftrace()
            jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                mutex_lock()
            mutex_lock()
            alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                kzalloc()
                INIT_LIST_HEAD()
                arch_prepare_optimized_kprobe()
            container_of()
            arch_prepared_optinsn()
            arch_remove_optimized_kprobe()
            kfree()
            init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                flush_insn_slot()
                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                kprobe_gone()
                aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                INIT_LIST_HEAD()
                INIT_HLIST_NODE()
                list_add_rcu()
                hlist_replace_rcu()
            optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    container_of()
                    arch_prepared_optinsn()
                kprobe_disabled()
                container_of()
                arch_check_optimized_kprobe()
                list_empty()
                list_del_init()
                list_add()
                kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                    schedule_delayed_work()
            mutex_unlock()
            jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                mutex_unlock()
        module_put() <void module_put (struct module *module) at module.c:1098>:
            preempt_disable()
            atomic_dec_if_positive()
            WARN_ON()
            trace_module_put()
            preempt_enable()
    unregister_kprobes() <void unregister_kprobes (struct kprobe **kps, int num) at kprobes.c:1689>:
        mutex_lock()
        mutex_unlock()
        synchronize_sched()
register_kretprobe() <int register_kretprobe (struct kretprobe *rp) at kprobes.c:1937>:
    kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
        kprobe_lookup_name()
        ERR_PTR()
    IS_ERR()
    PTR_ERR()
    pre_handler_kretprobe() <int pre_handler_kretprobe (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1959>:
        container_of()
        unlikely()
        in_nmi()
        hash_ptr()
        raw_spin_lock_irqsave()
        hlist_empty()
        hlist_entry()
        hlist_del()
        raw_spin_unlock_irqrestore()
        hlist_add_head()
        arch_prepare_kretprobe()
        INIT_HLIST_NODE()
        kretprobe_table_lock() < at kprobes.c:1108>:
            kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
            raw_spin_lock_irqsave()
        kretprobe_table_unlock() < at kprobes.c:1129>:
            kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
            raw_spin_unlock_irqrestore()
    max_t()
    num_possible_cpus()
    raw_spin_lock_init()
    INIT_HLIST_HEAD()
    kmalloc()
    free_rp_inst() <inline void free_rp_inst (struct kretprobe *rp) at kprobes.c:1171>:
        hlist_for_each_entry_safe()
        hlist_del()
        kfree()
    INIT_HLIST_NODE()
    hlist_add_head()
    register_kprobe() <int register_kprobe (struct kprobe *p) at kprobes.c:1481>:
        kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
            kprobe_lookup_name()
            ERR_PTR()
        IS_ERR()
        PTR_ERR()
        check_kprobe_rereg() <inline int check_kprobe_rereg (struct kprobe *p) at kprobes.c:1402>:
            mutex_lock()
            mutex_unlock()
        INIT_LIST_HEAD()
        check_kprobe_address_safe() <int check_kprobe_address_safe (struct kprobe *p, struct module **probed_mod) at kprobes.c:1432>:
            arch_check_ftrace_location() <int __weak arch_check_ftrace_location (struct kprobe *p) at kprobes.c:1414>:
                ftrace_location()
            jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                mutex_lock()
            preempt_disable()
            kernel_text_address() <int kernel_text_address (unsigned long addr) at extable.c:120>:
                core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
                    init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
                is_module_text_address() <bool is_module_text_address (unsigned long addr) at module.c:4052>:
                    preempt_disable()
                    preempt_enable()
                is_ftrace_trampoline()
            within_kprobe_blacklist() <bool within_kprobe_blacklist (unsigned long addr) at kprobes.c:1335>:
                arch_within_kprobe_blacklist() <bool __weak arch_within_kprobe_blacklist (unsigned long addr) at kprobes.c:1328>:
                list_for_each_entry()
            jump_label_text_reserved() <int jump_label_text_reserved (void *start, void *end) at jump_label.c:451>:
            unlikely()
            try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
                preempt_disable()
                likely()
                module_is_live()
                atomic_inc_not_zero()
                trace_module_get()
                preempt_enable()
            within_module_init()
            module_put() <void module_put (struct module *module) at module.c:1098>:
                preempt_disable()
                atomic_dec_if_positive()
                WARN_ON()
                trace_module_put()
                preempt_enable()
            preempt_enable()
            jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                mutex_unlock()
        mutex_lock()
        get_kprobe() <struct kprobe *get_kprobe (void *addr) at kprobes.c:304>:
            hash_ptr()
            hlist_for_each_entry_rcu()
        register_aggr_kprobe() <int register_aggr_kprobe (struct kprobe *orig_p, struct kprobe *p) at kprobes.c:1257>:
            jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                mutex_lock()
            get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                might_sleep()
                cpuhp_lock_acquire_read()
                mutex_lock()
                atomic_inc()
                mutex_unlock()
            mutex_lock()
            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
            alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                kzalloc()
                INIT_LIST_HEAD()
                arch_prepare_optimized_kprobe()
            init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                flush_insn_slot()
                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                kprobe_gone()
                aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                INIT_LIST_HEAD()
                INIT_HLIST_NODE()
                list_add_rcu()
                hlist_replace_rcu()
            kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                kprobe_disabled()
                list_empty()
            reuse_unused_kprobe() <void reuse_unused_kprobe (struct kprobe *ap) at kprobes.c:898>:
                BUG_ON()
                kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    kprobe_disabled()
                    list_empty()
                container_of()
                unlikely()
                list_empty()
                printk()
                kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    container_of()
                    arch_prepared_optinsn()
                optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                    kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        container_of()
                        arch_prepared_optinsn()
                    kprobe_disabled()
                    container_of()
                    arch_check_optimized_kprobe()
                    list_empty()
                    list_del_init()
                    list_add()
                    kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                        schedule_delayed_work()
            kprobe_gone()
            arch_prepare_kprobe()
            prepare_optimized_kprobe() <void prepare_optimized_kprobe (struct kprobe *p) at kprobes.c:715>:
                container_of()
                arch_prepare_optimized_kprobe()
            copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
            add_new_kprobe() <int add_new_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1207>:
                BUG_ON()
                kprobe_gone()
                unoptimize_kprobe() <void unoptimize_kprobe (struct kprobe *p, bool force) at kprobes.c:629>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    kprobe_disarmed() <inline int kprobe_disarmed (struct kprobe *p) at kprobes.c:390>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        kprobe_disabled()
                        container_of()
                        list_empty()
                    container_of()
                    kprobe_optimized()
                    list_empty()
                    list_del_init()
                    force_unoptimize_kprobe() <void force_unoptimize_kprobe (struct optimized_kprobe *op) at kprobes.c:619>:
                        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                            might_sleep()
                            cpuhp_lock_acquire_read()
                            mutex_lock()
                            atomic_inc()
                            mutex_unlock()
                        arch_unoptimize_kprobe()
                        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                            atomic_dec_return()
                            WARN_ON()
                            atomic_inc()
                            waitqueue_active()
                            wake_up()
                            cpuhp_lock_release()
                        kprobe_disabled()
                        arch_disarm_kprobe()
                    list_add()
                    kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                        schedule_delayed_work()
                list_add_tail_rcu()
                aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                list_add_rcu()
                aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
            mutex_unlock()
            put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                atomic_dec_return()
                WARN_ON()
                atomic_inc()
                waitqueue_active()
                wake_up()
                cpuhp_lock_release()
            jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                mutex_unlock()
            kprobe_disabled()
            arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                unlikely()
                kprobe_ftrace()
                arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                    ftrace_set_filter_ip()
                    WARN()
                    register_ftrace_function()
                mutex_lock()
                mutex_unlock()
        prepare_kprobe() <int prepare_kprobe (struct kprobe *p) at kprobes.c:924>:
            kprobe_ftrace()
            arch_prepare_kprobe()
            arch_prepare_kprobe_ftrace()
        mutex_unlock()
        INIT_HLIST_NODE()
        hlist_add_head_rcu()
        hash_ptr()
        kprobe_disabled()
        arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
            unlikely()
            kprobe_ftrace()
            arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                ftrace_set_filter_ip()
                WARN()
                register_ftrace_function()
            mutex_lock()
            mutex_unlock()
        try_to_optimize_kprobe() <void try_to_optimize_kprobe (struct kprobe *p) at kprobes.c:745>:
            kprobe_ftrace()
            jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                mutex_lock()
            mutex_lock()
            alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                kzalloc()
                INIT_LIST_HEAD()
                arch_prepare_optimized_kprobe()
            container_of()
            arch_prepared_optinsn()
            arch_remove_optimized_kprobe()
            kfree()
            init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                flush_insn_slot()
                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                kprobe_gone()
                aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                    list_for_each_entry_rcu()
                    likely()
                    kprobe_disabled()
                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                INIT_LIST_HEAD()
                INIT_HLIST_NODE()
                list_add_rcu()
                hlist_replace_rcu()
            optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    container_of()
                    arch_prepared_optinsn()
                kprobe_disabled()
                container_of()
                arch_check_optimized_kprobe()
                list_empty()
                list_del_init()
                list_add()
                kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                    schedule_delayed_work()
            mutex_unlock()
            jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                mutex_unlock()
        module_put() <void module_put (struct module *module) at module.c:1098>:
            preempt_disable()
            atomic_dec_if_positive()
            WARN_ON()
            trace_module_put()
            preempt_enable()
register_kretprobes() <int register_kretprobes (struct kretprobe **rps, int num) at kprobes.c:1943>:
    register_kretprobe() <int register_kretprobe (struct kretprobe *rp) at kprobes.c:1937>:
        kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
            kprobe_lookup_name()
            ERR_PTR()
        IS_ERR()
        PTR_ERR()
        pre_handler_kretprobe() <int pre_handler_kretprobe (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1959>:
            container_of()
            unlikely()
            in_nmi()
            hash_ptr()
            raw_spin_lock_irqsave()
            hlist_empty()
            hlist_entry()
            hlist_del()
            raw_spin_unlock_irqrestore()
            hlist_add_head()
            arch_prepare_kretprobe()
            INIT_HLIST_NODE()
            kretprobe_table_lock() < at kprobes.c:1108>:
                kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                raw_spin_lock_irqsave()
            kretprobe_table_unlock() < at kprobes.c:1129>:
                kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                raw_spin_unlock_irqrestore()
        max_t()
        num_possible_cpus()
        raw_spin_lock_init()
        INIT_HLIST_HEAD()
        kmalloc()
        free_rp_inst() <inline void free_rp_inst (struct kretprobe *rp) at kprobes.c:1171>:
            hlist_for_each_entry_safe()
            hlist_del()
            kfree()
        INIT_HLIST_NODE()
        hlist_add_head()
        register_kprobe() <int register_kprobe (struct kprobe *p) at kprobes.c:1481>:
            kprobe_addr() <kprobe_opcode_t *kprobe_addr (struct kprobe *p) at kprobes.c:1359>:
                kprobe_lookup_name()
                ERR_PTR()
            IS_ERR()
            PTR_ERR()
            check_kprobe_rereg() <inline int check_kprobe_rereg (struct kprobe *p) at kprobes.c:1402>:
                mutex_lock()
                mutex_unlock()
            INIT_LIST_HEAD()
            check_kprobe_address_safe() <int check_kprobe_address_safe (struct kprobe *p, struct module **probed_mod) at kprobes.c:1432>:
                arch_check_ftrace_location() <int __weak arch_check_ftrace_location (struct kprobe *p) at kprobes.c:1414>:
                    ftrace_location()
                jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                    mutex_lock()
                preempt_disable()
                kernel_text_address() <int kernel_text_address (unsigned long addr) at extable.c:120>:
                    core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
                        init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
                    is_module_text_address() <bool is_module_text_address (unsigned long addr) at module.c:4052>:
                        preempt_disable()
                        preempt_enable()
                    is_ftrace_trampoline()
                within_kprobe_blacklist() <bool within_kprobe_blacklist (unsigned long addr) at kprobes.c:1335>:
                    arch_within_kprobe_blacklist() <bool __weak arch_within_kprobe_blacklist (unsigned long addr) at kprobes.c:1328>:
                    list_for_each_entry()
                jump_label_text_reserved() <int jump_label_text_reserved (void *start, void *end) at jump_label.c:451>:
                unlikely()
                try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
                    preempt_disable()
                    likely()
                    module_is_live()
                    atomic_inc_not_zero()
                    trace_module_get()
                    preempt_enable()
                within_module_init()
                module_put() <void module_put (struct module *module) at module.c:1098>:
                    preempt_disable()
                    atomic_dec_if_positive()
                    WARN_ON()
                    trace_module_put()
                    preempt_enable()
                preempt_enable()
                jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                    mutex_unlock()
            mutex_lock()
            get_kprobe() <struct kprobe *get_kprobe (void *addr) at kprobes.c:304>:
                hash_ptr()
                hlist_for_each_entry_rcu()
            register_aggr_kprobe() <int register_aggr_kprobe (struct kprobe *orig_p, struct kprobe *p) at kprobes.c:1257>:
                jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                    mutex_lock()
                get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                    might_sleep()
                    cpuhp_lock_acquire_read()
                    mutex_lock()
                    atomic_inc()
                    mutex_unlock()
                mutex_lock()
                kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                    kzalloc()
                    INIT_LIST_HEAD()
                    arch_prepare_optimized_kprobe()
                init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                    copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                    flush_insn_slot()
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                    kprobe_gone()
                    aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    INIT_LIST_HEAD()
                    INIT_HLIST_NODE()
                    list_add_rcu()
                    hlist_replace_rcu()
                kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                    kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                        aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                            list_for_each_entry_rcu()
                            likely()
                            kprobe_disabled()
                            set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                            reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    kprobe_disabled()
                    list_empty()
                reuse_unused_kprobe() <void reuse_unused_kprobe (struct kprobe *ap) at kprobes.c:898>:
                    BUG_ON()
                    kprobe_unused() <inline int kprobe_unused (struct kprobe *p) at kprobes.c:328>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        kprobe_disabled()
                        list_empty()
                    container_of()
                    unlikely()
                    list_empty()
                    printk()
                    kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        container_of()
                        arch_prepared_optinsn()
                    optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                        kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            container_of()
                            arch_prepared_optinsn()
                        kprobe_disabled()
                        container_of()
                        arch_check_optimized_kprobe()
                        list_empty()
                        list_del_init()
                        list_add()
                        kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                            schedule_delayed_work()
                kprobe_gone()
                arch_prepare_kprobe()
                prepare_optimized_kprobe() <void prepare_optimized_kprobe (struct kprobe *p) at kprobes.c:715>:
                    container_of()
                    arch_prepare_optimized_kprobe()
                copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                add_new_kprobe() <int add_new_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1207>:
                    BUG_ON()
                    kprobe_gone()
                    unoptimize_kprobe() <void unoptimize_kprobe (struct kprobe *p, bool force) at kprobes.c:629>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        kprobe_disarmed() <inline int kprobe_disarmed (struct kprobe *p) at kprobes.c:390>:
                            kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                                aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                    list_for_each_entry_rcu()
                                    likely()
                                    kprobe_disabled()
                                    set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                    reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                            kprobe_disabled()
                            container_of()
                            list_empty()
                        container_of()
                        kprobe_optimized()
                        list_empty()
                        list_del_init()
                        force_unoptimize_kprobe() <void force_unoptimize_kprobe (struct optimized_kprobe *op) at kprobes.c:619>:
                            get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                                might_sleep()
                                cpuhp_lock_acquire_read()
                                mutex_lock()
                                atomic_inc()
                                mutex_unlock()
                            arch_unoptimize_kprobe()
                            put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                                atomic_dec_return()
                                WARN_ON()
                                atomic_inc()
                                waitqueue_active()
                                wake_up()
                                cpuhp_lock_release()
                            kprobe_disabled()
                            arch_disarm_kprobe()
                        list_add()
                        kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                            schedule_delayed_work()
                    list_add_tail_rcu()
                    aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    list_add_rcu()
                    aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                mutex_unlock()
                put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                    atomic_dec_return()
                    WARN_ON()
                    atomic_inc()
                    waitqueue_active()
                    wake_up()
                    cpuhp_lock_release()
                jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                    mutex_unlock()
                kprobe_disabled()
                arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                    unlikely()
                    kprobe_ftrace()
                    arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                        ftrace_set_filter_ip()
                        WARN()
                        register_ftrace_function()
                    mutex_lock()
                    mutex_unlock()
            prepare_kprobe() <int prepare_kprobe (struct kprobe *p) at kprobes.c:924>:
                kprobe_ftrace()
                arch_prepare_kprobe()
                arch_prepare_kprobe_ftrace()
            mutex_unlock()
            INIT_HLIST_NODE()
            hlist_add_head_rcu()
            hash_ptr()
            kprobe_disabled()
            arm_kprobe() <void arm_kprobe (struct kprobe *kp) at kprobes.c:968>:
                unlikely()
                kprobe_ftrace()
                arm_kprobe_ftrace() <void arm_kprobe_ftrace (struct kprobe *p) at kprobes.c:933>:
                    ftrace_set_filter_ip()
                    WARN()
                    register_ftrace_function()
                mutex_lock()
                mutex_unlock()
            try_to_optimize_kprobe() <void try_to_optimize_kprobe (struct kprobe *p) at kprobes.c:745>:
                kprobe_ftrace()
                jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                    mutex_lock()
                mutex_lock()
                alloc_aggr_kprobe() <struct kprobe *alloc_aggr_kprobe (struct kprobe *p) at kprobes.c:910>:
                    kzalloc()
                    INIT_LIST_HEAD()
                    arch_prepare_optimized_kprobe()
                container_of()
                arch_prepared_optinsn()
                arch_remove_optimized_kprobe()
                kfree()
                init_aggr_kprobe() <void init_aggr_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:1231>:
                    copy_kprobe() <inline void copy_kprobe (struct kprobe *ap, struct kprobe *p) at kprobes.c:337>:
                    flush_insn_slot()
                    aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    aggr_fault_handler() <int aggr_fault_handler (struct kprobe *p, struct pt_regs *regs, int trapnr) at kprobes.c:1032>:
                    kprobe_gone()
                    aggr_post_handler() <void aggr_post_handler (struct kprobe *p, struct pt_regs *regs, unsigned long flags) at kprobes.c:1017>:
                        list_for_each_entry_rcu()
                        likely()
                        kprobe_disabled()
                        set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    aggr_break_handler() <int aggr_break_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1049>:
                        reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                    INIT_LIST_HEAD()
                    INIT_HLIST_NODE()
                    list_add_rcu()
                    hlist_replace_rcu()
                optimize_kprobe() <void optimize_kprobe (struct kprobe *p) at kprobes.c:585>:
                    kprobe_optready() <inline int kprobe_optready (struct kprobe *p) at kprobes.c:377>:
                        kprobe_aggrprobe() <inline int kprobe_aggrprobe (struct kprobe *p) at kprobes.c:322>:
                            aggr_pre_handler() <int aggr_pre_handler (struct kprobe *p, struct pt_regs *regs) at kprobes.c:1001>:
                                list_for_each_entry_rcu()
                                likely()
                                kprobe_disabled()
                                set_kprobe_instance() <inline void set_kprobe_instance (struct kprobe *kp) at kprobes.c:288>:
                                reset_kprobe_instance() <inline void reset_kprobe_instance (void) at kprobes.c:293>:
                        container_of()
                        arch_prepared_optinsn()
                    kprobe_disabled()
                    container_of()
                    arch_check_optimized_kprobe()
                    list_empty()
                    list_del_init()
                    list_add()
                    kick_kprobe_optimizer() <void kick_kprobe_optimizer (void) at kprobes.c:524>:
                        schedule_delayed_work()
                mutex_unlock()
                jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                    mutex_unlock()
            module_put() <void module_put (struct module *module) at module.c:1098>:
                preempt_disable()
                atomic_dec_if_positive()
                WARN_ON()
                trace_module_put()
                preempt_enable()
    unregister_kretprobes() <void unregister_kretprobes (struct kretprobe **rps, int num) at kprobes.c:1954>:
        mutex_lock()
        mutex_unlock()
        synchronize_sched()
        cleanup_rp_inst() <void cleanup_rp_inst (struct kretprobe *rp) at kprobes.c:1182>:
            kretprobe_table_lock() < at kprobes.c:1108>:
                kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                raw_spin_lock_irqsave()
            hlist_for_each_entry_safe()
            kretprobe_table_unlock() < at kprobes.c:1129>:
                kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                raw_spin_unlock_irqrestore()
            free_rp_inst() <inline void free_rp_inst (struct kretprobe *rp) at kprobes.c:1171>:
                hlist_for_each_entry_safe()
                hlist_del()
                kfree()
register_module_notifier() <int register_module_notifier (struct notifier_block *nb) at module.c:285>:
    blocking_notifier_chain_register() <int blocking_notifier_chain_register (struct blocking_notifier_head *nh, struct notifier_block *n) at notifier.c:213>:
        unlikely()
        notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
            rcu_assign_pointer()
        down_write()
        up_write()
register_reboot_notifier() <int register_reboot_notifier (struct notifier_block *nb) at reboot.c:86>:
    blocking_notifier_chain_register() <int blocking_notifier_chain_register (struct blocking_notifier_head *nh, struct notifier_block *n) at notifier.c:213>:
        unlikely()
        notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
            rcu_assign_pointer()
        down_write()
        up_write()
register_restart_handler() <int register_restart_handler (struct notifier_block *nb) at reboot.c:151>:
    atomic_notifier_chain_register() <int atomic_notifier_chain_register (struct atomic_notifier_head *nh, struct notifier_block *n) at notifier.c:121>:
        spin_lock_irqsave()
        notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
            rcu_assign_pointer()
        spin_unlock_irqrestore()
register_tracepoint_module_notifier() <int register_tracepoint_module_notifier (struct notifier_block *nb) at tracepoint.c:343>:
    mutex_lock()
    blocking_notifier_chain_register() <int blocking_notifier_chain_register (struct blocking_notifier_head *nh, struct notifier_block *n) at notifier.c:213>:
        unlikely()
        notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
            rcu_assign_pointer()
        down_write()
        up_write()
    list_for_each_entry()
    mutex_unlock()
relay_buf_full() <int relay_buf_full (struct rchan_buf *buf) at relay.c:254>:
relay_close() <void relay_close (struct rchan *chan) at relay.c:812>:
    mutex_lock()
    relay_close_buf() <void relay_close_buf (struct rchan_buf *buf) at relay.c:479>:
        del_timer_sync()
        kref_put()
        relay_remove_buf() <void relay_remove_buf (struct kref *kref) at relay.c:231>:
            container_of()
            relay_destroy_buf() <void relay_destroy_buf (struct rchan_buf *buf) at relay.c:206>:
                likely()
                vunmap()
                relay_free_page_array() <void relay_free_page_array (struct page **array) at relay.c:82>:
                    kvfree()
                kfree()
                kref_put()
                relay_destroy_channel() <void relay_destroy_channel (struct kref *kref) at relay.c:196>:
                    container_of()
                    kfree()
    for_each_possible_cpu()
    printk()
    list_del()
    kref_put()
    relay_destroy_channel() <void relay_destroy_channel (struct kref *kref) at relay.c:196>:
        container_of()
        kfree()
    mutex_unlock()
relay_flush() <void relay_flush (struct rchan *chan) at relay.c:844>:
    relay_switch_subbuf() <size_t relay_switch_subbuf (struct rchan_buf *buf, size_t length) at relay.c:719>:
        unlikely()
        d_inode()
        smp_mb()
        waitqueue_active()
        mod_timer()
    mutex_lock()
    for_each_possible_cpu()
    mutex_unlock()
relay_late_setup_files() <int relay_late_setup_files (struct rchan *chan, const char *base_filename, struct dentry *parent) at relay.c:645>:
    strlcpy()
    mutex_lock()
    unlikely()
    mutex_unlock()
    get_cpu()
    for_each_online_cpu()
    WARN_ONCE()
    relay_create_buf_file() <struct dentry *relay_create_buf_file (struct rchan *chan, struct rchan_buf *buf, unsigned int cpu) at relay.c:410>:
        kzalloc()
        create_buf_file()
        kfree()
    local_irq_save()
    relay_set_buf_dentry() <inline void relay_set_buf_dentry (struct rchan_buf *buf, struct dentry *dentry) at relay.c:403>:
        d_inode()
    local_irq_restore()
    smp_mb()
    smp_call_function_single() <int smp_call_function_single (int cpu, void (*func) (void *info), void *info, int wait) at up.c:10>:
        get_cpu()
        WARN_ON_ONCE()
        cpu_online()
        irqs_disabled()
        this_cpu_ptr()
        csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
            csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                smp_load_acquire()
                cpu_relax()
            smp_wmb()
        generic_exec_single() <int generic_exec_single (int cpu, struct call_single_data *csd, smp_call_func_t func, void *info) at smp.c:144>:
            smp_processor_id()
            csd_unlock() <void csd_unlock (struct call_single_data *csd) at smp.c:127>:
                WARN_ON()
                smp_store_release()
            local_irq_save()
            local_irq_restore()
            cpu_online()
            llist_add()
            per_cpu()
            arch_send_call_function_single_ipi()
        csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
            smp_load_acquire()
            cpu_relax()
        put_cpu()
        WARN_ON()
        local_irq_save()
        local_irq_restore()
    put_cpu()
relay_open() <struct rchan *relay_open (const char *base_filename, struct dentry *parent, size_t subbuf_size, size_t n_subbufs, struct rchan_callbacks *cb, void *private_data) at relay.c:566>:
    kzalloc()
    PAGE_ALIGN()
    strlcpy()
    setup_callbacks() <void setup_callbacks (struct rchan *chan, struct rchan_callbacks *cb) at relay.c:487>:
        subbuf_start_default_callback() <int subbuf_start_default_callback (struct rchan_buf *buf, void *subbuf, void *prev_subbuf, size_t prev_padding) at relay.c:273>:
            relay_buf_full() <int relay_buf_full (struct rchan_buf *buf) at relay.c:254>:
        buf_mapped_default_callback() <void buf_mapped_default_callback (struct rchan_buf *buf, struct file *filp) at relay.c:287>
        buf_unmapped_default_callback() <void buf_unmapped_default_callback (struct rchan_buf *buf, struct file *filp) at relay.c:295>
        create_buf_file_default_callback() <struct dentry *create_buf_file_default_callback (const char *filename, struct dentry *parent, umode_t mode, struct rchan_buf *buf, int *is_global) at relay.c:303>:
        remove_buf_file_default_callback() <int remove_buf_file_default_callback (struct dentry *dentry) at relay.c:315>:
    kref_init()
    mutex_lock()
    for_each_online_cpu()
    relay_open_buf() <struct rchan_buf *relay_open_buf (struct rchan *chan, unsigned int cpu) at relay.c:437>:
        relay_create_buf() <struct rchan_buf *relay_create_buf (struct rchan *chan) at relay.c:162>:
            kzalloc()
            kmalloc()
            relay_alloc_buf() <void *relay_alloc_buf (struct rchan_buf *buf, size_t *size) at relay.c:123>:
                PAGE_ALIGN()
                relay_alloc_page_array() <struct page **relay_alloc_page_array (unsigned int n_pages) at relay.c:71>:
                    vzalloc()
                    kzalloc()
                alloc_page()
                unlikely()
                set_page_private()
                vmap()
                relay_free_page_array() <void relay_free_page_array (struct page **array) at relay.c:82>:
                    kvfree()
            kref_get()
            kfree()
        relay_create_buf_file() <struct dentry *relay_create_buf_file (struct rchan *chan, struct rchan_buf *buf, unsigned int cpu) at relay.c:410>:
            kzalloc()
            create_buf_file()
            kfree()
        relay_set_buf_dentry() <inline void relay_set_buf_dentry (struct rchan_buf *buf, struct dentry *dentry) at relay.c:403>:
            d_inode()
        relay_destroy_buf() <void relay_destroy_buf (struct rchan_buf *buf) at relay.c:206>:
            likely()
            vunmap()
            relay_free_page_array() <void relay_free_page_array (struct page **array) at relay.c:82>:
                kvfree()
            kfree()
            kref_put()
            relay_destroy_channel() <void relay_destroy_channel (struct kref *kref) at relay.c:196>:
                container_of()
                kfree()
    list_add()
    mutex_unlock()
    for_each_possible_cpu()
    relay_close_buf() <void relay_close_buf (struct rchan_buf *buf) at relay.c:479>:
        del_timer_sync()
        kref_put()
        relay_remove_buf() <void relay_remove_buf (struct kref *kref) at relay.c:231>:
            container_of()
            relay_destroy_buf() <void relay_destroy_buf (struct rchan_buf *buf) at relay.c:206>:
                likely()
                vunmap()
                relay_free_page_array() <void relay_free_page_array (struct page **array) at relay.c:82>:
                    kvfree()
                kfree()
                kref_put()
                relay_destroy_channel() <void relay_destroy_channel (struct kref *kref) at relay.c:196>:
                    container_of()
                    kfree()
    kref_put()
    relay_destroy_channel() <void relay_destroy_channel (struct kref *kref) at relay.c:196>:
        container_of()
        kfree()
relay_reset() <void relay_reset (struct rchan *chan) at relay.c:383>:
    mutex_lock()
    for_each_possible_cpu()
    mutex_unlock()
relay_subbufs_consumed() <void relay_subbufs_consumed (struct rchan *chan, unsigned int cpu, size_t subbufs_consumed) at relay.c:785>:
relay_switch_subbuf() <size_t relay_switch_subbuf (struct rchan_buf *buf, size_t length) at relay.c:719>:
    unlikely()
    d_inode()
    smp_mb()
    waitqueue_active()
    mod_timer()
release_child_resources() <void release_child_resources (struct resource *r) at resource.c:278>:
    write_lock()
    write_unlock()
release_mem_region_adjustable() <int release_mem_region_adjustable (struct resource *parent, resource_size_t start, resource_size_t size) at resource.c:1180>:
    alloc_resource() <struct resource *alloc_resource (gfp_t flags) at resource.c:188>:
        spin_lock()
        spin_unlock()
        kzalloc()
    write_lock()
    free_resource() <void free_resource (struct resource *res) at resource.c:173>:
        PageSlab()
        virt_to_head_page()
        spin_lock()
        spin_unlock()
        kfree()
    write_unlock()
release_resource() <int release_resource (struct resource *old) at resource.c:323>:
    write_lock()
    write_unlock()
release_task() <void release_task (struct task_struct *p) at exit.c:167>:
    rcu_read_lock()
    atomic_dec()
    rcu_read_unlock()
    proc_flush_task()
    write_lock_irq()
    ptrace_release_task()
    thread_group_empty()
    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
        BUG_ON()
        task_is_stopped_or_traced()
        thread_group_empty()
        rcu_read_lock()
        task_pid_nr_ns()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                    smp_rmb()
        task_cred_xxx()
        task_uid()
        rcu_read_unlock()
        task_cputime()
        cputime_to_clock_t()
        spin_lock_irqsave()
        valid_signal()
        spin_unlock_irqrestore()
    write_unlock_irq()
    release_thread()
    call_rcu()
    delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
        container_of()
        perf_event_delayed_put()
        trace_sched_process_free()
        put_task_struct()
    unlikely()
request_dma() <int request_dma (unsigned int dmanr, const char *device_id) at dma.c:103>:
    xchg()
request_resource() <int request_resource (struct resource *root, struct resource *new) at resource.c:309>:
    request_resource_conflict() <struct resource *request_resource_conflict (struct resource *root, struct resource *new) at resource.c:292>:
        write_lock()
        write_unlock()
request_resource_conflict() <struct resource *request_resource_conflict (struct resource *root, struct resource *new) at resource.c:292>:
    write_lock()
    write_unlock()
reserve_region_with_split() <void __init reserve_region_with_split (struct resource *root, resource_size_t start, resource_size_t end, const char *name) at resource.c:993>:
    write_lock()
    pr_err()
    dump_stack()
    write_unlock()
reset_hung_task_detector() <void reset_hung_task_detector (void) at hung_task.c:216>:
    atomic_set()
resource_alignment() <resource_size_t resource_alignment (struct resource *res) at resource.c:1028>:
    resource_size()
resource_list_create_entry() <struct resource_entry *resource_list_create_entry (struct resource *res, size_t extra_size) at resource.c:1520>:
    kzalloc()
    INIT_LIST_HEAD()
resource_list_free() <void resource_list_free (struct list_head *head) at resource.c:1535>:
    list_for_each_entry_safe()
    resource_list_destroy_entry()
restore_altstack() <int restore_altstack (const stack_t __user *uss) at signal.c:3160>:
    do_sigaltstack() <int do_sigaltstack (const stack_t __user *uss, stack_t __user *uoss, unsigned long sp) at signal.c:3091>:
        sas_ss_flags()
        access_ok()
        on_sig_stack()
    current_user_stack_pointer()
revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
    kdebug()
    atomic_read()
    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
        atomic_read()
    validate_creds()
    alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
        atomic_add()
    rcu_assign_pointer()
    put_cred()
sanity_check_segment_list() <int sanity_check_segment_list (struct kimage *image) at kexec_core.c:146>:
save_stack_trace_regs() <__weak void save_stack_trace_regs (struct pt_regs *regs, struct stack_trace *trace) at stacktrace.c:72>:
    WARN_ONCE()
save_stack_trace_tsk() <__weak void save_stack_trace_tsk (struct task_struct *tsk, struct stack_trace *trace) at stacktrace.c:66>:
    WARN_ONCE()
schedule_on_each_cpu() <int schedule_on_each_cpu (work_func_t func) at workqueue.c:3037>:
    alloc_percpu()
    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
        might_sleep()
        cpuhp_lock_acquire_read()
        mutex_lock()
        atomic_inc()
        mutex_unlock()
    for_each_online_cpu()
    per_cpu_ptr()
    INIT_WORK()
    schedule_work_on()
    flush_work() <bool flush_work (struct work_struct *work) at workqueue.c:2841>:
        lock_map_acquire()
        lock_map_release()
        start_flush_work() <bool start_flush_work (struct work_struct *work, struct wq_barrier *barr) at workqueue.c:2779>:
            might_sleep()
            local_irq_disable()
            get_work_pool() <struct worker_pool *get_work_pool (struct work_struct *work) at workqueue.c:703>:
                atomic_long_read()
                assert_rcu_or_pool_mutex()
                idr_find()
            local_irq_enable()
            spin_lock()
            get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                atomic_long_read()
            unlikely()
            find_worker_executing_work() <struct worker *find_worker_executing_work (struct worker_pool *pool, struct work_struct *work) at workqueue.c:996>:
                hash_for_each_possible()
            check_flush_dependency() <void check_flush_dependency (struct workqueue_struct *target_wq, struct work_struct *target_work) at workqueue.c:2403>:
                current_wq_worker()
                WARN_ONCE()
            insert_wq_barrier() <void insert_wq_barrier (struct pool_workqueue *pwq, struct wq_barrier *barr, struct work_struct *target, struct worker *worker) at workqueue.c:2460>:
                INIT_WORK_ONSTACK()
                wq_barrier_func() <void wq_barrier_func (struct work_struct *work) at workqueue.c:2430>:
                    container_of()
                    complete()
                work_data_bits()
                init_completion()
                debug_work_activate() <inline void debug_work_activate (struct work_struct *work) at workqueue.c:547>:
                    debug_object_activate()
                insert_work() <void insert_work (struct pool_workqueue *pwq, struct work_struct *work, struct list_head *head, unsigned int extra_flags) at workqueue.c:1290>:
                    set_work_pwq() <void set_work_pwq (struct work_struct *work, struct pool_workqueue *pwq, unsigned long extra_flags) at workqueue.c:645>:
                        set_work_data() <inline void set_work_data (struct work_struct *work, unsigned long data, unsigned long flags) at workqueue.c:638>:
                            WARN_ON_ONCE()
                            work_pending()
                            atomic_long_set()
                            work_static()
                    list_add_tail()
                    get_pwq() <void get_pwq (struct pool_workqueue *pwq) at workqueue.c:1058>:
                        lockdep_assert_held()
                        WARN_ON_ONCE()
                    smp_mb()
                    wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
                        first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                            unlikely()
                            list_empty()
                            list_first_entry()
                        likely()
                        wake_up_process()
                work_color_to_flags() <unsigned int work_color_to_flags (int color) at workqueue.c:602>:
            spin_unlock_irq()
            lock_map_acquire()
            lock_map_acquire_read()
            lock_map_release()
        wait_for_completion()
        destroy_work_on_stack() <void destroy_work_on_stack (struct work_struct *work) at workqueue.c:533>:
            debug_object_free()
    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
        atomic_dec_return()
        WARN_ON()
        atomic_inc()
        waitqueue_active()
        wake_up()
        cpuhp_lock_release()
    free_percpu()
search_exception_tables() <const struct exception_table_entry *search_exception_tables (unsigned long addr) at extable.c:51>:
    search_extable()
    search_module_extables() <const struct exception_table_entry *search_module_extables (unsigned long addr) at module.c:3975>:
        preempt_disable()
        list_for_each_entry_rcu()
        search_extable()
        preempt_enable()
search_module_extables() <const struct exception_table_entry *search_module_extables (unsigned long addr) at module.c:3975>:
    preempt_disable()
    list_for_each_entry_rcu()
    search_extable()
    preempt_enable()
seccomp_get_filter() <long seccomp_get_filter (struct task_struct *task, unsigned long filter_off, void __user *data) at seccomp.c:873>:
    capable() <bool capable (int cap) at capability.c:401>:
        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
            unlikely()
            cap_valid()
            pr_crit()
            BUG()
            security_capable()
            current_cred()
    spin_lock_irq()
    WARN_ON()
    get_seccomp_filter() <void get_seccomp_filter (struct task_struct *tsk) at seccomp.c:461>:
        atomic_inc()
    spin_unlock_irq()
    copy_to_user()
    bpf_classic_proglen()
    put_seccomp_filter() <void put_seccomp_filter (struct task_struct *tsk) at seccomp.c:479>:
        atomic_dec_and_test()
        seccomp_filter_free() <inline void seccomp_filter_free (struct seccomp_filter *filter) at seccomp.c:470>:
            bpf_prog_destroy()
            kfree()
seccomp_phase1() <u32 seccomp_phase1 (struct seccomp_data *sd) at seccomp.c:651>:
    syscall_get_nr()
    task_pt_regs()
    config_enabled()
    unlikely()
    BUG()
seccomp_phase2() <int seccomp_phase2 (u32 phase1_result) at seccomp.c:682>:
    task_pt_regs()
    BUG_ON()
    audit_seccomp()
    syscall_get_nr()
    ptrace_event_enabled()
    syscall_set_return_value()
    ptrace_event()
    fatal_signal_pending()
    do_exit() <void do_exit (long code) at exit.c:651>:
        TASKS_RCU()
        profile_task_exit() <void profile_task_exit (struct task_struct *task) at profile.c:137>:
            blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
        WARN_ON()
        blk_needs_flush_plug()
        unlikely()
        in_interrupt()
        panic() <void panic (const char *fmt, ...) at panic.c:83>:
            local_irq_disable()
            raw_smp_processor_id()
            atomic_cmpxchg()
            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                cpu_relax()
            console_verbose()
            bust_spinlocks()
            pr_emerg()
            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                test_bit()
            dump_stack()
            smp_send_stop()
            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
            kmsg_dump()
            debug_locks_off()
            console_flush_on_panic()
            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
            no_blink() <long no_blink (int state) at panic.c:46>
            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                raw_cpu_write()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            mdelay()
            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                kmsg_dump()
                machine_emergency_restart()
            disabled_wait()
            local_irq_enable()
            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                    raw_cpu_write()
                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                    per_cpu()
                raw_smp_processor_id()
        set_fs()
        ptrace_event()
        validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
        pr_alert()
        set_current_state()
        schedule()
        exit_signals() <void exit_signals (struct task_struct *tsk) at signal.c:2383>:
            threadgroup_change_begin()
            thread_group_empty()
            signal_group_exit()
            threadgroup_change_end()
            spin_lock_irq()
            signal_pending()
            signotset()
            retarget_shared_pending() <void retarget_shared_pending (struct task_struct *tsk, sigset_t *which) at signal.c:2356>:
                sigandsets()
                sigisemptyset()
                while_each_thread()
                has_pending_signals() <inline int has_pending_signals (sigset_t *signal, sigset_t *blocked) at signal.c:104>:
                signal_pending()
                signal_wake_up()
            unlikely()
            task_participate_group_stop() <bool task_participate_group_stop (struct task_struct *task) at signal.c:329>:
                WARN_ON_ONCE()
                task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
                    BUG_ON()
                    task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                        unlikely()
                        smp_mb()
                        wake_up_bit()
            spin_unlock_irq()
            read_lock()
            do_notify_parent_cldstop() <void do_notify_parent_cldstop (struct task_struct *tsk, bool for_ptracer, int why) at signal.c:1675>:
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                BUG()
                spin_lock_irqsave()
                spin_unlock_irqrestore()
            read_unlock()
        smp_mb()
        raw_spin_unlock_wait()
        in_atomic()
        pr_info()
        task_pid_nr()
        preempt_count()
        preempt_count_set()
        sync_mm_rss()
        acct_update_integrals() <void acct_update_integrals (struct task_struct *tsk) at tsacct.c:153>:
            task_cputime()
        atomic_dec_and_test()
        hrtimer_cancel()
        exit_itimers()
        setmax_mm_hiwater_rss()
        acct_collect() <void acct_collect (long exitcode, int group_dead) at acct.c:530>:
            down_read()
            up_read()
            spin_lock_irq()
            thread_group_leader()
            task_cputime()
            spin_unlock_irq()
        tty_audit_exit()
        audit_free()
        taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
            taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
                nla_total_size()
            taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
                thread_group_empty()
                kmem_cache_zalloc()
                spin_lock_irq()
                spin_unlock_irq()
                kmem_cache_free()
            fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
                spin_lock_irqsave()
                delayacct_add_tsk()
                spin_unlock_irqrestore()
            raw_cpu_ptr()
            list_empty()
            prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
                genlmsg_new()
                this_cpu_inc_return()
                genlmsg_put()
                genlmsg_put_reply()
                nlmsg_free()
            mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
                nla_put()
                nla_nest_start()
                nla_nest_cancel()
                nla_reserve()
                nla_nest_end()
                nla_data()
            task_pid_nr_ns()
            fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
                delayacct_add_tsk()
                bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
                    BUILD_BUG_ON()
                    ktime_get_ns()
                    do_div()
                    get_seconds()
                    thread_group_leader()
                    task_nice()
                    task_pid_nr_ns()
                    rcu_read_lock()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    pid_alive()
                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                        task_tgid()
                    rcu_dereference()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_usecs()
                    task_cputime_scaled()
                xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
                    get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                        task_lock()
                        atomic_inc()
                        task_unlock()
                    get_mm_hiwater_rss()
                    get_mm_hiwater_vm()
                    mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                        might_sleep()
                        atomic_dec_and_test()
                        uprobe_clear_state()
                        exit_aio()
                        ksm_exit()
                        khugepaged_exit()
                        exit_mmap()
                        set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                            rcu_dereference_raw()
                            get_file()
                            rcu_assign_pointer()
                            fput()
                        list_empty()
                        spin_lock()
                        list_del()
                        spin_unlock()
                        module_put() <void module_put (struct module *module) at module.c:1098>:
                            preempt_disable()
                            atomic_dec_if_positive()
                            WARN_ON()
                            trace_module_put()
                            preempt_enable()
                        mmdrop()
            task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                task_tgid()
            send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
                nlmsg_data()
                nlmsg_hdr()
                genlmsg_data()
                genlmsg_end()
                down_read()
                list_for_each_entry()
                list_is_last()
                skb_clone()
                genlmsg_unicast()
                up_read()
                nlmsg_free()
                down_write()
                list_for_each_entry_safe()
                list_del()
                kfree()
                up_write()
            nlmsg_free()
        exit_mm() <void exit_mm (struct task_struct *tsk) at exit.c:385>:
            mm_release() <void mm_release (struct task_struct *tsk, struct mm_struct *mm) at fork.c:856>:
                unlikely()
                exit_robust_list() <void exit_robust_list (struct task_struct *curr) at futex.c:2978>:
                    uninitialized_var()
                    fetch_robust_entry() <inline int fetch_robust_entry (struct robust_list __user **entry, struct robust_list __user *__user *head, unsigned int *pi) at futex.c:2957>:
                        get_user()
                    get_user()
                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                        uninitialized_var()
                        get_user()
                        task_pid_vnr()
                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                            pagefault_disable()
                            futex_atomic_cmpxchg_inatomic()
                            pagefault_enable()
                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                            down_read()
                            fixup_user_fault()
                            up_read()
                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                            WAKE_Q()
                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                unlikely()
                                access_ok()
                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                    should_fail()
                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                    ihold()
                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                        atomic_inc()
                                        smp_mb__after_atomic()
                                    smp_mb()
                                get_user_pages_fast()
                                lock_page()
                                compound_head()
                                PageSwapCache()
                                unlock_page()
                                put_page()
                                PageAnon()
                                basepage_index()
                            unlikely()
                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                jhash2()
                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                atomic_read()
                            spin_lock()
                            plist_for_each_entry_safe()
                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                WARN()
                                wake_q_add()
                                smp_wmb()
                            spin_unlock()
                            wake_up_q()
                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                    WARN_ON_ONCE()
                                    iput()
                                    mmdrop()
                    cond_resched()
                compat_exit_robust_list() <void compat_exit_robust_list (struct task_struct *curr) at futex_compat.c:50>:
                    uninitialized_var()
                    fetch_robust_entry() <inline int fetch_robust_entry (compat_uptr_t *uentry, struct robust_list __user **entry, compat_uptr_t __user *head, unsigned int *pi) at futex_compat.c:23>:
                        get_user()
                        compat_ptr()
                    get_user()
                    futex_uaddr() <void __user *futex_uaddr (struct robust_list __user *entry, compat_long_t futex_offset) at futex_compat.c:35>:
                        ptr_to_compat()
                        compat_ptr()
                    handle_futex_death() <int handle_futex_death (u32 __user *uaddr, struct task_struct *curr, int pi) at futex.c:2907>:
                        uninitialized_var()
                        get_user()
                        task_pid_vnr()
                        cmpxchg_futex_value_locked() <int cmpxchg_futex_value_locked (u32 *curval, u32 __user *uaddr, u32 uval, u32 newval) at futex.c:632>:
                            pagefault_disable()
                            futex_atomic_cmpxchg_inatomic()
                            pagefault_enable()
                        fault_in_user_writeable() <int fault_in_user_writeable (u32 __user *uaddr) at futex.c:600>:
                            down_read()
                            fixup_user_fault()
                            up_read()
                        futex_wake() <int futex_wake (u32 __user *uaddr, unsigned int flags, int nr_wake, u32 bitset) at futex.c:1281>:
                            WAKE_Q()
                            get_futex_key() <int get_futex_key (u32 __user *uaddr, int fshared, union futex_key *key, int rw) at futex.c:468>:
                                unlikely()
                                access_ok()
                                should_fail_futex() <inline bool should_fail_futex (bool fshared) at futex.c:325>:
                                    should_fail()
                                get_futex_key_refs() <void get_futex_key_refs (union futex_key *key) at futex.c:403>:
                                    ihold()
                                    futex_get_mm() <inline void futex_get_mm (union futex_key *key) at futex.c:331>:
                                        atomic_inc()
                                        smp_mb__after_atomic()
                                    smp_mb()
                                get_user_pages_fast()
                                lock_page()
                                compound_head()
                                PageSwapCache()
                                unlock_page()
                                put_page()
                                PageAnon()
                                basepage_index()
                            unlikely()
                            hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                                jhash2()
                            hb_waiters_pending() <inline int hb_waiters_pending (struct futex_hash_bucket *hb) at futex.c:367>:
                                atomic_read()
                            spin_lock()
                            plist_for_each_entry_safe()
                            match_futex() <inline int match_futex (union futex_key *key1, union futex_key *key2) at futex.c:390>:
                            mark_wake_futex() <void mark_wake_futex (struct wake_q_head *wake_q, struct futex_q *q) at futex.c:1151>:
                                WARN()
                                wake_q_add()
                                smp_wmb()
                            spin_unlock()
                            wake_up_q()
                            put_futex_key() <inline void put_futex_key (union futex_key *key) at futex.c:583>:
                                drop_futex_key_refs() <void drop_futex_key_refs (union futex_key *key) at futex.c:431>:
                                    WARN_ON_ONCE()
                                    iput()
                                    mmdrop()
                    cond_resched()
                list_empty()
                exit_pi_state_list() <void exit_pi_state_list (struct task_struct *curr) at futex.c:755>:
                    raw_spin_lock_irq()
                    list_empty()
                    list_entry()
                    hash_futex() <struct futex_hash_bucket *hash_futex (union futex_key *key) at futex.c:379>:
                        jhash2()
                    raw_spin_unlock_irq()
                    spin_lock()
                    spin_unlock()
                    WARN_ON()
                    list_del_init()
                    rt_mutex_unlock()
                uprobe_free_utask()
                deactivate_mm()
                atomic_read()
                put_user()
                sys_futex()
                complete_vfork_done() <void complete_vfork_done (struct task_struct *tsk) at fork.c:811>:
                    task_lock()
                    likely()
                    complete()
                    task_unlock()
            sync_mm_rss()
            down_read()
            up_read()
            xchg()
            atomic_dec_and_test()
            complete()
            set_task_state()
            freezable_schedule()
            atomic_inc()
            BUG_ON()
            task_lock()
            enter_lazy_tlb()
            task_unlock()
            mm_update_next_owner() <void mm_update_next_owner (struct mm_struct *mm) at exit.c:297>:
                atomic_read()
                read_lock()
                list_for_each_entry()
                for_each_process()
                for_each_thread()
                read_unlock()
                BUG_ON()
                get_task_struct()
                task_lock()
                task_unlock()
                put_task_struct()
            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                might_sleep()
                atomic_dec_and_test()
                uprobe_clear_state()
                exit_aio()
                ksm_exit()
                khugepaged_exit()
                exit_mmap()
                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                    rcu_dereference_raw()
                    get_file()
                    rcu_assign_pointer()
                    fput()
                list_empty()
                spin_lock()
                list_del()
                spin_unlock()
                module_put() <void module_put (struct module *module) at module.c:1098>:
                    preempt_disable()
                    atomic_dec_if_positive()
                    WARN_ON()
                    trace_module_put()
                    preempt_enable()
                mmdrop()
            test_thread_flag()
            exit_oom_victim()
        acct_process() <void acct_process (void) at acct.c:587>:
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
            unlikely()
            slow_acct_process() <void slow_acct_process (struct pid_namespace *ns) at acct.c:570>:
                acct_get() <struct bsd_acct_struct *acct_get (struct pid_namespace *ns) at acct.c:141>:
                    smp_rmb()
                    rcu_read_lock()
                    to_acct() <inline struct bsd_acct_struct *to_acct (struct fs_pin *p) at acct.c:136>:
                        container_of()
                    ACCESS_ONCE()
                    rcu_read_unlock()
                    atomic_long_inc_not_zero()
                    cpu_relax()
                    mutex_lock()
                    mutex_unlock()
                    acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                        atomic_long_dec_and_test()
                        kfree_rcu()
                do_acct_process() <void do_acct_process (struct bsd_acct_struct *acct) at acct.c:468>:
                    override_creds() <const struct cred *override_creds (const struct cred *new) at cred.c:520>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        validate_creds()
                        get_cred()
                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                            atomic_add()
                        rcu_assign_pointer()
                    check_free_space() <int check_free_space (struct bsd_acct_struct *acct) at acct.c:98>:
                        time_is_before_jiffies()
                        vfs_statfs()
                        do_div()
                        pr_info()
                    fill_ac() <void fill_ac (acct_t *ac) at acct.c:412>:
                        strlcpy()
                        ktime_get_ns()
                        nsec_to_AHZ()
                        encode_float() <u32 encode_float (u64 value) at acct.c:387>:
                        encode_comp_t() <comp_t encode_comp_t (unsigned long value) at acct.c:312>:
                        encode_comp2_t() <comp2_t encode_comp2_t (u64 value) at acct.c:354>:
                        do_div()
                        get_seconds()
                        spin_lock_irq()
                        old_encode_dev()
                        tty_devnum()
                        jiffies_to_AHZ()
                        cputime_to_jiffies()
                        spin_unlock_irq()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                        from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                        task_tgid()
                    rcu_read_lock()
                    rcu_dereference()
                    rcu_read_unlock()
                    file_start_write_trylock()
                    file_end_write()
                    revert_creds() <void revert_creds (const struct cred *old) at cred.c:549>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        validate_creds()
                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                            atomic_add()
                        rcu_assign_pointer()
                        put_cred()
                mutex_unlock()
                acct_put() <void acct_put (struct bsd_acct_struct *p) at acct.c:130>:
                    atomic_long_dec_and_test()
                    kfree_rcu()
        trace_sched_process_exit()
        exit_sem()
        exit_shm()
        exit_files()
        exit_fs()
        disassociate_ctty()
        exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
            switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                might_sleep()
                task_lock()
                task_unlock()
                atomic_dec_and_test()
                free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                    put_mnt_ns()
                    put_uts_ns()
                    put_ipc_ns()
                    put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                        kref_put()
                        free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                            container_of()
                            destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                ns_free_inum()
                                kfree()
                                put_user_ns()
                                call_rcu()
                                delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                    kmem_cache_free()
                                    container_of()
                    put_net()
                    kmem_cache_free()
        exit_task_work()
        exit_thread()
        perf_event_exit_task()
        cgroup_exit() <void cgroup_exit (struct task_struct *tsk) at cgroup.c:5628>:
            task_css_set()
            list_empty()
            spin_lock_bh()
            css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                lockdep_assert_held()
                WARN_ON_ONCE()
                list_empty()
                list_for_each_entry_safe()
                css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                    lockdep_assert_held()
                    WARN_ON_ONCE()
                    css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                        lockdep_assert_held()
                        container_of()
                        list_entry()
                        css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                            lockdep_assert_held()
                            list_empty()
                        list_empty()
                        list_del()
                        put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                            lockdep_assert_held()
                            atomic_dec_and_test()
                            for_each_subsys()
                            list_del()
                            css_put()
                            hash_del()
                            list_for_each_entry_safe()
                            cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                container_of()
                            cgroup_put()
                            kfree()
                            kfree_rcu()
                        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                            atomic_inc()
                        list_add()
                list_del_init()
                css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                    lockdep_assert_held()
                    list_empty()
                css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                    lockdep_assert_held()
                    list_for_each_entry()
                    cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                        lockdep_assert_held()
                        check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                            notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                test_bit()
                            cgroup_is_populated()
                            css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                rcu_read_lock()
                                css_for_each_child()
                                rcu_read_unlock()
                            cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                            schedule_work()
                        cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                            spin_lock_irqsave()
                            kernfs_notify()
                            spin_unlock_irqrestore()
                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                            container_of()
                rcu_assign_pointer()
                list_add_tail()
            spin_unlock_bh()
            get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                atomic_inc()
            for_each_subsys_which()
        flush_ptrace_hw_breakpoint()
        preempt_disable()
        preempt_enable()
        exit_notify() <void exit_notify (struct task_struct *tsk, int group_dead) at exit.c:587>:
            LIST_HEAD()
            write_lock_irq()
            forget_original_parent() <void forget_original_parent (struct task_struct *father, struct list_head *dead) at exit.c:549>:
                unlikely()
                list_empty()
                exit_ptrace() <void exit_ptrace (struct task_struct *tracer, struct list_head *dead) at ptrace.c:518>:
                    list_for_each_entry_safe()
                    unlikely()
                    send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
                        valid_signal()
                        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                            lock_task_sighand()
                            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                    SI_FROMUSER()
                                task_pid_nr_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                            unlock_task_sighand()
                    list_add()
                find_child_reaper()
                find_new_reaper() <struct task_struct *find_new_reaper (struct task_struct *father, struct task_struct *child_reaper) at exit.c:485>:
                    find_alive_thread() <struct task_struct *find_alive_thread (struct task_struct *p) at exit.c:440>:
                        for_each_thread()
                    same_thread_group()
                list_for_each_entry()
                for_each_thread()
                BUG_ON()
                likely()
                group_send_sig_info() <int group_send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1254>:
                    rcu_read_lock()
                    check_kill_permission() <int check_kill_permission (int sig, struct siginfo *info, struct task_struct *t) at signal.c:713>:
                        valid_signal()
                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                            SI_FROMUSER()
                        audit_signal_info()
                        same_thread_group()
                        kill_ok_by_cred() <int kill_ok_by_cred (struct task_struct *t) at signal.c:692>:
                            current_cred()
                            uid_eq()
                            ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                                unlikely()
                                cap_valid()
                                pr_crit()
                                BUG()
                                security_capable()
                                current_cred()
                        task_session()
                        security_task_kill()
                    rcu_read_unlock()
                    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
                        lock_task_sighand()
                        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                                SI_FROMUSER()
                            task_pid_nr_ns()
                            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                ns_of_pid()
                                task_pid()
                        unlock_task_sighand()
                same_thread_group()
                reparent_leader() <void reparent_leader (struct task_struct *father, struct task_struct *p, struct list_head *dead) at exit.c:520>:
                    unlikely()
                    thread_group_empty()
                    do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                        BUG_ON()
                        task_is_stopped_or_traced()
                        thread_group_empty()
                        rcu_read_lock()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                        from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                            from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                                map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                    smp_rmb()
                        task_cred_xxx()
                        task_uid()
                        rcu_read_unlock()
                        task_cputime()
                        cputime_to_clock_t()
                        spin_lock_irqsave()
                        valid_signal()
                        spin_unlock_irqrestore()
                    list_add()
                    kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                        task_pgrp()
                        task_session()
                        will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                            do_each_pid_task()
                            thread_group_empty()
                            is_global_init()
                            task_pgrp()
                            task_session()
                            while_each_pid_task()
                        has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                            do_each_pid_task()
                            while_each_pid_task()
                list_splice_tail_init()
            kill_orphaned_pgrp() <void kill_orphaned_pgrp (struct task_struct *tsk, struct task_struct *parent) at exit.c:268>:
                task_pgrp()
                task_session()
                will_become_orphaned_pgrp() <int will_become_orphaned_pgrp (struct pid *pgrp, struct task_struct *ignored_task) at exit.c:220>:
                    do_each_pid_task()
                    thread_group_empty()
                    is_global_init()
                    task_pgrp()
                    task_session()
                    while_each_pid_task()
                has_stopped_jobs() <bool has_stopped_jobs (struct pid *pgrp) at exit.c:250>:
                    do_each_pid_task()
                    while_each_pid_task()
            unlikely()
            thread_group_leader()
            thread_group_empty()
            ptrace_reparented()
            do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                BUG_ON()
                task_is_stopped_or_traced()
                thread_group_empty()
                rcu_read_lock()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
                from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                    from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                        map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                            smp_rmb()
                task_cred_xxx()
                task_uid()
                rcu_read_unlock()
                task_cputime()
                cputime_to_clock_t()
                spin_lock_irqsave()
                valid_signal()
                spin_unlock_irqrestore()
            list_add()
            wake_up_process()
            write_unlock_irq()
            list_for_each_entry_safe()
            list_del_init()
            release_task() <void release_task (struct task_struct *p) at exit.c:167>:
                rcu_read_lock()
                atomic_dec()
                rcu_read_unlock()
                proc_flush_task()
                write_lock_irq()
                ptrace_release_task()
                thread_group_empty()
                do_notify_parent() <bool do_notify_parent (struct task_struct *tsk, int sig) at signal.c:1572>:
                    BUG_ON()
                    task_is_stopped_or_traced()
                    thread_group_empty()
                    rcu_read_lock()
                    task_pid_nr_ns()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                        from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                            map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                                smp_rmb()
                    task_cred_xxx()
                    task_uid()
                    rcu_read_unlock()
                    task_cputime()
                    cputime_to_clock_t()
                    spin_lock_irqsave()
                    valid_signal()
                    spin_unlock_irqrestore()
                write_unlock_irq()
                release_thread()
                call_rcu()
                delayed_put_task_struct() <void delayed_put_task_struct (struct rcu_head *rhp) at exit.c:157>:
                    container_of()
                    perf_event_delayed_put()
                    trace_sched_process_free()
                    put_task_struct()
                unlikely()
        proc_exit_connector()
        task_lock()
        mpol_put()
        task_unlock()
        kfree()
        debug_check_no_locks_held()
        exit_io_context()
        free_pipe_info()
        put_page()
        check_stack_usage() <inline void check_stack_usage (void) at exit.c:648>:
            stack_not_used()
            spin_lock()
            pr_warn()
            task_pid_nr()
            spin_unlock()
        exit_rcu()
        BUG()
        cpu_relax()
secure_computing_strict() <void secure_computing_strict (int this_syscall) at seccomp.c:548>:
    config_enabled()
    unlikely()
    BUG()
send_sig() <int send_sig (int sig, struct task_struct *p, int priv) at signal.c:1429>:
    send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
        valid_signal()
        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
            lock_task_sighand()
            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                    SI_FROMUSER()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
            unlock_task_sighand()
send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
    valid_signal()
    do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
        lock_task_sighand()
        send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
            si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                SI_FROMUSER()
            task_pid_nr_ns()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
        unlock_task_sighand()
send_sigqueue() <int send_sigqueue (struct sigqueue *q, struct task_struct *t, int group) at signal.c:1521>:
    BUG_ON()
    likely()
    lock_task_sighand()
    prepare_signal() <bool prepare_signal (int sig, struct task_struct *p, bool force) at signal.c:784>:
        flush()
        sig_kernel_stop()
        siginitset()
        flush_sigqueue_mask() <int flush_sigqueue_mask (sigset_t *mask, struct sigpending *s) at signal.c:659>:
            sigandsets()
            sigisemptyset()
            sigandnsets()
            list_for_each_entry_safe()
            list_del_init()
        for_each_thread()
        task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
            BUG_ON()
            task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                unlikely()
                smp_mb()
                wake_up_bit()
        likely()
        wake_up_state()
        ptrace_trap_notify() <void ptrace_trap_notify (struct task_struct *t) at signal.c:765>:
            WARN_ON_ONCE()
            assert_spin_locked()
            task_set_jobctl_pending() <bool task_set_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:248>:
                BUG_ON()
                unlikely()
                fatal_signal_pending()
            ptrace_signal_wake_up()
        sig_ignored() <int sig_ignored (struct task_struct *t, int sig, bool force) at signal.c:81>:
            sig_task_ignored() <int sig_task_ignored (struct task_struct *t, int sig, bool force) at signal.c:68>:
                sig_handler() <void __user *sig_handler (struct task_struct *t, int sig) at signal.c:56>:
                unlikely()
                sig_handler_ignored() <int sig_handler_ignored (void __user *handler, int sig) at signal.c:61>:
                    sig_kernel_ignore()
    unlikely()
    list_empty()
    signalfd_notify()
    list_add_tail()
    complete_signal() <void complete_signal (int sig, struct task_struct *p, int group) at signal.c:870>:
        wants_signal() <inline int wants_signal (int sig, struct task_struct *p) at signal.c:857>:
            task_is_stopped_or_traced()
            task_curr()
            signal_pending()
        thread_group_empty()
        next_thread()
        sig_fatal()
        sig_kernel_coredump()
        task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
            BUG_ON()
            task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
                unlikely()
                smp_mb()
                wake_up_bit()
        signal_wake_up()
        while_each_thread()
    trace_signal_generate()
    unlock_task_sighand()
set_all_modules_text_ro() <void set_all_modules_text_ro (void) at module.c:1945>:
    mutex_lock()
    list_for_each_entry_rcu()
    frob_text() <void frob_text (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1866>:
        BUG_ON()
    mutex_unlock()
set_all_modules_text_rw() <void set_all_modules_text_rw (void) at module.c:1929>:
    mutex_lock()
    list_for_each_entry_rcu()
    frob_text() <void frob_text (const struct module_layout *layout, int (*set_memory) (unsigned long start, int num_pages)) at module.c:1866>:
        BUG_ON()
    mutex_unlock()
set_create_files_as() <int set_create_files_as (struct cred *new, struct inode *inode) at cred.c:690>:
    security_kernel_create_files_as()
set_current_blocked() <void set_current_blocked (sigset_t *newset) at signal.c:2478>:
    sigdelsetmask()
set_current_groups() <int set_current_groups (struct group_info *group_info) at groups.c:176>:
    prepare_creds() <struct cred *prepare_creds (void) at cred.c:243>:
        validate_process_creds()
        kmem_cache_alloc()
        kdebug()
        atomic_set()
        set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
            atomic_set()
        get_group_info()
        get_uid()
        get_user_ns()
        key_get()
        security_prepare_creds()
        validate_creds()
        abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
            BUG_ON()
            put_cred()
    set_groups() <void set_groups (struct cred *new, struct group_info *group_info) at groups.c:159>:
        put_group_info()
        groups_sort() <void groups_sort (struct group_info *group_info) at groups.c:104>:
            GROUP_AT()
            gid_gt()
        get_group_info()
    commit_creds() <int commit_creds (struct cred *new) at cred.c:422>:
        kdebug()
        atomic_read()
        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
            atomic_read()
        BUG_ON()
        validate_creds()
        get_cred()
        uid_eq()
        gid_eq()
        cred_cap_issubset() <bool cred_cap_issubset (const struct cred *set, const struct cred *subset) at cred.c:383>:
            cap_issubset()
            uid_eq()
        set_dumpable()
        smp_wmb()
        key_fsuid_changed()
        key_fsgid_changed()
        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
            atomic_add()
        atomic_inc()
        rcu_assign_pointer()
        atomic_dec()
        proc_id_connector()
        put_cred()
set_freezable() <bool set_freezable (void) at freezer.c:164>:
    might_sleep()
    spin_lock_irq()
    spin_unlock_irq()
    try_to_freeze()
set_groups() <void set_groups (struct cred *new, struct group_info *group_info) at groups.c:159>:
    put_group_info()
    groups_sort() <void groups_sort (struct group_info *group_info) at groups.c:104>:
        GROUP_AT()
        gid_gt()
    get_group_info()
set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
    rcu_dereference_raw()
    get_file()
    rcu_assign_pointer()
    fput()
set_security_override() <int set_security_override (struct cred *new, u32 secid) at cred.c:652>:
    security_kernel_act_as()
set_security_override_from_ctx() <int set_security_override_from_ctx (struct cred *new, const char *secctx) at cred.c:668>:
    security_secctx_to_secid()
    set_security_override() <int set_security_override (struct cred *new, u32 secid) at cred.c:652>:
        security_kernel_act_as()
set_task_stack_end_magic() <void set_task_stack_end_magic (struct task_struct *tsk) at fork.c:326>:
    end_of_stack()
set_worker_desc() <void set_worker_desc (const char *fmt, ...) at workqueue.c:4208>:
    current_wq_worker()
setup_nr_cpu_ids() <void __init setup_nr_cpu_ids (void) at smp.c:556>:
    find_last_bit()
    cpumask_bits()
show_workqueue_state() <void show_workqueue_state (void) at workqueue.c:4374>:
    rcu_read_lock_sched()
    pr_info()
    list_for_each_entry_rcu()
    for_each_pwq()
    list_empty()
    spin_lock_irqsave()
    show_pwq() <void show_pwq (struct pool_workqueue *pwq) at workqueue.c:4297>:
        pr_info()
        pr_cont_pool_info() <void pr_cont_pool_info (struct worker_pool *pool) at workqueue.c:4275>:
            pr_cont()
        pr_cont()
        list_empty()
        hash_for_each()
        task_pid_nr()
        list_for_each_entry()
        pr_cont_work() <void pr_cont_work (bool comma, struct work_struct *work) at workqueue.c:4283>:
            wq_barrier_func() <void wq_barrier_func (struct work_struct *work) at workqueue.c:2430>:
                container_of()
                complete()
            container_of()
            pr_cont()
            task_pid_nr()
        get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
            atomic_long_read()
        work_data_bits()
    spin_unlock_irqrestore()
    for_each_pool()
    pr_cont_pool_info() <void pr_cont_pool_info (struct worker_pool *pool) at workqueue.c:4275>:
        pr_cont()
    pr_cont()
    jiffies_to_msecs()
    task_pid_nr()
    list_for_each_entry()
    rcu_read_unlock_sched()
signal_setup_done() <void signal_setup_done (int failed, struct ksignal *ksig, int stepping) at signal.c:2343>:
    force_sigsegv() <int force_sigsegv (int sig, struct task_struct *p) at signal.c:1447>:
        spin_lock_irqsave()
        spin_unlock_irqrestore()
        force_sig() <void force_sig (int sig, struct task_struct *p) at signal.c:1435>:
            force_sig_info() <int force_sig_info (int sig, struct siginfo *info, struct task_struct *t) at signal.c:1160>:
                spin_lock_irqsave()
                recalc_sigpending_and_wake() <void recalc_sigpending_and_wake (struct task_struct *t) at signal.c:152>:
                    recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                        PENDING()
                        set_tsk_thread_flag()
                    signal_wake_up()
                specific_send_sig_info() <int specific_send_sig_info (int sig, struct siginfo *info, struct task_struct *t) at signal.c:1129>:
                    send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                        si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                            is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                            SI_FROMUSER()
                        task_pid_nr_ns()
                        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                            ns_of_pid()
                            task_pid()
                spin_unlock_irqrestore()
    signal_delivered() <void signal_delivered (struct ksignal *ksig, int stepping) at signal.c:2326>:
        clear_restore_sigmask()
        sigorsets()
        set_current_blocked() <void set_current_blocked (sigset_t *newset) at signal.c:2478>:
            sigdelsetmask()
        tracehook_signal_handler()
signal_wake_up_state() <void signal_wake_up_state (struct task_struct *t, unsigned int state) at signal.c:639>:
    set_tsk_thread_flag()
    wake_up_state()
    kick_process()
signals_init() <void __init signals_init (void) at signal.c:3582>:
    KMEM_CACHE()
sigprocmask() <int sigprocmask (int how, sigset_t *set, sigset_t *oldset) at signal.c:2501>:
    sigorsets()
    sigandnsets()
sigqueue_alloc() <struct sigqueue *sigqueue_alloc (void) at signal.c:1486>:
sigqueue_free() <void sigqueue_free (struct sigqueue *q) at signal.c:1496>:
    BUG_ON()
    spin_lock_irqsave()
    list_empty()
    spin_unlock_irqrestore()
sigset_from_compat() <void sigset_from_compat (sigset_t *set, const compat_sigset_t *compat) at compat.c:974>:
sigset_to_compat() <void sigset_to_compat (compat_sigset_t *compat, const sigset_t *set) at compat.c:986>:
smp_announce() <void __weak smp_announce (void) at smp.c:561>:
    printk()
    num_online_cpus()
smp_call_function() <int smp_call_function (smp_call_func_t func, void *info, int wait) at smp.c:488>:
    preempt_disable()
    smp_call_function_many() <void smp_call_function_many (const struct cpumask *mask, smp_call_func_t func, void *info, bool wait) at smp.c:404>:
        smp_processor_id()
        WARN_ON_ONCE()
        cpu_online()
        irqs_disabled()
        cpumask_first_and()
        cpumask_next_and()
        smp_call_function_single() <int smp_call_function_single (int cpu, void (*func) (void *info), void *info, int wait) at up.c:10>:
            get_cpu()
            WARN_ON_ONCE()
            cpu_online()
            irqs_disabled()
            this_cpu_ptr()
            csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
                csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                    smp_load_acquire()
                    cpu_relax()
                smp_wmb()
            generic_exec_single() <int generic_exec_single (int cpu, struct call_single_data *csd, smp_call_func_t func, void *info) at smp.c:144>:
                smp_processor_id()
                csd_unlock() <void csd_unlock (struct call_single_data *csd) at smp.c:127>:
                    WARN_ON()
                    smp_store_release()
                local_irq_save()
                local_irq_restore()
                cpu_online()
                llist_add()
                per_cpu()
                arch_send_call_function_single_ipi()
            csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                smp_load_acquire()
                cpu_relax()
            put_cpu()
            WARN_ON()
            local_irq_save()
            local_irq_restore()
        this_cpu_ptr()
        cpumask_and()
        cpumask_clear_cpu()
        unlikely()
        cpumask_weight()
        for_each_cpu()
        per_cpu_ptr()
        csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
            csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                smp_load_acquire()
                cpu_relax()
            smp_wmb()
        llist_add()
        per_cpu()
        arch_send_call_function_ipi_mask()
        csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
            smp_load_acquire()
            cpu_relax()
    preempt_enable()
smp_call_function_any() <int smp_call_function_any (const struct cpumask *mask, smp_call_func_t func, void *info, int wait) at smp.c:361>:
    get_cpu()
    cpumask_test_cpu()
    cpumask_of_node()
    cpu_to_node()
    cpumask_first_and()
    cpumask_next_and()
    cpu_online()
    cpumask_any_and()
    smp_call_function_single() <int smp_call_function_single (int cpu, void (*func) (void *info), void *info, int wait) at up.c:10>:
        get_cpu()
        WARN_ON_ONCE()
        cpu_online()
        irqs_disabled()
        this_cpu_ptr()
        csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
            csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                smp_load_acquire()
                cpu_relax()
            smp_wmb()
        generic_exec_single() <int generic_exec_single (int cpu, struct call_single_data *csd, smp_call_func_t func, void *info) at smp.c:144>:
            smp_processor_id()
            csd_unlock() <void csd_unlock (struct call_single_data *csd) at smp.c:127>:
                WARN_ON()
                smp_store_release()
            local_irq_save()
            local_irq_restore()
            cpu_online()
            llist_add()
            per_cpu()
            arch_send_call_function_single_ipi()
        csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
            smp_load_acquire()
            cpu_relax()
        put_cpu()
        WARN_ON()
        local_irq_save()
        local_irq_restore()
    put_cpu()
smp_call_function_many() <void smp_call_function_many (const struct cpumask *mask, smp_call_func_t func, void *info, bool wait) at smp.c:404>:
    smp_processor_id()
    WARN_ON_ONCE()
    cpu_online()
    irqs_disabled()
    cpumask_first_and()
    cpumask_next_and()
    smp_call_function_single() <int smp_call_function_single (int cpu, void (*func) (void *info), void *info, int wait) at up.c:10>:
        get_cpu()
        WARN_ON_ONCE()
        cpu_online()
        irqs_disabled()
        this_cpu_ptr()
        csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
            csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
                smp_load_acquire()
                cpu_relax()
            smp_wmb()
        generic_exec_single() <int generic_exec_single (int cpu, struct call_single_data *csd, smp_call_func_t func, void *info) at smp.c:144>:
            smp_processor_id()
            csd_unlock() <void csd_unlock (struct call_single_data *csd) at smp.c:127>:
                WARN_ON()
                smp_store_release()
            local_irq_save()
            local_irq_restore()
            cpu_online()
            llist_add()
            per_cpu()
            arch_send_call_function_single_ipi()
        csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
            smp_load_acquire()
            cpu_relax()
        put_cpu()
        WARN_ON()
        local_irq_save()
        local_irq_restore()
    this_cpu_ptr()
    cpumask_and()
    cpumask_clear_cpu()
    unlikely()
    cpumask_weight()
    for_each_cpu()
    per_cpu_ptr()
    csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
        csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
            smp_load_acquire()
            cpu_relax()
        smp_wmb()
    llist_add()
    per_cpu()
    arch_send_call_function_ipi_mask()
    csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
        smp_load_acquire()
        cpu_relax()
smp_call_function_single() <int smp_call_function_single (int cpu, void (*func) (void *info), void *info, int wait) at up.c:10>:
    get_cpu()
    WARN_ON_ONCE()
    cpu_online()
    irqs_disabled()
    this_cpu_ptr()
    csd_lock() <void csd_lock (struct call_single_data *csd) at smp.c:114>:
        csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
            smp_load_acquire()
            cpu_relax()
        smp_wmb()
    generic_exec_single() <int generic_exec_single (int cpu, struct call_single_data *csd, smp_call_func_t func, void *info) at smp.c:144>:
        smp_processor_id()
        csd_unlock() <void csd_unlock (struct call_single_data *csd) at smp.c:127>:
            WARN_ON()
            smp_store_release()
        local_irq_save()
        local_irq_restore()
        cpu_online()
        llist_add()
        per_cpu()
        arch_send_call_function_single_ipi()
    csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
        smp_load_acquire()
        cpu_relax()
    put_cpu()
    WARN_ON()
    local_irq_save()
    local_irq_restore()
smp_call_function_single_async() <int smp_call_function_single_async (int cpu, struct call_single_data *csd) at up.c:25>:
    preempt_disable()
    WARN_ON_ONCE()
    csd_lock_wait() <void csd_lock_wait (struct call_single_data *csd) at smp.c:108>:
        smp_load_acquire()
        cpu_relax()
    smp_wmb()
    generic_exec_single() <int generic_exec_single (int cpu, struct call_single_data *csd, smp_call_func_t func, void *info) at smp.c:144>:
        smp_processor_id()
        csd_unlock() <void csd_unlock (struct call_single_data *csd) at smp.c:127>:
            WARN_ON()
            smp_store_release()
        local_irq_save()
        local_irq_restore()
        cpu_online()
        llist_add()
        per_cpu()
        arch_send_call_function_single_ipi()
    preempt_enable()
    local_irq_save()
    local_irq_restore()
smp_init() <void __init smp_init (void) at smp.c:567>:
    idle_threads_init() <void __init idle_threads_init (void) at smpboot.c:65>:
        smp_processor_id()
        for_each_possible_cpu()
        idle_init() <inline void idle_init (unsigned int cpu) at smpboot.c:49>:
            per_cpu()
            fork_idle() <struct task_struct *fork_idle (int cpu) at fork.c:1673>:
                copy_process() <struct task_struct *copy_process (unsigned long clone_flags, unsigned long stack_start, unsigned long stack_size, int __user *child_tidptr, struct pid *pid, int trace, unsigned long tls) at fork.c:1242>:
                    ERR_PTR()
                    task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                        ns_of_pid()
                        task_pid()
                    security_task_create()
                    dup_task_struct() <struct task_struct *dup_task_struct (struct task_struct *orig) at fork.c:334>:
                        tsk_fork_get_node() <int tsk_fork_get_node (struct task_struct *tsk) at kthread.c:216>:
                        alloc_task_struct_node() <inline struct task_struct *alloc_task_struct_node (int node) at fork.c:139>:
                            kmem_cache_alloc_node()
                        alloc_thread_info_node() <struct thread_info *alloc_thread_info_node (struct task_struct *tsk, int node) at fork.c:177>:
                            alloc_kmem_pages_node()
                            page_address()
                            kmem_cache_alloc_node()
                        arch_dup_task_struct() <int __weak arch_dup_task_struct (struct task_struct *dst, struct task_struct *src) at fork.c:319>
                        setup_thread_stack()
                        clear_user_return_notifier()
                        clear_tsk_need_resched()
                        set_task_stack_end_magic() <void set_task_stack_end_magic (struct task_struct *tsk) at fork.c:326>:
                            end_of_stack()
                        get_random_int()
                        atomic_set()
                        account_kernel_stack() <void account_kernel_stack (struct thread_info *ti, int account) at fork.c:215>:
                            page_zone()
                            virt_to_page()
                            mod_zone_page_state()
                        free_thread_info() <void free_thread_info (struct thread_info *ti) at fork.c:183>:
                            free_kmem_pages()
                            kmem_cache_free()
                        free_task_struct() <inline void free_task_struct (struct task_struct *tsk) at fork.c:144>:
                            kmem_cache_free()
                    ftrace_graph_init_task()
                    rt_mutex_init_task() <void rt_mutex_init_task (struct task_struct *p) at fork.c:1205>:
                        raw_spin_lock_init()
                    DEBUG_LOCKS_WARN_ON()
                    atomic_read()
                    task_rlimit()
                    capable() <bool capable (int cap) at capability.c:401>:
                        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                            unlikely()
                            cap_valid()
                            pr_crit()
                            BUG()
                            security_capable()
                            current_cred()
                    copy_creds() <int copy_creds (struct task_struct *p, unsigned long clone_flags) at cred.c:322>:
                        get_cred()
                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                            atomic_add()
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        atomic_inc()
                        prepare_creds() <struct cred *prepare_creds (void) at cred.c:243>:
                            validate_process_creds()
                            kmem_cache_alloc()
                            kdebug()
                            atomic_set()
                            set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
                                atomic_set()
                            get_group_info()
                            get_uid()
                            get_user_ns()
                            key_get()
                            security_prepare_creds()
                            validate_creds()
                            abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
                                kdebug()
                                atomic_read()
                                read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                                    atomic_read()
                                BUG_ON()
                                put_cred()
                        create_user_ns() <int create_user_ns (struct cred *new) at user_namespace.c:60>:
                            current_chrooted()
                            kuid_has_mapping()
                            kgid_has_mapping()
                            kmem_cache_zalloc()
                            ns_alloc_inum()
                            kmem_cache_free()
                            atomic_set()
                            mutex_lock()
                            mutex_unlock()
                            set_cred_user_ns() <void set_cred_user_ns (struct cred *cred, struct user_namespace *user_ns) at user_namespace.c:33>:
                                key_put()
                            init_rwsem()
                        key_put()
                        install_thread_keyring_to_cred()
                        validate_creds()
                        put_cred()
                    delayacct_tsk_init()
                    INIT_LIST_HEAD()
                    rcu_copy_process()
                    spin_lock_init()
                    init_sigpending()
                    prev_cputime_init()
                    seqcount_init()
                    task_io_accounting_init()
                    acct_clear_integrals() <void acct_clear_integrals (struct task_struct *tsk) at tsacct.c:174>
                    posix_cpu_timers_init() <void posix_cpu_timers_init (struct task_struct *tsk) at fork.c:1218>:
                        INIT_LIST_HEAD()
                    ktime_get_ns()
                    ktime_get_boot_ns()
                    threadgroup_change_begin()
                    cgroup_fork() <void cgroup_fork (struct task_struct *child) at cgroup.c:5497>:
                        RCU_INIT_POINTER()
                        INIT_LIST_HEAD()
                    mpol_dup()
                    IS_ERR()
                    PTR_ERR()
                    sched_fork()
                    perf_event_init_task()
                    audit_alloc() <int audit_alloc (struct task_struct *tsk) at auditsc.c:920>:
                        likely()
                        audit_filter_task() <enum audit_state audit_filter_task (struct task_struct *tsk, char **key) at auditsc.c:708>:
                            rcu_read_lock()
                            list_for_each_entry_rcu()
                            audit_filter_rules() <int audit_filter_rules (struct task_struct *tsk, struct audit_krule *rule, struct audit_context *ctx, struct audit_names *name, enum audit_state *state, bool task_creation) at auditsc.c:438>:
                                rcu_dereference_check()
                                task_pid_nr()
                                audit_comparator() <int audit_comparator (u32 left, u32 op, u32 right) at auditfilter.c:1165>:
                                    BUG()
                                task_ppid_nr()
                                audit_exe_compare() <int audit_exe_compare (struct task_struct *tsk, struct audit_fsnotify_mark *mark) at audit_watch.c:541>:
                                    rcu_read_lock()
                                    rcu_dereference()
                                    rcu_read_unlock()
                                    audit_mark_compare() <int audit_mark_compare (struct audit_fsnotify_mark *mark, unsigned long ino, dev_t dev) at audit_fsnotify.c:69>:
                                audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
                                    uid_eq()
                                    uid_lt()
                                    uid_lte()
                                    uid_gt()
                                    uid_gte()
                                    BUG()
                                audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
                                    gid_eq()
                                    gid_lt()
                                    gid_lte()
                                    gid_gt()
                                    gid_gte()
                                    BUG()
                                in_group_p() <int in_group_p (kgid_t grp) at groups.c:255>:
                                    current_cred()
                                    gid_eq()
                                    groups_search() <int groups_search (const struct group_info *group_info, kgid_t grp) at groups.c:133>:
                                        gid_gt()
                                        GROUP_AT()
                                        gid_lt()
                                in_egroup_p() <int in_egroup_p (kgid_t grp) at groups.c:267>:
                                    current_cred()
                                    gid_eq()
                                    groups_search() <int groups_search (const struct group_info *group_info, kgid_t grp) at groups.c:133>:
                                        gid_gt()
                                        GROUP_AT()
                                        gid_lt()
                                MAJOR()
                                list_for_each_entry()
                                MINOR()
                                audit_watch_compare() <int audit_watch_compare (struct audit_watch *watch, unsigned long ino, dev_t dev) at audit_watch.c:139>:
                                match_tree_refs() <int match_tree_refs (struct audit_context *ctx, struct audit_tree *tree) at auditsc.c:287>:
                                    audit_tree_match() <bool audit_tree_match (struct audit_chunk *chunk, struct audit_tree *tree) at audit_tree.c:200>:
                                audit_loginuid_set()
                                security_task_getsecid()
                                security_audit_rule_match()
                                audit_match_perm() <int audit_match_perm (struct audit_context *ctx, int mask) at auditsc.c:131>:
                                    unlikely()
                                    audit_classify_syscall()
                                    audit_match_class() <int audit_match_class (int class, unsigned syscall) at auditfilter.c:197>:
                                        unlikely()
                                        AUDIT_WORD()
                                        AUDIT_BIT()
                                    ACC_MODE()
                                audit_match_filetype() <int audit_match_filetype (struct audit_context *ctx, int val) at auditsc.c:174>:
                                    unlikely()
                                    list_for_each_entry()
                                audit_field_compare() <int audit_field_compare (struct task_struct *tsk, const struct cred *cred, struct audit_field *f, struct audit_context *ctx, struct audit_names *name) at auditsc.c:358>:
                                    audit_compare_uid() <int audit_compare_uid (kuid_t uid, struct audit_names *name, struct audit_field *f, struct audit_context *ctx) at auditsc.c:310>:
                                        audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
                                            uid_eq()
                                            uid_lt()
                                            uid_lte()
                                            uid_gt()
                                            uid_gte()
                                            BUG()
                                        list_for_each_entry()
                                    audit_compare_gid() <int audit_compare_gid (kgid_t gid, struct audit_names *name, struct audit_field *f, struct audit_context *ctx) at auditsc.c:334>:
                                        audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
                                            gid_eq()
                                            gid_lt()
                                            gid_lte()
                                            gid_gt()
                                            gid_gte()
                                            BUG()
                                        list_for_each_entry()
                                    audit_uid_comparator() <int audit_uid_comparator (kuid_t left, u32 op, kuid_t right) at auditfilter.c:1190>:
                                        uid_eq()
                                        uid_lt()
                                        uid_lte()
                                        uid_gt()
                                        uid_gte()
                                        BUG()
                                    audit_gid_comparator() <int audit_gid_comparator (kgid_t left, u32 op, kgid_t right) at auditfilter.c:1213>:
                                        gid_eq()
                                        gid_lt()
                                        gid_lte()
                                        gid_gt()
                                        gid_gte()
                                        BUG()
                                    WARN()
                                kfree()
                                kstrdup()
                            kstrdup()
                            rcu_read_unlock()
                        clear_tsk_thread_flag()
                        audit_alloc_context() <inline struct audit_context *audit_alloc_context (enum audit_state state) at auditsc.c:897>:
                            kzalloc()
                            INIT_LIST_HEAD()
                        kfree()
                        audit_log_lost() <void audit_log_lost (const char *message) at audit.c:252>:
                            atomic_inc()
                            spin_lock_irqsave()
                            spin_unlock_irqrestore()
                            printk_ratelimit()
                            pr_warn()
                            atomic_read()
                            audit_panic() <void audit_panic (const char *message) at audit.c:198>:
                                printk_ratelimit()
                                pr_err()
                                panic() <void panic (const char *fmt, ...) at panic.c:83>:
                                    local_irq_disable()
                                    raw_smp_processor_id()
                                    atomic_cmpxchg()
                                    panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                                        cpu_relax()
                                    console_verbose()
                                    bust_spinlocks()
                                    pr_emerg()
                                    test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                                        test_bit()
                                    dump_stack()
                                    smp_send_stop()
                                    atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
                                    kmsg_dump()
                                    debug_locks_off()
                                    console_flush_on_panic()
                                    panic_blink() <long (*panic_blink) (int state) at panic.c:52>
                                    no_blink() <long no_blink (int state) at panic.c:46>
                                    touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                                        raw_cpu_write()
                                        touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                            touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                                raw_cpu_write()
                                            wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                                per_cpu()
                                            raw_smp_processor_id()
                                    mdelay()
                                    emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                                        kmsg_dump()
                                        machine_emergency_restart()
                                    disabled_wait()
                                    local_irq_enable()
                                    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                                        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                                            raw_cpu_write()
                                        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                                            per_cpu()
                                        raw_smp_processor_id()
                        set_tsk_thread_flag()
                    shm_init_task()
                    copy_semundo()
                    copy_files() <int copy_files (unsigned long clone_flags, struct task_struct *tsk) at fork.c:1013>:
                        atomic_inc()
                        dup_fd()
                    copy_fs() <int copy_fs (unsigned long clone_flags, struct task_struct *tsk) at fork.c:993>:
                        spin_lock()
                        spin_unlock()
                        copy_fs_struct()
                    copy_sighand() <int copy_sighand (unsigned long clone_flags, struct task_struct *tsk) at fork.c:1066>:
                        atomic_inc()
                        kmem_cache_alloc()
                        rcu_assign_pointer()
                        atomic_set()
                    copy_signal() <int copy_signal (unsigned long clone_flags, struct task_struct *tsk) at fork.c:1115>:
                        kmem_cache_zalloc()
                        atomic_set()
                        LIST_HEAD_INIT()
                        init_waitqueue_head()
                        init_sigpending()
                        INIT_LIST_HEAD()
                        seqlock_init()
                        prev_cputime_init()
                        hrtimer_init()
                        task_lock()
                        task_unlock()
                        posix_cpu_timers_init_group() <void posix_cpu_timers_init_group (struct signal_struct *sig) at fork.c:1099>:
                            READ_ONCE()
                            secs_to_cputime()
                            INIT_LIST_HEAD()
                        tty_audit_fork()
                        sched_autogroup_fork()
                        mutex_init()
                    copy_mm() <int copy_mm (unsigned long clone_flags, struct task_struct *tsk) at fork.c:947>:
                        vmacache_flush()
                        atomic_inc()
                        dup_mm() <struct mm_struct *dup_mm (struct task_struct *tsk) at fork.c:912>:
                            allocate_mm()
                            mm_init() <struct mm_struct *mm_init (struct mm_struct *mm, struct task_struct *p) at fork.c:587>:
                                atomic_set()
                                init_rwsem()
                                INIT_LIST_HEAD()
                                atomic_long_set()
                                mm_nr_pmds_init()
                                spin_lock_init()
                                mm_init_cpumask()
                                mm_init_aio() <void mm_init_aio (struct mm_struct *mm) at fork.c:572>:
                                    spin_lock_init()
                                mm_init_owner() <void mm_init_owner (struct mm_struct *mm, struct task_struct *p) at fork.c:580>
                                mmu_notifier_mm_init()
                                clear_tlb_flush_pending()
                                mm_alloc_pgd() <inline int mm_alloc_pgd (struct mm_struct *mm) at fork.c:529>:
                                    pgd_alloc()
                                    unlikely()
                                init_new_context()
                                mm_free_pgd() <inline void mm_free_pgd (struct mm_struct *mm) at fork.c:537>:
                                    pgd_free()
                                free_mm()
                            dup_mmap() <int dup_mmap (struct mm_struct *mm, struct mm_struct *oldmm) at fork.c:542>:
                                uprobe_start_dup_mmap()
                                down_write()
                                flush_cache_dup_mm()
                                uprobe_dup_mmap()
                                down_write_nested()
                                RCU_INIT_POINTER()
                                get_mm_exe_file() <struct file *get_mm_exe_file (struct mm_struct *mm) at fork.c:752>:
                                    rcu_read_lock()
                                    rcu_dereference()
                                    get_file_rcu()
                                    rcu_read_unlock()
                                ksm_fork()
                                khugepaged_fork()
                                vm_stat_account()
                                vma_pages()
                                security_vm_enough_memory_mm()
                                kmem_cache_alloc()
                                INIT_LIST_HEAD()
                                vma_dup_policy()
                                anon_vma_fork()
                                file_inode()
                                get_file()
                                atomic_dec()
                                i_mmap_lock_write()
                                atomic_inc()
                                flush_dcache_mmap_lock()
                                vma_interval_tree_insert_after()
                                flush_dcache_mmap_unlock()
                                i_mmap_unlock_write()
                                is_vm_hugetlb_page()
                                reset_vma_resv_huge_pages()
                                copy_page_range()
                                arch_dup_mmap()
                                up_write()
                                flush_tlb_mm()
                                uprobe_end_dup_mmap()
                                mpol_put()
                                vma_policy()
                                kmem_cache_free()
                                vm_unacct_memory()
                            get_mm_rss()
                            try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
                                preempt_disable()
                                likely()
                                module_is_live()
                                atomic_inc_not_zero()
                                trace_module_get()
                                preempt_enable()
                            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                                might_sleep()
                                atomic_dec_and_test()
                                uprobe_clear_state()
                                exit_aio()
                                ksm_exit()
                                khugepaged_exit()
                                exit_mmap()
                                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                                    rcu_dereference_raw()
                                    get_file()
                                    rcu_assign_pointer()
                                    fput()
                                list_empty()
                                spin_lock()
                                list_del()
                                spin_unlock()
                                module_put() <void module_put (struct module *module) at module.c:1098>:
                                    preempt_disable()
                                    atomic_dec_if_positive()
                                    WARN_ON()
                                    trace_module_put()
                                    preempt_enable()
                                mmdrop()
                    copy_namespaces() <int copy_namespaces (unsigned long flags, struct task_struct *tsk) at nsproxy.c:124>:
                        task_cred_xxx()
                        likely()
                        get_nsproxy()
                        ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
                            unlikely()
                            cap_valid()
                            pr_crit()
                            BUG()
                            security_capable()
                            current_cred()
                        create_new_namespaces() <struct nsproxy *create_new_namespaces (unsigned long flags, struct task_struct *tsk, struct user_namespace *user_ns, struct fs_struct *new_fs) at nsproxy.c:59>:
                            create_nsproxy() <inline struct nsproxy *create_nsproxy (void) at nsproxy.c:44>:
                                kmem_cache_alloc()
                                atomic_set()
                            ERR_PTR()
                            copy_mnt_ns()
                            IS_ERR()
                            PTR_ERR()
                            copy_utsname() <struct uts_namespace *copy_utsname (unsigned long flags, struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:66>:
                                BUG_ON()
                                get_uts_ns()
                                clone_uts_ns() <struct uts_namespace *clone_uts_ns (struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:35>:
                                    create_uts_ns() <struct uts_namespace *create_uts_ns (void) at utsname.c:20>:
                                        kmalloc()
                                        kref_init()
                                    ERR_PTR()
                                    ns_alloc_inum()
                                    kfree()
                                    down_read()
                                    get_user_ns()
                                    up_read()
                                put_uts_ns()
                            copy_ipcs()
                            copy_pid_ns() <struct pid_namespace *copy_pid_ns (unsigned long flags, struct user_namespace *user_ns, struct pid_namespace *old_ns) at pid_namespace.c:153>:
                                get_pid_ns()
                                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                                    ns_of_pid()
                                    task_pid()
                                ERR_PTR()
                                create_pid_namespace() <struct pid_namespace *create_pid_namespace (struct user_namespace *user_ns, struct pid_namespace *parent_pid_ns) at pid_namespace.c:82>:
                                    kmem_cache_zalloc()
                                    kzalloc()
                                    create_pid_cachep() <struct kmem_cache *create_pid_cachep (int nr_ids) at pid_namespace.c:38>:
                                        mutex_lock()
                                        list_for_each_entry()
                                        kmalloc()
                                        kmem_cache_create()
                                        list_add()
                                        mutex_unlock()
                                        kfree()
                                    ns_alloc_inum()
                                    kref_init()
                                    get_pid_ns()
                                    get_user_ns()
                                    INIT_WORK()
                                    proc_cleanup_work() <void proc_cleanup_work (struct work_struct *work) at pid_namespace.c:73>:
                                        container_of()
                                        pid_ns_release_proc()
                                    set_bit()
                                    atomic_set()
                                    kfree()
                                    kmem_cache_free()
                                    ERR_PTR()
                            copy_net_ns()
                            put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                                kref_put()
                                free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                    container_of()
                                    destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                        ns_free_inum()
                                        kfree()
                                        put_user_ns()
                                        call_rcu()
                                        delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                            kmem_cache_free()
                                            container_of()
                            put_ipc_ns()
                            put_uts_ns()
                            put_mnt_ns()
                            kmem_cache_free()
                        IS_ERR()
                        PTR_ERR()
                    copy_io() <int copy_io (unsigned long clone_flags, struct task_struct *tsk) at fork.c:1040>:
                        ioc_task_link()
                        ioprio_valid()
                        get_task_io_context()
                        unlikely()
                        put_io_context()
                    copy_thread_tls()
                    alloc_pid() <struct pid *alloc_pid (struct pid_namespace *ns) at pid.c:297>:
                        kmem_cache_alloc()
                        ERR_PTR()
                        alloc_pidmap() <int alloc_pidmap (struct pid_namespace *pid_ns) at pid.c:154>:
                            DIV_ROUND_UP()
                            unlikely()
                            kzalloc()
                            spin_lock_irq()
                            spin_unlock_irq()
                            kfree()
                            likely()
                            atomic_read()
                            test_and_set_bit()
                            atomic_dec()
                            set_last_pid() <void set_last_pid (struct pid_namespace *pid_ns, int base, int pid) at pid.c:144>:
                                cmpxchg()
                                pid_before() <int pid_before (int base, int a, int b) at pid.c:118>
                            find_next_offset()
                            mk_pid() <inline int mk_pid (struct pid_namespace *pid_ns, struct pidmap *map, int off) at pid.c:55>:
                        IS_ERR_VALUE()
                        unlikely()
                        is_child_reaper()
                        pid_ns_prepare_proc()
                        get_pid_ns()
                        atomic_set()
                        INIT_HLIST_HEAD()
                        spin_lock_irq()
                        hlist_add_head_rcu()
                        pid_hashfn()
                        spin_unlock_irq()
                        put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                            kref_put()
                            free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                container_of()
                                destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                    ns_free_inum()
                                    kfree()
                                    put_user_ns()
                                    call_rcu()
                                    delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                        kmem_cache_free()
                                        container_of()
                        free_pidmap() <void free_pidmap (struct upid *upid) at pid.c:105>:
                            clear_bit()
                            atomic_inc()
                        kmem_cache_free()
                    user_disable_single_step()
                    clear_tsk_thread_flag()
                    clear_all_latency_tracing() <void clear_all_latency_tracing (struct task_struct *p) at latencytop.c:68>:
                        raw_spin_lock_irqsave()
                        raw_spin_unlock_irqrestore()
                    pid_nr()
                    cgroup_can_fork() <int cgroup_can_fork (struct task_struct *child) at cgroup.c:5511>:
                        for_each_subsys_which()
                        for_each_subsys()
                    write_lock_irq()
                    spin_lock()
                    copy_seccomp() <void copy_seccomp (struct task_struct *p) at fork.c:1165>:
                        assert_spin_locked()
                        get_seccomp_filter() <void get_seccomp_filter (struct task_struct *tsk) at seccomp.c:461>:
                            atomic_inc()
                        task_no_new_privs()
                        task_set_no_new_privs()
                        set_tsk_thread_flag()
                    recalc_sigpending() <void recalc_sigpending (void) at signal.c:158>:
                        recalc_sigpending_tsk() <int recalc_sigpending_tsk (struct task_struct *t) at signal.c:132>:
                            PENDING()
                            set_tsk_thread_flag()
                        freezing()
                        clear_thread_flag()
                    signal_pending()
                    spin_unlock()
                    write_unlock_irq()
                    likely()
                    ptrace_init_task()
                    init_task_pid() <inline void init_task_pid (struct task_struct *task, enum pid_type type, struct pid *pid) at fork.c:1229>
                    thread_group_leader()
                    task_pgrp()
                    task_session()
                    is_child_reaper()
                    ns_of_pid()
                    tty_kref_get()
                    list_add_tail()
                    list_add_tail_rcu()
                    attach_pid() <void attach_pid (struct task_struct *task, enum pid_type type) at pid.c:389>:
                        hlist_add_head_rcu()
                    atomic_inc()
                    syscall_tracepoint_update()
                    proc_fork_connector()
                    cgroup_post_fork() <void cgroup_post_fork (struct task_struct *child) at cgroup.c:5562>:
                        spin_lock_bh()
                        task_css_set()
                        list_empty()
                        get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                            atomic_inc()
                        css_set_move_task() <void css_set_move_task (struct task_struct *task, struct css_set *from_cset, struct css_set *to_cset, bool use_mg_tasks) at cgroup.c:662>:
                            lockdep_assert_held()
                            WARN_ON_ONCE()
                            list_empty()
                            list_for_each_entry_safe()
                            css_task_iter_advance() <void css_task_iter_advance (struct css_task_iter *it) at cgroup.c:3905>:
                                lockdep_assert_held()
                                WARN_ON_ONCE()
                                css_task_iter_advance_css_set() <void css_task_iter_advance_css_set (struct css_task_iter *it) at cgroup.c:3845>:
                                    lockdep_assert_held()
                                    container_of()
                                    list_entry()
                                    css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                        lockdep_assert_held()
                                        list_empty()
                                    list_empty()
                                    list_del()
                                    put_css_set_locked() <void put_css_set_locked (struct css_set *cset) at cgroup.c:730>:
                                        lockdep_assert_held()
                                        atomic_dec_and_test()
                                        for_each_subsys()
                                        list_del()
                                        css_put()
                                        hash_del()
                                        list_for_each_entry_safe()
                                        cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                            container_of()
                                        cgroup_put()
                                        kfree()
                                        kfree_rcu()
                                    get_css_set() <inline void get_css_set (struct css_set *cset) at cgroup.c:778>:
                                        atomic_inc()
                                    list_add()
                            list_del_init()
                            css_set_populated() <bool css_set_populated (struct css_set *cset) at cgroup.c:584>:
                                lockdep_assert_held()
                                list_empty()
                            css_set_update_populated() <void css_set_update_populated (struct css_set *cset, bool populated) at cgroup.c:637>:
                                lockdep_assert_held()
                                list_for_each_entry()
                                cgroup_update_populated() <void cgroup_update_populated (struct cgroup *cgrp, bool populated) at cgroup.c:607>:
                                    lockdep_assert_held()
                                    check_for_release() <void check_for_release (struct cgroup *cgrp) at cgroup.c:5665>:
                                        notify_on_release() <int notify_on_release (const struct cgroup *cgrp) at cgroup.c:465>:
                                            test_bit()
                                        cgroup_is_populated()
                                        css_has_online_children() <bool css_has_online_children (struct cgroup_subsys_state *css) at cgroup.c:3823>:
                                            rcu_read_lock()
                                            css_for_each_child()
                                            rcu_read_unlock()
                                        cgroup_is_dead() <inline bool cgroup_is_dead (const struct cgroup *cgrp) at cgroup.c:429>:
                                        schedule_work()
                                    cgroup_file_notify() <void cgroup_file_notify (struct cgroup_file *cfile) at cgroup.c:3584>:
                                        spin_lock_irqsave()
                                        kernfs_notify()
                                        spin_unlock_irqrestore()
                                    cgroup_parent() <struct cgroup *cgroup_parent (struct cgroup *cgrp) at cgroup.c:333>:
                                        container_of()
                            rcu_assign_pointer()
                            list_add_tail()
                        spin_unlock_bh()
                        for_each_subsys_which()
                    threadgroup_change_end()
                    perf_event_fork()
                    trace_task_newtask()
                    uprobe_copy_process()
                    cgroup_cancel_fork() <void cgroup_cancel_fork (struct task_struct *child) at cgroup.c:5542>:
                        for_each_subsys()
                    free_pid() <void free_pid (struct pid *pid) at pid.c:259>:
                        spin_lock_irqsave()
                        hlist_del_rcu()
                        wake_up_process()
                        WARN_ON()
                        schedule_work()
                        spin_unlock_irqrestore()
                        free_pidmap() <void free_pidmap (struct upid *upid) at pid.c:105>:
                            clear_bit()
                            atomic_inc()
                        call_rcu()
                        delayed_put_pid() <void delayed_put_pid (struct rcu_head *rhp) at pid.c:253>:
                            container_of()
                            put_pid() <void put_pid (struct pid *pid) at pid.c:237>:
                                atomic_read()
                                atomic_dec_and_test()
                                kmem_cache_free()
                                put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                                    kref_put()
                                    free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                        container_of()
                                        destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                            ns_free_inum()
                                            kfree()
                                            put_user_ns()
                                            call_rcu()
                                            delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                                kmem_cache_free()
                                                container_of()
                    exit_io_context()
                    exit_task_namespaces() <void exit_task_namespaces (struct task_struct *p) at nsproxy.c:216>:
                        switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
                            might_sleep()
                            task_lock()
                            task_unlock()
                            atomic_dec_and_test()
                            free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
                                put_mnt_ns()
                                put_uts_ns()
                                put_ipc_ns()
                                put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
                                    kref_put()
                                    free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                                        container_of()
                                        destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                                            ns_free_inum()
                                            kfree()
                                            put_user_ns()
                                            call_rcu()
                                            delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                                                kmem_cache_free()
                                                container_of()
                                put_net()
                                kmem_cache_free()
                    mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                        might_sleep()
                        atomic_dec_and_test()
                        uprobe_clear_state()
                        exit_aio()
                        ksm_exit()
                        khugepaged_exit()
                        exit_mmap()
                        set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                            rcu_dereference_raw()
                            get_file()
                            rcu_assign_pointer()
                            fput()
                        list_empty()
                        spin_lock()
                        list_del()
                        spin_unlock()
                        module_put() <void module_put (struct module *module) at module.c:1098>:
                            preempt_disable()
                            atomic_dec_if_positive()
                            WARN_ON()
                            trace_module_put()
                            preempt_enable()
                        mmdrop()
                    free_signal_struct() <inline void free_signal_struct (struct signal_struct *sig) at fork.c:235>:
                        taskstats_tgid_free()
                        sched_autogroup_exit()
                        kmem_cache_free()
                    exit_fs()
                    exit_files()
                    exit_sem()
                    audit_free()
                    perf_event_free_task()
                    mpol_put()
                    delayacct_tsk_free()
                    atomic_dec()
                    exit_creds() <void exit_creds (struct task_struct *tsk) at cred.c:156>:
                        kdebug()
                        atomic_read()
                        read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                            atomic_read()
                        validate_creds()
                        alter_cred_subscribers() <inline void alter_cred_subscribers (const struct cred *_cred, int n) at cred.c:83>:
                            atomic_add()
                        put_cred()
                    free_task() <void free_task (struct task_struct *tsk) at fork.c:222>:
                        account_kernel_stack() <void account_kernel_stack (struct thread_info *ti, int account) at fork.c:215>:
                            page_zone()
                            virt_to_page()
                            mod_zone_page_state()
                        arch_release_thread_info() <void __weak arch_release_thread_info (struct thread_info *ti) at fork.c:150>
                        free_thread_info() <void free_thread_info (struct thread_info *ti) at fork.c:183>:
                            free_kmem_pages()
                            kmem_cache_free()
                        rt_mutex_debug_task_free()
                        ftrace_graph_exit_task()
                        put_seccomp_filter() <void put_seccomp_filter (struct task_struct *tsk) at seccomp.c:479>:
                            atomic_dec_and_test()
                            seccomp_filter_free() <inline void seccomp_filter_free (struct seccomp_filter *filter) at seccomp.c:470>:
                                bpf_prog_destroy()
                                kfree()
                        arch_release_task_struct() <void __weak arch_release_task_struct (struct task_struct *tsk) at fork.c:132>
                        free_task_struct() <inline void free_task_struct (struct task_struct *tsk) at fork.c:144>:
                            kmem_cache_free()
                IS_ERR()
                init_idle_pids() <inline void init_idle_pids (struct pid_link *links) at fork.c:1663>:
                    INIT_HLIST_NODE()
                init_idle()
            IS_ERR()
            pr_err()
    for_each_present_cpu()
    num_online_cpus()
    cpu_online()
    cpu_up() <int cpu_up (unsigned int cpu) at cpu.c:537>:
        cpu_possible()
        pr_err()
        try_online_node()
        cpu_to_node()
        cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
            mutex_lock()
        cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
            mutex_unlock()
    smp_announce() <void __weak smp_announce (void) at smp.c:561>:
        printk()
        num_online_cpus()
    smp_cpus_done()
smpboot_create_threads() <int smpboot_create_threads (unsigned int cpu) at smpboot.c:206>:
    mutex_lock()
    list_for_each_entry()
    mutex_unlock()
smpboot_park_threads() <void smpboot_park_threads (unsigned int cpu) at smpboot.c:248>:
    mutex_lock()
    list_for_each_entry_reverse()
    smpboot_park_thread() <void smpboot_park_thread (struct smp_hotplug_thread *ht, unsigned int cpu) at smpboot.c:240>:
        per_cpu_ptr()
        kthread_park() <int kthread_park (struct task_struct *k) at kthread.c:445>:
            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                ACCESS_ONCE()
                likely()
            test_bit()
            set_bit()
            wake_up_process()
            wait_for_completion()
    mutex_unlock()
smpboot_register_percpu_thread_cpumask() <int smpboot_register_percpu_thread_cpumask (struct smp_hotplug_thread *plug_thread, const struct cpumask *cpumask) at smpboot.c:282>:
    alloc_cpumask_var()
    cpumask_copy()
    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
        might_sleep()
        cpuhp_lock_acquire_read()
        mutex_lock()
        atomic_inc()
        mutex_unlock()
    mutex_lock()
    for_each_online_cpu()
    smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
        for_each_possible_cpu()
        per_cpu_ptr()
        kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
            trace_sched_kthread_stop()
            get_task_struct()
            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                ACCESS_ONCE()
                likely()
            set_bit()
            wake_up_process()
            wait_for_completion()
            put_task_struct()
            trace_sched_kthread_stop_ret()
        put_task_struct()
    free_cpumask_var()
    cpumask_test_cpu()
    smpboot_unpark_thread() <void smpboot_unpark_thread (struct smp_hotplug_thread *ht, unsigned int cpu) at smpboot.c:221>:
        per_cpu_ptr()
        kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                ACCESS_ONCE()
                likely()
    list_add()
    mutex_unlock()
    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
        atomic_dec_return()
        WARN_ON()
        atomic_inc()
        waitqueue_active()
        wake_up()
        cpuhp_lock_release()
smpboot_thread_init() <void smpboot_thread_init (void) at cpu.c:480>:
    register_cpu_notifier() <int register_cpu_notifier (struct notifier_block *nb) at cpu.c:196>:
        cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
            mutex_lock()
        raw_notifier_chain_register() <int raw_notifier_chain_register (struct raw_notifier_head *nh, struct notifier_block *n) at notifier.c:347>:
            notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
                rcu_assign_pointer()
        cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
            mutex_unlock()
smpboot_unpark_threads() <void smpboot_unpark_threads (unsigned int cpu) at smpboot.c:229>:
    mutex_lock()
    list_for_each_entry()
    cpumask_test_cpu()
    smpboot_unpark_thread() <void smpboot_unpark_thread (struct smp_hotplug_thread *ht, unsigned int cpu) at smpboot.c:221>:
        per_cpu_ptr()
        kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                ACCESS_ONCE()
                likely()
    mutex_unlock()
smpboot_unregister_percpu_thread() <void smpboot_unregister_percpu_thread (struct smp_hotplug_thread *plug_thread) at smpboot.c:318>:
    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
        might_sleep()
        cpuhp_lock_acquire_read()
        mutex_lock()
        atomic_inc()
        mutex_unlock()
    mutex_lock()
    list_del()
    smpboot_destroy_threads() <void smpboot_destroy_threads (struct smp_hotplug_thread *ht) at smpboot.c:258>:
        for_each_possible_cpu()
        per_cpu_ptr()
        kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
            trace_sched_kthread_stop()
            get_task_struct()
            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                ACCESS_ONCE()
                likely()
            set_bit()
            wake_up_process()
            wait_for_completion()
            put_task_struct()
            trace_sched_kthread_stop_ret()
        put_task_struct()
    mutex_unlock()
    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
        atomic_dec_return()
        WARN_ON()
        atomic_inc()
        waitqueue_active()
        wake_up()
        cpuhp_lock_release()
    free_cpumask_var()
smpboot_update_cpumask_percpu_thread() <int smpboot_update_cpumask_percpu_thread (struct smp_hotplug_thread *plug_thread, const struct cpumask *new) at smpboot.c:339>:
    alloc_cpumask_var()
    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
        might_sleep()
        cpuhp_lock_acquire_read()
        mutex_lock()
        atomic_inc()
        mutex_unlock()
    mutex_lock()
    cpumask_andnot()
    for_each_cpu_and()
    smpboot_park_thread() <void smpboot_park_thread (struct smp_hotplug_thread *ht, unsigned int cpu) at smpboot.c:240>:
        per_cpu_ptr()
        kthread_park() <int kthread_park (struct task_struct *k) at kthread.c:445>:
            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                ACCESS_ONCE()
                likely()
            test_bit()
            set_bit()
            wake_up_process()
            wait_for_completion()
    smpboot_unpark_thread() <void smpboot_unpark_thread (struct smp_hotplug_thread *ht, unsigned int cpu) at smpboot.c:221>:
        per_cpu_ptr()
        kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                ACCESS_ONCE()
                likely()
    cpumask_copy()
    mutex_unlock()
    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
        atomic_dec_return()
        WARN_ON()
        atomic_inc()
        waitqueue_active()
        wake_up()
        cpuhp_lock_release()
    free_cpumask_var()
snprint_stack_trace() <int snprint_stack_trace (char *buf, size_t size, struct stack_trace *trace, int spaces) at stacktrace.c:28>:
    WARN_ON()
softirq_init() <void __init softirq_init (void) at softirq.c:634>:
    for_each_possible_cpu()
    per_cpu()
    open_softirq() <void open_softirq (int nr, void (*action) (struct softirq_action *)) at softirq.c:433>:
    tasklet_action() <void tasklet_action (struct softirq_action *a) at softirq.c:485>:
        local_irq_disable()
        this_cpu_ptr()
        local_irq_enable()
        tasklet_trylock()
        atomic_read()
        test_and_clear_bit()
        BUG()
        tasklet_unlock()
    tasklet_hi_action() <void tasklet_hi_action (struct softirq_action *a) at softirq.c:521>:
        local_irq_disable()
        this_cpu_ptr()
        local_irq_enable()
        tasklet_trylock()
        atomic_read()
        test_and_clear_bit()
        BUG()
        tasklet_unlock()
sort_main_extable() <void __init sort_main_extable (void) at extable.c:42>:
    pr_notice()
    sort_extable()
sort_range() <void sort_range (struct range *range, int nr_range) at range.c:159>:
    sort()
    cmp_range() <int cmp_range (const void *x1, const void *x2) at range.c:112>:
sprint_backtrace() <int sprint_backtrace (char *buffer, unsigned long address) at kallsyms.c:431>:
sprint_symbol() <int sprint_symbol (char *buffer, unsigned long address) at kallsyms.c:394>:
sprint_symbol_no_offset() <int sprint_symbol_no_offset (char *buffer, unsigned long address) at kallsyms.c:411>:
srcu_init_notifier_head() <void srcu_init_notifier_head (struct srcu_notifier_head *nh) at notifier.c:523>:
    mutex_init()
    init_srcu_struct()
    BUG()
srcu_notifier_call_chain() <int srcu_notifier_call_chain (struct srcu_notifier_head *nh, unsigned long val, void *v) at notifier.c:504>:
srcu_notifier_chain_register() <int srcu_notifier_chain_register (struct srcu_notifier_head *nh, struct notifier_block *n) at notifier.c:421>:
    unlikely()
    notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
        rcu_assign_pointer()
    mutex_lock()
    mutex_unlock()
srcu_notifier_chain_unregister() <int srcu_notifier_chain_unregister (struct srcu_notifier_head *nh, struct notifier_block *n) at notifier.c:451>:
    unlikely()
    notifier_chain_unregister() <int notifier_chain_unregister (struct notifier_block **nl, struct notifier_block *n) at notifier.c:49>:
        rcu_assign_pointer()
    mutex_lock()
    mutex_unlock()
    synchronize_srcu()
static_key_slow_dec() <void static_key_slow_dec (struct static_key *key) at jump_label.c:97>:
    STATIC_KEY_CHECK_USE()
static_key_slow_dec_deferred() <void static_key_slow_dec_deferred (struct static_key_deferred *key) at jump_label.c:104>:
    STATIC_KEY_CHECK_USE()
static_key_slow_inc() <void static_key_slow_inc (struct static_key *key) at jump_label.c:59>:
    STATIC_KEY_CHECK_USE()
    atomic_inc_not_zero()
    jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
        mutex_lock()
    atomic_inc_return()
    jump_label_update() <void jump_label_update (struct static_key *key) at jump_label.c:465>:
        static_key_entries() <inline struct jump_entry *static_key_entries (struct static_key *key) at jump_label.c:156>:
        preempt_disable()
        preempt_enable()
    jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
        mutex_unlock()
stop_cpus() <int stop_cpus (const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg) at stop_machine.c:381>:
    mutex_lock()
    mutex_unlock()
stop_machine() <int stop_machine (cpu_stop_fn_t fn, void *data, const struct cpumask *cpus) at stop_machine.c:565>:
    get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
        might_sleep()
        cpuhp_lock_acquire_read()
        mutex_lock()
        atomic_inc()
        mutex_unlock()
    put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
        atomic_dec_return()
        WARN_ON()
        atomic_inc()
        waitqueue_active()
        wake_up()
        cpuhp_lock_release()
stop_machine_from_inactive_cpu() <int stop_machine_from_inactive_cpu (cpu_stop_fn_t fn, void *data, const struct cpumask *cpus) at stop_machine.c:599>:
    BUG_ON()
    cpu_active()
    raw_smp_processor_id()
    num_active_cpus()
    mutex_trylock()
    cpu_relax()
    set_state() <void set_state (struct multi_stop_data *msdata, enum multi_stop_state newstate) at stop_machine.c:157>:
        atomic_set()
        smp_wmb()
    cpu_stop_init_done() <void cpu_stop_init_done (struct cpu_stop_done *done, unsigned int nr_todo) at stop_machine.c:57>:
        atomic_set()
        init_completion()
    queue_stop_cpus_work() <bool queue_stop_cpus_work (const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg, struct cpu_stop_done *done) at stop_machine.c:314>:
        lg_global_lock()
        for_each_cpu()
        per_cpu()
        cpu_stop_queue_work() <bool cpu_stop_queue_work (unsigned int cpu, struct cpu_stop_work *work) at stop_machine.c:79>:
            per_cpu()
            spin_lock_irqsave()
            cpu_stop_signal_done() <void cpu_stop_signal_done (struct cpu_stop_done *done) at stop_machine.c:65>:
                atomic_dec_and_test()
                complete()
            spin_unlock_irqrestore()
        lg_global_unlock()
    multi_cpu_stop() <int multi_cpu_stop (void *data) at stop_machine.c:174>:
        smp_processor_id()
        local_save_flags()
        cpumask_first()
        cpumask_test_cpu()
        cpu_relax()
        local_irq_disable()
        hard_irq_disable()
        ack_state() <void ack_state (struct multi_stop_data *msdata) at stop_machine.c:167>:
            atomic_dec_and_test()
            set_state() <void set_state (struct multi_stop_data *msdata, enum multi_stop_state newstate) at stop_machine.c:157>:
                atomic_set()
                smp_wmb()
        local_irq_restore()
    completion_done()
    mutex_unlock()
stop_machine_park() <void stop_machine_park (int cpu) at stop_machine.c:470>:
    per_cpu()
    kthread_park() <int kthread_park (struct task_struct *k) at kthread.c:445>:
        to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
            ACCESS_ONCE()
            likely()
        test_bit()
        set_bit()
        wake_up_process()
        wait_for_completion()
stop_machine_unpark() <void stop_machine_unpark (int cpu) at stop_machine.c:496>:
    per_cpu()
    kthread_unpark() <void kthread_unpark (struct task_struct *k) at kthread.c:424>:
        to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
            ACCESS_ONCE()
            likely()
stop_one_cpu() <int stop_one_cpu (unsigned int cpu, cpu_stop_fn_t fn, void *arg) at stop_machine.c:120>:
    cpu_stop_init_done() <void cpu_stop_init_done (struct cpu_stop_done *done, unsigned int nr_todo) at stop_machine.c:57>:
        atomic_set()
        init_completion()
    cpu_stop_queue_work() <bool cpu_stop_queue_work (unsigned int cpu, struct cpu_stop_work *work) at stop_machine.c:79>:
        per_cpu()
        spin_lock_irqsave()
        cpu_stop_signal_done() <void cpu_stop_signal_done (struct cpu_stop_done *done) at stop_machine.c:65>:
            atomic_dec_and_test()
            complete()
        spin_unlock_irqrestore()
    wait_for_completion()
stop_one_cpu_nowait() <bool stop_one_cpu_nowait (unsigned int cpu, cpu_stop_fn_t fn, void *arg, struct cpu_stop_work *work_buf) at stop_machine.c:304>:
    cpu_stop_queue_work() <bool cpu_stop_queue_work (unsigned int cpu, struct cpu_stop_work *work) at stop_machine.c:79>:
        per_cpu()
        spin_lock_irqsave()
        cpu_stop_signal_done() <void cpu_stop_signal_done (struct cpu_stop_done *done) at stop_machine.c:65>:
            atomic_dec_and_test()
            complete()
        spin_unlock_irqrestore()
stop_two_cpus() <int stop_two_cpus (unsigned int cpu1, unsigned int cpu2, cpu_stop_fn_t fn, void *arg) at stop_machine.c:255>:
    cpumask_of()
    multi_cpu_stop() <int multi_cpu_stop (void *data) at stop_machine.c:174>:
        smp_processor_id()
        local_save_flags()
        cpumask_first()
        cpumask_test_cpu()
        cpu_relax()
        local_irq_disable()
        hard_irq_disable()
        ack_state() <void ack_state (struct multi_stop_data *msdata) at stop_machine.c:167>:
            atomic_dec_and_test()
            set_state() <void set_state (struct multi_stop_data *msdata, enum multi_stop_state newstate) at stop_machine.c:157>:
                atomic_set()
                smp_wmb()
        local_irq_restore()
    cpu_stop_init_done() <void cpu_stop_init_done (struct cpu_stop_done *done, unsigned int nr_todo) at stop_machine.c:57>:
        atomic_set()
        init_completion()
    set_state() <void set_state (struct multi_stop_data *msdata, enum multi_stop_state newstate) at stop_machine.c:157>:
        atomic_set()
        smp_wmb()
    swap()
    cpu_stop_queue_two_works() <int cpu_stop_queue_two_works (int cpu1, struct cpu_stop_work *work1, int cpu2, struct cpu_stop_work *work2) at stop_machine.c:219>:
        per_cpu_ptr()
        lg_double_lock()
        spin_lock_irq()
        spin_lock_nested()
        spin_unlock()
        spin_unlock_irq()
        lg_double_unlock()
    wait_for_completion()
stutter_wait() <void stutter_wait (const char *title) at torture.c:524>:
    cond_resched_rcu_qs()
    READ_ONCE()
    schedule_timeout_interruptible()
    cond_resched()
    round_jiffies_relative()
    torture_shutdown_absorb() <void torture_shutdown_absorb (const char *title) at torture.c:410>:
        READ_ONCE()
        pr_notice()
        schedule_timeout_uninterruptible()
subtract_range() <void subtract_range (struct range *range, int az, u64 start, u64 end) at range.c:63>:
    pr_err()
switch_task_namespaces() <void switch_task_namespaces (struct task_struct *p, struct nsproxy *new) at nsproxy.c:201>:
    might_sleep()
    task_lock()
    task_unlock()
    atomic_dec_and_test()
    free_nsproxy() <void free_nsproxy (struct nsproxy *ns) at nsproxy.c:158>:
        put_mnt_ns()
        put_uts_ns()
        put_ipc_ns()
        put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
            kref_put()
            free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                container_of()
                destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                    ns_free_inum()
                    kfree()
                    put_user_ns()
                    call_rcu()
                    delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                        kmem_cache_free()
                        container_of()
        put_net()
        kmem_cache_free()
symbol_put_addr() <void symbol_put_addr (void *addr) at module.c:1039>:
    dereference_function_descriptor()
    core_kernel_text() <int core_kernel_text (unsigned long addr) at extable.c:69>:
        init_kernel_text() <inline int init_kernel_text (unsigned long addr) at extable.c:61>:
    preempt_disable()
    BUG_ON()
    module_put() <void module_put (struct module *module) at module.c:1098>:
        preempt_disable()
        atomic_dec_if_positive()
        WARN_ON()
        trace_module_put()
        preempt_enable()
    preempt_enable()
sys_ni_syscall() <asmlinkage long sys_ni_syscall (void) at sys_ni.c:14>:
syscall_regfunc() <void syscall_regfunc (void) at tracepoint.c:532>:
    read_lock()
    for_each_process_thread()
    set_tsk_thread_flag()
    read_unlock()
syscall_unregfunc() <void syscall_unregfunc (void) at tracepoint.c:546>:
    read_lock()
    for_each_process_thread()
    clear_tsk_thread_flag()
    read_unlock()
sysctl_init() <int __init sysctl_init (void) at sysctl.c:1805>:
    register_sysctl_table()
    kmemleak_not_leak()
sysctl_max_threads() <int sysctl_max_threads (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at fork.c:2096>:
    proc_dointvec_minmax() <int proc_dointvec_minmax (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos) at sysctl.c:2794>:
        min()
        max()
        do_proc_dointvec() <int do_proc_dointvec (struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos, int (*conv) (bool *negp, unsigned long *lvalp, int *valp, int write, void *data), void *data) at sysctl.c:2169>:
        do_proc_dointvec_minmax_conv() <int do_proc_dointvec_minmax_conv (bool *negp, unsigned long *lvalp, int *valp, int write, void *data) at sysctl.c:2250>:
    set_max_threads() <void set_max_threads (unsigned int max_threads_suggested) at fork.c:271>:
        fls64()
        div64_u64()
        clamp_t()
task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
    ns_of_pid()
    task_pid()
task_cgroup_path() <char *task_cgroup_path (struct task_struct *task, char *buf, size_t buflen) at cgroup.c:2183>:
    mutex_lock()
    spin_lock_bh()
    idr_get_next()
    task_cgroup_from_root() <struct cgroup *task_cgroup_from_root (struct task_struct *task, struct cgroup_root *root) at cgroup.c:1172>:
        cset_cgroup_from_root() <struct cgroup *cset_cgroup_from_root (struct css_set *cset, struct cgroup_root *root) at cgroup.c:1141>:
            lockdep_assert_held()
            list_for_each_entry()
            BUG_ON()
        task_css_set()
    cgroup_path()
    strlcpy()
    spin_unlock_bh()
    mutex_unlock()
task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
    BUG_ON()
    task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
        unlikely()
        smp_mb()
        wake_up_bit()
task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
    unlikely()
    smp_mb()
    wake_up_bit()
task_handoff_register() <int task_handoff_register (struct notifier_block *n) at profile.c:154>:
    atomic_notifier_chain_register() <int atomic_notifier_chain_register (struct atomic_notifier_head *nh, struct notifier_block *n) at notifier.c:121>:
        spin_lock_irqsave()
        notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
            rcu_assign_pointer()
        spin_unlock_irqrestore()
task_handoff_unregister() <int task_handoff_unregister (struct notifier_block *n) at profile.c:160>:
    atomic_notifier_chain_unregister() <int atomic_notifier_chain_unregister (struct atomic_notifier_head *nh, struct notifier_block *n) at notifier.c:143>:
        spin_lock_irqsave()
        notifier_chain_unregister() <int notifier_chain_unregister (struct notifier_block **nl, struct notifier_block *n) at notifier.c:49>:
            rcu_assign_pointer()
        spin_unlock_irqrestore()
        synchronize_rcu()
task_set_jobctl_pending() <bool task_set_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:248>:
    BUG_ON()
    unlikely()
    fatal_signal_pending()
task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
    pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
    task_tgid()
task_work_add() <int task_work_add (struct task_struct *task, struct callback_head *work, bool notify) at task_work.c:27>:
    ACCESS_ONCE()
    unlikely()
    cmpxchg()
    set_notify_resume()
task_work_cancel() <struct callback_head *task_work_cancel (struct task_struct *task, task_work_func_t func) at task_work.c:55>:
    raw_spin_lock_irqsave()
    ACCESS_ONCE()
    smp_read_barrier_depends()
    cmpxchg()
    raw_spin_unlock_irqrestore()
task_work_run() <void task_work_run (void) at task_work.c:87>:
    ACCESS_ONCE()
    cmpxchg()
    raw_spin_unlock_wait()
    smp_mb()
    cond_resched()
tasklet_hrtimer_init() <void tasklet_hrtimer_init (struct tasklet_hrtimer *ttimer, enum hrtimer_restart (*function) (struct hrtimer *), clockid_t which_clock, enum hrtimer_mode mode) at softirq.c:622>:
    hrtimer_init()
    tasklet_init() <void tasklet_init (struct tasklet_struct *t, void (*func) (unsigned long), unsigned long data) at softirq.c:557>:
        atomic_set()
tasklet_init() <void tasklet_init (struct tasklet_struct *t, void (*func) (unsigned long), unsigned long data) at softirq.c:557>:
    atomic_set()
tasklet_kill() <void tasklet_kill (struct tasklet_struct *t) at softirq.c:568>:
    in_interrupt()
    pr_notice()
    test_and_set_bit()
    yield()
    test_bit()
    tasklet_unlock_wait()
    clear_bit()
tasklet_kill_immediate() <void tasklet_kill_immediate (struct tasklet_struct *t, unsigned int cpu) at softirq.c:680>:
    BUG_ON()
    cpu_online()
    test_bit()
    per_cpu()
    BUG()
taskstats_exit() <void taskstats_exit (struct task_struct *tsk, int group_dead) at taskstats.c:607>:
    taskstats_packet_size() <size_t taskstats_packet_size (void) at taskstats.c:498>:
        nla_total_size()
    taskstats_tgid_alloc() <struct taskstats *taskstats_tgid_alloc (struct task_struct *tsk) at taskstats.c:582>:
        thread_group_empty()
        kmem_cache_zalloc()
        spin_lock_irq()
        spin_unlock_irq()
        kmem_cache_free()
    fill_tgid_exit() <void fill_tgid_exit (struct task_struct *tsk) at taskstats.c:259>:
        spin_lock_irqsave()
        delayacct_add_tsk()
        spin_unlock_irqrestore()
    raw_cpu_ptr()
    list_empty()
    prepare_reply() <int prepare_reply (struct genl_info *info, u8 cmd, struct sk_buff **skbp, size_t size) at taskstats.c:79>:
        genlmsg_new()
        this_cpu_inc_return()
        genlmsg_put()
        genlmsg_put_reply()
        nlmsg_free()
    mk_reply() <struct taskstats *mk_reply (struct sk_buff *skb, int type, u32 pid) at taskstats.c:364>:
        nla_put()
        nla_nest_start()
        nla_nest_cancel()
        nla_reserve()
        nla_nest_end()
        nla_data()
    task_pid_nr_ns()
    fill_stats() <void fill_stats (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct task_struct *tsk, struct taskstats *stats) at taskstats.c:169>:
        delayacct_add_tsk()
        bacct_add_tsk() <void bacct_add_tsk (struct user_namespace *user_ns, struct pid_namespace *pid_ns, struct taskstats *stats, struct task_struct *tsk) at tsacct.c:29>:
            BUILD_BUG_ON()
            ktime_get_ns()
            do_div()
            get_seconds()
            thread_group_leader()
            task_nice()
            task_pid_nr_ns()
            rcu_read_lock()
            from_kuid_munged() <uid_t from_kuid_munged (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:283>:
                from_kuid() <uid_t from_kuid (struct user_namespace *targ, kuid_t kuid) at user_namespace.c:258>:
                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                        smp_rmb()
            from_kgid_munged() <gid_t from_kgid_munged (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:350>:
                from_kgid() <gid_t from_kgid (struct user_namespace *targ, kgid_t kgid) at user_namespace.c:326>:
                    map_id_up() <u32 map_id_up (struct uid_gid_map *map, u32 id) at user_namespace.c:203>:
                        smp_rmb()
            pid_alive()
            task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
                pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
                task_tgid()
            rcu_dereference()
            rcu_read_unlock()
            task_cputime()
            cputime_to_usecs()
            task_cputime_scaled()
        xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
            get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
                task_lock()
                atomic_inc()
                task_unlock()
            get_mm_hiwater_rss()
            get_mm_hiwater_vm()
            mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
                might_sleep()
                atomic_dec_and_test()
                uprobe_clear_state()
                exit_aio()
                ksm_exit()
                khugepaged_exit()
                exit_mmap()
                set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
                    rcu_dereference_raw()
                    get_file()
                    rcu_assign_pointer()
                    fput()
                list_empty()
                spin_lock()
                list_del()
                spin_unlock()
                module_put() <void module_put (struct module *module) at module.c:1098>:
                    preempt_disable()
                    atomic_dec_if_positive()
                    WARN_ON()
                    trace_module_put()
                    preempt_enable()
                mmdrop()
    task_tgid_nr_ns() <pid_t task_tgid_nr_ns (struct task_struct *tsk, struct pid_namespace *ns) at pid.c:539>:
        pid_nr_ns() <pid_t pid_nr_ns (struct pid *pid, struct pid_namespace *ns) at pid.c:500>:
        task_tgid()
    send_cpu_listeners() <void send_cpu_listeners (struct sk_buff *skb, struct listener_list *listeners) at taskstats.c:123>:
        nlmsg_data()
        nlmsg_hdr()
        genlmsg_data()
        genlmsg_end()
        down_read()
        list_for_each_entry()
        list_is_last()
        skb_clone()
        genlmsg_unicast()
        up_read()
        nlmsg_free()
        down_write()
        list_for_each_entry_safe()
        list_del()
        kfree()
        up_write()
    nlmsg_free()
taskstats_init_early() <void __init taskstats_init_early (void) at taskstats.c:682>:
    KMEM_CACHE()
    for_each_possible_cpu()
    INIT_LIST_HEAD()
    per_cpu()
    init_rwsem()
test_taint() <int test_taint (unsigned flag) at panic.c:311>:
    test_bit()
thaw_workqueues() <void thaw_workqueues (void) at workqueue.c:4809>:
    mutex_lock()
    list_for_each_entry()
    for_each_pwq()
    pwq_adjust_max_active() <void pwq_adjust_max_active (struct pool_workqueue *pwq) at workqueue.c:3415>:
        lockdep_assert_held()
        spin_lock_irq()
        list_empty()
        pwq_activate_first_delayed() <void pwq_activate_first_delayed (struct pool_workqueue *pwq) at workqueue.c:1121>:
            list_first_entry()
            pwq_activate_delayed_work() <void pwq_activate_delayed_work (struct work_struct *work) at workqueue.c:1109>:
                get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                    atomic_long_read()
                trace_workqueue_activate_work()
                list_empty()
                move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                    list_for_each_entry_safe_from()
                    list_move_tail()
                    work_data_bits()
                work_data_bits()
        wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
            first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                unlikely()
                list_empty()
                list_first_entry()
            likely()
            wake_up_process()
        spin_unlock_irq()
    mutex_unlock()
thread_info_cache_init() <void thread_info_cache_init (void) at fork.c:188>:
    kmem_cache_create()
    BUG_ON()
to_vmem_altmap() <struct vmem_altmap *to_vmem_altmap (unsigned long memmap_start) at memremap.c:387>:
    rcu_read_lock()
    find_dev_pagemap() <struct dev_pagemap *find_dev_pagemap (resource_size_t phys) at memremap.c:245>:
        WARN_ON_ONCE()
        rcu_read_lock_held()
        radix_tree_lookup()
    page_to_pfn()
    rcu_read_unlock()
torture_cleanup_begin() <bool torture_cleanup_begin (void) at torture.c:643>:
    mutex_lock()
    READ_ONCE()
    pr_warn()
    mutex_unlock()
    schedule_timeout_uninterruptible()
    WRITE_ONCE()
    torture_shutdown_cleanup() <void torture_shutdown_cleanup (void) at torture.c:501>:
        unregister_reboot_notifier() <int unregister_reboot_notifier (struct notifier_block *nb) at reboot.c:101>:
            blocking_notifier_chain_unregister() <int blocking_notifier_chain_unregister (struct blocking_notifier_head *nh, struct notifier_block *n) at notifier.c:266>:
                unlikely()
                notifier_chain_unregister() <int notifier_chain_unregister (struct notifier_block **nl, struct notifier_block *n) at notifier.c:49>:
                    rcu_assign_pointer()
                down_write()
                up_write()
        VERBOSE_TOROUT_STRING()
        kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
            trace_sched_kthread_stop()
            get_task_struct()
            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                ACCESS_ONCE()
                likely()
            set_bit()
            wake_up_process()
            wait_for_completion()
            put_task_struct()
            trace_sched_kthread_stop_ret()
    torture_shuffle_cleanup() <void torture_shuffle_cleanup (void) at torture.c:385>:
        torture_shuffle_task_unregister_all() <void torture_shuffle_task_unregister_all (void) at torture.c:302>:
            mutex_lock()
            list_for_each_entry_safe()
            list_del()
            kfree()
            mutex_unlock()
        VERBOSE_TOROUT_STRING()
        kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
            trace_sched_kthread_stop()
            get_task_struct()
            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                ACCESS_ONCE()
                likely()
            set_bit()
            wake_up_process()
            wait_for_completion()
            put_task_struct()
            trace_sched_kthread_stop_ret()
        free_cpumask_var()
    torture_stutter_cleanup() <void torture_stutter_cleanup (void) at torture.c:583>:
        VERBOSE_TOROUT_STRING()
        kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
            trace_sched_kthread_stop()
            get_task_struct()
            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                ACCESS_ONCE()
                likely()
            set_bit()
            wake_up_process()
            wait_for_completion()
            put_task_struct()
            trace_sched_kthread_stop_ret()
    torture_onoff_cleanup() <void torture_onoff_cleanup (void) at torture.c:199>:
        VERBOSE_TOROUT_STRING()
        kthread_stop() <int kthread_stop (struct task_struct *k) at kthread.c:479>:
            trace_sched_kthread_stop()
            get_task_struct()
            to_live_kthread() <struct kthread *to_live_kthread (struct task_struct *k) at kthread.c:64>:
                ACCESS_ONCE()
                likely()
            set_bit()
            wake_up_process()
            wait_for_completion()
            put_task_struct()
            trace_sched_kthread_stop_ret()
torture_cleanup_end() <void torture_cleanup_end (void) at torture.c:662>:
    mutex_lock()
    mutex_unlock()
torture_init_begin() <bool torture_init_begin (char *ttype, bool v, int *runnable) at torture.c:601>:
    mutex_lock()
    pr_alert()
    mutex_unlock()
torture_init_end() <void torture_init_end (void) at torture.c:621>:
    mutex_unlock()
    register_reboot_notifier() <int register_reboot_notifier (struct notifier_block *nb) at reboot.c:86>:
        blocking_notifier_chain_register() <int blocking_notifier_chain_register (struct blocking_notifier_head *nh, struct notifier_block *n) at notifier.c:213>:
            unlikely()
            notifier_chain_register() <int notifier_chain_register (struct notifier_block **nl, struct notifier_block *n) at notifier.c:21>:
                rcu_assign_pointer()
            down_write()
            up_write()
torture_kthread_stopping() <void torture_kthread_stopping (char *title) at torture.c:696>:
    VERBOSE_TOROUT_STRING()
    kthread_should_stop() <bool kthread_should_stop (void) at kthread.c:79>:
        test_bit()
        to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
    torture_shutdown_absorb() <void torture_shutdown_absorb (const char *title) at torture.c:410>:
        READ_ONCE()
        pr_notice()
        schedule_timeout_uninterruptible()
    schedule_timeout_uninterruptible()
torture_must_stop() <bool torture_must_stop (void) at torture.c:673>:
    torture_must_stop_irq() <bool torture_must_stop_irq (void) at torture.c:683>:
        READ_ONCE()
    kthread_should_stop() <bool kthread_should_stop (void) at kthread.c:79>:
        test_bit()
        to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
torture_must_stop_irq() <bool torture_must_stop_irq (void) at torture.c:683>:
    READ_ONCE()
torture_onoff_failures() <bool torture_onoff_failures (void) at torture.c:230>:
torture_onoff_init() <int torture_onoff_init (long ooholdoff, long oointerval) at torture.c:181>:
    torture_create_kthread()
    torture_onoff() <int torture_onoff (void *arg) at torture.c:89>:
        DEFINE_TORTURE_RANDOM()
        VERBOSE_TOROUT_STRING()
        for_each_online_cpu()
        WARN_ON()
        schedule_timeout_interruptible()
        torture_must_stop() <bool torture_must_stop (void) at torture.c:673>:
            torture_must_stop_irq() <bool torture_must_stop_irq (void) at torture.c:683>:
                READ_ONCE()
            kthread_should_stop() <bool kthread_should_stop (void) at kthread.c:79>:
                test_bit()
                to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
        torture_random() <unsigned long torture_random (struct torture_random_state *trsp) at torture.c:250>:
            local_clock()
            swahw32()
        cpu_online()
        cpu_is_hotpluggable()
        pr_alert()
        cpu_down() <int cpu_down (unsigned int cpu) at cpu.c:433>:
            cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
                mutex_lock()
            cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
                mutex_unlock()
        cpu_up() <int cpu_up (unsigned int cpu) at cpu.c:537>:
            cpu_possible()
            pr_err()
            try_online_node()
            cpu_to_node()
            cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
                mutex_lock()
            cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
                mutex_unlock()
        torture_kthread_stopping() <void torture_kthread_stopping (char *title) at torture.c:696>:
            VERBOSE_TOROUT_STRING()
            kthread_should_stop() <bool kthread_should_stop (void) at kthread.c:79>:
                test_bit()
                to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
            torture_shutdown_absorb() <void torture_shutdown_absorb (const char *title) at torture.c:410>:
                READ_ONCE()
                pr_notice()
                schedule_timeout_uninterruptible()
            schedule_timeout_uninterruptible()
torture_onoff_stats() <void torture_onoff_stats (void) at torture.c:214>:
    pr_cont()
torture_random() <unsigned long torture_random (struct torture_random_state *trsp) at torture.c:250>:
    local_clock()
    swahw32()
torture_shuffle_init() <int torture_shuffle_init (long shuffint) at torture.c:366>:
    alloc_cpumask_var()
    VERBOSE_TOROUT_ERRSTRING()
    torture_create_kthread()
    torture_shuffle() <int torture_shuffle (void *arg) at torture.c:351>:
        VERBOSE_TOROUT_STRING()
        schedule_timeout_interruptible()
        torture_shuffle_tasks() <void torture_shuffle_tasks (void) at torture.c:319>:
            cpumask_setall()
            get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
                might_sleep()
                cpuhp_lock_acquire_read()
                mutex_lock()
                atomic_inc()
                mutex_unlock()
            num_online_cpus()
            put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
                atomic_dec_return()
                WARN_ON()
                atomic_inc()
                waitqueue_active()
                wake_up()
                cpuhp_lock_release()
            cpumask_next()
            cpumask_clear_cpu()
            mutex_lock()
            list_for_each_entry()
            set_cpus_allowed_ptr()
            mutex_unlock()
        torture_shutdown_absorb() <void torture_shutdown_absorb (const char *title) at torture.c:410>:
            READ_ONCE()
            pr_notice()
            schedule_timeout_uninterruptible()
        torture_must_stop() <bool torture_must_stop (void) at torture.c:673>:
            torture_must_stop_irq() <bool torture_must_stop_irq (void) at torture.c:683>:
                READ_ONCE()
            kthread_should_stop() <bool kthread_should_stop (void) at kthread.c:79>:
                test_bit()
                to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
        torture_kthread_stopping() <void torture_kthread_stopping (char *title) at torture.c:696>:
            VERBOSE_TOROUT_STRING()
            kthread_should_stop() <bool kthread_should_stop (void) at kthread.c:79>:
                test_bit()
                to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
            torture_shutdown_absorb() <void torture_shutdown_absorb (const char *title) at torture.c:410>:
                READ_ONCE()
                pr_notice()
                schedule_timeout_uninterruptible()
            schedule_timeout_uninterruptible()
torture_shuffle_task_register() <void torture_shuffle_task_register (struct task_struct *tp) at torture.c:283>:
    WARN_ON_ONCE()
    kmalloc()
    mutex_lock()
    list_add()
    mutex_unlock()
torture_shutdown_absorb() <void torture_shutdown_absorb (const char *title) at torture.c:410>:
    READ_ONCE()
    pr_notice()
    schedule_timeout_uninterruptible()
torture_shutdown_init() <int torture_shutdown_init (int ssecs, void (*cleanup) (void)) at torture.c:461>:
    torture_shutdown_hook() <void (*torture_shutdown_hook) (void) at torture.c:404>
    torture_create_kthread()
    torture_shutdown() <int torture_shutdown (void *arg) at torture.c:424>:
        VERBOSE_TOROUT_STRING()
        ULONG_CMP_LT()
        torture_must_stop() <bool torture_must_stop (void) at torture.c:673>:
            torture_must_stop_irq() <bool torture_must_stop_irq (void) at torture.c:683>:
                READ_ONCE()
            kthread_should_stop() <bool kthread_should_stop (void) at kthread.c:79>:
                test_bit()
                to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
        pr_alert()
        schedule_timeout_interruptible()
        torture_kthread_stopping() <void torture_kthread_stopping (char *title) at torture.c:696>:
            VERBOSE_TOROUT_STRING()
            kthread_should_stop() <bool kthread_should_stop (void) at kthread.c:79>:
                test_bit()
                to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
            torture_shutdown_absorb() <void torture_shutdown_absorb (const char *title) at torture.c:410>:
                READ_ONCE()
                pr_notice()
                schedule_timeout_uninterruptible()
            schedule_timeout_uninterruptible()
        torture_shutdown_hook() <void (*torture_shutdown_hook) (void) at torture.c:404>
        kernel_power_off() <void kernel_power_off (void) at reboot.c:257>:
            kernel_shutdown_prepare() <void kernel_shutdown_prepare (enum system_states state) at reboot.c:228>:
                blocking_notifier_call_chain() <int blocking_notifier_call_chain (struct blocking_notifier_head *nh, unsigned long val, void *v) at notifier.c:325>:
                usermodehelper_disable()
                device_shutdown()
            pm_power_off_prepare() <void (*pm_power_off_prepare) (void) at reboot.c:51>
            migrate_to_reboot_cpu() <void migrate_to_reboot_cpu (void) at reboot.c:188>:
                cpu_hotplug_disable() <void cpu_hotplug_disable (void) at cpu.c:178>:
                    cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
                        mutex_lock()
                    cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
                        mutex_unlock()
                cpu_online()
                cpumask_first()
                set_cpus_allowed_ptr()
                cpumask_of()
            syscore_shutdown()
            pr_emerg()
            kmsg_dump()
            machine_power_off()
torture_stutter_init() <int torture_stutter_init (int s) at torture.c:570>:
    torture_create_kthread()
    torture_stutter() <int torture_stutter (void *arg) at torture.c:546>:
        VERBOSE_TOROUT_STRING()
        torture_must_stop() <bool torture_must_stop (void) at torture.c:673>:
            torture_must_stop_irq() <bool torture_must_stop_irq (void) at torture.c:683>:
                READ_ONCE()
            kthread_should_stop() <bool kthread_should_stop (void) at kthread.c:79>:
                test_bit()
                to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
        schedule_timeout_interruptible()
        WRITE_ONCE()
        torture_shutdown_absorb() <void torture_shutdown_absorb (const char *title) at torture.c:410>:
            READ_ONCE()
            pr_notice()
            schedule_timeout_uninterruptible()
        torture_kthread_stopping() <void torture_kthread_stopping (char *title) at torture.c:696>:
            VERBOSE_TOROUT_STRING()
            kthread_should_stop() <bool kthread_should_stop (void) at kthread.c:79>:
                test_bit()
                to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
            torture_shutdown_absorb() <void torture_shutdown_absorb (const char *title) at torture.c:410>:
                READ_ONCE()
                pr_notice()
                schedule_timeout_uninterruptible()
            schedule_timeout_uninterruptible()
touch_all_softlockup_watchdogs() <void touch_all_softlockup_watchdogs (void) at watchdog.c:253>:
    for_each_watchdog_cpu()
    per_cpu()
    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
        per_cpu()
touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
    raw_cpu_write()
    touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
        touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
            raw_cpu_write()
        wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
            per_cpu()
        raw_smp_processor_id()
touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
        raw_cpu_write()
    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
        per_cpu()
    raw_smp_processor_id()
touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
    raw_cpu_write()
touch_softlockup_watchdog_sync() <void touch_softlockup_watchdog_sync (void) at watchdog.c:284>:
trace_module_has_bad_taint() <bool trace_module_has_bad_taint (struct module *mod) at tracepoint.c:326>:
tracepoint_probe_register() <int tracepoint_probe_register (struct tracepoint *tp, void *probe, void *data) at tracepoint.c:297>:
    tracepoint_probe_register_prio() <int tracepoint_probe_register_prio (struct tracepoint *tp, void *probe, void *data, int prio) at tracepoint.c:268>:
        mutex_lock()
        tracepoint_add_func() <int tracepoint_add_func (struct tracepoint *tp, struct tracepoint_func *func, int prio) at tracepoint.c:193>:
            static_key_enabled()
            rcu_dereference_protected()
            lockdep_is_held()
            func_add() <struct tracepoint_func *func_add (struct tracepoint_func **funcs, struct tracepoint_func *tp_func, int prio) at tracepoint.c:95>:
                WARN_ON()
                ERR_PTR()
                debug_print_probes() <void debug_print_probes (struct tracepoint_func *funcs) at tracepoint.c:83>:
                    func()
                    printk()
                func()
                allocate_probes() <inline void *allocate_probes (int count) at tracepoint.c:62>:
                    kmalloc()
            IS_ERR()
            WARN_ON_ONCE()
            PTR_ERR()
            rcu_assign_pointer()
            static_key_slow_inc() <void static_key_slow_inc (struct static_key *key) at jump_label.c:59>:
                STATIC_KEY_CHECK_USE()
                atomic_inc_not_zero()
                jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                    mutex_lock()
                atomic_inc_return()
                jump_label_update() <void jump_label_update (struct static_key *key) at jump_label.c:465>:
                    static_key_entries() <inline struct jump_entry *static_key_entries (struct static_key *key) at jump_label.c:156>:
                    preempt_disable()
                    preempt_enable()
                jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                    mutex_unlock()
            release_probes() <inline void release_probes (struct tracepoint_func *old) at tracepoint.c:74>:
                container_of()
                call_rcu_sched()
                rcu_free_old_probes() <void rcu_free_old_probes (struct rcu_head *head) at tracepoint.c:69>:
                    kfree()
                    container_of()
        mutex_unlock()
tracepoint_probe_register_prio() <int tracepoint_probe_register_prio (struct tracepoint *tp, void *probe, void *data, int prio) at tracepoint.c:268>:
    mutex_lock()
    tracepoint_add_func() <int tracepoint_add_func (struct tracepoint *tp, struct tracepoint_func *func, int prio) at tracepoint.c:193>:
        static_key_enabled()
        rcu_dereference_protected()
        lockdep_is_held()
        func_add() <struct tracepoint_func *func_add (struct tracepoint_func **funcs, struct tracepoint_func *tp_func, int prio) at tracepoint.c:95>:
            WARN_ON()
            ERR_PTR()
            debug_print_probes() <void debug_print_probes (struct tracepoint_func *funcs) at tracepoint.c:83>:
                func()
                printk()
            func()
            allocate_probes() <inline void *allocate_probes (int count) at tracepoint.c:62>:
                kmalloc()
        IS_ERR()
        WARN_ON_ONCE()
        PTR_ERR()
        rcu_assign_pointer()
        static_key_slow_inc() <void static_key_slow_inc (struct static_key *key) at jump_label.c:59>:
            STATIC_KEY_CHECK_USE()
            atomic_inc_not_zero()
            jump_label_lock() <void jump_label_lock (void) at jump_label.c:23>:
                mutex_lock()
            atomic_inc_return()
            jump_label_update() <void jump_label_update (struct static_key *key) at jump_label.c:465>:
                static_key_entries() <inline struct jump_entry *static_key_entries (struct static_key *key) at jump_label.c:156>:
                preempt_disable()
                preempt_enable()
            jump_label_unlock() <void jump_label_unlock (void) at jump_label.c:28>:
                mutex_unlock()
        release_probes() <inline void release_probes (struct tracepoint_func *old) at tracepoint.c:74>:
            container_of()
            call_rcu_sched()
            rcu_free_old_probes() <void rcu_free_old_probes (struct rcu_head *head) at tracepoint.c:69>:
                kfree()
                container_of()
    mutex_unlock()
tracepoint_probe_unregister() <int tracepoint_probe_unregister (struct tracepoint *tp, void *probe, void *data) at tracepoint.c:311>:
    mutex_lock()
    tracepoint_remove_func() <int tracepoint_remove_func (struct tracepoint *tp, struct tracepoint_func *func) at tracepoint.c:229>:
        rcu_dereference_protected()
        lockdep_is_held()
        func_remove() <void *func_remove (struct tracepoint_func **funcs, struct tracepoint_func *tp_func) at tracepoint.c:142>:
            ERR_PTR()
            debug_print_probes() <void debug_print_probes (struct tracepoint_func *funcs) at tracepoint.c:83>:
                func()
                printk()
            func()
            allocate_probes() <inline void *allocate_probes (int count) at tracepoint.c:62>:
                kmalloc()
        IS_ERR()
        WARN_ON_ONCE()
        PTR_ERR()
        static_key_enabled()
        static_key_slow_dec() <void static_key_slow_dec (struct static_key *key) at jump_label.c:97>:
            STATIC_KEY_CHECK_USE()
        rcu_assign_pointer()
        release_probes() <inline void release_probes (struct tracepoint_func *old) at tracepoint.c:74>:
            container_of()
            call_rcu_sched()
            rcu_free_old_probes() <void rcu_free_old_probes (struct rcu_head *head) at tracepoint.c:69>:
                kfree()
                container_of()
    mutex_unlock()
transfer_pid() <void transfer_pid (struct task_struct *old, struct task_struct *new, enum pid_type type) at pid.c:428>:
    hlist_replace_rcu()
try_module_get() <bool try_module_get (struct module *module) at module.c:1079>:
    preempt_disable()
    likely()
    module_is_live()
    atomic_inc_not_zero()
    trace_module_get()
    preempt_enable()
try_stop_cpus() <int try_stop_cpus (const struct cpumask *cpumask, cpu_stop_fn_t fn, void *arg) at stop_machine.c:410>:
    mutex_trylock()
    mutex_unlock()
tsk_fork_get_node() <int tsk_fork_get_node (struct task_struct *tsk) at kthread.c:216>:
unhandled_signal() <int unhandled_signal (struct task_struct *tsk, int sig) at signal.c:495>:
    is_global_init()
unregister_cpu_notifier() <void unregister_cpu_notifier (struct notifier_block *nb) at cpu.c:235>:
    cpu_maps_update_begin() <void cpu_maps_update_begin (void) at cpu.c:40>:
        mutex_lock()
    raw_notifier_chain_unregister() <int raw_notifier_chain_unregister (struct raw_notifier_head *nh, struct notifier_block *n) at notifier.c:364>:
        notifier_chain_unregister() <int notifier_chain_unregister (struct notifier_block **nl, struct notifier_block *n) at notifier.c:49>:
            rcu_assign_pointer()
    cpu_maps_update_done() <void cpu_maps_update_done (void) at cpu.c:46>:
        mutex_unlock()
unregister_die_notifier() <int unregister_die_notifier (struct notifier_block *nb) at notifier.c:560>:
    atomic_notifier_chain_unregister() <int atomic_notifier_chain_unregister (struct atomic_notifier_head *nh, struct notifier_block *n) at notifier.c:143>:
        spin_lock_irqsave()
        notifier_chain_unregister() <int notifier_chain_unregister (struct notifier_block **nl, struct notifier_block *n) at notifier.c:49>:
            rcu_assign_pointer()
        spin_unlock_irqrestore()
        synchronize_rcu()
unregister_jprobe() <void unregister_jprobe (struct jprobe *jp) at kprobes.c:1755>:
    unregister_jprobes() <void unregister_jprobes (struct jprobe **jps, int num) at kprobes.c:1761>:
        mutex_lock()
        mutex_unlock()
        synchronize_sched()
unregister_jprobes() <void unregister_jprobes (struct jprobe **jps, int num) at kprobes.c:1761>:
    mutex_lock()
    mutex_unlock()
    synchronize_sched()
unregister_kprobe() <void unregister_kprobe (struct kprobe *p) at kprobes.c:1683>:
    unregister_kprobes() <void unregister_kprobes (struct kprobe **kps, int num) at kprobes.c:1689>:
        mutex_lock()
        mutex_unlock()
        synchronize_sched()
unregister_kprobes() <void unregister_kprobes (struct kprobe **kps, int num) at kprobes.c:1689>:
    mutex_lock()
    mutex_unlock()
    synchronize_sched()
unregister_kretprobe() <void unregister_kretprobe (struct kretprobe *rp) at kprobes.c:1949>:
    unregister_kretprobes() <void unregister_kretprobes (struct kretprobe **rps, int num) at kprobes.c:1954>:
        mutex_lock()
        mutex_unlock()
        synchronize_sched()
        cleanup_rp_inst() <void cleanup_rp_inst (struct kretprobe *rp) at kprobes.c:1182>:
            kretprobe_table_lock() < at kprobes.c:1108>:
                kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                raw_spin_lock_irqsave()
            hlist_for_each_entry_safe()
            kretprobe_table_unlock() < at kprobes.c:1129>:
                kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
                raw_spin_unlock_irqrestore()
            free_rp_inst() <inline void free_rp_inst (struct kretprobe *rp) at kprobes.c:1171>:
                hlist_for_each_entry_safe()
                hlist_del()
                kfree()
unregister_kretprobes() <void unregister_kretprobes (struct kretprobe **rps, int num) at kprobes.c:1954>:
    mutex_lock()
    mutex_unlock()
    synchronize_sched()
    cleanup_rp_inst() <void cleanup_rp_inst (struct kretprobe *rp) at kprobes.c:1182>:
        kretprobe_table_lock() < at kprobes.c:1108>:
            kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
            raw_spin_lock_irqsave()
        hlist_for_each_entry_safe()
        kretprobe_table_unlock() < at kprobes.c:1129>:
            kretprobe_table_lock_ptr() <raw_spinlock_t *kretprobe_table_lock_ptr (unsigned long hash) at kprobes.c:84>:
            raw_spin_unlock_irqrestore()
        free_rp_inst() <inline void free_rp_inst (struct kretprobe *rp) at kprobes.c:1171>:
            hlist_for_each_entry_safe()
            hlist_del()
            kfree()
unregister_module_notifier() <int unregister_module_notifier (struct notifier_block *nb) at module.c:291>:
    blocking_notifier_chain_unregister() <int blocking_notifier_chain_unregister (struct blocking_notifier_head *nh, struct notifier_block *n) at notifier.c:266>:
        unlikely()
        notifier_chain_unregister() <int notifier_chain_unregister (struct notifier_block **nl, struct notifier_block *n) at notifier.c:49>:
            rcu_assign_pointer()
        down_write()
        up_write()
unregister_reboot_notifier() <int unregister_reboot_notifier (struct notifier_block *nb) at reboot.c:101>:
    blocking_notifier_chain_unregister() <int blocking_notifier_chain_unregister (struct blocking_notifier_head *nh, struct notifier_block *n) at notifier.c:266>:
        unlikely()
        notifier_chain_unregister() <int notifier_chain_unregister (struct notifier_block **nl, struct notifier_block *n) at notifier.c:49>:
            rcu_assign_pointer()
        down_write()
        up_write()
unregister_restart_handler() <int unregister_restart_handler (struct notifier_block *nb) at reboot.c:166>:
    atomic_notifier_chain_unregister() <int atomic_notifier_chain_unregister (struct atomic_notifier_head *nh, struct notifier_block *n) at notifier.c:143>:
        spin_lock_irqsave()
        notifier_chain_unregister() <int notifier_chain_unregister (struct notifier_block **nl, struct notifier_block *n) at notifier.c:49>:
            rcu_assign_pointer()
        spin_unlock_irqrestore()
        synchronize_rcu()
unregister_tracepoint_module_notifier() <int unregister_tracepoint_module_notifier (struct notifier_block *nb) at tracepoint.c:367>:
    mutex_lock()
    blocking_notifier_chain_unregister() <int blocking_notifier_chain_unregister (struct blocking_notifier_head *nh, struct notifier_block *n) at notifier.c:266>:
        unlikely()
        notifier_chain_unregister() <int notifier_chain_unregister (struct notifier_block **nl, struct notifier_block *n) at notifier.c:49>:
            rcu_assign_pointer()
        down_write()
        up_write()
    list_for_each_entry()
    mutex_unlock()
unshare_files() <int unshare_files (struct files_struct **displaced) at fork.c:2078>:
    unshare_fd() <int unshare_fd (unsigned long unshare_flags, struct files_struct **new_fdp) at fork.c:1935>:
        atomic_read()
        dup_fd()
    task_lock()
    task_unlock()
unshare_nsproxy_namespaces() <int unshare_nsproxy_namespaces (unsigned long unshare_flags, struct nsproxy **new_nsp, struct cred *new_cred, struct fs_struct *new_fs) at nsproxy.c:176>:
    current_user_ns()
    ns_capable() <bool ns_capable (struct user_namespace *ns, int cap) at capability.c:375>:
        unlikely()
        cap_valid()
        pr_crit()
        BUG()
        security_capable()
        current_cred()
    create_new_namespaces() <struct nsproxy *create_new_namespaces (unsigned long flags, struct task_struct *tsk, struct user_namespace *user_ns, struct fs_struct *new_fs) at nsproxy.c:59>:
        create_nsproxy() <inline struct nsproxy *create_nsproxy (void) at nsproxy.c:44>:
            kmem_cache_alloc()
            atomic_set()
        ERR_PTR()
        copy_mnt_ns()
        IS_ERR()
        PTR_ERR()
        copy_utsname() <struct uts_namespace *copy_utsname (unsigned long flags, struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:66>:
            BUG_ON()
            get_uts_ns()
            clone_uts_ns() <struct uts_namespace *clone_uts_ns (struct user_namespace *user_ns, struct uts_namespace *old_ns) at utsname.c:35>:
                create_uts_ns() <struct uts_namespace *create_uts_ns (void) at utsname.c:20>:
                    kmalloc()
                    kref_init()
                ERR_PTR()
                ns_alloc_inum()
                kfree()
                down_read()
                get_user_ns()
                up_read()
            put_uts_ns()
        copy_ipcs()
        copy_pid_ns() <struct pid_namespace *copy_pid_ns (unsigned long flags, struct user_namespace *user_ns, struct pid_namespace *old_ns) at pid_namespace.c:153>:
            get_pid_ns()
            task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                ns_of_pid()
                task_pid()
            ERR_PTR()
            create_pid_namespace() <struct pid_namespace *create_pid_namespace (struct user_namespace *user_ns, struct pid_namespace *parent_pid_ns) at pid_namespace.c:82>:
                kmem_cache_zalloc()
                kzalloc()
                create_pid_cachep() <struct kmem_cache *create_pid_cachep (int nr_ids) at pid_namespace.c:38>:
                    mutex_lock()
                    list_for_each_entry()
                    kmalloc()
                    kmem_cache_create()
                    list_add()
                    mutex_unlock()
                    kfree()
                ns_alloc_inum()
                kref_init()
                get_pid_ns()
                get_user_ns()
                INIT_WORK()
                proc_cleanup_work() <void proc_cleanup_work (struct work_struct *work) at pid_namespace.c:73>:
                    container_of()
                    pid_ns_release_proc()
                set_bit()
                atomic_set()
                kfree()
                kmem_cache_free()
                ERR_PTR()
        copy_net_ns()
        put_pid_ns() <void put_pid_ns (struct pid_namespace *ns) at pid_namespace.c:171>:
            kref_put()
            free_pid_ns() <void free_pid_ns (struct kref *kref) at pid_namespace.c:163>:
                container_of()
                destroy_pid_namespace() <void destroy_pid_namespace (struct pid_namespace *ns) at pid_namespace.c:142>:
                    ns_free_inum()
                    kfree()
                    put_user_ns()
                    call_rcu()
                    delayed_free_pidns() <void delayed_free_pidns (struct rcu_head *p) at pid_namespace.c:136>:
                        kmem_cache_free()
                        container_of()
        put_ipc_ns()
        put_uts_ns()
        put_mnt_ns()
        kmem_cache_free()
    IS_ERR()
    PTR_ERR()
unshare_userns() <int unshare_userns (unsigned long unshare_flags, struct cred **new_cred) at user_namespace.c:118>:
    prepare_creds() <struct cred *prepare_creds (void) at cred.c:243>:
        validate_process_creds()
        kmem_cache_alloc()
        kdebug()
        atomic_set()
        set_cred_subscribers() <inline void set_cred_subscribers (struct cred *cred, int n) at cred.c:67>:
            atomic_set()
        get_group_info()
        get_uid()
        get_user_ns()
        key_get()
        security_prepare_creds()
        validate_creds()
        abort_creds() <void abort_creds (struct cred *new) at cred.c:499>:
            kdebug()
            atomic_read()
            read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
                atomic_read()
            BUG_ON()
            put_cred()
    create_user_ns() <int create_user_ns (struct cred *new) at user_namespace.c:60>:
        current_chrooted()
        kuid_has_mapping()
        kgid_has_mapping()
        kmem_cache_zalloc()
        ns_alloc_inum()
        kmem_cache_free()
        atomic_set()
        mutex_lock()
        mutex_unlock()
        set_cred_user_ns() <void set_cred_user_ns (struct cred *cred, struct user_namespace *user_ns) at user_namespace.c:33>:
            key_put()
        init_rwsem()
    put_cred()
user_return_notifier_register() <void user_return_notifier_register (struct user_return_notifier *urn) at user-return-notifier.c:14>:
    set_tsk_thread_flag()
    hlist_add_head()
    this_cpu_ptr()
user_return_notifier_unregister() <void user_return_notifier_unregister (struct user_return_notifier *urn) at user-return-notifier.c:25>:
    hlist_del()
    hlist_empty()
    this_cpu_ptr()
    clear_tsk_thread_flag()
usermodehelper_read_lock_wait() <long usermodehelper_read_lock_wait (long timeout) at kmod.c:403>:
    DEFINE_WAIT()
    down_read()
    prepare_to_wait()
    up_read()
    schedule_timeout()
    finish_wait()
usermodehelper_read_trylock() <int usermodehelper_read_trylock (void) at kmod.c:373>:
    DEFINE_WAIT()
    down_read()
    prepare_to_wait()
    up_read()
    schedule()
    try_to_freeze()
    finish_wait()
usermodehelper_read_unlock() <void usermodehelper_read_unlock (void) at kmod.c:430>:
    up_read()
userns_may_setgroups() <bool userns_may_setgroups (const struct user_namespace *ns) at user_namespace.c:925>:
    mutex_lock()
    mutex_unlock()
uts_proc_notify() <void uts_proc_notify (enum uts_proc proc) at utsname_sysctl.c:124>:
    proc_sys_poll_notify()
validate_creds_for_do_exit() <void validate_creds_for_do_exit (struct task_struct *tsk) at cred.c:805>:
    kdebug()
    atomic_read()
    read_cred_subscribers() <inline int read_cred_subscribers (const struct cred *cred) at cred.c:74>:
        atomic_read()
vmcoreinfo_append_str() <void vmcoreinfo_append_str (const char *fmt, ...) at kexec_core.c:1352>:
    vscnprintf()
    min()
wake_up_all_idle_cpus() <void wake_up_all_idle_cpus (void) at smp.c:728>:
    preempt_disable()
    for_each_online_cpu()
    smp_processor_id()
    wake_up_if_idle()
    preempt_enable()
walk_iomem_res() <int walk_iomem_res (char *name, unsigned long flags, u64 start, u64 end, void *arg, int (*func) (u64, u64, void *)) at resource.c:395>:
    find_next_iomem_res() <int find_next_iomem_res (struct resource *res, char *name, bool first_level_children_only) at resource.c:342>:
        start()
        BUG_ON()
        read_lock()
        next_resource() <struct resource *next_resource (struct resource *p, bool sibling_only) at resource.c:63>
        read_unlock()
walk_system_ram_range() <int walk_system_ram_range (unsigned long start_pfn, unsigned long nr_pages, void *arg, int (*func) (unsigned long, unsigned long, void *)) at resource.c:453>:
    find_next_iomem_res() <int find_next_iomem_res (struct resource *res, char *name, bool first_level_children_only) at resource.c:342>:
        start()
        BUG_ON()
        read_lock()
        next_resource() <struct resource *next_resource (struct resource *p, bool sibling_only) at resource.c:63>
        read_unlock()
walk_system_ram_res() <int walk_system_ram_res (u64 start, u64 end, void *arg, int (*func) (u64, u64, void *)) at resource.c:424>:
    find_next_iomem_res() <int find_next_iomem_res (struct resource *res, char *name, bool first_level_children_only) at resource.c:342>:
        start()
        BUG_ON()
        read_lock()
        next_resource() <struct resource *next_resource (struct resource *p, bool sibling_only) at resource.c:63>
        read_unlock()
warn_slowpath_fmt() <void warn_slowpath_fmt (const char *file, int line, const char *fmt, ...) at panic.c:488>:
    warn_slowpath_common() <void warn_slowpath_common (const char *file, int line, void *caller, unsigned taint, struct slowpath_args *args) at panic.c:458>:
        disable_trace_on_warning()
        pr_warn()
        raw_smp_processor_id()
        vprintk()
        panic() <void panic (const char *fmt, ...) at panic.c:83>:
            local_irq_disable()
            raw_smp_processor_id()
            atomic_cmpxchg()
            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                cpu_relax()
            console_verbose()
            bust_spinlocks()
            pr_emerg()
            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                test_bit()
            dump_stack()
            smp_send_stop()
            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
            kmsg_dump()
            debug_locks_off()
            console_flush_on_panic()
            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
            no_blink() <long no_blink (int state) at panic.c:46>
            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                raw_cpu_write()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            mdelay()
            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                kmsg_dump()
                machine_emergency_restart()
            disabled_wait()
            local_irq_enable()
            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                    raw_cpu_write()
                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                    per_cpu()
                raw_smp_processor_id()
        print_modules() <void print_modules (void) at module.c:4084>:
            printk()
            preempt_disable()
            list_for_each_entry_rcu()
            pr_cont()
            module_flags() <char *module_flags (struct module *mod, char *buf) at module.c:3872>:
                BUG_ON()
                module_flags_taint() <size_t module_flags_taint (struct module *mod, char *buf) at module.c:1135>:
            preempt_enable()
        dump_stack()
        print_oops_end_marker() <void print_oops_end_marker (void) at panic.c:435>:
            init_oops_id() <int init_oops_id (void) at panic.c:424>:
                get_random_bytes()
            pr_warn()
        add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
            pr_warn()
            set_bit()
warn_slowpath_fmt_taint() <void warn_slowpath_fmt_taint (const char *file, int line, unsigned taint, const char *fmt, ...) at panic.c:500>:
    warn_slowpath_common() <void warn_slowpath_common (const char *file, int line, void *caller, unsigned taint, struct slowpath_args *args) at panic.c:458>:
        disable_trace_on_warning()
        pr_warn()
        raw_smp_processor_id()
        vprintk()
        panic() <void panic (const char *fmt, ...) at panic.c:83>:
            local_irq_disable()
            raw_smp_processor_id()
            atomic_cmpxchg()
            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                cpu_relax()
            console_verbose()
            bust_spinlocks()
            pr_emerg()
            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                test_bit()
            dump_stack()
            smp_send_stop()
            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
            kmsg_dump()
            debug_locks_off()
            console_flush_on_panic()
            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
            no_blink() <long no_blink (int state) at panic.c:46>
            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                raw_cpu_write()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            mdelay()
            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                kmsg_dump()
                machine_emergency_restart()
            disabled_wait()
            local_irq_enable()
            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                    raw_cpu_write()
                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                    per_cpu()
                raw_smp_processor_id()
        print_modules() <void print_modules (void) at module.c:4084>:
            printk()
            preempt_disable()
            list_for_each_entry_rcu()
            pr_cont()
            module_flags() <char *module_flags (struct module *mod, char *buf) at module.c:3872>:
                BUG_ON()
                module_flags_taint() <size_t module_flags_taint (struct module *mod, char *buf) at module.c:1135>:
            preempt_enable()
        dump_stack()
        print_oops_end_marker() <void print_oops_end_marker (void) at panic.c:435>:
            init_oops_id() <int init_oops_id (void) at panic.c:424>:
                get_random_bytes()
            pr_warn()
        add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
            pr_warn()
            set_bit()
warn_slowpath_null() <void warn_slowpath_null (const char *file, int line) at panic.c:513>:
    warn_slowpath_common() <void warn_slowpath_common (const char *file, int line, void *caller, unsigned taint, struct slowpath_args *args) at panic.c:458>:
        disable_trace_on_warning()
        pr_warn()
        raw_smp_processor_id()
        vprintk()
        panic() <void panic (const char *fmt, ...) at panic.c:83>:
            local_irq_disable()
            raw_smp_processor_id()
            atomic_cmpxchg()
            panic_smp_self_stop() <void __weak panic_smp_self_stop (void) at panic.c:58>:
                cpu_relax()
            console_verbose()
            bust_spinlocks()
            pr_emerg()
            test_taint() <int test_taint (unsigned flag) at panic.c:311>:
                test_bit()
            dump_stack()
            smp_send_stop()
            atomic_notifier_call_chain() <int atomic_notifier_call_chain (struct atomic_notifier_head *nh, unsigned long val, void *v) at notifier.c:190>:
            kmsg_dump()
            debug_locks_off()
            console_flush_on_panic()
            panic_blink() <long (*panic_blink) (int state) at panic.c:52>
            no_blink() <long no_blink (int state) at panic.c:46>
            touch_nmi_watchdog() <void touch_nmi_watchdog (void) at watchdog.c:268>:
                raw_cpu_write()
                touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                    touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                        raw_cpu_write()
                    wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                        per_cpu()
                    raw_smp_processor_id()
            mdelay()
            emergency_restart() <void emergency_restart (void) at reboot.c:61>:
                kmsg_dump()
                machine_emergency_restart()
            disabled_wait()
            local_irq_enable()
            touch_softlockup_watchdog() <void touch_softlockup_watchdog (void) at watchdog.c:246>:
                touch_softlockup_watchdog_sched() <void touch_softlockup_watchdog_sched (void) at watchdog.c:237>:
                    raw_cpu_write()
                wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
                    per_cpu()
                raw_smp_processor_id()
        print_modules() <void print_modules (void) at module.c:4084>:
            printk()
            preempt_disable()
            list_for_each_entry_rcu()
            pr_cont()
            module_flags() <char *module_flags (struct module *mod, char *buf) at module.c:3872>:
                BUG_ON()
                module_flags_taint() <size_t module_flags_taint (struct module *mod, char *buf) at module.c:1135>:
            preempt_enable()
        dump_stack()
        print_oops_end_marker() <void print_oops_end_marker (void) at panic.c:435>:
            init_oops_id() <int init_oops_id (void) at panic.c:424>:
                get_random_bytes()
            pr_warn()
        add_taint() <void add_taint (unsigned flag, enum lockdep_ok lockdep_ok) at panic.c:330>:
            pr_warn()
            set_bit()
within_kprobe_blacklist() <bool within_kprobe_blacklist (unsigned long addr) at kprobes.c:1335>:
    arch_within_kprobe_blacklist() <bool __weak arch_within_kprobe_blacklist (unsigned long addr) at kprobes.c:1328>:
    list_for_each_entry()
work_busy() <unsigned int work_busy (struct work_struct *work) at workqueue.c:4175>:
    work_pending()
    local_irq_save()
    get_work_pool() <struct worker_pool *get_work_pool (struct work_struct *work) at workqueue.c:703>:
        atomic_long_read()
        assert_rcu_or_pool_mutex()
        idr_find()
    spin_lock()
    find_worker_executing_work() <struct worker *find_worker_executing_work (struct worker_pool *pool, struct work_struct *work) at workqueue.c:996>:
        hash_for_each_possible()
    spin_unlock()
    local_irq_restore()
work_on_cpu() <long work_on_cpu (int cpu, long (*fn) (void *), void *arg) at workqueue.c:4709>:
    INIT_WORK_ONSTACK()
    work_for_cpu_fn() <void work_for_cpu_fn (struct work_struct *work) at workqueue.c:4691>:
        container_of()
    schedule_work_on()
    flush_work() <bool flush_work (struct work_struct *work) at workqueue.c:2841>:
        lock_map_acquire()
        lock_map_release()
        start_flush_work() <bool start_flush_work (struct work_struct *work, struct wq_barrier *barr) at workqueue.c:2779>:
            might_sleep()
            local_irq_disable()
            get_work_pool() <struct worker_pool *get_work_pool (struct work_struct *work) at workqueue.c:703>:
                atomic_long_read()
                assert_rcu_or_pool_mutex()
                idr_find()
            local_irq_enable()
            spin_lock()
            get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                atomic_long_read()
            unlikely()
            find_worker_executing_work() <struct worker *find_worker_executing_work (struct worker_pool *pool, struct work_struct *work) at workqueue.c:996>:
                hash_for_each_possible()
            check_flush_dependency() <void check_flush_dependency (struct workqueue_struct *target_wq, struct work_struct *target_work) at workqueue.c:2403>:
                current_wq_worker()
                WARN_ONCE()
            insert_wq_barrier() <void insert_wq_barrier (struct pool_workqueue *pwq, struct wq_barrier *barr, struct work_struct *target, struct worker *worker) at workqueue.c:2460>:
                INIT_WORK_ONSTACK()
                wq_barrier_func() <void wq_barrier_func (struct work_struct *work) at workqueue.c:2430>:
                    container_of()
                    complete()
                work_data_bits()
                init_completion()
                debug_work_activate() <inline void debug_work_activate (struct work_struct *work) at workqueue.c:547>:
                    debug_object_activate()
                insert_work() <void insert_work (struct pool_workqueue *pwq, struct work_struct *work, struct list_head *head, unsigned int extra_flags) at workqueue.c:1290>:
                    set_work_pwq() <void set_work_pwq (struct work_struct *work, struct pool_workqueue *pwq, unsigned long extra_flags) at workqueue.c:645>:
                        set_work_data() <inline void set_work_data (struct work_struct *work, unsigned long data, unsigned long flags) at workqueue.c:638>:
                            WARN_ON_ONCE()
                            work_pending()
                            atomic_long_set()
                            work_static()
                    list_add_tail()
                    get_pwq() <void get_pwq (struct pool_workqueue *pwq) at workqueue.c:1058>:
                        lockdep_assert_held()
                        WARN_ON_ONCE()
                    smp_mb()
                    wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
                        first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                            unlikely()
                            list_empty()
                            list_first_entry()
                        likely()
                        wake_up_process()
                work_color_to_flags() <unsigned int work_color_to_flags (int color) at workqueue.c:602>:
            spin_unlock_irq()
            lock_map_acquire()
            lock_map_acquire_read()
            lock_map_release()
        wait_for_completion()
        destroy_work_on_stack() <void destroy_work_on_stack (struct work_struct *work) at workqueue.c:533>:
            debug_object_free()
    destroy_work_on_stack() <void destroy_work_on_stack (struct work_struct *work) at workqueue.c:533>:
        debug_object_free()
workqueue_congested() <bool workqueue_congested (int cpu, struct workqueue_struct *wq) at workqueue.c:4142>:
    rcu_read_lock_sched()
    smp_processor_id()
    per_cpu_ptr()
    unbound_pwq_by_node() <struct pool_workqueue *unbound_pwq_by_node (struct workqueue_struct *wq, int node) at workqueue.c:585>:
        assert_rcu_or_wq_mutex_or_pool_mutex()
        unlikely()
        rcu_dereference_raw()
    cpu_to_node()
    list_empty()
    rcu_read_unlock_sched()
workqueue_set_max_active() <void workqueue_set_max_active (struct workqueue_struct *wq, int max_active) at workqueue.c:4088>:
    WARN_ON()
    wq_clamp_max_active() <int wq_clamp_max_active (int max_active, unsigned int flags, const char *name) at workqueue.c:3882>:
        pr_warn()
        clamp_val()
    mutex_lock()
    for_each_pwq()
    pwq_adjust_max_active() <void pwq_adjust_max_active (struct pool_workqueue *pwq) at workqueue.c:3415>:
        lockdep_assert_held()
        spin_lock_irq()
        list_empty()
        pwq_activate_first_delayed() <void pwq_activate_first_delayed (struct pool_workqueue *pwq) at workqueue.c:1121>:
            list_first_entry()
            pwq_activate_delayed_work() <void pwq_activate_delayed_work (struct work_struct *work) at workqueue.c:1109>:
                get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                    atomic_long_read()
                trace_workqueue_activate_work()
                list_empty()
                move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                    list_for_each_entry_safe_from()
                    list_move_tail()
                    work_data_bits()
                work_data_bits()
        wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
            first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                unlikely()
                list_empty()
                list_first_entry()
            likely()
            wake_up_process()
        spin_unlock_irq()
    mutex_unlock()
workqueue_set_unbound_cpumask() <int workqueue_set_unbound_cpumask (cpumask_var_t cpumask) at workqueue.c:4880>:
    zalloc_cpumask_var()
    cpumask_and()
    cpumask_empty()
    apply_wqattrs_lock() <void apply_wqattrs_lock (void) at workqueue.c:3697>:
        get_online_cpus() <void get_online_cpus (void) at cpu.c:93>:
            might_sleep()
            cpuhp_lock_acquire_read()
            mutex_lock()
            atomic_inc()
            mutex_unlock()
        mutex_lock()
    cpumask_copy()
    workqueue_apply_unbound_cpumask() <int workqueue_apply_unbound_cpumask (void) at workqueue.c:4834>:
        LIST_HEAD()
        lockdep_assert_held()
        list_for_each_entry()
        apply_wqattrs_prepare() <struct apply_wqattrs_ctx *apply_wqattrs_prepare (struct workqueue_struct *wq, const struct workqueue_attrs *attrs) at workqueue.c:3605>:
            lockdep_assert_held()
            kzalloc()
            alloc_workqueue_attrs() <struct workqueue_attrs *alloc_workqueue_attrs (gfp_t gfp_mask) at workqueue.c:3112>:
                kzalloc()
                alloc_cpumask_var()
                cpumask_copy()
                free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                    free_cpumask_var()
                    kfree()
            copy_workqueue_attrs() <void copy_workqueue_attrs (struct workqueue_attrs *to, const struct workqueue_attrs *from) at workqueue.c:3129>:
                cpumask_copy()
            cpumask_and()
            unlikely()
            cpumask_empty()
            cpumask_copy()
            alloc_unbound_pwq() <struct pool_workqueue *alloc_unbound_pwq (struct workqueue_struct *wq, const struct workqueue_attrs *attrs) at workqueue.c:3493>:
                lockdep_assert_held()
                get_unbound_pool() <struct worker_pool *get_unbound_pool (const struct workqueue_attrs *attrs) at workqueue.c:3307>:
                    wqattrs_hash() <u32 wqattrs_hash (const struct workqueue_attrs *attrs) at workqueue.c:3143>:
                        jhash_1word()
                        jhash()
                        cpumask_bits()
                        BITS_TO_LONGS()
                    lockdep_assert_held()
                    hash_for_each_possible()
                    wqattrs_equal() <bool wqattrs_equal (const struct workqueue_attrs *a, const struct workqueue_attrs *b) at workqueue.c:3154>:
                        cpumask_equal()
                    for_each_node()
                    cpumask_subset()
                    kzalloc_node()
                    init_worker_pool() <int init_worker_pool (struct worker_pool *pool) at workqueue.c:3174>:
                        spin_lock_init()
                        INIT_LIST_HEAD()
                        hash_init()
                        init_timer_deferrable()
                        idle_worker_timeout() <void idle_worker_timeout (unsigned long __pool) at workqueue.c:1833>:
                            spin_lock_irq()
                            too_many_workers() <bool too_many_workers (struct worker_pool *pool) at workqueue.c:798>:
                                mutex_is_locked()
                            list_entry()
                            time_before()
                            mod_timer()
                            destroy_worker() <void destroy_worker (struct worker *worker) at workqueue.c:1813>:
                                lockdep_assert_held()
                                WARN_ON()
                                list_empty()
                                list_del_init()
                                wake_up_process()
                            spin_unlock_irq()
                        setup_timer()
                        pool_mayday_timeout() <void pool_mayday_timeout (unsigned long __pool) at workqueue.c:1881>:
                            spin_lock_irq()
                            spin_lock()
                            need_to_create_worker() <bool need_to_create_worker (struct worker_pool *pool) at workqueue.c:792>:
                                need_more_worker() <bool need_more_worker (struct worker_pool *pool) at workqueue.c:773>:
                                    list_empty()
                                may_start_working() <bool may_start_working (struct worker_pool *pool) at workqueue.c:779>
                            list_for_each_entry()
                            send_mayday() <void send_mayday (struct work_struct *work) at workqueue.c:1858>:
                                get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                                    atomic_long_read()
                                lockdep_assert_held()
                                list_empty()
                                get_pwq() <void get_pwq (struct pool_workqueue *pwq) at workqueue.c:1058>:
                                    lockdep_assert_held()
                                    WARN_ON_ONCE()
                                list_add_tail()
                                wake_up_process()
                            spin_unlock()
                            spin_unlock_irq()
                            mod_timer()
                        mutex_init()
                        ida_init()
                        INIT_HLIST_NODE()
                        alloc_workqueue_attrs() <struct workqueue_attrs *alloc_workqueue_attrs (gfp_t gfp_mask) at workqueue.c:3112>:
                            kzalloc()
                            alloc_cpumask_var()
                            cpumask_copy()
                            free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                                free_cpumask_var()
                                kfree()
                    lockdep_set_subclass()
                    copy_workqueue_attrs() <void copy_workqueue_attrs (struct workqueue_attrs *to, const struct workqueue_attrs *from) at workqueue.c:3129>:
                        cpumask_copy()
                    worker_pool_assign_id() <int worker_pool_assign_id (struct worker_pool *pool) at workqueue.c:558>:
                        lockdep_assert_held()
                        idr_alloc()
                    create_worker() <struct worker *create_worker (struct worker_pool *pool) at workqueue.c:1752>:
                        ida_simple_get()
                        alloc_worker() <struct worker *alloc_worker (int node) at workqueue.c:1665>:
                            kzalloc_node()
                            INIT_LIST_HEAD()
                        kthread_create_on_node() <struct task_struct *kthread_create_on_node (int (*threadfn) (void *data), void *data, int node, const char namefmt[], ...) at kthread.c:270>:
                            DECLARE_COMPLETION_ONSTACK()
                            kmalloc()
                            ERR_PTR()
                            spin_lock()
                            list_add_tail()
                            spin_unlock()
                            wake_up_process()
                            unlikely()
                            wait_for_completion_killable()
                            xchg()
                            wait_for_completion()
                            IS_ERR()
                            sched_setscheduler_nocheck()
                            set_cpus_allowed_ptr()
                            kfree()
                        worker_thread() <int worker_thread (void *__worker) at workqueue.c:2171>:
                            spin_lock_irq()
                            unlikely()
                            spin_unlock_irq()
                            WARN_ON_ONCE()
                            list_empty()
                            set_task_comm()
                            ida_simple_remove()
                            worker_detach_from_pool() <void worker_detach_from_pool (struct worker *worker, struct worker_pool *pool) at workqueue.c:1722>:
                                mutex_lock()
                                list_del()
                                list_empty()
                                mutex_unlock()
                                complete()
                            kfree()
                            worker_leave_idle() <void worker_leave_idle (struct worker *worker) at workqueue.c:1654>:
                                WARN_ON_ONCE()
                                worker_clr_flags() <inline void worker_clr_flags (struct worker *worker, unsigned int flags) at workqueue.c:944>:
                                    WARN_ON_ONCE()
                                    atomic_inc()
                                list_del_init()
                            need_more_worker() <bool need_more_worker (struct worker_pool *pool) at workqueue.c:773>:
                                list_empty()
                            may_start_working() <bool may_start_working (struct worker_pool *pool) at workqueue.c:779>
                            manage_workers() <bool manage_workers (struct worker *worker) at workqueue.c:1977>:
                                mutex_trylock()
                                maybe_create_worker()
                                mutex_unlock()
                            worker_clr_flags() <inline void worker_clr_flags (struct worker *worker, unsigned int flags) at workqueue.c:944>:
                                WARN_ON_ONCE()
                                atomic_inc()
                            list_first_entry()
                            likely()
                            work_data_bits()
                            process_one_work() <void process_one_work (struct worker *worker, struct work_struct *work) at workqueue.c:2016>:
                                get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                                    atomic_long_read()
                                lockdep_copy_map()
                                WARN_ON_ONCE()
                                raw_smp_processor_id()
                                find_worker_executing_work() <struct worker *find_worker_executing_work (struct worker_pool *pool, struct work_struct *work) at workqueue.c:996>:
                                    hash_for_each_possible()
                                unlikely()
                                move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                                    list_for_each_entry_safe_from()
                                    list_move_tail()
                                    work_data_bits()
                                debug_work_deactivate() <inline void debug_work_deactivate (struct work_struct *work) at workqueue.c:548>:
                                    debug_object_deactivate()
                                hash_add()
                                get_work_color() <int get_work_color (struct work_struct *work) at workqueue.c:607>:
                                    work_data_bits()
                                list_del_init()
                                worker_set_flags() <inline void worker_set_flags (struct worker *worker, unsigned int flags) at workqueue.c:919>:
                                    WARN_ON_ONCE()
                                    atomic_dec()
                                need_more_worker() <bool need_more_worker (struct worker_pool *pool) at workqueue.c:773>:
                                    list_empty()
                                wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
                                    first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                                        unlikely()
                                        list_empty()
                                        list_first_entry()
                                    likely()
                                    wake_up_process()
                                set_work_pool_and_clear_pending() <void set_work_pool_and_clear_pending (struct work_struct *work, int pool_id) at workqueue.c:659>:
                                    smp_wmb()
                                    set_work_data() <inline void set_work_data (struct work_struct *work, unsigned long data, unsigned long flags) at workqueue.c:638>:
                                        WARN_ON_ONCE()
                                        work_pending()
                                        atomic_long_set()
                                        work_static()
                                spin_unlock_irq()
                                lock_map_acquire_read()
                                lock_map_acquire()
                                trace_workqueue_execute_start()
                                trace_workqueue_execute_end()
                                lock_map_release()
                                in_atomic()
                                lockdep_depth()
                                pr_err()
                                preempt_count()
                                task_pid_nr()
                                debug_show_held_locks()
                                dump_stack()
                                cond_resched_rcu_qs()
                                spin_lock_irq()
                                worker_clr_flags() <inline void worker_clr_flags (struct worker *worker, unsigned int flags) at workqueue.c:944>:
                                    WARN_ON_ONCE()
                                    atomic_inc()
                                hash_del()
                                pwq_dec_nr_in_flight() <void pwq_dec_nr_in_flight (struct pool_workqueue *pwq, int color) at workqueue.c:1140>:
                                    list_empty()
                                    pwq_activate_first_delayed() <void pwq_activate_first_delayed (struct pool_workqueue *pwq) at workqueue.c:1121>:
                                        list_first_entry()
                                        pwq_activate_delayed_work() <void pwq_activate_delayed_work (struct work_struct *work) at workqueue.c:1109>:
                                            get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                                                atomic_long_read()
                                            trace_workqueue_activate_work()
                                            list_empty()
                                            move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                                                list_for_each_entry_safe_from()
                                                list_move_tail()
                                                work_data_bits()
                                            work_data_bits()
                                    likely()
                                    atomic_dec_and_test()
                                    complete()
                                    put_pwq() <void put_pwq (struct pool_workqueue *pwq) at workqueue.c:1072>:
                                        lockdep_assert_held()
                                        likely()
                                        WARN_ON_ONCE()
                                        schedule_work()
                            process_scheduled_works() <void process_scheduled_works (struct worker *worker) at workqueue.c:2150>:
                                list_empty()
                                list_first_entry()
                                process_one_work() <void process_one_work (struct worker *worker, struct work_struct *work) at workqueue.c:2016>:
                                    get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                                        atomic_long_read()
                                    lockdep_copy_map()
                                    WARN_ON_ONCE()
                                    raw_smp_processor_id()
                                    find_worker_executing_work() <struct worker *find_worker_executing_work (struct worker_pool *pool, struct work_struct *work) at workqueue.c:996>:
                                        hash_for_each_possible()
                                    unlikely()
                                    move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                                        list_for_each_entry_safe_from()
                                        list_move_tail()
                                        work_data_bits()
                                    debug_work_deactivate() <inline void debug_work_deactivate (struct work_struct *work) at workqueue.c:548>:
                                        debug_object_deactivate()
                                    hash_add()
                                    get_work_color() <int get_work_color (struct work_struct *work) at workqueue.c:607>:
                                        work_data_bits()
                                    list_del_init()
                                    worker_set_flags() <inline void worker_set_flags (struct worker *worker, unsigned int flags) at workqueue.c:919>:
                                        WARN_ON_ONCE()
                                        atomic_dec()
                                    need_more_worker() <bool need_more_worker (struct worker_pool *pool) at workqueue.c:773>:
                                        list_empty()
                                    wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
                                        first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                                            unlikely()
                                            list_empty()
                                            list_first_entry()
                                        likely()
                                        wake_up_process()
                                    set_work_pool_and_clear_pending() <void set_work_pool_and_clear_pending (struct work_struct *work, int pool_id) at workqueue.c:659>:
                                        smp_wmb()
                                        set_work_data() <inline void set_work_data (struct work_struct *work, unsigned long data, unsigned long flags) at workqueue.c:638>:
                                            WARN_ON_ONCE()
                                            work_pending()
                                            atomic_long_set()
                                            work_static()
                                    spin_unlock_irq()
                                    lock_map_acquire_read()
                                    lock_map_acquire()
                                    trace_workqueue_execute_start()
                                    trace_workqueue_execute_end()
                                    lock_map_release()
                                    in_atomic()
                                    lockdep_depth()
                                    pr_err()
                                    preempt_count()
                                    task_pid_nr()
                                    debug_show_held_locks()
                                    dump_stack()
                                    cond_resched_rcu_qs()
                                    spin_lock_irq()
                                    worker_clr_flags() <inline void worker_clr_flags (struct worker *worker, unsigned int flags) at workqueue.c:944>:
                                        WARN_ON_ONCE()
                                        atomic_inc()
                                    hash_del()
                                    pwq_dec_nr_in_flight() <void pwq_dec_nr_in_flight (struct pool_workqueue *pwq, int color) at workqueue.c:1140>:
                                        list_empty()
                                        pwq_activate_first_delayed() <void pwq_activate_first_delayed (struct pool_workqueue *pwq) at workqueue.c:1121>:
                                            list_first_entry()
                                            pwq_activate_delayed_work() <void pwq_activate_delayed_work (struct work_struct *work) at workqueue.c:1109>:
                                                get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                                                    atomic_long_read()
                                                trace_workqueue_activate_work()
                                                list_empty()
                                                move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                                                    list_for_each_entry_safe_from()
                                                    list_move_tail()
                                                    work_data_bits()
                                                work_data_bits()
                                        likely()
                                        atomic_dec_and_test()
                                        complete()
                                        put_pwq() <void put_pwq (struct pool_workqueue *pwq) at workqueue.c:1072>:
                                            lockdep_assert_held()
                                            likely()
                                            WARN_ON_ONCE()
                                            schedule_work()
                            move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                                list_for_each_entry_safe_from()
                                list_move_tail()
                                work_data_bits()
                            keep_working() <bool keep_working (struct worker_pool *pool) at workqueue.c:785>:
                                list_empty()
                                atomic_read()
                            worker_set_flags() <inline void worker_set_flags (struct worker *worker, unsigned int flags) at workqueue.c:919>:
                                WARN_ON_ONCE()
                                atomic_dec()
                            worker_enter_idle() <void worker_enter_idle (struct worker *worker) at workqueue.c:1614>:
                                WARN_ON_ONCE()
                                list_empty()
                                list_add()
                                too_many_workers() <bool too_many_workers (struct worker_pool *pool) at workqueue.c:798>:
                                    mutex_is_locked()
                                timer_pending()
                                mod_timer()
                                atomic_read()
                            schedule()
                        IS_ERR()
                        set_user_nice()
                        kthread_bind_mask() <void kthread_bind_mask (struct task_struct *p, const struct cpumask *mask) at kthread.c:352>:
                        worker_attach_to_pool() <void worker_attach_to_pool (struct worker *worker, struct worker_pool *pool) at workqueue.c:1689>:
                            mutex_lock()
                            set_cpus_allowed_ptr()
                            list_add_tail()
                            mutex_unlock()
                        spin_lock_irq()
                        worker_enter_idle() <void worker_enter_idle (struct worker *worker) at workqueue.c:1614>:
                            WARN_ON_ONCE()
                            list_empty()
                            list_add()
                            too_many_workers() <bool too_many_workers (struct worker_pool *pool) at workqueue.c:798>:
                                mutex_is_locked()
                            timer_pending()
                            mod_timer()
                            atomic_read()
                        wake_up_process()
                        spin_unlock_irq()
                        ida_simple_remove()
                        kfree()
                    hash_add()
                    put_unbound_pool() <void put_unbound_pool (struct worker_pool *pool) at workqueue.c:3242>:
                        DECLARE_COMPLETION_ONSTACK()
                        lockdep_assert_held()
                        WARN_ON()
                        list_empty()
                        idr_remove()
                        hash_del()
                        mutex_lock()
                        spin_lock_irq()
                        first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                            unlikely()
                            list_empty()
                            list_first_entry()
                        destroy_worker() <void destroy_worker (struct worker *worker) at workqueue.c:1813>:
                            lockdep_assert_held()
                            WARN_ON()
                            list_empty()
                            list_del_init()
                            wake_up_process()
                        spin_unlock_irq()
                        mutex_unlock()
                        wait_for_completion()
                        del_timer_sync()
                        call_rcu_sched()
                        rcu_free_pool() <void rcu_free_pool (struct rcu_head *rcu) at workqueue.c:3222>:
                            container_of()
                            ida_destroy()
                            free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                                free_cpumask_var()
                                kfree()
                            kfree()
                kmem_cache_alloc_node()
                put_unbound_pool() <void put_unbound_pool (struct worker_pool *pool) at workqueue.c:3242>:
                    DECLARE_COMPLETION_ONSTACK()
                    lockdep_assert_held()
                    WARN_ON()
                    list_empty()
                    idr_remove()
                    hash_del()
                    mutex_lock()
                    spin_lock_irq()
                    first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                        unlikely()
                        list_empty()
                        list_first_entry()
                    destroy_worker() <void destroy_worker (struct worker *worker) at workqueue.c:1813>:
                        lockdep_assert_held()
                        WARN_ON()
                        list_empty()
                        list_del_init()
                        wake_up_process()
                    spin_unlock_irq()
                    mutex_unlock()
                    wait_for_completion()
                    del_timer_sync()
                    call_rcu_sched()
                    rcu_free_pool() <void rcu_free_pool (struct rcu_head *rcu) at workqueue.c:3222>:
                        container_of()
                        ida_destroy()
                        free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                            free_cpumask_var()
                            kfree()
                        kfree()
                init_pwq() <void init_pwq (struct pool_workqueue *pwq, struct workqueue_struct *wq, struct worker_pool *pool) at workqueue.c:3454>:
                    BUG_ON()
                    INIT_LIST_HEAD()
                    INIT_WORK()
                    pwq_unbound_release_workfn() <void pwq_unbound_release_workfn (struct work_struct *work) at workqueue.c:3377>:
                        container_of()
                        WARN_ON_ONCE()
                        mutex_lock()
                        list_del_rcu()
                        list_empty()
                        mutex_unlock()
                        put_unbound_pool() <void put_unbound_pool (struct worker_pool *pool) at workqueue.c:3242>:
                            DECLARE_COMPLETION_ONSTACK()
                            lockdep_assert_held()
                            WARN_ON()
                            list_empty()
                            idr_remove()
                            hash_del()
                            mutex_lock()
                            spin_lock_irq()
                            first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                                unlikely()
                                list_empty()
                                list_first_entry()
                            destroy_worker() <void destroy_worker (struct worker *worker) at workqueue.c:1813>:
                                lockdep_assert_held()
                                WARN_ON()
                                list_empty()
                                list_del_init()
                                wake_up_process()
                            spin_unlock_irq()
                            mutex_unlock()
                            wait_for_completion()
                            del_timer_sync()
                            call_rcu_sched()
                            rcu_free_pool() <void rcu_free_pool (struct rcu_head *rcu) at workqueue.c:3222>:
                                container_of()
                                ida_destroy()
                                free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                                    free_cpumask_var()
                                    kfree()
                                kfree()
                        call_rcu_sched()
                        rcu_free_pwq() <void rcu_free_pwq (struct rcu_head *rcu) at workqueue.c:3367>:
                            kmem_cache_free()
                            container_of()
                        rcu_free_wq() <void rcu_free_wq (struct rcu_head *rcu) at workqueue.c:3208>:
                            container_of()
                            free_percpu()
                            free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                                free_cpumask_var()
                                kfree()
                            kfree()
            for_each_node()
            wq_calc_node_cpumask() <bool wq_calc_node_cpumask (const struct workqueue_attrs *attrs, int node, int cpu_going_down, cpumask_t *cpumask) at workqueue.c:3537>:
                cpumask_and()
                cpumask_of_node()
                cpumask_clear_cpu()
                cpumask_empty()
                cpumask_equal()
                cpumask_copy()
            free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                free_cpumask_var()
                kfree()
            apply_wqattrs_cleanup() <void apply_wqattrs_cleanup (struct apply_wqattrs_ctx *ctx) at workqueue.c:3588>:
                for_each_node()
                put_pwq_unlocked() <void put_pwq_unlocked (struct pool_workqueue *pwq) at workqueue.c:1096>:
                    spin_lock_irq()
                    put_pwq() <void put_pwq (struct pool_workqueue *pwq) at workqueue.c:1072>:
                        lockdep_assert_held()
                        likely()
                        WARN_ON_ONCE()
                        schedule_work()
                    spin_unlock_irq()
                free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                    free_cpumask_var()
                    kfree()
                kfree()
        list_add_tail()
        list_for_each_entry_safe()
        apply_wqattrs_commit() <void apply_wqattrs_commit (struct apply_wqattrs_ctx *ctx) at workqueue.c:3676>:
            mutex_lock()
            copy_workqueue_attrs() <void copy_workqueue_attrs (struct workqueue_attrs *to, const struct workqueue_attrs *from) at workqueue.c:3129>:
                cpumask_copy()
            for_each_node()
            numa_pwq_tbl_install() <struct pool_workqueue *numa_pwq_tbl_install (struct workqueue_struct *wq, int node, struct pool_workqueue *pwq) at workqueue.c:3561>:
                lockdep_assert_held()
                link_pwq() <void link_pwq (struct pool_workqueue *pwq) at workqueue.c:3472>:
                    lockdep_assert_held()
                    list_empty()
                    pwq_adjust_max_active() <void pwq_adjust_max_active (struct pool_workqueue *pwq) at workqueue.c:3415>:
                        lockdep_assert_held()
                        spin_lock_irq()
                        list_empty()
                        pwq_activate_first_delayed() <void pwq_activate_first_delayed (struct pool_workqueue *pwq) at workqueue.c:1121>:
                            list_first_entry()
                            pwq_activate_delayed_work() <void pwq_activate_delayed_work (struct work_struct *work) at workqueue.c:1109>:
                                get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                                    atomic_long_read()
                                trace_workqueue_activate_work()
                                list_empty()
                                move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                                    list_for_each_entry_safe_from()
                                    list_move_tail()
                                    work_data_bits()
                                work_data_bits()
                        wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
                            first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                                unlikely()
                                list_empty()
                                list_first_entry()
                            likely()
                            wake_up_process()
                        spin_unlock_irq()
                    list_add_rcu()
                rcu_access_pointer()
                rcu_assign_pointer()
            link_pwq() <void link_pwq (struct pool_workqueue *pwq) at workqueue.c:3472>:
                lockdep_assert_held()
                list_empty()
                pwq_adjust_max_active() <void pwq_adjust_max_active (struct pool_workqueue *pwq) at workqueue.c:3415>:
                    lockdep_assert_held()
                    spin_lock_irq()
                    list_empty()
                    pwq_activate_first_delayed() <void pwq_activate_first_delayed (struct pool_workqueue *pwq) at workqueue.c:1121>:
                        list_first_entry()
                        pwq_activate_delayed_work() <void pwq_activate_delayed_work (struct work_struct *work) at workqueue.c:1109>:
                            get_work_pwq() <struct pool_workqueue *get_work_pwq (struct work_struct *work) at workqueue.c:678>:
                                atomic_long_read()
                            trace_workqueue_activate_work()
                            list_empty()
                            move_linked_works() <void move_linked_works (struct work_struct *work, struct list_head *head, struct work_struct **nextp) at workqueue.c:1027>:
                                list_for_each_entry_safe_from()
                                list_move_tail()
                                work_data_bits()
                            work_data_bits()
                    wake_up_worker() <void wake_up_worker (struct worker_pool *pool) at workqueue.c:829>:
                        first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
                            unlikely()
                            list_empty()
                            list_first_entry()
                        likely()
                        wake_up_process()
                    spin_unlock_irq()
                list_add_rcu()
            swap()
            mutex_unlock()
        apply_wqattrs_cleanup() <void apply_wqattrs_cleanup (struct apply_wqattrs_ctx *ctx) at workqueue.c:3588>:
            for_each_node()
            put_pwq_unlocked() <void put_pwq_unlocked (struct pool_workqueue *pwq) at workqueue.c:1096>:
                spin_lock_irq()
                put_pwq() <void put_pwq (struct pool_workqueue *pwq) at workqueue.c:1072>:
                    lockdep_assert_held()
                    likely()
                    WARN_ON_ONCE()
                    schedule_work()
                spin_unlock_irq()
            free_workqueue_attrs() <void free_workqueue_attrs (struct workqueue_attrs *attrs) at workqueue.c:3095>:
                free_cpumask_var()
                kfree()
            kfree()
    apply_wqattrs_unlock() <void apply_wqattrs_unlock (void) at workqueue.c:3704>:
        mutex_unlock()
        put_online_cpus() <void put_online_cpus (void) at cpu.c:105>:
            atomic_dec_return()
            WARN_ON()
            atomic_inc()
            waitqueue_active()
            wake_up()
            cpuhp_lock_release()
    free_cpumask_var()
workqueue_sysfs_register() <int workqueue_sysfs_register (struct workqueue_struct *wq) at workqueue.c:5206>:
    WARN_ON()
    kzalloc()
    wq_device_release() <void wq_device_release (struct device *dev) at workqueue.c:5184>:
        container_of()
        kfree()
    dev_set_uevent_suppress()
    device_register()
    kfree()
    device_create_file()
    device_unregister()
    kobject_uevent()
wq_watchdog_touch() <void wq_watchdog_touch (int cpu) at workqueue.c:5370>:
    per_cpu()
wq_worker_sleeping() <struct task_struct *wq_worker_sleeping (struct task_struct *task, int cpu) at workqueue.c:873>:
    kthread_data() <void *kthread_data (struct task_struct *task) at kthread.c:135>:
        to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
    WARN_ON_ONCE()
    raw_smp_processor_id()
    atomic_dec_and_test()
    list_empty()
    first_idle_worker() <struct worker *first_idle_worker (struct worker_pool *pool) at workqueue.c:812>:
        unlikely()
        list_empty()
        list_first_entry()
wq_worker_waking_up() <void wq_worker_waking_up (struct task_struct *task, int cpu) at workqueue.c:848>:
    kthread_data() <void *kthread_data (struct task_struct *task) at kthread.c:135>:
        to_kthread() <inline struct kthread *to_kthread (struct task_struct *k) at kthread.c:59>:
    WARN_ON_ONCE()
    atomic_inc()
xacct_add_tsk() <void xacct_add_tsk (struct taskstats *stats, struct task_struct *p) at tsacct.c:92>:
    get_task_mm() <struct mm_struct *get_task_mm (struct task_struct *task) at fork.c:774>:
        task_lock()
        atomic_inc()
        task_unlock()
    get_mm_hiwater_rss()
    get_mm_hiwater_vm()
    mmput() <void mmput (struct mm_struct *mm) at fork.c:694>:
        might_sleep()
        atomic_dec_and_test()
        uprobe_clear_state()
        exit_aio()
        ksm_exit()
        khugepaged_exit()
        exit_mmap()
        set_mm_exe_file() <void set_mm_exe_file (struct mm_struct *mm, struct file *new_exe_file) at fork.c:728>:
            rcu_dereference_raw()
            get_file()
            rcu_assign_pointer()
            fput()
        list_empty()
        spin_lock()
        list_del()
        spin_unlock()
        module_put() <void module_put (struct module *module) at module.c:1098>:
            preempt_disable()
            atomic_dec_if_positive()
            WARN_ON()
            trace_module_put()
            preempt_enable()
        mmdrop()
zap_other_threads() <int zap_other_threads (struct task_struct *p) at signal.c:1188>:
    while_each_thread()
    task_clear_jobctl_pending() <void task_clear_jobctl_pending (struct task_struct *task, unsigned long mask) at signal.c:300>:
        BUG_ON()
        task_clear_jobctl_trapping() <void task_clear_jobctl_trapping (struct task_struct *task) at signal.c:276>:
            unlikely()
            smp_mb()
            wake_up_bit()
    signal_wake_up()
zap_pid_ns_processes() <void zap_pid_ns_processes (struct pid_namespace *pid_ns) at pid_namespace.c:184>:
    thread_group_leader()
    disable_pid_allocation() <void disable_pid_allocation (struct pid_namespace *ns) at pid.c:359>:
        spin_lock_irq()
        spin_unlock_irq()
    spin_lock_irq()
    spin_unlock_irq()
    read_lock()
    next_pidmap() <int next_pidmap (struct pid_namespace *pid_ns, unsigned int last) at pid.c:216>:
        unlikely()
        find_next_bit()
        mk_pid() <inline int mk_pid (struct pid_namespace *pid_ns, struct pidmap *map, int off) at pid.c:55>:
    rcu_read_lock()
    pid_task() <struct task_struct *pid_task (struct pid *pid, enum pid_type type) at pid.c:435>:
        rcu_dereference_check()
        hlist_first_rcu()
        lockdep_tasklist_lock_is_held() <int lockdep_tasklist_lock_is_held (void) at fork.c:114>:
            lockdep_is_held()
        hlist_entry()
    find_vpid() <struct pid *find_vpid (int nr) at pid.c:380>:
        find_pid_ns() <struct pid *find_pid_ns (int nr, struct pid_namespace *ns) at pid.c:366>:
            hlist_for_each_entry_rcu()
            pid_hashfn()
            container_of()
        task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
            ns_of_pid()
            task_pid()
    send_sig_info() <int send_sig_info (int sig, struct siginfo *info, struct task_struct *p) at signal.c:1413>:
        valid_signal()
        do_send_sig_info() <int do_send_sig_info (int sig, struct siginfo *info, struct task_struct *p, bool group) at signal.c:1134>:
            lock_task_sighand()
            send_signal() <int send_signal (int sig, struct siginfo *info, struct task_struct *t, int group) at signal.c:1076>:
                si_fromuser() <inline bool si_fromuser (const struct siginfo *info) at signal.c:683>:
                    is_si_special() <inline int is_si_special (const struct siginfo *info) at signal.c:678>:
                    SI_FROMUSER()
                task_pid_nr_ns()
                task_active_pid_ns() <struct pid_namespace *task_active_pid_ns (struct task_struct *tsk) at pid.c:545>:
                    ns_of_pid()
                    task_pid()
            unlock_task_sighand()
    rcu_read_unlock()
    read_unlock()
    clear_thread_flag()
    sys_wait4()
    set_current_state()
    schedule()
    acct_exit_ns() <void acct_exit_ns (struct pid_namespace *ns) at acct.c:294>:
        rcu_read_lock()
        pin_kill()
